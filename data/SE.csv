Id,PostTypeId,AcceptedAnswerId,ParentId,CreationDate,DeletionDate,Score,ViewCount,Body,OwnerUserId,OwnerDisplayName,LastEditorUserId,LastEditorDisplayName,LastEditDate,LastActivityDate,Title,Tags,AnswerCount,CommentCount,FavoriteCount,ClosedDate,CommunityOwnedDate,ContentLicense
"220080","1","220083","","2013-12-02 18:41:04","","4","4291","<p>Assume there is a web service which is visible publicly but it must be just responsive to a specific client application. Is there any mechanism to check client side application identity to prevent disallowed application to access the service?</p>

<p>For instance, I have a web service which is called by my iOS application. I want to prevent others from calling my web service.</p>

<p>Regarding the fact that others can decompile my client application and create another one which is working the same as mine, I think the only way to avoid unwanted access to the service is to check application identity on server to ensure the request comes from my own application.</p>

<p>Is there any robust and secure way to do that?</p>
","86940","","86940","","2013-12-02 18:47:51","2013-12-02 20:16:03","Is it possible to check a client side application identity from server side?","<security><app><identity>","3","2","","2013-12-03 22:55:40","","CC BY-SA 3.0"
"220095","1","220101","","2013-12-02 21:35:15","","1","440","<p>I'm taking an Introduction to Agile Software Development course, The instructor was discussing an example about online store and asked us to write the <strong>User Stories</strong> and the <strong>Conditions of satisfactions</strong> and one story was <em>As a user I can commit for marketing card that was selected previously in order to buy my goods</em>, the conditions of satisfactions in this case contained some conditions in addition to <strong>The system must secure the Credit Card data across the internet connection using https</strong></p>

<ul>
<li>I disagreed with that and said this is a thing that must be done, not just in case the user asked me to protect it, and it is a fatal threat like or more important than SQl Injections and this is a non-functional requirement at the technical level and if the user mention it or didn't this must be taken in our development, some project managers in the course showed their disagreement and said this is a time wast on features that the user didn't ask for!, the instructor didn't give my comment any attention and didn't reply to me.</li>
</ul>

<p>I really think I'm true and not convinced, but all of those trained people disagreed with me[I'm new in the software engineering field but used always to work as a developer], so I'm asking you about this.</p>
","16625","","","","","2013-12-03 03:59:36","Is securing the credit card data is considered a requirement from the customer","<agile><security><requirements><user-story>","4","7","","","","CC BY-SA 3.0"
"25163","1","25172","","2010-12-10 12:19:07","","3","384","<p>I've been developing intranet web sites and public web sites with no big issues concerning security. There were nothing to steal and nothing to gain. Nothing to attract people to try to reach the website behind the scene. I don't talk about login &amp; password but more about the security against user attacks.</p>

<p>So, what's the best way to learn to secure the access to a site, to learn about common mistakes or weakness to think about ? Do I have to find a framework related to the language I use and rely on it or is there a source (book, website, ...) where I can find information about general design and tricks ?</p>
","133","","","","","2010-12-10 13:02:17","How did you learn about security in your web development?","<web-development><security>","4","4","","","","CC BY-SA 2.5"
"338655","1","338661","","2016-12-22 09:59:11","","0","343","<p>I have an application, that can run on both Windows and macOS. I want to apply a digital signature to its binaries. I have already got a Thawte certificate (with private key) for Windows. Can I use the same certificate to sign my macOS <code>.pkg</code> installer?</p>
","104459","","","","","2016-12-22 10:56:28","Are all code signing certificates cross-platform?","<security><distribution>","2","1","","","","CC BY-SA 3.0"
"338795","1","","","2016-12-23 17:26:29","","1","1194","<p>I'm building a chrome extension that I would like to offer for free for a given trial period and then the users buys a registration key on our website for a forever version .</p>

<p>I've built software previously, but I've never made something paid. </p>

<p>Using my basic knowledge of cryptography and membership websites, I thought of the following :</p>

<ul>
<li><p>When the user installs the extension for the first time it create a variable for the registration key with an empty value, which means that the user hasn't bought the product yet and they are in a trial period. </p></li>
<li><p>Once the user opens the extension it will check if the trial period has ended by doing date computations .</p></li>
<li><p>If the trial has ended the user will have a form for his email and registration code. </p></li>
<li><p>The user buys the registration code on our website. We process payments via stripe, and as a callback the server will create a hashed key based on their email . It will also hash a string based on the browser ID they're using to make sure that the paid version works only on one platform. After that it will save all those hashed keys in a DB by email. </p></li>
<li><p>The registration code is sent to the user via email</p></li>
<li><p>The user can now reopen the extension and enter their email + registration code . The extension send an Ajax request to the server with the entered mail and key.  </p></li>
<li><p>the server check the sent data with the data stored in the DB . </p></li>
<li><p>the extension acts on the status of the response .</p></li>
</ul>

<p>I don't know if this is the right approach to solve this. Is there a better and more secure approach? How quick are those method to build? Are there ready-made APIs that take care of situations like this?</p>

<p>The software is a chrome extension built in JS and offered for free on the chrome store, so an average user can access its code. An average hacker would be able to reverse engineer it and crack it, making torrents of a cracked version and so on. </p>

<p>I intend to build the backend via Python and flask. </p>
","257676","","110531","","2016-12-23 18:14:05","2016-12-23 18:14:05","How to create a licensing system for a software","<design><security><software-distribution>","0","7","","","","CC BY-SA 3.0"
"220950","1","222852","","2013-12-10 21:59:42","","42","64097","<p>Say I want some parts of my software to be encrypted. For example, the credentials for a database, etc. I need to store those values somewhere, but doing so in cleartext would make it easy for an attacker to gain unauthorised access.</p>

<p>However, if I encrypt some cleartext, then where do I store the key? Anything that software has access to, a determined attacker would have access to, no matter what level of obfuscation:</p>

<ul>
<li>Say the key is protected by the filesystem's security model; but what about (malicious) superusers, or platforms that don't provide such fidelity?</li>
<li>Or the key is hardcoded into software binaries, but it could always be decompiled and what about open source software or interpreted code?</li>
<li>If the key is generated, such an algorithm would need to be deterministic (presumably) and then the same problem applies to the seed.</li>
<li>etc.</li>
</ul>

<p>Cryptography is only as strong as the weakest link in its chain and this seems like a pretty loose one! Presuming it's the right tool for the job (humour me), then how can one secure such information robustly?</p>

<hr>

<p>Regarding the right tool for the job: Probably, in -- for example -- the case of service access (DBs, authentication servers, etc.), you would restrict access at this tier with a service account, maybe with some service-level auditing, etc. and so having the credentials in cleartext isn't such a worry.</p>

<p>To me, however, that still seems inadequate: I don't want anyone poking around where they shouldn't be!</p>
","34493","","","","","2019-09-13 08:28:09","Where to store the private key?","<security><cryptography>","5","7","","","","CC BY-SA 3.0"
"221075","1","","","2013-12-11 21:24:08","","26","2657","<p>I am a new software developer and I wish to sell my software. I recently realized that from C++ code we can not stop the user seeing parts of the code that are related to scripts or system commands.</p>

<p>Would you make some comments on how software written in C++/JAVA (distributed via CD-ROMs or available via download) is protected from reverse engineering, scanners for when the code is in memory and direct copy of parts (as system commands). </p>

<p>What a small software company which just starts producing software should do to protect its product from the technological point of view (it should not be able to pay legal fees â€¦)?</p>
","111434","","57792","","2013-12-11 21:26:11","2013-12-12 18:50:03","How is major software protected?","<java><c++><security>","6","5","","2013-12-13 07:20:10","","CC BY-SA 3.0"
"221201","1","","","2013-12-12 19:16:37","","2","396","<p>I'm working on a payment processing website that will function like PayPal does on many e-commerce websites. The idea is for the customer to fill their shopping cart and click checkout, then be directed to the payment page on a secure site. After the payment page processes the payment, it directs the customer back to the original website. So far, I think I'm ok up to the point of receiving the payment, but what mechanism do sites like PayPal use to allow the original website to verify whether the payment was successfully received?</p>
<h3>My Current Process:</h3>
<ul>
<li>Customer click's checkout</li>
<li>Store cart items as a pending order in database</li>
<li>Post merchant ID, payment amount, the return URL, etc. to secure payment page. This uses SSL and I have also posted a hash of the other posted values to ensure they are not tampered with in transit.</li>
<li>Customer enters card info and clicks &quot;Pay&quot;</li>
<li>Secure site redirects to the specified return URL with a query string of relevant transaction information including a flag indicating success or failure.</li>
</ul>
<p>For the last step, the original site needs to be sure the request came from the payment site so that a user can't just navigate to that URL, providing the query string themselves, to complete an order. I currently have the same hashing mechanism in place to make sure the query string variables are not tampered with. It is very crude. I append the variables into one long string and then append a shared secret key to the end, hash that whole string, send it. The receiving end does the same thing and compares the hashes.</p>
","57419","","-1","","2020-06-16 10:01:49","2015-07-20 13:17:26","How do I verify if 3rd party payment succeeded?","<security><asp.net><transaction><verification><payment>","1","0","","","","CC BY-SA 3.0"
"221495","1","","","2013-12-16 12:44:29","","6","6189","<p>I have built a restful json api for an online store using Laravel.</p>

<p>I now wish to create an AngularJS app to run the front-end web application. Product prices for my store need to update every second, so Angular needs to get the product json from the server once per second to update the html.</p>

<p>I wish to somehow do something to protect this publicly accessible json data from being stolen by scrapers / bots repetitively hitting my api to steal my product and pricing data.</p>

<p>My thoughts:</p>

<p>Each json api response contains a random use-once token (i am aware about doing stuff to stop collisions).</p>

<p>This random token is injected via AngularJS into a hidden field within the html page. Angularjs reads the hidden token prior to re-requesting the api and uses this in the header of the next get request.</p>

<p>A json response is only provided with the correct token in the header. Once the token is used, it expires, and any attempt to re-use the expired token, results in that IP address being locked out for a period of time or flagged to administrator to investigate.</p>

<p>Is there a better way of doing the above? Are there any kind of actual available solutions to my problem? Considering that I am paying for the product pricing feed in the first place, I really don't want some schmuck getting it from me for free just because I exposed an api!</p>

<p>Whilst I understand that there is probably no way of being 99% certain that somebody could find a way of scraping my json, there must be something relatively simple I can do to protect my json feed from dumb bots / scrapers simply using curl to steal data.</p>
","111862","","","","","2014-01-18 22:12:14","Is it possible to protect json api scraping using random tokens?","<security><json>","1","6","","","","CC BY-SA 3.0"
"339650","1","339654","","2017-01-07 14:21:04","","0","1052","<p>After 50 years of software engineering, why are computer systems still insecure? I don't get it.</p>

<p>Two questions: (i) What's so hard about just denying or restricting networked access to bad actors who lack passwords? It's not like these bad actors arrive with crowbars and dynamite; they only have bits and bytes, right? (ii) Once a bad actor has achieved networked access, why haven't operating-system kernels been re-engineered to make privilege escalation unfeasible?</p>

<p>I am not looking for a book-length answer but merely for a missing concept. If you can see the flaw in my thinking and can shed a little light on the flaw, that will be answer enough.</p>

<p>Is there some specific reason top scholars have not yet been able to solve the problem? Is there a sound reason we still have, say, <a href=""http://wiki.c2.com/?TheKenThompsonHack"" rel=""nofollow noreferrer"">bootstrapped compilers</a> and unauditable microprocessor designs, despite the long-known security risks?</p>

<p>Is there some central observation, answerable at StackExchange length, that ties all this together? Why <em>are</em> computer systems still insecure?</p>

<p><strong>Update:</strong> Commenters have added some interesting links, especially <a href=""https://softwareengineering.stackexchange.com/questions/184874/is-ken-thompsons-compiler-hack-still-a-threat"">""Is Ken Thompson's compiler hack still a threat?""</a></p>
","53118","","-1","","2017-04-13 12:45:55","2017-01-08 00:07:48","Why are computer systems still insecure?","<security><operating-systems><networks>","4","11","","2017-01-08 05:11:21","","CC BY-SA 3.0"
"28238","1","28240","","2010-12-20 11:11:24","","19","16355","<p>I've often come across bugs that have been caused by using the <code>ELSE</code> construct.  A prime example is something along the lines of:</p>

<pre><code>If (passwordCheck() == false){
    displayMessage();
}else{
    letThemIn();
}
</code></pre>

<p>To me this screams security problem.  I know that passwordCheck is likely to be a boolean, but I wouldn't place my applications security on it. What would happen if its a string, int etc?</p>

<p>I usually try to avoid using <code>ELSE</code>, and instead opt for two completely separate IF statements to test for what I expect.  Anything else then either gets ignored OR is specifically handled.</p>

<p>Surely this is a better way to prevent bugs / security issues entering your app.</p>

<p>How do you guys do it?</p>
","4630","","136","","2010-12-20 13:03:51","2012-08-23 16:30:09","Is using ELSE bad programming?","<self-improvement><programming-practices><security>","13","20","","2012-08-23 20:59:09","","CC BY-SA 2.5"
"340140","1","","","2017-01-13 17:06:11","","2","278","<p>Let's say I am using a RSA keypair to encrypt and decrypt a large amount of traffic over a public network. Assume all traffic is padded and the key is 2048 bits, how often would you recommend renewing the private key?</p>

<p>Is there a mathematical solution to how much encrypted data is needed in bytes that would allow a hacker to calculate the private key?</p>

<p>A real life example of this might be a messaging service which encrypts all traffic with one key.</p>
","258552","","","","","2017-01-24 10:03:41","RSA Private key renewal - How often?","<security><encryption>","0","9","","","","CC BY-SA 3.0"
"340260","1","","","2017-01-16 07:43:44","","1","911","<p>I am currently implementing WYSIWYG editor that will be available on the web, what are the main security issues I should tackle? The editor currently works that when user is done typing, the text gets saved to folder with editor text on same domain, and the iframe gets refreshed with the contents of it. </p>

<p>I know that when it comes to JS, someone could scale up the DOM from the parent windows, but how could that affect security of my website?</p>

<p>The editor instances are not share-able between users and never will be. Only admins can view all instances.</p>
","259626","","235135","","2017-01-16 08:04:29","2017-02-15 08:07:58","What are security risks of WYSIWYG HTML/CSS/JS editors running as web service?","<javascript><security><html><css>","1","0","","","","CC BY-SA 3.0"
"222568","1","","","2013-12-29 00:46:51","","0","170","<p>This is an open-ended question which I am analysing while doing some fun projects in leisure. Websites like Google, Facebook do store user activities and perhaps sell them or use them for advertisements. But I believe anonymity is maintained. For instance, I need to expose that there are 5 people between age 45-50 who are drug-addicts in a given area... but I don't want to offer the names of the people. In fact I want to be sure that noone can access their names, otherwise resulting in privacy violation (Sorry for the weird example !)</p>

<p>Is there some tool/standard which everyone(especially smaller organizations) follow to limit legal complications due to identity theft like this ? </p>

<p>I am tagging MongoDB and Java, as I am using these technologies and answers specific to them would be easier to implement.</p>
","113011","","","","","2014-01-03 18:47:06","Do we have any special design considerations for maintaining anonymity in an application?","<java><architecture><security><database-design><mongodb>","1","2","","","","CC BY-SA 3.0"
"340473","1","","","2017-01-18 22:18:30","","0","479","<p>I'm developing a Cordova app and I've got the UI ready but I need data to my app from a database. For example I want my cordova app to include user authentication when the user opens the app which means, I have to access my database in some way to check the user input. I would also like to get data from the database and show in the app such as the members information, ranking and so on. How do I do this in a easy and proper way? Am I right when I say that there is not a good thing to access a database directly from the javascript in the cordova app, for security reasons?</p>

<p>Is the solution through a architecture that looks like this?</p>

<p>Cordova app(In Google play) --> Application Server --> Database</p>
","259924","","","user22815","2017-01-19 18:12:06","2017-01-19 18:12:06","Send data between database and Apache Cordova app in a secure way","<architecture><database><data><apache><server-security>","1","0","","","","CC BY-SA 3.0"
"340665","1","","","2017-01-21 16:57:40","","2","115","<p>When designing an application I usually stumble upon a problem I've never quite managed to handle properly.</p>

<p>Suppose you have Products and Orders. Usually in my data-access layer I have repositories that can return back lists of these object already filtered based, for example, the logged user that made the request. When I say ""already filtered"" I mean that the security-layer of the application (which is a cross-cutting concern) constructed the necessary criteria so that the data-access layer can actually query the db asking for object the logged user can actually see - no other filters are applied in memory. </p>

<p>Suppose that the actual Product class is something like this:</p>

<pre><code>public class Product
{
    public virtual IList&lt;Order&gt; Orders {get; set;}
    // other stuff 
}
</code></pre>

<p>where the Orders collection contains <em>all</em> orders (from every user) placed on the product. </p>

<p>Now, this presents a problem because by accessing this property I can potentially show a user orders placed by other users.</p>

<p>I usually use NHibernate as an ORM an I cannot find a proper solution to this problem. I'm aware of ""filters"" but they are just string and not really useful when you need to make something more complex than the contrived example given here for brevity. Unless there is a way to use the criteria api with filters but, as far as I know, it's not possible</p>
","","user260171","","","","2017-03-23 15:28:10","How to make associations security proof","<orm><layers><nhibernate><code-security>","1","4","","","","CC BY-SA 3.0"
"340715","1","","","2017-01-23 07:43:06","","3","517","<p>I've come across a few cases lately where a package on NuGet has a name that starts with ""Microsoft"" but is actually uploaded by someone else. Take <a href=""https://www.nuget.org/packages/Microsoft.TestApi/"" rel=""nofollow noreferrer"">Microsoft.TestApi</a> for example. Ostensibly this is a NuGet wrapper around the <a href=""https://testapi.codeplex.com/"" rel=""nofollow noreferrer"">TestAPI project on CodePlex</a>. The CodePlex project is from Microsoft as there are <a href=""https://blogs.msdn.microsoft.com/ivo_manolov/2009/10/14/testapi-slide-deck-from-the-patterns-practices-summit/"" rel=""nofollow noreferrer"">blog posts</a> hosted on a Microsoft domain talking in great detail about the project and containing direct links to the CodePlex site. So I'm comfortable that downloading the package from there is safe.</p>

<p>However, the team who made the CodePlex project have not created a NuGet wrapper. Someone else has gone ahead and created one, which has gained some traction - 15k downloads at the time of writing. The owner is a personal account, in contrast to the clearly official <a href=""https://www.nuget.org/profiles/microsoft"" rel=""nofollow noreferrer"">Microsoft</a> one used for other Microsoft packages. So far the only evidence I have for the provenance of the TestAPI package is a <a href=""https://testapi.codeplex.com/discussions/264291"" rel=""nofollow noreferrer"">conversation on CodePlex</a> where the owner of the original package looks like they are an acquaintance of the person who uploaded the NuGet one.</p>

<p>I feel like the above security credential is weak, and I am therefore minded to obtain the source directly from CodePlex. I would rather get it from NuGet though as then it is consistent with all my other packages. Have I missed something in NuGet's validation process? Maybe there is a signing process where it does not matter who uploads it because the package is securely signed and versioned previously?</p>
","75084","","4","","2017-01-26 11:17:21","2017-01-26 11:17:24","How can I be sure that an unofficially uploaded NuGet package is genuine?","<security><packages><nuget>","1","4","","","","CC BY-SA 3.0"
"340825","1","340833","","2017-01-24 18:15:37","","0","2930","<p>I'm building a web application wherein users CRUD their own private data.</p>

<ol>
<li>Can I safely expose API endpoints?</li>
</ol>

<p>Despite years in-industry and endless web-research, I'm not clear on the best architecture and how to most efficiently ensure security of the user data.  The most basic requirements include: user authorization, view/add/update your own data.  I already wrote a version 1 of the app and would like develop a version 2 from scratch.  Exposing API endpoints could help isolate my front-end and back-end development.  Is security still possible if I want a pure js front-end app?</p>
","164483","","164483","","2017-02-01 16:00:46","2017-02-01 16:00:46","How can I safely expose web API endpoints for user-private data?","<web-development><web-applications><api><security><web-api>","1","0","0","","","CC BY-SA 3.0"
"29753","1","29755","","2010-12-24 09:38:23","","7","5047","<p>I am looking for ways to verify the user in order to reset their passwords. 2 commonly used ones:</p>

<ul>
<li>Email verification</li>
<li>Secret question</li>
</ul>

<p>I wonder which will you recommend? I am trying to avoid having to use email at all (users won't need to provide emails, most hosts limit emails sent). But Secret Question alone seems a little unsecure. What do you think?</p>
","526","","31260","","2014-07-29 07:18:10","2023-07-08 22:43:50","What type of Password Reset/Forgot Password (verification) mechanism would you recommend","<security><passwords>","5","2","","","","CC BY-SA 3.0"
"223669","1","223687","","2014-01-09 21:44:33","","0","469","<p>We have data stored in a data warehouse as follows:</p>

<p>Price</p>

<p>Date</p>

<p>Product Name (varchar(25))</p>

<p>We currently only have seven products. Once every business day, seven new data points are added representing the day's price for each product.</p>

<p>On the website, a user sees this information on a page load. Analytics shows that the amount of page loads is about 100 per day.</p>

<p>The website server is an external server to our data center. The data warehouse server is internal to our data center and has other critical data (in different tables) not related and should not be accessible to the website.</p>

<p>The following approaches have been considered:</p>

<p>1) The data warehouse could daily push (SFTP) a CSV file containing the daily data to the web server. The web server would have a process running on a crontab every 15 minutes. It would check if the file had changed. If so, it would update its database with the data. Then, on page loads, the web server would query its database to get the data to display on the web page.</p>

<p>Usually, the push would only be once a day, but more than one push could be possible to communicate (infrequent) price corrections. Even in the price correction scenario, all data would be delivered in the file. The polling process would pick up the change and overwrite the data in the database.</p>

<p>2) The web server could request data from the data warehouse using JDBC or similar SQL connection technology. </p>

<p>However, a security concerns have been voiced. The concern is that by allowing the web server access to our data warehouse, SQL injection attack or some other external attack through the website could compromise the data warehouse. Measures could be put in place to reduce the risk, but the easiest and safest approach has been suggested to simply not allow any public facing system to directly access the data warehouse. In other words, the data warehouse can establish a communication with other servers (say to SFTP the file), but no server can initiate a connection with the data warehouse. Do these concerns seem reasonable and hard to mitigate? </p>

<p>3) A web service could be built, and the web server could call the web service that is hosted in our internal data center.</p>

<p>4) A process hosted in our internal data center could call the web server when it knows the data warehouse has data available. If so, how should this be done? HTTPS with some way to prevent other unauthorized clients from making the same call?</p>

<p>Which of the above approaches is best or is there a better approach than listed above? What are the pros and cons to an approach?</p>
","90340","","","","","2014-01-09 23:31:48","How to provide data to a web server using a data warehouse?","<security><web-services><websites><data-warehouse><ftp>","1","0","","","","CC BY-SA 3.0"
"30076","1","30087","","2010-12-26 07:13:10","","12","7843","<p>Is registration login using email a better idea than username to identify the user?</p>
","526","","25936","","2013-06-24 06:00:34","2021-01-20 16:24:00","Login using email or username?","<security><user-interface><front-end>","10","4","","","","CC BY-SA 2.5"
"30140","1","30327","","2010-12-26 18:59:29","","1","5903","<p>I want to obfuscate all the webpages of my website. I Googled through some free tools like HTML and Javascript obfuscation but don't know how effective they are.</p>

<p>First of all, does it makes sense to obfuscate a webpage that could comprise of variety of codes like Javascript, PHP etc.</p>

<p>Secondly, how effective is this method?</p>
","6001","","55400","","2015-04-16 11:43:03","2017-06-08 20:05:14","Entire webpage obfuscation","<security><obfuscation>","5","14","","","","CC BY-SA 3.0"
"113911","1","","","2011-10-12 15:21:24","","10","6181","<p>This is the password policy I just got from UPS (just for package status checking):</p>

<blockquote>
  <p>Your password must be between 8 and 26 characters long. It must
  contain at least three of the following character types: lowercase
  letters, capital letters, numerals, special characters, or spaces. The
  password may not contain your User ID, your name, or your e-mail
  address. (SSO_1007)</p>
</blockquote>

<p>I actually have to wrack my brain somewhat to generate this password, but not only that, most importantly, I am sure that after 3 days I will forget what this password is.  Users won't be so happy.  Password reset can be frequent.  I think users will try to avoid using the site unless they have to.</p>

<p>What is a reasonable and secure password policy when setting up a website?   I think some companies may fear some hackers trying passwords a million times or more, so they add all those requirements for ""special characters, lower case, upper case"", but won't it be reasonable to turn off the account or just disable the password and require a password reset if a user has tried 30 times or 100 times?  Or, add a 5 second delay each time after the user tried 30 times?  If so, then those special characters won't be that much needed.</p>
","5487","","","user8","2011-10-12 18:44:07","2015-04-28 18:47:28","What is a reasonable and secure password requirement for user registration?","<security><passwords>","9","6","","","","CC BY-SA 3.0"
"223855","1","223867","","2014-01-11 13:41:41","","0","202","<p>I have a File database table with the following columns:</p>

<p><code>Id (PK), Filename</code></p>

<p>And a Document database table with the following columns:</p>

<p><code>Id (PK), Name, Description, FileId (FK)</code></p>

<p>When a user wants to ""save"" a Document, my client-side JavaScript does it in two quick AJAX calls (in an attempt to be RESTful and save each resource individually):</p>

<ol>
<li><p>Uploads the file they have selected. This will create a File record in the database, and the client will receive its Id in response.</p></li>
<li><p>Saves the Document with the given data (Name, FileId, etc.). This will create/update a Document record in the database.</p></li>
</ol>

<p>I have a service set up that allows a user to download a file, provided they specify its Id.  However, there is some security logic in the service that checks whether a user has <em>permission</em> to download the file, by checking whether there is at least one database ""entity"" associated with it that the user has access to. For example, a Document would be one such entity. So if a user can access a particular Document (determined by some business rules - but let's just say multiple users can access the same Document), they can download its file.</p>

<p>This all seems fine on the surface, <strong>but there is a problem</strong>. The 2-step save process for a Document is all client-side Javascript, so a hacker could easily modify step 2 so that any arbitrary FileId is sent to the server. This would then associate that file with the Document, meaning afterwards the user will have permission to download it!</p>

<p>What are some ways I can solve this problem?</p>
","76667","","","","","2014-01-11 16:02:24","How can I solve this potential security exploit (concerning the saving of REST resources)?","<javascript><security><rest><ajax><server-side>","2","4","","","","CC BY-SA 3.0"
"114376","1","118206","","2011-10-14 14:19:26","","5","195","<p>I am working on a product that requires devices to exists anywhere in the world hooked up to the internet though cell modems or on WLAN lines which communicates to a server(s) that exists elsewhere in the world. </p>

<p><em>When deigning the networking portion of the program i cant figure what the best option is for securing the communication between the server and end device.</em></p>

<p>From my searches iv'e come up with two options. </p>

<p><strong>Option 1:</strong> <em>Using a host to host vpn connection between the two devices.</em></p>

<p><strong>Pros:</strong> VPN software seems to be well tested and does not require extra programming for the network protocol. The IT department is more comfortable with it because of using software that is already tested and they comfortable with vpn.</p>

<p><strong>Cons:</strong> Since my end devices are linux on OMAP platforms cross compiling the vpn software if not already done could be tricky. Dealing with firewalls and routers behind the end devices network. Setup of the connection can be tricky.</p>

<p><strong>Option 2:</strong> <em>Implementing the TLSv1 protocol in my program to deal with the encryption.</em> </p>

<p><strong>Pros:</strong> Does not require extra software to be running on the device. Only relies on the encryption libraries as a dependency. Don't have to worry about dealing with nats and firewalls because the protocol will only require one tcp port to be open.</p>

<p><strong>Cons:</strong> Extra coding to the network software. IT is skeptical because our program is responsible for securing the protocol. </p>

<p><strong>FYI:</strong> For implementing the TLSv1 i would use <a href=""http://www.gnu.org/software/gnutls/"" rel=""nofollow"">http://www.gnu.org/software/gnutls/</a></p>
","35640","","1204","","2011-10-14 19:43:21","2011-11-06 21:33:11","VPN or TLSv1 for securing a programs protocol from field device to mainframe","<security><networking>","3","3","","","","CC BY-SA 3.0"
"341544","1","341690","","2017-02-04 14:43:13","","1","2705","<p>Suppose I have a <code>REST API</code> backend and it is used by a mobile app. Authentication is based on tokens (JWT) with expiration time. Mobile app user does not want to enter credentials so often, even for weeks. In other side I think token must not have expiration time more than 24 hours or so. If I do not include token invalidation on backend (which imposes a session management on a REST server) what options are available and what is cons and pros of each one?</p>

<p>What about to force mobile app to login automatically behind the eyes of the user if token is expired? In this way user and password must be saved somewhere in mobile app that I'm not sure if it is a good idea.</p>

<p>Our back-end in ASP.NET Core Web API and current mobile app is Xamarin.IOS.</p>
","12879","","","","","2017-02-06 23:36:51","Is it good idea to save user/password and get token from server automatically behind the eyes of the user?","<security><asp.net><mobile><xamarin>","1","2","0","","","CC BY-SA 3.0"
"31527","1","","","2010-12-28 22:53:57","","-1","177","<p>Why don't browsers have the ability to differentiate between events triggered via input devices and scripts ex: element.onEvent()?  Wouldn't this be a very simple way counter attack web spam bots? Or am I way off on this?</p>
","11908","","","","","2010-12-29 03:04:43","Why don't browsers have the ability to differentiate between events triggered via input devices and scripts ex: element.onEvent()?","<javascript><security><jquery><browser>","2","2","","","","CC BY-SA 2.5"
"341883","1","341886","","2017-02-09 10:43:25","","0","151","<p>In the simplest form, our (near future) project consists of a end user program, that directly connects to databases and apis.</p>

<p>This is obviously bad as then the end user program consists of sensitive data such as usernames and passwords.</p>

<p>How do I avoid this properly?</p>

<p>searching on the web seems to point to Remote Method Invocation, wherein I put all sensitive data into an program that lies on an web server and end user program simply calls the methods from server program. Is this the right way or is there a better one??</p>
","203782","","","","","2017-02-09 11:07:09","What is the right way not to put passwords into end user program in java?","<java><security><networking>","1","0","","","","CC BY-SA 3.0"
"341913","1","341916","","2017-02-09 17:15:49","","3","3919","<p>I am working a project which involves back-end Restful API and single-page front-end app. I am wondering if the back-end API has to implement all sort of data validation logic , which is also to be implemented in the front end input forms?</p>
","164647","","145892","","2017-02-09 18:23:23","2017-02-09 18:23:23","Should a backend Restful API implement data validation","<web-applications><security><api-design><validation>","2","1","","","","CC BY-SA 3.0"
"224746","1","","","2014-01-20 05:47:02","","2","179","<p>I'm currently working on a pet project with two of my buddies. This web service will provide basic functionality such as Login/Password Modification/Registration etc.</p>

<p>All of us are comfortable with jQuery and ASP.NET. My friend's idea is to - </p>

<p><code>Set up a web service on the same domain and send it data for registration, validation and password retrieval through jQuery ajax.</code></p>

<p>This same process is going to be used for other CRUD ops as well.</p>

<p>I'm not sure though, isn't this a huge security risk? Couldn't a normal person write some code that could create thousands of dummy users in our application?</p>

<p>Would setting up a secondary web service that handles authorization (OAUTH 2.0 or something like that) and calls the web service that connects directly to the database reduce the security risk?</p>
","56109","","74165","","2014-05-20 19:56:18","2014-05-20 19:56:18","Security concern regarding web service","<security><web-services><ajax>","2","0","","","","CC BY-SA 3.0"
"115018","1","","","2011-10-19 01:04:14","","4","1406","<p>A friend asked me recently about mobile applications and the security surrounding them. As he wishes to make a mobile app that would handle very secure information such as credit card numbers, I was starting to wonder about the issue of security surrounding these devices. Does it seem reasonable to store sensitive information inside of a mobile app? I wonder this because I have seen dex to class to java decompilers online and I imagine that on any mobile device there is no guarentee that the data in the <em>secure</em> locations is as secure as they would like you to believe.</p>

<p>But, I'm not an expert on these things; I feel like I'm a stranger when it comes to the wonderful world of security. So that's why I ask you this, what is the best way to securely store the data? Is it feasible to securely store credit card information/passwords/etc on a mobile device? If so, what methods should one take in order to assure the users that the best possible measures were taken to securely store their information. If not, what is a good alternative to store all that sensitive information? Even then, with the stories in the news about user data stored in web sites being compromised what measures should be taken to ensure that the data stored there is also secure?</p>
","38934","","","","","2013-07-31 13:05:46","Best practice regarding security in mobile applications","<security><mobile>","3","3","","2013-08-01 05:51:23","","CC BY-SA 3.0"
"115105","1","","","2011-10-19 12:43:33","","3","220","<p>Are there any standardised security procedures or auditing techniques that can be used to assess the security of a piece of software?  I'm specifically interested in auditing software written in Java, but other tips for other languages as well as general practices would be useful to know about as. A list of frequent identified security vulnerabilities would be helpful, as well.</p>

<p>I'm looking for things that are specific to software engineering practices, rather than, for example system administrators.</p>
","9470","","4","","2011-10-19 13:11:32","2011-10-19 13:11:32","What procedures or audits should be used to assess the security of a software system?","<java><security><secure-coding>","1","3","","","","CC BY-SA 3.0"
"342095","1","342107","","2017-02-12 08:05:53","","0","150","<p>I've been looking at ways to monitor for changes in things like price and availability on e-commerce sites via visiting browsers, with three constraints:</p>

<ul>
<li>the sites often don't have much ongoing development effort behind them, so the solution needs to be simple to implement</li>
<li>there should be minimal impact on how quickly the page is generated and delivered</li>
<li>it should not be possible for a third-party to spoof reports of changes</li>
</ul>

<p>The approach I'm using at the moment is to give the site developer an SDK that allows them to generate an JSON object using the same data they're using to generate the page. They render this object into a <code>script</code> element in the page, along with an HMAC of the JSON using a secret key. The page also references a small script that pulls out that JSON and POSTs it to my server, which rejects anything that doesn't have a valid HMAC or has a timestamp too far in the past. This prevents most spoofing, except for a small replay window.</p>

<p>To make it even simpler for the site developer, I have considered using a microformat approach where they add attributes to declare things like ""this element contains the price"" and ""this element says whether the item is in stock or not"". Again, my JavaScript would be referenced in the page, but this time it would look for those attributes and build the JSON itself rather than pulling it out of one element. This means no extra work while generating the page, but it has the drawback that there's no HMAC, so it's easily spoofed. Am I right, or am I missing something?</p>

<p>One possible solution is to verify differences by retrieving the page directly, and parsing it on the server side to find those attributes, but I'd prefer not to increase the load on the e-commerce site unnecessarily.</p>

<p>Is there a solution that can use the microformat, but still have a reliable anti-spoofing measure?</p>
","54726","","","","","2017-02-12 12:45:07","Using browsers to monitor changes in e-commerce pages","<design><javascript><security><browser><hmac>","1","0","","","","CC BY-SA 3.0"
"115110","1","","","2011-10-19 12:41:58","","5","4639","<p>I'm building a site that needs to guarantee user reputation scores are accurate by preventing users from creating more than one account, at the cost of decreased user signups. So far, the only solutions I have thought of are allowing users to:</p>

<ul>
<li>Link to their (verified) PayPal account through <a href=""https://cms.paypal.com/us/cgi-bin/?cmd=_render-content&amp;content_ID=developer/howto_api_reference"">PayPal Account Authentication</a></li>
<li>Provide their PGP public key, and checking that the MSD (a metric of trustworthiness) is below a certain value</li>
</ul>

<p>Of course, even these methods aren't bulletproof, but are likely to make creating a sock-puppet account very difficult. Are there any others I haven't considered?</p>
","38978","Alek Storm","","","","2011-10-23 00:18:09","How can I prevent users from creating multiple accounts on a web site?","<web-development><security><cryptography>","6","10","","","","CC BY-SA 3.0"
"343293","1","","","2017-03-02 08:01:51","","0","216","<p>I'm working on a security concept of a bigger project. It will be done with Spring,but that's actually not relevant right now.</p>

<p>The whole system is a hierarchical tree of computer nodes that run a custom platfrom software, whereas layer 1 nodes connect to a node on layer 2, layer 2 nodes connect to a node on layer 3 and so on.</p>

<p><a href=""https://i.stack.imgur.com/SkEbV.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/SkEbV.png"" alt=""enter image description here""></a></p>

<p>The idea is that the whole system has a master node which will be the root of the tree. The whole user management including authentication will be done there. Meaning a login request from a lower layer node will be forwarded to the root node. The concept for this is pretty much done and looks good.</p>

<p>The difficult part right now is the authorization. The system should give a top down SingleSignOn feeling. Meaning if I've signed on on a layer 3 node, I will not have to sign on on any lower layer node again. Currently I imagine it like this:</p>

<p><strong>Sign on</strong></p>

<ol>
<li>User signs on on an upper node</li>
<li>User gets the session key stored in a cookie</li>
<li>User access a platform on a lower node</li>
<li>Lower node's authorization module does not know the session key provided</li>
<li>Authorization module ask upper node if session key is known</li>
<li>An upper node instance knows session key and responses with an OK</li>
<li>Authorization module on the node with attempted access creates a new local session for this user.</li>
<li>Session key gets added to cookie.</li>
<li>User uses local session key for further access of this node.</li>
</ol>

<p><strong>Sign off</strong></p>

<ol>
<li>User signs off on a random node</li>
<li>Node on which the user signed off informs the node with the stored original session key, that the session is not valid any more.</li>
<li>The node with the stored session original session key send a broadcast down to inform all clients that this session is now invalid.</li>
</ol>

<p>The whole inter layer communication will be secured of course.</p>

<p>This concept would technically work, I guess. As I never had to create a complex security concept like this, I really d'like to hear another opinion. Maybe I'm overseeing a major issue. Can you see a fatal hole in the story, or should I go with that?</p>

<p><strong>UPDATE</strong></p>

<p>An important detail I missed, is that a lower layer does not necessarily have direct network access to the top layer. It can happen that the layers are in different networks and only will have direct network connection to next higher layer. Therefore I will not have the possibility to make a central login server as usually used with SSO.</p>

<p><strong>UPDATE</strong></p>

<p>Sequence diagram explaining the whole process and need of keys</p>

<p><a href=""https://i.stack.imgur.com/9ma4V.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/9ma4V.png"" alt=""enter image description here""></a></p>
","264141","","264141","","2017-07-03 11:29:48","2017-10-01 17:02:41","Multilayer security concept","<security><concepts><multi-platform><sso>","2","4","","","","CC BY-SA 3.0"
"226343","1","226358","","2014-02-01 11:06:40","","11","6450","<p>The current <a href=""https://www.rfc-editor.org/rfc/rfc6455"" rel=""nofollow noreferrer"">Websocket RFC</a> requires that websocket <a href=""https://www.rfc-editor.org/rfc/rfc6455#section-5.3"" rel=""nofollow noreferrer"">clients mask all data</a> within frames when sending (but server is not required to). <a href=""https://www.rfc-editor.org/rfc/rfc6455#section-10.3"" rel=""nofollow noreferrer"">The reason</a> the protocol was designed this way is to prevent frame data from being altered by malicious services between the client and server (proxies, etc). However, the masking key is still known to such services (it is sent on a per frame basis at the beginning of each frame)</p>
<p>Am I wrong to assume that such services can still use the key to unmask, alter, and than re-mask the contents before passing the frame to the next point? If I'm not wrong, how does this fix the supposed vulnerability?</p>
","116076","","-1","","2021-10-07 06:47:20","2020-12-09 22:30:40","Is masking really necessary when sending from Websocket client","<security><protocol><websockets>","2","0","","","","CC BY-SA 3.0"
"226427","1","226429","","2014-02-02 11:28:55","","2","2350","<p>I know many people have asked the same question but I think it really depends on the type of the website. So that's why I am asking the question about my website.</p>

<p>I am developing a PHP web application for an insurance company. the application contains all information about the customers but this app is only used by the admins and salesman of the company. The admin creates a user then that user can add customers or renew their insurance. the address will be something like example.com/manage/ and the login is only for the users that admin person has created. Of course I will be using validation, salt, encryption, etc. But do I need SSL certificate?</p>
","114048","","","","","2014-02-02 11:55:39","How important is an SSL certificate for a internal website?","<web-development><security><ssl>","1","0","","","","CC BY-SA 3.0"
"226482","1","226485","","2014-02-03 01:14:49","","2","224","<p>Earlier, I was messaged about a potential security risk in one of my projects.
I checked it and found that it allows for ""arbitrary code execution"". (Quotes because it is running in a VM, but the damage that can be done is huge nonetheless)</p>

<p>Since it is an open source project, I imagine other people have found it and exploited it already. However, I am reluctant to fix it, because everybody will be able to see the commit and know about the exploit. Since I have no way of contacting the users and no way of forcing an update (updates are manual), I am at a loss at what to do here.</p>

<p>If I let it stay, people are going to exploit it. If I fix it, people are going to exploit it even more.</p>

<p>How can I proceed?</p>
","117344","","31260","","2014-02-03 06:59:37","2014-02-03 06:59:37","Fixing a security exploit - but then everyone knows about it","<open-source><security>","2","5","","","","CC BY-SA 3.0"
"227702","1","227703","","2014-02-04 18:14:07","","13","1033","<p><strong>Background</strong></p>

<p>I'm been contracted to help a company maintain their server. I work on some minor PHP projects but also look over performance issues and recently, scan logs for hackers.</p>

<p>These guys have been running their server for some time and have what I would call a legacy application on its last legs. It uses magic quotes, global variables (which allows <code>$id</code> to be overwritten by <code>$_GET['id']</code>), use .htaccess as their only security in some instances, you name it. A security and programming nightmare.</p>

<p>We have been hacked in the past, mostly with SQL injections, which would run <code>SLEEP(99999999)</code> commands and act as a DOS-attack. Luckily they didn't run ""little bobby tables"",</p>

<p><img src=""https://i.stack.imgur.com/OSBpv.png"" alt=""http://xkcd.com/327/""></p>

<p>XKCD: <a href=""http://xkcd.com/327/"" rel=""nofollow noreferrer"">http://xkcd.com/327/</a></p>

<p>So I re-wrote their vulnerable SQL statements from <code>mysql_query()</code> (not mysqli) to PDO transactions. I'm also analyzing the queries for <code>SLEEP</code> and <code>UNION</code>, which we don't use but the injections have. So far, so good.</p>

<p><strong>Latest Issue</strong></p>

<p>Recently we've been told records are changing in the DB for users, such as their e-mail addresses to ones presumably made by spammers.</p>

<p>I noticed their columns didn't have a <code>last_modified</code> column, so we weren't able to even know when they were being changed, let alone by who. I added that column, but that's barely a first step.</p>

<p>When I was looking in to this table, I noticed the passwords weren't salted nor even hashed, just saved as plaintext.</p>

<p><strong>Client Communication</strong></p>

<p>How can I approach them about the entire situation, as a contractor, without flailing my arms like a madman? Any advice? I was thinking a calm approach of,</p>

<pre>
    ISSUE #1
        Synopsis
        Why this is an issue
        What can happen if this is not fixed
        Suggested fix

    ISSUE #2
        Synopsis
        Why this is an issue
        What can happen if this is not fixed
        Suggested fix
        </pre>
","52032","bafromca","25476","","2014-02-07 13:21:16","2014-02-07 15:00:28","What to do when your company doesn't encrypt passwords","<php><apache><security><mysql>","4","5","","","","CC BY-SA 3.0"
"228418","1","228421","","2014-02-10 16:18:36","","2","1083","<p>Many a times I need to log into a website that I used months ago and have forgotten my password. So clicking the reset password link and the site sends me an email with a single use link which allows me to enter a new password and logs me in.</p>

<p>Happy days.</p>

<p>This got me thinking; how about we skip the whole password thing and just send a single use link in an email that I click which logs me into a month long session.</p>

<p>So, tell me.  Why wouldn't this work?</p>
","119309","","","","","2014-02-10 20:05:19","Is just using an email address for login a good idea?","<security><passwords><login>","4","6","0","","","CC BY-SA 3.0"
"36065","1","","","2011-01-12 18:02:21","","26","21173","<p>We have a asp.net MVC web service framework for serving out xml/json for peoples Get requests but are struggling to figure out the best way (fast, easy, trivial for users coding with javascript or OO languages) to authenticate users.  It's not that our data is sensitive or anything, we just want users to register so we can have their email address to notify them of changes and track usage.  </p>

<p>In our previous attempt we had the username in the URI and would just make sure that username existed and increment db tables with usage.  This was super basic but we'd notice people using demo as a username etc so we need it to be a little more sophisticated.</p>

<p>What authentication techniques are available?  What do the major players use/do.  </p>
","13049","","","","","2014-02-04 02:37:54","Web api authentication techniques","<security><api><web><services><rest>","4","2","","","","CC BY-SA 2.5"
"118136","1","118139","","2011-11-06 12:42:43","","24","1673","<p>My employer asked me to implement a feature that would require storing passwords in clear text in a database (or using an obscure encrypt/decrypt function stored in a binary, which is a bit better, but also insecure).</p>

<p>I replied that I was willing to implement such a feature, provided that customers were acknowledged of security implications when using it. </p>

<p>When discussing this problem with colleagues, someone told me that, as a software engineer, we are personally responsible (in the legal sense) for security problems that we introduce in our products. I looked into my contract, but did not found anything related to a similar case.</p>

<p>From a legal point of view, should I refuse to implement such a feature?
Is it true that my employer could take me to court if a customer experiences damage due to this feature, even if he was aware of security concerns as well?</p>

<hr>

<p><em>EDIT:</em> I understand this question can only be answered reliably from a lawyer. The same is true for licensing questions: people here give their understanding and their experience, sometimes after having consulted a lawyer, with no guarantee it applies in another jurisdiction. But licensing is explicitly accepted as a topic here, see <a href=""https://softwareengineering.stackexchange.com/faq#questions"">What kind of questions can I ask here?</a>. I believe other programmers may have the same issue, and other may have been confronted to this situation before, and may have consulted a lawyer for that.</p>
","40071","","-1","","2017-04-12 07:31:29","2017-10-26 22:28:11","Should I accept to write unsecure code if my employer requests me to do so?","<security><legal>","11","12","","2015-02-26 19:30:52","","CC BY-SA 3.0"
"118575","1","","","2011-11-08 17:10:14","","4","325","<p>I was wondering: it now seems to be more and more common to see people/framework putting cryptographic tokens in the URLs their webapps are generating (to prevent quite effectively against quite some attacks).  It is advised by OWASP etc.</p>

<p>However I was wondering: what was the earliest known usage of this technique (specifically inside Web URLs)?</p>

<p>I've found a message on Usenet dating from 2003 (for a Java webapp) describing the technique by someone who, obviously, independently discovered it (he's asking for know ""prior art""):</p>

<pre><code>Every single link in any of the jsp page transmitted to the client is 
generated with a checksum that act as a signature for the URL
</code></pre>

<p>The description clearly shows it's a cryptographic checksum being used (and the way it works seems very close to the modern ""tokens"" OWASP advocates etc.).</p>

<p>Interestingly enough the person describing it says that ""it cannot hurt"" but that it may not be that useful since that Java is relatively immune to buffer overflow.  The author couldn't have imagined that this technique would has stopped most XSS and CSRF exploits dead in their track way before these techniques were even invented...</p>

<p>So my question is simple: what are the oldest know usage of this technique you know of?</p>

<p><strong>EDIT</strong> Upon re-reading the old description, I think in that message from 2003 the technique is even more advanced than the ""per-session tokens"" that OWASP advocates in that every single parameters are checked against forgery (but I'm not sure)</p>
","39479","","39479","","2011-11-08 17:17:21","2012-01-03 12:18:38","What was the earliest use of cryptographic tokens in URLs?","<web-applications><security><cryptography>","1","8","","","","CC BY-SA 3.0"
"118639","1","118641","","2011-11-08 22:22:00","","15","10580","<p>Recently I have a discussion with some of my colleagues at my work because they said that it's better have in a .DLL a string connection encrypted. And I said why just don't use the string connection defined in the web.config encrypted? it's the same and it's better because entity framework, for example looks for the name of the connection in the web config of the application, Now i want to know from a security point what's better or what's the best practice??</p>
","33763","","13156","","2011-11-08 22:28:00","2011-11-09 05:19:51","Is it a good practice set connection strings in a web config?","<web-development><c#><asp.net><security><entity-framework>","3","2","","","","CC BY-SA 3.0"
"229126","1","","","2014-02-15 21:37:27","","0","382","<p>Say I'm making a snapchat clone app for Android and iOS. Let's say that I get a snapchat from Baz. I want to pre-download the audio for this snapchat. However, as the developer, I want to secure this audio from being viewable outside of the app.</p>

<p>I've been thinking of encrypting it using AES with an IV and key that are both generated from a pseudo-random function that takes the user's unique ID as input. However, if an attacker found out that this was the way we encrypt our files, and had access to our PRF, he would easily be able to decrypt it and store it permanently. The thing is, I don't have enough background in cryptography or android programming to tell if that's really a concern or not. The attacker has to learn a lot about our cipher in order to break it, but he could gain pretty much all of that from looking at the unobfuscated source of our app.</p>

<p>Is my suggested approach cryptographically secure? What other, better or simpler approaches could I take to solving this problem?</p>
","120013","","","","","2014-09-14 11:33:44","Snapchat clone: How do I secure pre-downloaded notifications so that they cannot be opened outside of the app?","<security><android><ios><encryption><cryptography>","2","3","","","","CC BY-SA 3.0"
"344890","1","344915","","2017-03-25 00:15:44","","1","325","<p>On a regular Hard Drive a <a href=""https://en.wikipedia.org/wiki/Data_erasure#Standards"" rel=""nofollow noreferrer"">secure delete</a> of a file is possible by overwriting it, does simply overwriting the registry key is enough to secure delete the key ?</p>

<p>If not how I can proceed to secure delete my registry key ?</p>
","266610","","57344","","2017-03-27 11:45:38","2017-03-27 11:45:38","Secure delete a registry key","<security><windows><windows-registry>","1","0","","","","CC BY-SA 3.0"
"345072","1","345086","","2017-03-28 08:39:53","","4","792","<p>To make maintenance and versions tracking easier, I would like to expose the app version of each of the applications I develop on all my environnements.</p>

<p>Can the app version and the last deploy datetime of my own application be considered as a sensitive information that should not be public ? Is it professional to do this ?</p>
","161607","","161607","","2017-03-28 19:43:33","2017-03-29 22:30:34","Is my app version a sensitive information","<security><deployment>","3","4","","","","CC BY-SA 3.0"
"119301","1","","","2011-11-11 20:56:06","","3","311","<p>Iâ€™m developing a simple peer-to-peer app in .Net which should enable users to share specific content (text and picture files). Inappropriate content can â€œrelativelyâ€ easily be identified / controlled in a centralized environment. But what about a peer-to-peer network, what are the best methods to protect a decentralized system from unwanted (illegal) content?</p>

<p>At the moment I only see the following two methods:</p>

<ol>
<li><p>A protocol (a set of rules) defines what kind of data (e.g. only .txt and jpg-files, not bigger than 20KB etc.) can be shared over the p2p-network and all clients (peers) must implement this protocol. If a peer doesnâ€™t, it gets blocked by other peers. Pro: easy to implement. Con: Itâ€™s not possible to define the perfect protocol (I think eMail-Spam filters have the same problem)</p></li>
<li><p>Some kind of rating/reputation system must be implemented (similar to stackoverflow), so â€œbad guysâ€ and inappropriate content can be identified / blocked by other users. Pro: Would be very accurate. Con: Would be slow and in my view technically very hard to implement.</p></li>
</ol>

<p>Are there other/better solutions?</p>
","31705","","173670","","2016-06-15 16:40:04","2016-06-15 16:40:04","How to protect a peer-to-peer network from inappropriate content?","<security><networking><concepts><internet>","2","10","","","","CC BY-SA 3.0"
"229732","1","229753","","2014-02-20 18:16:53","","1","98","<h1>Passwords exposed in URIs</h1>

<p>An application stores URIs to be used for file transfers via SFTP, FTP, FTPS and SCP.  Many of these URIs contain passwords, for example:</p>

<pre><code>sftp://someuser:sekrit@host.example.com/
</code></pre>

<p>These URIs are visible to too many people.  We cannot hide email addresses from these people.</p>

<h1>A mini-language to get passwords out of URIs</h1>

<p>Using a mini-DSL, we can specify the parts of the email address we don't want to show:</p>

<pre><code>sftp://someuser:&lt;&lt;CONFIG:customers/widgitco/password&gt;&gt;@host.example.com/
</code></pre>

<p>The program that does the file transfer would look for instances of this mini-DSL in the URI, parse them, look up the appropriate strings from restricted sources, and substitute those strings into the URI.  For example, supposing that restricted source contains this key/value pair:</p>

<pre><code>customers/widgitco/password: moresekrit
</code></pre>

<p>Then, after replacement, the URI should be:</p>

<pre><code>sftp://someuser:moresekrit@host.example.com/
</code></pre>

<p>Each instance of the mini-DSL within the URI would be delimited with <code>&lt;&lt;</code> and <code>&gt;&gt;</code>.  Details of the mini-DSL between the <code>&lt;&lt;</code> and <code>&gt;&gt;</code> would be free to vary in order to meet future requirements; the only requirement would be that it contain no <code>&gt;&gt;</code>.</p>

<p>This would achieve my goal of reducing the exposure of these passwords.</p>

<h1>Is this mini-language fragile?</h1>

<ul>
<li>Are there valid FTP/FTPS/SFTP/SCP URIs which will break this scheme?</li>
<li>Are they at all likely?</li>
<li>What mini-DSL is less likely to be broken by valid URIs?</li>
</ul>
","8655","","","","","2014-02-20 22:26:57","Is this mini-DSL for hiding URI passwords compatible with the URI spec?","<security><dsl><uri>","1","6","","","","CC BY-SA 3.0"
"229796","1","229797","","2014-02-21 08:18:08","","2","241","<p>I was looking at cross-domain requests for a design and stumbled upon something that puzzles me. From a local site I'm firing an Ajax request to another domain (with jQuery and vanilla XMLHttpRequest). Sure, the request fails and I can only get a fail event, which seems perfectly normal du to same-origin policy. But I noticed in Fiddler that the request is actually made and succeeds! It's seems that it's just that I can't process the response.</p>

<p>Am I missing something, or is that a security hole? Sure, you can't access data, but what's the point of allowing sending data and just preventing response access?</p>
","72180","","","","","2014-02-21 08:28:44","How is same-origin policy implemented?","<security><ajax>","1","0","","","","CC BY-SA 3.0"
"345328","1","345334","","2017-03-31 13:38:51","","7","2305","<p>This is more about architecture question. </p>

<p>I will be developing microservice in Lumen or Slim, it will not be accessible from the public. The private microservice will be dealing private stuff. Laravel backend will communicate with microservice via REST API (Private / Internal use only). Users will know nothing about microservice.</p>

<p>If Frontend website (public) ever get hacked, it will minimise damage from accessing private stuff on the microservice.</p>

<p>However I want users to use Public API to communicate from public Frontend which then execute requests to microservice. To me this seem to duplicated API Requests - One for Public, and other one for Private (Backend to Microservice)? Or is it nothing wrong with that design?</p>

<p><a href=""https://i.stack.imgur.com/wnf7V.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/wnf7V.png"" alt=""enter image description here""></a></p>
","267250","","","","","2017-03-31 14:09:29","Is exposing a public API that calls a private API a good practice?","<architecture><rest><api><security><microservices>","2","0","","","","CC BY-SA 3.0"
"229859","1","229868","","2014-02-21 15:52:09","","12","24411","<p>I have to design a ""widget"", a script that partners will embed in their websites to display some UI and make calls to our API.</p>

<p>Basically it will display our data on these sites based on some IDs they provide in our API calls. <strong>What we would like to avoid is someone abusing the API and using it to scrape the entirety of our catalog.</strong></p>

<p>Each partner that embeds our script will be given a public key that must be provided when calling the API. An idea would be to ask them to append this key when loading the script, e.g.:</p>

<pre><code>&lt;script src=""//initrode.com/widget/loader.js?key=xxxx""&gt;&lt;/script&gt;
</code></pre>

<p>That way the request for the script can be used to register the key/source IP pair, and answer subsequent API calls only if the key/IP pair matches a registered one (with a limited lifetime, and a limit on requests per day).</p>

<p>I'm not sure it's a good idea since it's obviously security through obfuscation (someone reloading the script will completely bypass it) ; but I don't see any other way to restrict access. I cannot provide a unique key to every user, only to partners. I can't use a private-key system since all the code will be available to anyone. It's basically restricting access to a public API, i.e. contradictory in its definition.</p>

<p>What do you think of this solution, and what would you do with these constraints?</p>
","72180","","","","","2014-02-21 20:06:43","How to avoid unauthorized use of an API?","<security><api-design><web-api>","2","4","","","","CC BY-SA 3.0"
"345697","1","","","2017-04-06 18:19:41","","2","732","<p>I am using JWT for authentication in a micro service architecture. There is 1 UI web app and multiple REST API exposed services in the backend. I am considering a IAM service which will give a JWT to UI with permission information. The UI can use this to contact another Micro service X. But in this case should X contact IAM to validate or since it is self contained, should X go ahead with the request ? </p>

<p>Note that users can logout their sessions in IAM.</p>
","171835","","171835","","2017-04-06 18:29:43","2017-04-07 02:38:07","Can a third party service rely on JWT for authorization","<security><authentication><microservices><authorization>","1","0","","","","CC BY-SA 3.0"
"38894","1","38897","","2011-01-22 01:58:10","","4","113","<p>Does anybody have any advice on this? I currently work as a kind of lead developer/team leader and we have some remote team members and sometimes a contractor or two. At times, the entire team might be working on a large project and server details are usually managed by the entire team.</p>

<p>What is the best practice way to deal with this? Is there something I'm missing? I can't see anyway to have somebody access a server without the details. Also, I'm considering the security protection they have on their machines, should I be ensuring certain things happen to the data like encryption, shredding.</p>

<p>Should I use a 'company' proxy for connections?</p>

<p>Please advise!</p>
","9682","","","","","2011-01-22 02:11:02","Advice On How To Securely Manage [Client] Server Details Across Team?","<project-management><development-process><team><security>","1","1","","","","CC BY-SA 2.5"
"230654","1","","","2014-02-27 18:11:49","","1","649","<p>I want to modify one list (actually info stored in a database).  A person doesn't have access to update every part of the list, but can update and delete parts they do have access to and add whatever they want to the list. </p>

<p>Here's my pseudocode:</p>

<pre><code>ModifiedList 
OriginalList
OriginalListWithUserRights

for each Thing in ModifiedList do
  if Thing in OriginalList then
    //Leave Along - nothing to change
  else
    OriginalList.add(Thing)

for each Thing in OriginalList do
  if (Thing in ModifiedList) then
    //LeaveAlone - nothing to change (same as above)
  else 
    for each RightsThing in OriginalListWithUserRights do
       if RightsThing not in OriginalList then
         //Leave Alone - don't remove things you don't have rights to
       else 
         OriginalList.Remove(RightsThing)

OriginalList.ReIndex() //because there will be some gaps
</code></pre>

<p>So, I guess this would work, but I think it's not right because it's just an obvious solution.  I don't need to start with three lists as my inputs to this function.  I could look up particular pieces of information while I'm iterating through my modified list.  It just seems to structured and not object oriented enough for 2014.</p>

<p>One problem I have is that I'm going to be adding everything to the end of the list, seems like I should be adding things relative to where they were in the passed in list, but in a way that doesn't mess up the order of things that are not in my OriginalListWithUserRights.  </p>
","1973","","1973","","2014-02-27 19:00:32","2014-02-27 19:00:32","Is there a design pattern for updating lists?","<security><list>","1","3","","","","CC BY-SA 3.0"
"38976","1","","","2011-01-22 14:17:15","","7","745","<p>While there are certainly many economic, social and practical decisions to be made when deciding whether a system should be open source, are there any situations in which it is impossible, purely from a technical standpoint, to open source your code?</p>

<p>Essentially; a feature which when the code is made public, invalidates/reduces the functionality of that feature.</p>

<p>Some examples I can think of:</p>

<ul>
<li><a href=""http://www.catb.org/~esr/writings/quake-cheats.html"">Cheating in Quake</a> - once the game was released as open source, id had to release a closed-source 'wrapper' to validate client code in order to prevent cheating.</li>
<li>Reddit - while the majority of the source for social news site Reddit is available, their anti-spam mechanisms are not. If the spammers knew how they worked, they'd be easier to work around.</li>
</ul>

<p>Both security related and both as a result of using implementations security experts would probably frown on (Quake: trusting the client, Reddit: security through obscurity). Whether there are feasible alternatives to these implementations is another matter altogether...</p>

<p>What other examples are there of this? Are there any that aren't security related? Are they all due to 'workarounds' in order to make our systems work with the technology we have?</p>
","10839","","","","","2015-08-21 14:40:44","In what situations would it be technically 'impossible' to release a system as open source?","<open-source><security>","10","3","","","","CC BY-SA 2.5"
"347130","1","347237","","2017-04-13 15:48:43","","3","93","<p>If I have written a privacy tool as a .NET web application which is to be hosted on a commercial hosting site, other than hosting it in a privacy friendly country, how can I assure users that the application has not been compromised by a third party at the host?</p>

<p>Obviously SSL will be used and the assemblies will be as obfuscated as possible, but these can only go so far.</p>

<p>For example, is there a way I can ensure that my assemblies haven't been wrapped to intercept plain-text user details?</p>
","56449","","","","","2017-04-15 22:02:05","How to ensure privacy on a remotely hosted server?","<.net><security><privacy>","1","3","","","","CC BY-SA 3.0"
"230856","1","230993","","2014-03-01 06:13:03","","2","2575","<p>I would like to hear advice from the more experienced developers. The project is now in the design stage. It's mobile application and a simple web application. Content is pictures, comments, personal correspondence.  </p>

<p>Pictures can be quite personal. Need a very serious attitude to security.  </p>

<p>The question is simple: <strong>where to store photos and how to secure it?</strong> </p>

<p>I think it's will be in the following way:<br>
1. User make some photo. Via SSL the application sends photo to the server.<br>
2. The server recieve photo, encrypt it and store somewhere.  </p>

<p>Also, via app the user can see all own photos.<br>
1. Request to server for photos.<br>
2. Server decrypt stored photos and send via SSL to client.</p>

<p>I need some technical advices: where to save images, I know that database is quite slow for this case, which algorithms use for encrypt/decrypt, what about cache. It will be highload project and performance is very important.  </p>

<p>Mobile application is planned on cross-platform framework like phoneGap, Titanium. On the server is .NET. But it is planned. I also consider full stack frameworks for javascript. </p>
","61612","","61612","","2014-03-01 13:04:58","2014-03-14 17:37:10","secure photos on server","<javascript><security><asp.net-mvc><cryptography>","5","4","","2014-03-20 12:58:14","","CC BY-SA 3.0"
"231500","1","231540","","2014-03-06 15:56:25","","1","2269","<p>I have been doing some research on accessing a DB from mobile devices. There are so many different ways of doing it. There are also multiple ways to make it secure. What is a good way to access a database from a mobile device securely? </p>

<p>Also considering my specific case, where I have an existing WCF service which does everything I would need for the app, I would like to re-use it. I have been working on using jsonp calls to the service and develop apps for iOS, Android and windows phone. The calls are secured by HTTPS and I would be implementing some authentication policy for the calls. But how secure would all this be?</p>

<p>I have some really sensitive data to worry about. I am using HTML5 and JS for app development to keep it uniform and less difficult to manage for all platforms.</p>

<p>How do I access the database and keep my data secure?</p>
","89794","","31260","","2014-03-06 16:30:38","2015-06-16 10:58:17","How do I access databases from a mobile device securely?","<security><mobile><wcf>","2","2","","","","CC BY-SA 3.0"
"347817","1","347819","","2017-04-25 20:54:52","","2","140","<p>I have a set of machines that I'm going to setup to push data to my web server over HTTPS at regular intervals. These units will automatically send requests using a script, so I plan on giving them configuration files with a username and long password for authenticating with my server.</p>

<p>Is there anything I should do in addition to user credentials to increase security? I'm not so much concerned about the security of the data as I am about unauthorized users getting access to my server. I figure I can try encrypting the the username/password, but I don't know if that will give me any additional security considering I'll be sending the requests using HTTPS.</p>
","261823","","","","","2017-04-25 21:24:11","Securing an HTTPS endpoint for non-browser Post requests","<security><https>","1","3","","","","CC BY-SA 3.0"
"231914","1","","","2014-03-10 18:33:12","","2","2424","<p><a href=""http://www.thebuzzmedia.com/designing-a-secure-rest-api-without-oauth-authentication/"" rel=""nofollow"">http://www.thebuzzmedia.com/designing-a-secure-rest-api-without-oauth-authentication/</a></p>

<p>I've been reading the article and I haven't really grasped it yet. When is the private key given to the client?</p>

<p><strong>Say I have a JavaScript client - where would I store this private key (once assigned) - a cookie?</strong></p>

<p>I think that this maybe is done when authenticating a user, if a JavaScript client makes a post request and authenticates a user, the server validates the input and gives back user id ( a public key ) and then some generated string (stored in a table) = the private key?</p>

<p>And then just follow the approach (quoted) from article:</p>

<pre><code>[CLIENT] Before making the REST API call, combine a bunch of unique data together (this is typically all the parameters and values you intend on sending, it is the â€œdataâ€ argument in the code snippets on AWSâ€™s site)
[CLIENT] Hash (HMAC-SHA1 or SHA256 preferably) the blob of data data (from Step #1) with your private key assigned to you by the system.
[CLIENT] Send the server the following data:
    Some user-identifiable information like an â€œAPI Keyâ€, client ID, user ID or something else it can use to identify who you are. This is the public API key, never the private API key. This is a public value that anyone (even evil masterminds can know and you donâ€™t mind). It is just a way for the system to know WHO is sending the request, not if it should trust the sender or not (it will figure that out based on the HMAC).
    Send the HMAC (hash) you generated.
    Send all the data (parameters and values) you were planning on sending anyway. Probably unencrypted if they are harmless values, like â€œmode=start&amp;number=4&amp;order=descâ€ or other operating nonsense. If the values are private, youâ€™ll need to encrypt them.
(OPTIONAL) The only way to protect against â€œreplay attacksâ€ on your API is to include a timestamp of time kind along with the request so the server can decide if this is an â€œoldâ€ request, and deny it. The timestamp must be included into the HMAC generation (effectively stamping a created-on time on the hash) in addition to being checked â€œwithin acceptable boundsâ€ on the server.
[SERVER] Receive all the data from the client.
[SERVER] (see OPTIONAL) Compare the current serverâ€™s timestamp to the timestamp the client sent. Make sure the difference between the two timestamps it within an acceptable time limit (5-15mins maybe) to hinder replay attacks.
    NOTE: Be sure to compare the same timezones and watch out for issues that popup with daylight savings time change-overs.
    UPDATE: As correctly pointed out by a few folks, just use UTC time and forget about the DST issues.
[SERVER] Using the user-identifying data sent along with the request (e.g. API Key) look the user up in the DB and load their private key.
[SERVER] Re-combine the same data together that the client did in the same way the client did it. Then hash (generate HMAC) that data blob using the private key you looked up from the DB.
    (see OPTIONAL) If you are protecting against replay attacks, include the timestamp from the client in the HMAC re-calculation on the server. Since you already determined this timestamp was within acceptable bounds to be accepted, you have to re-apply it to the hash calculation to make sure it was the same timestamp sent from the client originally, and not a made-up timestamp from a man-in-the-middle attack.
[SERVER] Run that mess of data through the HMAC hash, exactly like you did on the client.
[SERVER] Compare the hash you just got on the server, with the hash the client sent you; if they match, then the client is considered legit, so process the command. Otherwise reject the command!
</code></pre>

<p>On second note, I believe it would be more readable from the article itself...</p>

<p>Am I getting this right? </p>
","109190","","1204","","2014-03-10 21:44:38","2014-03-11 01:02:19","When is the private key given to the client?","<security><api><server><client>","2","0","0","2014-03-11 14:15:13","","CC BY-SA 3.0"
"121500","1","","","2011-11-24 13:48:29","","11","1767","<p>I'm in a bit of a disagreement with a more experienced developer on this issue, and wondering what others think about it; our environment is Java, EJB 3, services, etc.</p>

<p>The code I wrote calls a service to get things and to create things. The problem I ran into was that I got null pointer exceptions that didn't make sense. For example, when I ask the service to create an object, I get null back; when I try to look up an object with a known valid ID, I get null back. I spent some time trying to figure out what was wrong in my code; since I'm less experienced I usually assume I've done something wrong, but it turns out the reason for the null returns was security. If the user principal using my service didn't have the right permissions for the target service, then it simply returns null. Most other services here aren't documented very well either, so apparently this is just something you have to know.</p>

<p>This is rather confusing as a developer writing code that interacts with the service. It would make much more sense to me if the service thew an exception that would tell me that the user didn't have the proper permissions to load this thing or to create that thing; I would then immediately know why my service wasn't working as expected.</p>

<p>The more experienced developer who wrote the service argued that asking for the data is not an error condition, and that exceptions should only be thrown in an error condition, not when the user doesn't have access to the data. This data is often looked up in a GUI, and for those users without the right permissions, these things simply ""do not exist"". So, in short: asking is not wrong, hence no exception. Get methods return null because to those users those things ""don't exist"". Create methods return null when the user wasn't allowed to create that thing.</p>

<p>Is this normal and/or good practice? I prefer using exceptions because I find it much easier to know what's going on. So I would for example also prefer to throw a NotFoundException if you asked for an object with an invalid ID, rather than returning null.</p>
","633","","31260","","2015-09-09 20:42:46","2015-09-09 21:31:30","Should security restrictions cause a service to return null or throw an exception?","<java><security><exceptions><null>","10","7","","2015-09-10 19:21:50","","CC BY-SA 3.0"
"348146","1","348157","","2017-05-01 15:06:02","","1","178","<p>I'm developing a web application which stores sensitive information, which the user can access after a check that I built. This function then returns a download url to the user which leads to the FTP Server.</p>

<p>My concern is that it might be vulnerable to exploitation, people could alter certain url's to download files from the FTP Server.
For example changing:</p>

<pre><code>/App_Data/Company1/Financials_2015.pdf
</code></pre>

<p>To:</p>

<pre><code>/App_Data/Company2/Financials_2015.pdf
</code></pre>

<p>Is this possible to be exploited and if so, is there a better way to make sure this can't be abused?</p>
","250420","","","","","2017-05-01 19:45:38","How do I secure downloadable data so that it cannot be exploited easily?","<web-applications><security>","3","4","","","","CC BY-SA 3.0"
"348261","1","","","2017-05-03 11:27:23","","0","142","<p>Yesterday, the deployment of a financial website on a client was replaced with an older version which created unexpected issues and a downtime of almost 12 hours.</p>

<p>We came to know that two guys from their IT are creating problems for each other and it was done by one of them, don't want to go into the details.</p>

<p>This could have lead to financial discrepancies and losses, but fortunately didn't.</p>

<p>IT guys have full rights on the server so it can not be controlled at machine/OS level.</p>

<p>So, is there any possibility/option available inside ASP.NET to secure or ensure integrity of the deployment? </p>

<p>For example what if version/hashcode of assemblies could be cross checked against database?</p>
","109712","","109712","","2017-05-03 13:06:49","2017-05-03 13:06:49","Deployed Website's Integrity","<web-development><security><asp.net><websites>","2","3","","","","CC BY-SA 3.0"
"348281","1","","","2017-05-03 15:50:42","","4","3840","<p>I'm developing an enterprise web application, hosted on site and managed by the corporate IT team. I do not have remote access to the server, and the only way in is through the web interface. I'd like to install the phpMyAdmin-like Adminer (<a href=""https://www.adminer.org/"" rel=""nofollow noreferrer"">https://www.adminer.org/</a>) so I can do database maintenance remotely. </p>

<p>How do I properly secure it? I don't feel comfortable just using the SQL database login, since the application contains sensitive information. I want to implement a multi-factor authentication. First logging in to the web application, then requesting a security token sent to my email, and only when I successfully provide both my password and the token, am I allowed access to Adminer, using which I will login to the database.</p>

<p>Update:
One way I can think of is to put the Adminer.php file out of the publicly accessible directory, and then require it in after passing authentication tests? Would that be secure enough? Of course I would make a new SQL user with very limited privileges.</p>
","271408","","271408","","2017-05-03 16:00:40","2021-11-08 10:37:48","How should I secure Adminer for production use?","<security><web-servers>","2","3","","","","CC BY-SA 3.0"
"232562","1","232571","","2014-03-16 16:25:37","","13","3050","<p>Most popular applications nowadays require account activation by email. I've never done it with apps that I've developed so am I missing some crucial security feature?</p>

<p>By email activation I mean when you register to a site they send you an email that contains a link that you have to click before your account gets activated.</p>
","35806","","","","","2014-03-17 11:18:59","Why do most sites require email activation","<security><email>","6","5","","2014-03-17 12:47:17","","CC BY-SA 3.0"
"348504","1","","","2017-05-07 11:08:51","","1","941","<p>I am trying to design a public facing website and would like to experiment with a WebAPI backend and one of the popular front end javascript frameworks.
Now, this application is not going to require users to login so there is no authentication process involved.</p>
<p>
To be honest most of the rest applications I have developed have been intranet applications so I have not had to worry about scrapping data by others. In the past I have primarily used server side frameworks like ASP.NET/PHP for public facing websites/applications, which would render html output rather than a JSON document.
</p>
<p>
My current concept in mind involves a javascript, running in the browser requesting my WebAPI endpoint for a JSON document to be returned.
Potentially in the future there would also be a mobile application as a client consuming this endpoint.
</p>
<p>
I obviously cannot provide a shared secret to be stored in the client side to generate a authentication token. <br/> I could think of enforcing CORS headers on the servers to only allow requests from my own domain, but then again nothing stops people from viewing the network activity of this website and getting hold of the endpoint and pinging the endpoint directly from their own client.<br/>
I could make use of a short lived access token that my server would hand over only to a valid request from my own website frontend.<br/> But then again nothing stops people from grabbing this token from just refreshing my website and passing on this token to their client.<br/> Also think like host headers, user-agent, etc can be easily spoofed.
</p>
<p>
I could potentially issue a HTTP cookie to my own domain and each time validate http requests against this cookie.
But since I'll also be making ajax calls to the servers my own requests could not be honoured as my scripts also cannot access HTTP only cookies ?.
</p>
<p>
The best I could do is restrict CORS allow-access setting to my domain name, I do understanding preventing scrapping is a very daunting task, but my view is scrapping a api that returns JSON data would be a much simpler task than say scrapping a HTML output from the server.
</p>
<p>
Would you recommend the SPA model with a REST api backend for developing such public facing applications that does not require authentication ?
</p>
","163742","","-1","","2020-06-16 10:01:49","2017-05-07 12:23:52","Is it possible to secure a REST API and validate the integrity of each requests?","<web-development><rest><security>","1","2","","","","CC BY-SA 3.0"
"122353","1","122360","","2011-11-29 17:16:29","","0","9265","<p>I'm interested in adopting a tool/scripting language to automate some daily tasks connected with fighting forum spammers.  A brief overview of these tasks: analyze new registrations and posts on a phpBB forum, and delete or deactivate spammers using <a href=""http://www.stopforumspam.com/"" rel=""nofollow"">a website/community that collects such spam reports</a>.</p>

<p>Typically such automation is integrated into the phpBB installation itself, which certainly has its advantages.  My approach has the advantage of independent operation, etc.</p>

<p>One way to think about this is in terms of browser automation.  I've used iOpus iMacros for Firefox (<a href=""http://www.iopus.com/imacros/firefox/"" rel=""nofollow"">the free version</a>) in the past to respond to individual spammers, but current attacks are highly distributed.  My ""logic"" for pigeonholing spammers vs. nonspammers seems beyond the easy reach of the free version of iMacros.</p>

<p>From a more technical perspective one can think about dispensing with the browser altogether and programming GET/POST requests directed to my forum and other Web-based resources.</p>

<p>I'm familiar with some scripting languages like Ruby and Lua, but I could be persuaded that a compiled application is better suited for these tasks.  However in my experience the dynamic flexibility of interpreted environments is very useful in prototyping and debugging the application logic.  So I'm leaning in the direction of scripting languages.</p>

<p>Among browsers I favor Firefox and Chrome. I use both Windows and Linux platforms, and if the tool can adapt to an Android platform, it would make a neat demonstration of skills, yes?</p>

<p>Thanks in advance for your suggestions!</p>
","10103","","10103","","2011-12-02 01:55:50","2012-03-21 19:12:54","A good tool for browser automation/client-side Web scripting","<security><scripting><browser><web-scraping>","2","7","","2012-01-28 19:45:46","","CC BY-SA 3.0"
"348847","1","","","2017-05-12 16:11:48","","0","99","<p>I have a portfolio website and i'm planning on allowing comments as a sort of ""guestbook"" feature. What are some things i should consider before starting? I don't want to get screwed over by a malicious user. Here's some of my thoughts</p>

<ul>
<li>Comment needs to be approved before appearing on the website </li>
<li>Insert comment onto website as text instead of html</li>
<li>Limit input size</li>
<li>Storage requirements are minimal, probably going to use SQLite, therefore i'm aware of preventing sql injections. Also considering MongoDB. I'm going to be storing very little data, so I just need a simple and easy database.</li>
</ul>

<p>Comment approval theoretically trumps all other security measures, but I want to know that i'm heading in the right direction. Like what if one day, i decide to stop moderating comments? Then the rest of the security measures should still work.</p>
","181619","","","","","2017-05-13 02:23:06","What should I be aware of when allowing user comments on my website?","<security>","3","3","","","","CC BY-SA 3.0"
"349219","1","","","2017-05-18 16:31:12","","0","133","<p>I have a proxy server that talks to a bunch of services and I want to have a way to prove to servers behind the proxy they are actually receiving a request from the proxy server and not from something else.</p>

<p>I thought about letting clients register themselves dynamically with a key/secret pair thing and sign requests with this pair but there might be other solutions out there that I'm not considering.</p>

<p>I have full control over clients and servers but would rather not have to do this at the network but at the application layer. These apps specifically are built in go.</p>
","34538","","34538","","2017-05-18 18:27:04","2017-05-18 21:56:11","What are the options to guarantee that a client that's connecting to a server is really who I think it is?","<security><microservices><proxy>","1","3","","","","CC BY-SA 3.0"
"349274","1","349290","","2017-05-19 12:57:57","","4","2120","<p>I have a login page, where user logs in via his mobile number, He gets an OTP send via backend server, once he enters a One-Time Passcode (OTP), we hit an API like this:</p>

<pre><code>https://backend.com/api/login?mobile=9123123123&amp;otp=1234
</code></pre>

<p>My question is this good enough from security point of view or should I encrypt both mobile number and OTP via some algorithm and send those like following:</p>

<pre><code>https://backend.com/api/login?authToken=jshfkasfasfbmsabvj&amp;authKey=amsfgjkashfkashjfjasgfkjahsfkj
</code></pre>

<p>where <code>authToken</code> is encrypted mobile number and <code>authKey</code> is encrypted OTP.</p>

<p>What are good practices regarding this, what are good encryption algo, which can be used here?</p>

<hr>

<p>Few suggestions came to use https, which indeed I am using but missed to have in the question somehow. What my concern is someone can figure out the API, and start hitting with different combination of OTPs for mobile number and gain the access of a account.</p>
","272893","","222996","","2017-07-15 21:01:56","2017-07-15 21:01:56","Should I encrypt mobile number and otp when sending to backend","<rest><api><security><authentication><encryption>","5","3","","","","CC BY-SA 3.0"
"233611","1","","","2014-03-25 14:18:35","","5","3392","<p>I am writing a simple webmail where I want (obviously) to display the emails.</p>

<p>I'm wondering if I should take any precaution while displaying HTML emails: is dumping the email content into a <code>&lt;div&gt;</code> a security risk?</p>

<p>I'm guessing that yes since the email could contain anything (could it contain Javascript?). But then how should I proceed? How do other webmails do?</p>

<p>I'm thinking that stripping dangerous HTML tags would be a bad solution since it's impossible to think of all the cases.</p>
","3100","","","","","2014-03-25 15:54:09","Is displaying an HTML email a security risk?","<security><email>","2","4","","","","CC BY-SA 3.0"
"349809","1","","","2017-05-30 00:19:54","","1","128","<p>I am tasked with implementing a web-based gambling system that's operated on site. The requirements given to me by the company co-founder and designer for user login give red flags in regards to security, which surprises me because all of the other roles are required to be secure (cashier, site owner, admin, etc. all have usernames and passwords).</p>

<p>Here is how users are supposed to log into this system:</p>

<ul>
<li>User goes to cashier, registers, and pays money for credits.</li>
<li>Cashier creates user, gives their account credits, and gives them their user ID.

<ul>
<li>The user ID is only seven characters.</li>
<li>The user ID is only digits.</li>
<li>The user ID is shown in plain text on the screen to the cashier.</li>
<li>The user ID is printed on a receipt given to the user.</li>
<li>There is no password. The user ID alone is used to log in.</li>
</ul></li>
<li>User goes to a terminal at a site, logs in with user ID, and plays games.</li>
</ul>

<p>The user ID is made to appear as a password because, when the player goes to a terminal to log in, they are presented on screen with a number pad and the digits they enter are masked.</p>

<p>What are all of the ways this system can be compromised? I suggested to him that 7 digits was insecure as it could be guessed, but he said that users don't want to have to enter long numbers to log in and that there could be max 2,000 users per site.</p>
","272432","","","","","2017-05-31 11:26:33","What ways can a system in which users log in with a PIN be compromised?","<web-applications><security>","2","4","","","","CC BY-SA 3.0"
"234248","1","","","2014-03-30 22:54:06","","0","252","<p>I'm designing a system, and it needs future expandability for the use of a permission system of some kind. I'm wondering if the flyweight pattern would be a good choice to implement this. I'm not responsible for the implementation right now, as it is just a prototype, and we're not prototyping any parts that need the right system. However, because of the demand for future extensibility to parts that need permission management the interface needs to be solid. This means that in the end it will be a thought experiment, rather than a real part of what I have to work on. However, I do need to be able to explain and justify my design in this area of the application.</p>

<p>In favour of using the  are that you can define permissions by having them symbolized through a token class, as represented in the flyweight pattern. If you're dealing with hundreds of users, this would somewhat simplify the handling and issuing of the rights a user holds, and the required rights a user needs for an action within the system; as well as the memory usage of the rights assigned to all the users.
In the system I have in mind, a factory method of some kind will assign the rights needed at construction time.</p>

<p>As I'm not really experienced with designing with security in mind, I'm having a paranoid line of thought of which I can't determine if it's justified, security wise. A shared pointer could be hijacked by 'evil intruders' to gain rights they should not be getting. This is the major argument against the use of a flyweight that keeps bugging me, Even though the 'how' is undefined, and I wouldn't know how someone would get it done. (no experience in the security mindset, or it's workings. However, I'm not really looking for a lecture in security beyond the secure use of patterns, unless motivated and clearly related to the question)</p>

<p>Q: Is the flyweight pattern a suitable pattern to manage the representation of the rights of a user (or other some 'hand out' type of data) in the design of a software system that needs to be secure by design? Does the use of flyweight objects as representation of permissions pose more of a security risk than other patterns (I could also use a decorator chain for it, even though that would take up more memory) when dealing with permissions?</p>
","26120","","26120","","2014-03-31 04:02:02","2014-03-31 04:02:02","Is the flyweight pattern a good security choice for managing permissions?","<design-patterns><code-security>","1","0","","","","CC BY-SA 3.0"
"234482","1","","","2014-04-02 02:18:20","","1","2072","<p>I have a RESTful API, built in NODE.js that does what you would expect it to: consumes data and then makes it accessible. Currently, data being submitted to my server is nested form data:</p>

<pre><code>data[0][username]=...
data[0][email]=...
data[0][phone]=...
...
data[12][username]=...
data[12][email]=...
data[12][phone]=...
</code></pre>

<p>or as a query string</p>

<pre><code>data[0][username]=...&amp;data[0][email]=...&amp;data[0][phone]=...
</code></pre>

<p>SO when I parse it on the server, I get a JS array of objects with those particular fields. What I am wondering is, is it safe for me accept a string that I can JSON.parse and the process it?</p>

<pre><code>data=(some stringified json object)
</code></pre>

<p>I am unsure if it's possible for malicious code or anything to be included in the JSON object that would blow up my server once run through a parser</p>

<p>Thanks.</p>
","118945","","","","","2014-04-02 03:07:31","Is parsing a submitted JSON object safe?","<javascript><node.js><json><code-security><malicious-code>","1","3","","","","CC BY-SA 3.0"
"124713","1","124774","","2011-12-13 00:21:00","","2","297","<p>I have a course with the following description:</p>

<blockquote>
  <p>The purpose of this course is the study of programming language security features  and languages designed to support it explicitly. Static and dynamic constructs for security in languages and systems, as well as software engineering security principles/patterns.</p>
  
  <p>Topics:</p>
  
  <ul>
  <li>Basic Programming Language security framework.</li>
  <li>Designing secure programming languages</li>
  <li>Access control in programming languages</li>
  <li>Information flow languages</li>
  <li>Capability Languages</li>
  <li>Mobile programming languages</li>
  <li>Software Engineering and Security</li>
  <li>Basic software vulnerabilities in systems</li>
  <li>Secure Software Engineering life-cycle</li>
  <li>Patterns, and Practices for software security</li>
  </ul>
</blockquote>

<p>I'm confused - How is PL security different from regular security? I'm looking for possible textbooks/books to study, or websites that are good in this topic, or any advice/tips. The professor told me to know C and Java well, that's all I know so far. </p>

<p>I appreciate any tips or advice.</p>
","29032","","25936","","2011-12-13 01:33:23","2011-12-14 06:13:29","What's a good way to prepare for this course titled ""Programming Language Security""?","<programming-languages><programming-practices><security><language-features>","7","2","","","","CC BY-SA 3.0"
"234888","1","234894","","2014-04-04 23:59:34","","1","172","<blockquote>
  <p>An agency wants to develop a highly secret computer system using public contractors. So they hire different companies to implement different components of the system. When all the components are put together the system is functional, but each component on it's own does not reveal the true nature of the system. Often the nature of the system is controversial, illegal or dangerous.</p>
</blockquote>

<p>That scenario has been played out many times in movies and books, but is it really possible to build such a computer system in the real-world without at least one company knowing the nature of the system.</p>

<p>As an example, in the movie <a href=""http://www.imdb.com/title/tt0468569/"" rel=""nofollow"">Batman: The Dark Knight</a>. Batman uses contractors to build a spy network that allows him to use mobile phones as sonar devices. He claims in the movie that no one knows the nature of the system, because it was out sourced to many different parties.</p>

<p>Sounds good in science fiction, but in the real world can systems been engineered this way. While I know parts of a system can easily be outsourced. Could an agency build a large complex computer system using contractors without anyone knowing the nature of the system?</p>
","52871","","","","","2014-04-05 12:37:33","Is secretive systems development really possible?","<project-management><security>","4","0","0","","","CC BY-SA 3.0"
"235008","1","235156","","2014-04-06 12:14:31","","2","458","<p>I am currently looking into Google Caja to run user-supplied JS code in the browser and in Node.</p>

<p>So far, I understand, that, in a browser context, ""cajoled code"" disallows reading and messing with the window state by running unsafe code through a full-blown parser that gets rid of all kinds of attack vectors, and then safely executing that code in an <code>iframe</code> of the same origin.</p>

<p>However, I am currently working on a solution using HTML5's <code>Worker</code> (<a href=""https://stackoverflow.com/questions/22506026/how-to-safely-run-user-supplied-javascript-code/22892328#22892328"">see here</a>) and it seems to have the same effect. What does Caja have to offer that Worker does not have, other than the ability to customize security policies? Does it have any additional safety features?</p>
","126027","","-1","","2017-05-23 12:40:14","2014-04-07 17:14:31","What are security advantages of Google Caja over using the web worker API?","<web-development><javascript><security><google>","1","5","","2014-04-08 00:08:58","","CC BY-SA 3.0"
"350512","1","350513","","2017-06-08 21:06:59","","-6","368","<p>I looked at using python for the AI in a security application for hobby-business but apparently you either release it as source code or it can be easily decompiled. Of the new machine learning languages/packages, which can be kept confidential? </p>

<p>Likely I would use it to identify between good and bad traffic and content for a network intrusion prevention system and content filtering. The language I would use for all the network programming would be C/C++. That can't change.</p>

<p>By business I mean selling it for a dollar eventually... maybe. I'm basically choosing what I'm going to program in my free time and would be learning(I'm new) both C++ and the AI language. Thank you for taking the time.</p>
","267519","","","","","2017-06-09 10:31:13","AI Language that doesn't release source code or can't be decompiled","<security><artificial-intelligence><machine-learning>","4","2","","","","CC BY-SA 3.0"
"125258","1","125285","","2011-12-15 00:57:41","","1","135","<p>I have a requirement to create a donation software for a project.</p>

<p>Does anyone know how KickStarter designed theirs? What are the security elements involved? How do I create the credit card transactions-processing part? Is there some common library/service used for that?</p>

<p>I am still in research phases for this, so any ideas appreciated!</p>
","23383","","88986","","2015-07-19 23:17:57","2015-07-19 23:17:57","How to create donation software?","<security><web-design>","1","1","","2015-07-21 14:44:35","","CC BY-SA 3.0"
"45369","1","45372","","2011-02-08 08:44:20","","2","1402","<p>Assuming that you're working on a piece of software which is required to pass a third party security/penetration test before being released to the client, at which point in the project life-cycle would you perform the tests?</p>

<p>Passing the test means that no major flaws are detected, or, more likely, that any flaws detected have been properly corrected before release.</p>
","4091","","","","","2011-02-08 13:17:28","When in the project life-cycle would you fit in external penetration/security testing of the software?","<project-management><testing><security>","5","2","","","","CC BY-SA 2.5"
"351077","1","","","2017-06-17 05:37:20","","3","295","<p>When designing an activity-based authorization system, how should additional conditional checks be handled?</p>

<p>For example, I have the following authority:</p>

<pre><code>VIEW_COMPANY_TRANSACTIONS
</code></pre>

<p>which allows the user to hit the endpoint </p>

<pre><code>GET /company/{companyName}/transactions
</code></pre>

<p>However, what if my authority <code>VIEW_COMPANY_TRANSACTIONS</code> has other restrictions based on the activity parameters that in fact make the authority effectively <code>VIEW_COMPANY_TRANSACTIONS(companyName=company_a)</code>. I don't want to encode that information into the authority system, and end up with the following new authority:</p>

<pre><code>VIEW_COMPANY_TRANSACTIONS_FOR_COMPANY_A
</code></pre>

<p>The above authority seems to mix up the filtering of the views and the authority itself which makes everything somewhat tedious and inflexible.</p>

<p>In another example, I have the following authority:</p>

<pre><code>APPROVE_TRANSACTION
</code></pre>

<p>which allows the user to hit the endpoint:</p>

<pre><code>POST /company/{companyName}/transactions/{id}/approvals
</code></pre>

<p>But what if the approval can only be done if the <code>transaction.amount &lt; maxAmount</code> in which case, it's even harder to encode this into a new hardcoded authority.</p>

<p>Note that these authorities may also be included in a JWT token, so they must somewhat <em>transferable</em> as well.</p>

<p>What's the best way to design such a system? Any tips?</p>
","106540","","252124","","2017-06-18 00:12:24","2017-06-18 00:12:24","When designing an activity-based authorization system, how should additional conditional checks be handled?","<design><rest><api><security><microservices>","0","0","","","","CC BY-SA 3.0"
"351132","1","351137","","2017-06-18 13:34:14","","1","839","<p>I have a program that can get code from a user as input (This question is language-agnostic, though I am primarily interested in answers for Java and Python). Usually, this code is going to be useful, but I don't have a guarantee that the user isn't making a mistake, or even deliberately giving malicious code.</p>

<p>I want to be able to execute this code safely, i.e. without harmful side effects if it turns out to be faulty or malicious.</p>

<p>More specifically:</p>

<ul>
<li><p>the user specifies that the input code should operate on some objects that exist in the primary program (the program that gets the code from the user and executes it). Optimally, it should be able to access these objects directly, but sending them over to the child program through some communication protocol or a file is also fine.</p></li>
<li><p>in the same way, the code should generate some output that is transmitted back to the parent program.</p></li>
<li><p>the user can specify whether the code should be allowed to access any other data, whether it should be allowed to read or write to files, and whether it should have access to any other interfaces or OS methods.</p></li>
<li><p>it is possible to specify a maximum runtime after which the code will be interrupted if it hasn't finished executing yet.</p></li>
<li><p>the parent program and the code to execute may be different languages. You can assume that the programs necessary to compile and execute the given code are installed and available to the parent program. If the languages are different assume that some standard format like JSON can be used for transmitting the data (or is there a way to do this more efficiently?)</p></li>
</ul>

<hr>

<p>I think that this should be doable with a Virtual Machine. However, speed is a concern and I want to be able to execute many code blocks quickly, so that creating and tearing down a VM for each of them may be prohibitively expensive.</p>

<p>Another option is creating a sandbox, which e.g. Java can do, but as far as I am aware only for executing other Java code. I am unable to find a solution to do this with arbitrary languages.</p>

<hr>

<p>For which languages does this work well, for which is it difficult?</p>

<p>Is this easier on some OS than on others?</p>
","275694","","","","","2017-06-18 15:29:27","safely executing arbitrary code","<security><virtual-machine>","1","2","","","","CC BY-SA 3.0"
"125867","1","125872","","2011-12-18 22:07:51","","5","3516","<p>I'm developing an authentication library (*) for a website and I realized that maybe I'm not completely understanding what an ""autologin"" feature is, and how to develop it. </p>

<p>While gathering infos and studying other code I came across a couple of libraries which implement the option to login the user without having to sign in (these libraries are Tank Auth and Ion Auth, built for the PHP framework CodeIgniter); basically they work on creating a cookie which, in case the user is not logged (session datas are not set) but this cookie is found, it allows them to login nonetheless.</p>

<p>Ok, so far it's clear. What I don't understand, though, is why both library <em>delete</em> the autologin cookie when the user logs out. I mean: I log in, I check the ""remember me"" option (**), I do what I need to do in my admin panel, then I log out; if the autologin cookie is deleted, next time I'll have to log in again by filling the form, ignoring the option I flagged. What's its purpose then? I thought this ""autologin"" would be an extendend login which allowed me to <em>avoid</em> having to fill in the sign in form again. </p>

<p>So I went on and developed my autologin feature, but of course I bumped into the problem of not being able to logout <em>at all</em>, as I'm not deleting it. So I log out, redirect to the home page, then go to the admin panel and the system logs me in...well, it works as expected, but I'm not sure if this is how it's meant to be...How should this be done correctly?</p>

<p>Can someone explain to me how this actually should work? I'm getting a bit confused</p>

<p>P.S. Don't know if this is the right place to ask it, or if SO is a better fit; I'm sorry if I posted on the wrong SE site.</p>

<p>(*) Please don't tell me <em>""don't reinvent the wheel""</em> or any variant of it; I'm doing this to learn and I'm planning to make it an open source project for the public amusement, so I volutarily <em>do</em> want to reinvent the wheel, at the cost of making it oval.</p>

<p>(**) I think I guessed the difference between the ""remember me"" option and the ""autologin"" feature; so far, I didn't consider the first one ( 1-because many browsers ask you to do that nonetheless; 2-because I don't know how to do it right, i.e. how to have the login fields automatically filled without this posing the security threat of having the password stored in clear text inside a cookie), but please tell me if I misunderstood this also..</p>
","43304","","","","","2011-12-18 23:48:34","Did I understand the website ""autologin"" feature right?","<security><authentication><login>","3","2","","","","CC BY-SA 3.0"
"45855","1","","","2011-02-09 14:41:59","","6","1667","<p>When I changed my Facebook password yesterday, by mistake I entered the old one and got this:</p>

<p><img src=""https://i.stack.imgur.com/T1M59.png"" alt=""Screen capture of facebook login""></p>

<p>Am I missing something here or this is a big potencial risk for users.</p>

<p>In my opinion this is a problem BECAUSE it is FaceBook and is used by, well, everyone and the latest statistics show that 76.3% of the users are idiots [source:<a href=""https://softwareengineering.stackexchange.com/users/5014/trufa"">me</a>], that is more that 3/4!!</p>

<p>All kidding aside:</p>

<ul>
<li>Isn't this useful information for an attacker?</li>
<li>It reveals private information about the user!</li>
<li>It could help the attacker gain access to another site in which the user used the same password

<ul>
<li>Granted, you should't use use the same password twice (but remember: 76.3%!!!)</li>
</ul></li>
<li>Doesn't this simply increase the surface area for attackers?</li>
<li>It increases the chances of getting useful information at least.</li>
<li>In a site like Facebook 1st choice for hackers and (bad) people interested in valued personal information shouldn't anything increasing the chance of a vulnerability be removed?</li>
</ul>

<p>Am I missing something? Am I being paranoid? Will 76.3% of the accounts will be hacked after this post?</p>
","5014","","-1","user40980","2017-04-12 07:31:28","2013-10-04 15:14:46","Is it safe to display information about old passwords on login failure?","<security><passwords><vulnerabilities>","5","2","","","","CC BY-SA 3.0"
"46029","1","","","2011-02-09 20:26:15","","5","524","<p>I've come across SQL injection vulnerabilities on my companies ecommerce page. It was fairly poorly put together. I believe I have prevented future attempts however we are getting calls about fraudulent credit card charges on our site and others. This leads me to believe that someone was able to get a list of our credit card numbers. What doesn't make sense is that we don't store that information and we use Authorize.net for the transaction. If someone was able to get the CC#s, what should I do next? Inform ALL of our customers that someone broken into our system and stole their information? I have a feeling that will be bad for business.</p>
","","user16566","","","","2011-02-09 20:44:23","Steps after SQL Injection detected","<security>","4","2","","","","CC BY-SA 2.5"
"351370","1","","","2017-06-21 19:27:07","","0","85","<p>I created a wiki-like application. Currently, there is no security, so all the contents have ""edit""-buttons where the user can edit everything. Now, I want my application to have a public read-only access and the read/write access to edit content.</p>

<p>First of all, I think it is useful to do that with two roles: viewer and editor. For editors, there has to be an authentication mechanism etc..</p>

<p>But then, I see two ways:</p>

<ol>
<li><p>Make an ""editors portal"" and a ""viewers portal"". Editors portal is an admin-like interface for good editing. Viewers portal is good for just reading.</p></li>
<li><p>Make just one portal for read-access, but when the user is an editor, there is something like an Editing-Layer on top of that. E.g. additional ""Edit""-Buttons or mouseover-hint-buttons...something like that. </p></li>
</ol>

<p>The 2-portals solution seems to be common for me. Do you have any experiences with the layer-solution or some other advice?</p>
","276041","","173647","","2017-07-18 23:28:04","2017-07-18 23:28:04","Security concept for a wiki-like application","<security><user-experience>","1","1","","","","CC BY-SA 3.0"
"46434","1","46460","","2011-02-10 21:56:44","","82","57251","<p>Why does it seem so easy to pirate today?</p>

<p>It just seems a little hard to believe that with all of our technological advances and the billions of dollars spent on engineering the most unbelievable and mind-blowing software, we still have no other means of protecting against piracy than a ""serial number/activation key"". I'm sure a ton of money, maybe even billions, went into creating Windows 7 or Office and even Snow Leopard, yet I can get it for free in less than 20 minutes. Same for all of Adobe's products, which are probably the easiest.</p>

<p>Can there exist a fool-proof and hack-proof method of protecting your software against piracy? If not realistically, how about theoretically possible? Or no matter what mechanisms these companies deploy, can hackers always find a way around it?</p>
","7631","","31260","","2016-02-26 04:24:31","2016-02-26 04:24:31","How can software be protected from piracy?","<security>","17","18","","","2011-02-11 03:26:08","CC BY-SA 3.0"
"236341","1","","","2014-04-18 23:04:59","","0","115","<p>I was wondering, if it makes sense to encrypt passwords for external services stored in my config file with an symmetric encryption algorithm?</p>

<p>On the one hand I think, if someone gets access to the config file, he will probably also get access to the code and it will relatively easy to decrypt the passwords... on the other hand I am not comfortable to store the passwords in plain text either.</p>

<p>Whats your opinion on this topic? Are there any ""best practices""?</p>
","127395","","","","","2014-04-19 02:55:22","Encyption for passwords in config file?","<security><encryption><configuration>","1","4","0","2015-07-27 16:04:48","","CC BY-SA 3.0"
"236459","1","","","2014-04-20 16:11:26","","0","311","<p>I've been finding a lot of blog posts claiming JS encryption is unsafe, here's a couple of detailed ones:</p>
<p><a href=""http://www.matasano.com/articles/javascript-cryptography/"" rel=""nofollow noreferrer"">http://www.matasano.com/articles/javascript-cryptography/</a></p>
<p><a href=""http://rdist.root.org/2010/11/29/final-post-on-javascript-crypto/"" rel=""nofollow noreferrer"">http://rdist.root.org/2010/11/29/final-post-on-javascript-crypto/</a></p>
<p>My question is, if browsers truly are inherently unsafe then, by extension, entering any PCI-related info in the browser is unsafe - regardless of JS encryption, HTTPS, or any other security measures? Which would imply that malicious parties should be taking major advantage of this fact, right? Could someone provide specific examples where browser vulnerabilities were leveraged to steal <strong>massive</strong> amounts of PCI-info/PII (by &quot;massive&quot; I mean comparable to the amount that could be obtained by hacking into the hosting servers/DB)?</p>
<p>Also, despite all those posts describing security flaws there's a proliferation of payment services and JS crypto libraries - does that indicate that most companies/communities:</p>
<ol>
<li>are unaware of browser vulnerabilities?</li>
<li>are simply disregarding the underlying issues and jumping on the bandwagon to make some dough?</li>
<li>have weighted the (possibly low) likelihood of someone going through the trouble of exploiting browsers and decided it's still worth to capture payments through browsers?</li>
</ol>
<p>EDIT</p>
<p>Using SSL/TLS addresses some of the issues, but definitely not all. Here are a few notable issues that fall outside of the area that SSL/TLS can solve (quoted directly from the Matasano blog post):</p>
<blockquote>
<p>The prevalence of content-controlled code.</p>
<ul>
<li>We mean that pages are built from multiple requests, some of them conveying Javascript directly, and some of them influencing Javascript using DOM tag attributes (such as &quot;onmouseover&quot;).</li>
</ul>
<p>The malleability of the Javascript runtime.</p>
<ul>
<li>There is no reliable way for any piece of Javascript code to verify its execution environment. Javascript crypto code can't ask, &quot;am I really dealing with a random number generator, or with some facsimile of one provided by an attacker?&quot; And it certainly can't assert &quot;nobody is allowed to do anything with this crypto secret except in ways that I, the author, approve of&quot;. These are two properties that often are provided in other environments that use crypto, and they're impossible in Javascript.</li>
</ul>
<p>What else is the Javascript runtime lacking for crypto implementors?</p>
<ul>
<li>Two big ones are secure erase (Javascript is usually garbage collected, so secrets are lurking in memory potentially long after they're needed) and functions with known timing characteristics. Real crypto libraries are carefully studied and vetted to eliminate data-dependant code paths --- ensuring that one similarly-sized bucket of bits takes as long to process as any other --- because without that vetting, attackers can extract crypto keys from timing.</li>
</ul>
</blockquote>
<p>Again, my main point is that, technically, once a credit card number (or some other important piece of info) is entered into a text field of a page there's a chance that it's been compromised - and at that, compromised more easily then if it were entered in the native application.</p>
","127510","","-1","","2020-06-16 10:01:49","2014-04-21 00:00:50","Browser security and payments","<javascript><security><browser><encryption>","1","7","","","","CC BY-SA 3.0"
"46451","1","46456","","2011-02-10 22:28:39","","6","609","<p>I am designing a login system for a project, and have an issue about it requiring two trips to the database when a user logs in.</p>

<ol>
<li>User types in username and password</li>
<li>Database is polled and password hash is retrieved for comparative purposes (first trip)</li>
<li>Code tests hash against entered password (and salt), and if verified, resets the session ID</li>
<li>New session ID and username are sent back to the database to write a row to the login table, and generate a login ID for that session.</li>
</ol>

<p>EDIT: I am using a random salt.</p>

<p>Does this design make sense? Am I missing something? Is my concern about two trips unfounded?</p>

<p>Comments and suggestions are welcome.</p>
","","user2039","","user2039","2011-02-10 22:53:54","2011-03-05 17:21:02","Are two database trips reasonable for a login system?","<design><database><security>","3","3","","","","CC BY-SA 2.5"
"126645","1","126650","","2011-12-22 21:31:55","","1","680","<p>We develop a Windows client application that locally caches a user's credentials for connecting to our server application using the <strong><a href=""http://www.microsoft.com/indonesia/msdn/credmgmt.aspx"" rel=""nofollow"">Windows Credential Management API</a></strong>.  </p>

<p><strong>Our caching logic works in the following way:</strong></p>

<ol>
<li>The user opens the application and <strong>selects a server</strong> in the UI.  It then queries the server for authentication requirements.  (If no credentials are needed, then we just connect without authentication.)</li>
<li>The application <strong>reads the cache</strong> to see if there are cached credentials.</li>
<li>If there are <strong>existing cached credentials</strong>, they are used.  Otherwise, the Windows API is used to bring up a <strong>dialog box</strong>.</li>
<li>The application attempts to <strong>authenticate with the server</strong> using the credentials.</li>
<li>If the connection is a success, then the credentials used are <strong>cached for the lifetime of the Windows session</strong> (this is a feature of the Windows API).  Otherwise, we <strong>clear the cache</strong> and return to step 3.</li>
</ol>

<p><strong>The question is: are there other valid situations where the credential cache should be cleared?</strong>  In other words, what would you consider to be best practices on how to manage the lifetime and invalidation logic for this potentially sensitive information?</p>

<p><em>(Since I will probably be asked, the information we store using this API is encrypted using our own encryption logic, and stored in memory via SecureString.  No doubt there are potential holes in this approach, but that is for another discussion.)</em></p>
","39690","","","","","2011-12-22 22:03:42","When should I invalidate a cache of a user's credentials?","<security><caching>","1","0","","","","CC BY-SA 3.0"
"126700","1","","","2011-12-23 06:11:16","","6","3716","<p>I am trying to build a system for my company which wants to check for unusual/abusive pattern of users (mainly web scrapers).</p>

<p>Currently the logic I have implemented parses the http access logs and takes into account the following parameters to calculate the potential of a user being a scraper or bot:</p>

<ol>
<li><p>It checks v/s HTTP 'POST/GET' requests ratio for each IP</p></li>
<li><p>It calculates the ratio of unique URLs and total number of hits (sparsity) by each IP</p></li>
</ol>

<p>Based on the above two parameters, we try to block any IP showing unusual behaviour, but these two parameters alone have not been sufficient for bot detection. Thus I would like to know:</p>

<ol>
<li><p>Are there any other parameters which can be included to improve the detection?</p></li>
<li><p>I found a paper published in ACM library which follows the Bayesian approach to detect a crawler. Has anyone used this? How effective is this?</p></li>
<li><p>Stack Overflow and other high traffic sites have such kind of systems deployed, what logic do they follow to keep unwanted spammers/crawlers away in real time?</p></li>
</ol>
","43624","","88040","","2015-06-03 10:22:38","2015-06-03 10:22:38","Development of a bot/web crawler detection system","<security><web-crawler><heuristics><crawlers>","4","10","","","","CC BY-SA 3.0"
"236810","1","","","2014-04-23 23:47:50","","1","1348","<p>I am making HTTP calls on the client side and the server expects me to supply a client nonce. It needs to be 4 bytes long. I am planning to use this combination:</p>

<pre><code>base64(parts of the MAC address + random bits generated by RNG)
</code></pre>

<p>Given that the protocol is created by experts (thus its security is not to be questioned), is my nonce calculation acceptable in your view ?</p>
","127889","","","","","2014-07-04 12:14:21","Is it safe to generate client nonces using random number generator?","<security><http><protocol>","1","4","","","","CC BY-SA 3.0"
"236846","1","","","2014-04-24 09:44:59","","1","1657","<p>I currently have an app which basically runs two halves of an API - a restful API for the web app, and a synchronisation API for the native clients (all over SSL).</p>

<p>The web app is completely javascript based and is quite similar to the native clients anyway - except it currently does not work offline.</p>

<p>What I'm hoping to do is merge the fragmented APIs into a single restful API. The web app currently authenticates by issuing a cookie to the client whereas the native clients work using a custom HMAC access token implementation. Obviously a public/private key scenario for a javascript app is a little pointless.</p>

<p>I think the best solution would be to create an OAuth2 endpoint on the API (like Instagram, for example <a href=""http://instagram.com/developer/authentication/"" rel=""nofollow"">http://instagram.com/developer/authentication/</a>) which is used by both the native apps and the web app.</p>

<p>My question is, in terms of security how does an implicit OAuth2 flow compare (storing the access token in local storage) to ""secure"" cookies? Presumably although SSL solves man in the middle attacks, the user could theoretically grab the access token from local storage and copy it to another machine?</p>
","113837","","","","","2014-10-21 15:42:11","Implicit OAuth2 endpoint vs. cookies","<security><api><authentication><oauth>","1","0","","","","CC BY-SA 3.0"
"351965","1","","","2017-06-30 19:21:06","","8","4440","<p>I am implementing a token-based authentication system for a REST API using a short-lived access token and a long-lived refresh token. This is an abstract overview of the relevant API endpoints (HTTPS is enforced for all endpoints):</p>

<h2>Endpoints:</h2>

<pre><code>POST /register/
POST /login/
POST /logout/
POST /password/change/
</code></pre>

<hr>

<h2>Implementation:</h2>

<p><code>POST /register/</code>:</p>

<ul>
<li>Request: Client sends username, email, and password in JSON.</li>
<li>Server actions:

<ol>
<li>Validates input, creates user in database (stores user id, username, email, and password hash).</li>
<li>Creates short-lived access token in JWT format (contains user id, issued date, and expiration date).</li>
<li>Creates long-lived refresh token as a UUID string and stores it in database (stores user id and refresh token).</li>
</ol></li>
<li>Response: Server returns access token and refresh token in JSON.</li>
</ul>

<p><code>POST /login/</code>:</p>

<ul>
<li>Request: Client sends username and password in JSON.</li>
<li>Server actions:

<ol>
<li>Validates input, checks if credentials are valid by checking database.</li>
<li>If credentials are valid, creates short-lived access token and long-lived refresh token as mentioned previously.</li>
</ol></li>
<li>Response: Same as <code>/register/</code>, returns access token and refresh token in JSON.</li>
</ul>

<p><code>POST /logout/</code>:</p>

<ul>
<li>Request: Client sends <strong>refresh</strong> token in <code>Authorization</code> header as <code>Bearer</code> token.</li>
<li>Server actions:

<ol>
<li>Validates refresh token by checking refresh token database.</li>
<li>Removes the refresh token from the database.<br>
<strong>Note:</strong> This leaves the access token valid, but since it will be short-lived (1 hour or so, I think it should be fine).</li>
</ol></li>
<li>Response: Returns whether the logout request was successfully processed in JSON.</li>
</ul>

<p><code>POST /password/change/</code>:</p>

<ul>
<li>Request: Client sends <strong>access</strong> token in <code>Authorization</code> header as <code>Bearer</code> token, and also sends old password and new password in JSON through HTTPS.</li>
<li>Server actions:

<ol>
<li>Decodes access token to retrieve the user, and checks the user's old password with the database.</li>
<li>Sets password hash of user in the database to new password's hash.</li>
<li>Removes all refresh tokens associated with user in the refresh token database to essentially log out existing sessions (leaves short-lived access tokens valid).</li>
</ol></li>
<li>Response: Returns whether the password change request was successfully processed in JSON.</li>
</ul>

<hr>

<h2>Questions:</h2>

<ol>
<li>Is this approach secure? Specifically:

<ul>
<li>Is sending the username and password through JSON safe if done over HTTPS? How would I prevent unauthorized domains from making calls to this endpoint? Furthermore, how would I prevent programmatic logins?</li>
<li>Should the refresh tokens be hashed before storing them in the database, or am I just being paranoid?</li>
</ul></li>
<li><strong>If the client were a web browser, how would I securely store the refresh token on the client?</strong>

<ul>
<li>One idea I have for storing the refresh token is: when the user logs in, in addition to sending the refresh token to the client, the server stores the token in an <code>HttpOnly</code> cookie with a <code>secure</code> flag. Authorization will still be done through the <code>Authorization</code> header, but when the client initially loads up, it can send a <code>GET</code> request to an endpoint that checks if the cookie contains a valid refresh token, and if so, return it to the user in JSON. In other words, the only time the cookie will actually be used is to return the refresh token inside the cookie to the client. Is this approach secure? I think it will prevent CSRF as there are no side effects when requesting the refresh token from the cookie, but is there another way an attacker could intercept the refresh token (assuming HTTPS)?</li>
</ul></li>
</ol>
","150456","","","","","2017-07-03 08:12:02","Token-based authentication using access and refresh tokens","<design><rest><api><security><authentication>","1","3","","","","CC BY-SA 3.0"
"126766","1","","","2011-12-23 14:08:15","","0","2113","<p>We have a unique situation (at least for me, first time seeing this).</p>

<p>We have a web form where accountants can fill in requests and that part is taken care of.  But after their login we redirect them to a third-party website where we need more information from them. The process is crazy right now since we have to give our account login info to all people filing with us.  So is there a way in PHP or any other solution where we can after that form on our website auto login with our information to that third party website in a way that our credentials are not visible to the users using the service?</p>
","43652","","","","","2017-03-20 14:58:30","How to do a login page for third party service without letting them sign on?","<php><security><login>","1","3","","","","CC BY-SA 3.0"
"126924","1","126955","","2011-12-24 17:46:28","","16","8497","<p>It seems less common with newer websites, but many websites I need an account on (like for paying bills, etc.) prevent me from creating a password with spaces in it.  This only makes things more <a href=""http://xkcd.com/936/"">difficult to remember</a>, and I am aware of no database or programming restrictions on spaces in passwords, encrypted or (heaven forbid) otherwise.  Why, then, is the spacebar so commonly discriminated against when it comes to signing up for a site?</p>
","41793","beanland","","","","2011-12-25 10:08:37","Why do certain sites prevent spaces in passwords?","<security><login><privacy>","4","3","","","","CC BY-SA 3.0"
"352434","1","","","2017-07-09 21:08:03","","0","79","<p>I'm looking for perspectives on how risk analysis is performed when there's not precisely a ""dollar value"" associated with the risk, as in an Open Source project. Traditionally, risk analysis takes the form of</p>

<p>Asset Value X Annual Probability of Loss X Probable Outcome of Loss = Risk</p>

<p>Open source community driven projects provide great value to people, and their development faces significant risks, both from a project standpoint (ranging from wasted developer cycles to failure to ever deliver) and from a product standpoint (users could not like the product, and update could make people leave or a security hole could leave millions of systems vulnerable to a nasty malware attack). Nevertheless, it doesn't quite lend itself to this formula.</p>

<p>Who is responsible for identifying and managing these risks in Open Source community driven projects? How does the team decide which risks are most significant to the outcome of the project? Are there any official standards or approaches in this area?</p>

<p>In the case of <em>adopting</em> Open Source, I believe this question has some solid answers:</p>

<p><a href=""https://www.federalreserve.gov/boarddocs/srletters/2004/SR0417a1.pdf"" rel=""nofollow noreferrer"">https://www.federalreserve.gov/boarddocs/srletters/2004/SR0417a1.pdf</a>
<a href=""https://opensource.com/article/17/3/risks-open-source-project-management"" rel=""nofollow noreferrer"">https://opensource.com/article/17/3/risks-open-source-project-management</a></p>

<p>On the other hand, I don't see any literature or voices speaking to this aspect of the creation of such software. Any input from people actively involved in this community?</p>
","277478","","","","","2017-07-10 01:03:24","Risk Analysis in Open Source Community Driven Projects","<open-source><security><risk><risk-assesment>","1","4","","","","CC BY-SA 3.0"
"237532","1","237535","","2014-04-30 21:14:15","","1","300","<p>If I retrieve a random number from a database (e.g. RAND() in SQL Server) or using a programming language and send this in some form back to a client machine, is there an economic chance I will be sending an indicator of what's in my server's memory that might form a security problem (like revealing my schema, etc)?</p>
","63575","","","","","2014-04-30 21:33:33","Are random number generators security holes?","<security><random><server-security>","2","7","0","","","CC BY-SA 3.0"
"352491","1","","","2017-07-10 13:56:42","","1","280","<p>I'm planning on making a web app that'll use MySQL as the database, Java/Grails as the backend and JavaScript/VueJS as the frontend and then they'll communicate using only RESTful JSON APIs (that way I can have frontend apps running on any platform, all with the same backend). What I'm thinking is that every action (that requires db access) will have to be authenticated so I'm thinking that when a user logs in (successfully) I'll create an ""auth token"" on the backend, encrypt it and send it to the front end where it gets stored in browser storage so from that point on every time a user does something that token gets used for authentication. But what I'm not sure about how to implement is authentication for user registration (and any other action that doesn't require the user to be logged in, e.g. sending a Contact Us query). For example I could have a ""REST_PASSWORD"" variable in the front-end JavaScript that gets used for these unlogged-in actions but that's essentially useless because anyone can access the JavaScript code and grab the password.</p>

<p>So my question is what is the best way to implement user registration through a JSON REST API so that my application doesn't get taken advantage of by bots/malicious users? It's been suggested that I implement CAPTCHA on the frontend and while I'm definitely gonna give that a look, I'm wondering if that'll be enough security and/or if I need more that?</p>
","224521","","173647","","2017-07-10 17:54:27","2017-07-10 17:54:27","User registration web service","<rest><security><authentication>","0","1","","","","CC BY-SA 3.0"
"352512","1","352513","","2017-07-10 21:23:24","","1","2248","<p>I'm currently building an Android app that uses OAuth to sign in to a service. With OAuth, I need to provide a client ID and a client secret to the service so it can identify my app. Right now, I'm storing the credentials like this:</p>

<pre><code>public class Creds {
    public static final String CLIENT_ID = ""THE_CLIENT_ID"";
    public static final String CLIENT_SECRET = ""THE_CLIENT_SECRET"";
}
</code></pre>

<p>Obviously, this is not secure at all. Anyone can just <a href=""https://stackoverflow.com/q/3593420/4077294"">decompile</a> the APK file and see the strings instantly. How can I prevent people from doing so?</p>

<p>I wouldn't consider an obfuscator an acceptable solution since anyone who goes through enough effort can still recreate the strings.</p>

<p><strong>note:</strong> This is not a dupe of <a href=""https://softwareengineering.stackexchange.com/questions/205606/strategy-for-keeping-secret-info-such-as-api-keys-out-of-source-control"">this question</a> since that discusses how to keep strings out of source control, not hide them inside the APK file. For example, a configuration file containing the keys could be kept out of source control but present in the decompiled APK.</p>

<p><strong>edit:</strong> What if I put the strings in native code and retrieved them via JNI? Native code is much harder to decompile.</p>
","161912","","161912","","2017-07-10 21:36:35","2017-07-10 21:51:18","How to prevent users from decompiling app to find API key?","<api><security><android><oauth><reverse-engineering>","1","2","","","","CC BY-SA 3.0"
"127809","1","127810","","2011-12-31 00:24:15","","21","4799","<p>Which aspects do I need to consider when designing and publishing software that must meet the US export restrictions for cryptographic software?</p>

<p><a href=""http://en.wikipedia.org/wiki/Export_of_cryptography_in_the_United_States"">Wikipedia</a> says that there are various categories which you can assign to cryptographic software. And the export destination (e.g. China, Russia) does play a major role as well. But I didn't really understand those restrictions and their effect on my work.</p>

<p>Can anybody explain that to me? </p>

<p>I'm asking because if you try to publish your application (e.g. on Apple's App Store or Android's Market) you have to assure that your application meets the US export restrictions. And there are lots of applications who offer secure information storage, e.g. for passwords. </p>

<p>Have they all notified the government and asked for a review? Of course, you cannot know if they did. But do they need to do this?</p>
","44111","Marco W.","25936","","2011-12-31 01:09:24","2012-01-10 10:43:18","Programmers' concerns about export restrictions from the United States","<security><encryption><cryptography>","4","5","","","","CC BY-SA 3.0"
"352653","1","352656","","2017-07-12 18:29:36","","8","5515","<p>I'm in the process of writing a development philosophy document for a small groups of developers (6.5 developers to be specific), but it's ideally a document that will set down the company's best practices as our team scales up. In the process of creating this document I've been interviewing each engineer to understand their development processes, to make something that's a good mix of helpful in eliminating redundant work, and not overly prescriptive.</p>

<p>Most of the issues I've found there are pretty good solutions for, but there's something that I assume must be a common issue that I can't seem to find a good solution for. That's managing environment variables that are required for local development. For instance, we've got a development key for AWS. It's required to use a lot of functions and features within the application we're developing.</p>

<p>At present the process is pretty bad. Obviously we can't commit an env file to Github as it's sensitive information that we don't want the entire org to have access to. Right now we have a secure S3 file that contains the env file required for development.</p>

<p>We've found that there are a lot of issues both keeping this up-to-date both in terms new env variables making it into this file, and pulling this down during development. It's not very surprising since it's a single piece of the development cycle that's not a part of Github, and it's something that only has to be updated or accessed pretty rarely. That said, when people run into issues it can be very frustrating since realizing that you've got the wrong S3 key, or something isn't a standard kind of error-checking.</p>

<p>Are there any solutions for managing environment variables that people have found work particularly well? We had an employee write a repo that is the best solution we've currently got (<a href=""https://github.com/sihrc/privvy"" rel=""noreferrer"">https://github.com/sihrc/privvy</a>), but is there something better?</p>

<p>EDIT: The reason why private repositories are not the solution for this problem (we're already using private repos)</p>

<ol>
<li><p>These variables aren't limited to a single project. The development
env file for instance is </p></li>
<li><p>Version-controlling this file would make development difficult or impossible. If we roll an API key, that's the API key that we
need to use forever more. If you need to revert to an older revision
and the key changes, that's a problem</p></li>
<li><p>It's not strange for us to have to add a third-party to a repo. It's VERY important that they be able to view the code, but not the
credentials.</p></li>
</ol>
","83817","","83817","","2017-07-12 19:31:58","2021-06-18 01:53:49","How to manage environment variables in local development","<security><development-process><development-environment>","1","16","","","","CC BY-SA 3.0"
"128044","1","","","2012-01-02 18:26:48","","0","355","<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""https://softwareengineering.stackexchange.com/questions/10340/how-do-you-prevent-the-piracy-of-your-software"">How do you prevent the piracy of your software?</a>  </p>
</blockquote>



<p>Is possible to protect some file from copying if you are administrator of machine? I heard some story about some behavior: one software developer sells his software in some way. He is installing it on every client's computer and this software does not work on other computers or cannot be copied physically. How to implement the first and second protection. Is it effectively protection if software costs about $100 for all copies across client's company? </p>
","1483","","-1","","2017-04-12 07:31:27","2016-02-27 16:20:18","How to protect own software from copying","<security>","0","0","0","2012-01-03 14:46:43","","CC BY-SA 3.0"
"352832","1","352833","","2017-07-15 01:19:04","","2","1390","<p>I'm currently in the process of writing an API that will interact with a web application, iPhone app, and Android app for my work.  The API is pretty simple and deals with pilots and their availability.</p>

<p>Since I am creating the API and the client-side applications it seems to me that OAuth2 is overkill for this since I don't really care if username/password passes through the client applications.</p>

<p>I do need to have different user_roles such as 'Admin', 'Supervisor', and 'User' and then restrict access to API calls based on this.</p>

<p>Is there a simple way to go about this?  Basic authentication over SSL?</p>
","274856","","222996","","2017-07-15 21:35:17","2017-07-17 09:11:21","OAuth2 overkill for small business","<php><security><authentication><authorization>","3","1","","","","CC BY-SA 3.0"
"128434","1","","","2012-01-05 00:27:36","","-1","234","<p>As a digital security consultant when is it 'ok' to use tools someone else made (dumb to reinvent the wheel, right?) and when should I make my own?</p>
","42650","","41811","","2012-01-05 16:16:20","2012-01-05 16:29:31","Computer security expert using pre-made tools or own?","<productivity><security><hacking>","5","2","0","2014-08-11 14:46:53","","CC BY-SA 3.0"
"49067","1","49078","","2011-02-17 21:47:36","","38","6786","<p>While working on a project for my company, I needed to build functionality that allows users to import/export data to/from our competitor's site. While doing this, I discovered a very serious security exploit that could, in short, perform any script on the competitor's website.</p>

<p>My natural feeling is to report the issue to them in the spirit of good-will. Exploiting the issue to gain advantage crossed my mind, but I don't want to go down that path. </p>

<p>So my question is, would you report a serious vulnerability to your direct competition, in order to help them? Or would you keep your mouth shut? Is there a better way of going about this, perhaps to gain at least some advantage from the fact that I'm helping them by reporting the issue? </p>

<p><strong>Update (Clarification)</strong>:</p>

<p>Thanks for all your feedback so far, I appreciate it. Would your answers change if I were to add that the competition in question is a behemoth in the market (hundreds of employees in several continents), and my company only started a few weeks ago (three employees)? It goes without saying, they most definitely will not remember us, and if anything, only realize that their site needs work (which is why we entered this market in the first place). </p>

<p>This might be one of those moral vs. business toss-ups, but I appreciate all the advice.</p>
","17610","","17610","","2011-02-20 21:09:19","2013-10-08 13:19:42","What to do if you find a vulnerability in a competitor's site?","<business><security><ethics><vulnerabilities>","14","7","","","2013-05-11 21:06:45","CC BY-SA 2.5"
"238398","1","","","2014-05-08 14:23:19","","1","838","<p>If you have a menu ""Admin tasks"" and different admin tasks (like 10) that you could separately assign to each user, but there are users who don't have any admin tasks, how would you deal with ""Hiding admin menu""  for those users?</p>

<p>I was thinking of 3 ways:</p>

<p>1) Javascript, check if Admin menu is empty and then hide it.</p>

<p>2) Check for all permissions in Admin menu, with a counter, and show it if counter > 0. And then also re-check the permissions for each item to show.</p>

<p>3) Save all permissions in associative array. Test all and assign ' true' to granted items. When building the menu, have a function that tests if there is at least one permission granted. I wouldn't need to re-check permissions against DB, just against the array for each item.</p>

<p>Is there any better way?</p>
","66889","","","","","2015-03-04 20:24:08","Hide admin menu if no admin option is available","<security><html><permissions>","2","1","","","","CC BY-SA 3.0"
"353240","1","354358","","2017-07-21 16:29:07","","7","20084","<p>I have an api where visitor can send an email through subscription:</p>

<p>/api/subscribe</p>

<p>To prevent massive load due to public exposure, how can I secure this endpoint? Do I have to use database or can I do it without that with some kind of caching, inmemory etc which releases ever 10 minutes etc?</p>
","102291","","","","","2017-09-30 18:11:06","What approach to use to prevent multiple requests to API which is exposed to public","<security><api-design>","5","2","","","","CC BY-SA 3.0"
"49326","1","49349","","2011-02-18 15:41:56","","20","2263","<p>If I create a login for an app that has middle to low security risk (in other words, its not a banking app or anything), is it acceptable for me to verify a password entered by the user by just saying something like:</p>

<pre><code>if(enteredPassword == verifiedPassword)
     SendToRestrictedArea();
else
     DisplayPasswordUnknownMessage();
</code></pre>

<p>It seems to easy to be effective, but I certainly would not mind if that was all that was required. Is a simple check on username/password combo enough?</p>

<p><strong>Update:</strong> The particular project happens to be a web service, the verification is entirely server side, and it is not open-source. Does the domain change how you would deal with this?</p>
","3792","","3792","","2011-02-18 21:37:12","2012-06-10 07:57:49","Is an 'if password == XXXXXXX' enough for minimum security?","<security><passwords><validation>","9","9","","","","CC BY-SA 2.5"
"238635","1","","","2014-05-10 15:28:46","","2","441","<p>I'm in the process of building a .NET MVC website where a requirement is that admin users should be able to lock accounts to not only prevent future log-ins but to also immediately revoke access to the site for a given authenticated user.</p>

<p>Locking the account is easy, but is there an established method of preventing access immediately in this type of scenario. Is it a case of checking on each request whether the requester's account is locked in the db and then clearing the authentication cookie if required?</p>

<p>I'd appreciate any pointers anyone has.</p>
","99465","","","","","2014-06-24 16:01:54","Standard ways of revoking user access to a site","<c#><asp.net><security>","1","4","","","","CC BY-SA 3.0"
"49550","1","145633","","2011-02-19 00:03:26","","1638","818944","<p>Which hashing algorithm is best for uniqueness and speed? Example (good) uses include hash dictionaries. </p>

<p>I know there are things like <a href=""http://en.wikipedia.org/wiki/SHA-2"">SHA-256</a> and such, but these algorithms are <strong>designed</strong> to be <strong>secure</strong>, which usually means they are slower than algorithms that are less <em>unique</em>. I want a hash algorithm designed to be fast, yet remain fairly unique to avoid collisions. </p>
","483","","208831","","2019-11-22 08:11:00","2021-05-18 06:07:10","Which hashing algorithm is best for uniqueness and speed?","<algorithms><security><performance><hashing><unique-data>","11","30","","","","CC BY-SA 3.0"
"128989","1","128992","","2012-01-07 19:41:30","","1","4566","<p>From a security perspective, the special characters like '&amp;' or <code>&lt;b&gt;</code> are a big no no in URLs and query strings. I could find the articles that explained the ways to bypass this restriction, but could find something that explained with example how can this be a security risk.</p>

<p>Please explain the risks of these special characters. The question is simpler and I could google a bit more to find the answer. But the reason I am asking it here is that it will help someone in the future. Besides the level of detailing and specification one gets here, cannot be learned anywhere else.  </p>
","32803","","32803","","2012-01-07 20:15:51","2012-01-07 20:31:08","Why special characters are deemed risky in URL and query strings?","<security><server-security>","2","3","","","","CC BY-SA 3.0"
"354621","1","","","2017-07-27 20:30:08","","3","228","<p>This is specifically about when to develop and implement code for authentication and authorization.  I do <em>not</em> mean things the developer should be aware of such as exploits or using Prepared Statements for SQL Injection, and <a href=""https://softwareengineering.stackexchange.com/questions/14584/do-you-actively-think-about-security-when-coding"">so on</a>.  These should be axiomatic for the developer.</p>

<p>What I mean is when in your development cycle do you build in the Authentication and Authorization ""system/membership/whatever you want to call it""?  Do you do it as you're going along, maybe you just turn it off or make yourself an admin, so you can run your code?  Whether it is ""Role Based"" or ""Activity Based"" or something else I don't think should matter for this question.  I might know what security I want to use, the system, architecture, etc., but when in the SDLC do I put that system in the actual code (whether I wrote it or it is some plugin)?</p>

<p>I do not mean the database.  Only the application and that with Usernames and Passwords.  I do not mean in my mind.  I mean when you sit down to start typing your tests or however it is you write your software.  When do I actually start typing the security stuff in?  Before I do anything, during it, after it?  All three+?</p>

<p>Side question, would TDD necessitate I do security as I go along?</p>

<p>There were <a href=""https://softwareengineering.stackexchange.com/questions/87226/develop-secureness-first-or-as-a-later-step"">promising</a> question titles, but not the answer(s) I was looking for.  It <em>feels</em> like it would get in the way of making things work.  But I don't want it to be an afterthought either.</p>

<p>I put the word compile in the title to emphasize what I meant by ""when.""</p>

<p>Edit:  For example, do I add this as I do this:</p>

<pre><code> // Create a PrincipalPermission object.
            PrincipalPermission MyPermission = 
                new PrincipalPermission(""MyUser"", ""Administrator"");
</code></pre>

<p>or</p>

<pre><code>[AttributeUsage(AttributeTargets.Field, AllowMultiple=false)]
</code></pre>

<p>or</p>

<pre><code>IsInRole...
</code></pre>

<p>I am not asking for which kind of security I should implement.  There is no way for you to know that.  I am only asking the when it should be typed in.</p>

<p>(Code I copied from MS sites)</p>
","8802","","8802","","2017-07-27 20:35:50","2017-07-28 00:15:06","Do you integrate and compile User Authentication and Authorization code from the beginning of your project?","<design><security>","5","0","","","","CC BY-SA 3.0"
"129238","1","129254","","2012-01-09 16:57:39","","3","626","<p>I am working on an application that I developed a security layer for. It uses the hardware ID of the hard drive, MAC address and another hardware serial key, to lock the software a particular piece of hardware.</p>

<p>I came across sites online, that said I should use fairly weird names for the procedures/functions/variables in the the security layer. For instance</p>

<pre><code>function XtDmat: Boolean; 
var
  x3mat: string;
  hhiTms: Interger;
begin
  Result := False;
  x3mat := GWindosColr;  //this returns the HD ID
  hhiTms := GalilDriverID; //this gets a controller ID
  if (t5gFx=x3mat) and (hhiTms=f4teXX) then Result := True; //match IDs with those saved in the registry
end;
</code></pre>

<p>And for the messages dialog box:</p>

<pre><code>procedure Tfrm_MainWindow.mxProtectorExpiration( Sender: TObject );
begin
  lbl_Remaining.Caption := GetClassPath('xsedfers34;;''kd'); // encrypted value  decryted and shown       '0 days remained'
  lbl_Message.Caption := GetClassPath('qwe23vftTxxx ii gtr');   //decryt and show       'This license has expired'
  btn_Go.Enabled := False;
end;
</code></pre>

<p>I did this because I used <a href=""http://www.softpedia.com/get/Programming/Debuggers-Decompilers-Dissasemblers/DeDe.shtml"" rel=""nofollow"">Delphi DEDE</a> to decompile my code and found even the registry key 'HCKU\software\myapplication' to be in plain sight.</p>

<p>Now, however, it has become difficult to </p>

<ol>
<li>explain to my fellow team mates, why I did this (meaning the names),</li>
<li>document as the names do not make sense,</li>
<li>debug which gives me headaches.</li>
</ol>

<p>Can anyone suggest a good way to document this type of code in this type of situation.
So the code becomes easier to, but is still diffcult to decompile. Alternatively, could one suggest a obfuscator for Delphi.</p>
","42987","","40190","","2012-01-09 20:29:39","2012-01-09 20:56:31","How to Document the Security/Encryption Code of an Application","<security><delphi>","2","6","","","","CC BY-SA 3.0"
"354756","1","354767","","2017-07-29 21:17:09","","0","399","<p>Iâ€™m building a payment system for some ebooks with Reactjs on the frontend, Firebase as hosting and database and cloud functions at the backend side. Customers donâ€™t need an account to buy ebooks so they are not logged in or getting an account.</p>

<p>At this point Iâ€™ve got a form for their firstname, lastname and email and a hidden field with the ebook they want to buy. This is the first step. After submitting the form Iâ€™m checking if everything is valid. When everything is valid I want to send the data to the server. I want to check the data there as well (you never know if somebody is changing the fronted code). When the server check is done and valid, a push to the database has to be made. At this point, a new entry is made with a unique key. All the time, the user is on a redirected page (something like <code>www.mydomain.com/addNewCustomerInformation</code> (to send information to my server) (Note: the url is a redirect from <code>https://us-central1-&lt;projectname&gt;.cloudfunctions.net/addNewCustomerInformation</code>)) with a loading icon.</p>

<p>Now that the basic information is known and put in the database another redirect takes place to send the user to a confirmation page. First the user has to check if the information is correct, secondly he has to choose a payment option (Iâ€™m using Stripe). The options are Alipay, iDeal, bancontact, bitcoin and credit card. So Iâ€™m having a more complex system than examples that are only using credit card. Because there are some examples for credit cards, I will go on for iDeal.</p>

<p>When the user has checked his information (Itâ€™s not with a confirm button. You can edit your information if there was something wrong.) and clicked on the iDeal button a Stripe source needs to be made and with a redirect the user will be guided through the iDeal steps. The payment part already works so I will skip this. After the payment, the user gets a mail with a 72h link to download the ordered eBook. This is for security sharing reasons. After 72h the link needs to expire (how can I do this?).</p>

<p>So here are my questions:</p>

<p>1) The part were I redirect the user to another url so I can do a post to my server (webhooks), let them wait with a loading icon and do another redirect when Iâ€™m getting data back from the server looks very unclean to me. What is a better way to do this?</p>

<p>2) How can I make the url expire after 72h? (so, how can I make the unique id thatâ€™s in the database expire after 72h)</p>
","279256","","","","","2017-07-30 09:01:07","Best practice to send data to webhooks without multiple redirects","<web-applications><security><node.js><server-side><payment>","1","5","","","","CC BY-SA 3.0"
"50227","1","50249","","2011-02-21 18:49:58","","12","4546","<p>When adding salt values to a hash value for something like a password that cannot be stored in plain text, what is the best place to get the salt values come from? For context, let us suppose this is for passwords on a webpage login. </p>
","3792","","","","","2014-05-08 21:16:08","Where should salt hash values come from?","<security><hashing>","6","1","","","","CC BY-SA 2.5"
"354878","1","","","2017-08-01 08:22:38","","-2","77","<p>Situation</p>

<p>I have a Desktop Application and a Web Application. </p>

<p>I need the 2 to interact with each other. Such though that when a button is clicked on the Web App the Desktop App activates and replies with a form for the Web App to fill in and send back. My biggest concern is doing this as securely as possible with minimal manipulation from the Web App other than polling for the Desktop App, receiving the form, filling in the form and sending it back to the Desktop App.
When the Desktop App is 'activated' a password will be prompted.</p>

<p>Any help would be greatly appreciated!</p>
","279425","","","","","2017-08-01 08:31:31","Web API interacting with local application","<web-applications><security><cross-platform><desktop-application>","1","0","","2017-08-13 01:03:33","","CC BY-SA 3.0"
"240427","1","","","2014-05-18 15:59:04","","1","1899","<p>This is my situation: I have a search results page in PHP where most of the logic resides in a javascript file in order to avoid refreshing the page every time an action is performed. The first thing I do using PHP is filter out and save valid query string values to PHP variables and I make use of the htmlspecialchars function to prevent injection. Now, I'd like to call my javascript function using those variables, so I created a script tag at the bottom of the page in order to pass the PHP variables to it (see my example). </p>

<p>When I put all of my javascript code inside of its own scope (as I read this was a good security practice), I realized that I could no longer call my function from outside of it. I also realize that the javascript method can still be called with anything a hacker wants, so does that mean I can't really make use of htmlspecialchars in my situation?</p>

<p>Here's a stripped-down version of my code:</p>

<pre><code>&lt;?php
try {       
  if (isset($_GET[""id""])) {
    if (!is_numeric($_GET[""id""]))
      throw new Exception(""URL is not in a correct format"");
    $id= $_GET[""id""];
  }
  elseif (isset($_GET[""keyword""])) {
    $keyword = htmlspecialchars($_GET[""keyword""]);
  }
}
catch (Exception $e) {
  // handle error
}
?&gt;
&lt;html&gt;
&lt;head&gt;&lt;/head&gt;
&lt;body&gt;
  &lt;div class=""searchResults""&gt;&lt;!-- placeholder --&gt;&lt;/div&gt;
  &lt;?php
  if (isset($id)) { 
    echo '&lt;script type=""text/javascript""&gt;ShowSearchResults(""id"",'.$id.');&lt;/script&gt;';        
  }
  elseif (isset($keyword)) { 
    echo '&lt;script type=""text/javascript""&gt;ShowSearchResults(""keyword"",""'.$keyword.'"");&lt;/script&gt;'; 
  }
  ?&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>

<p>This is basically the js:</p>

<pre><code>function ShowSearchResults(key,value)
{
    $.getJSON(""includes/search_results.php?""+key+""=""+value, 
    function(data) {
      // populate search results
      $("".searchResults"").html( ""search results"" );
    })
    .error(function() { 
       $("".searchResults"").html( ""no results"" );
    });
}
</code></pre>

<p>My questions are (while keeping security and best practices in mind):</p>

<p>Is it bad practice to pass the query string values to my javascript function from within the body? I initially did this because I had the impression that it was not a good idea to extract query string values using javascript. Maybe I'm wrong there.</p>

<p>Should I be extracting the query string values from the $(document).ready function, and then calling the appropriate javascript functions from there? What is the appropriate way to do that (htmlspecialchars equivalent)?</p>

<p>Keep in mind that within my javascript code, I use $.getJSON to call another server side function (in PHP) that can reject anything insecure.</p>

<p>Any insight would be greatly appreciated.</p>
","131727","","131727","","2014-05-18 16:15:27","2014-05-18 17:43:07","What is the proper way to extract and pass parameters to call javascript functionality from my PHP page?","<php><security><coding-standards><jquery>","1","5","","","","CC BY-SA 3.0"
"50958","1","50963","","2011-02-23 15:42:33","","8","344","<p>I feel that no one in the group I work in, myself included, <em>really</em> groks encryption and security, or the reasons behind making certain decisions. For example, we recently had a conversation regarding encryption of data that we handle for another group that we work with - the data ends up in a database that is on our secure corporate network (I work in a small group in a large software company, so the integrity of the corporate network is very high), along with everything else we handle. Of course, standard guidelines call for ""encryption"" of this data.</p>

<p>Obviously, that could mean many things - IPSec/encrypted connections, encrypted fileshares, encryption implemented in the DB (whole-DB or column), encryption of the actual bits in the file, etc. - and some people in the group are under the impression that the only kind of encryption that really counts is directly encrypting the bits that are stored, the argument being that everything else is too easy to circumvent - ""if the DB is encrypted, I could still log into it and see the data there; if the file share is encrypted, as long as I have permissions to the folder I can just grab the file; but if the bits are directly encrypted, I won't be able to read it"". My instinct says that that statement is based on limited understanding: they can see themselves logging into SQL Server Management Studio to see the data, but since they wouldn't know how to take a stream or array of encrypted data and use a certificate that they probably have access to to decrypt it, it's probably safe. Are they right? Am I right? No one seems to really know, so decisions get based on the opinion of the loudest or highest-paid person.</p>

<p>Anyway, that's just kind of an extended example of what I'm talking about. I feel like it's the blind leading the blind here, with decisions based on limited understanding, and it's frustrating. I'm no expert on the technical bits of encryption, but I know how to use standard libraries to encrypt streams and arrays and the like - where I really need more knowledge is about architecting data security and information on which I can base decisions like the above. Where can I read about this kind of stuff?</p>
","3044","","","","","2013-10-11 06:36:07","Data encryption/protection - where to find info about high-level best practices","<security><encryption>","2","4","","2013-10-10 18:03:17","","CC BY-SA 2.5"
"355162","1","","","2017-08-05 17:20:35","","-2","82","<p>I'm building for a client's service that allows developers to build client side forms, similar to formspree.io, etc. Basically, developers can set an action to their HTML forms which send the POST data to my service. However, I need a way to authenticate requests.</p>

<p>Formspree does it like: <code>&lt;form action=""https://formspree.io/your@email.com""
      method=""POST""&gt;</code>.</p>

<p>But the client wants to charge per request. So I need a way to make sure that when XYZ.company puts a form on their website, only the requests THEY actually make are charged.</p>

<p>I'm thinking I could issue out a key, have the users server encrypt it somehow, and then generate a random link?</p>

<p>Ideas?</p>
","79640","","","","","2017-08-06 18:01:02","How to let users send to a link","<design><web-development><security><encryption>","1","0","","","","CC BY-SA 3.0"
"50985","1","51022","","2011-02-23 16:33:07","","7","10842","<p>There are several different ways to connect to SQL Server from an ASP.NET application.  I'm working on rebuilding an ASP.NET / SQL Server environment right now and I'm trying to figure out which method I should be going for.  Here are the options as I see them:</p>

<ul>
<li>Connect via SQL Server ID that is stored in web.config.  Pro: simple.  Cons: password in web.config; have to specifically configure SQL Server ID.</li>
<li>Connect via user NT ID via ASP.NET impersonation.  Pro: no passwords in web.config; fine-grained control of security per user.  Cons: administrative overhead of configuring user accounts in SQL Server; SQL Server monitoring of application is scattered across many accounts.</li>
<li>Run ASP.NET as a custom NT ID, and have that NT ID configured in SQL Server.  Pros: connecting to SQL Server as one ID - simple; no passwords in web.config.  Cons: complicated from a security perspective.  Have to configure <a href=""https://serverfault.com/questions/236734/iis-windows-authentication-not-working-in-internet-explorer-via-host-name-works"">custom SPNs in Active Directory for Kerberos authentication</a>.</li>
</ul>

<p>Are there other options that I'm missing?  Which of these options are used in which situations?  Which are more standard?  Are there pros and cons that I'm not thinking about?</p>

<p>Note that my assumption is that users are authenticating with ASP.NET via integrated windows authentication; this is for an intranet application.</p>
","3124","","-1","","2017-04-13 12:13:51","2014-04-30 05:59:38","Best practices for connecting from ASP.NET to SQL Server?","<asp.net><security><sql-server>","3","0","","2014-05-01 19:49:18","","CC BY-SA 2.5"
"240665","1","","","2014-05-20 20:55:54","","1","49","<p>I have developed an application for android requiring no permissions, but the biggest downside of this is that I don't have error reporting. So, I was playing around for the past week with any alternative options which would allow error reporting without network permissions and without privacy risks. So I came up with the following:</p>

<p>Errors could be reported through a custom Google Play API, but would only be displayed once more than n users would have triggered the same error and displayed only in the aggregate sense. This (I believe) would prevent exploitation where an app could use this as a method to communicate private data. N would be defined by something along the lines of <code>max(10,number_of_users * 0.001)</code> or something along those lines.</p>

<p>So my question is, would such an architecture be safe or am I overlooking possible exploits? If not it seems a huge waste android lacks such an API as right now virtually every app requires network access for exactly this reason. A similar API could then also be used for rudimentary statistics, once again without the up and downsites of user identifiable analytics like with Google Analytics for android.</p>
","50636","","","","","2014-05-20 20:55:54","Online error reporting without network access","<security><android><api-design>","0","0","","","","CC BY-SA 3.0"
"240760","1","","","2014-05-21 20:29:33","","0","83","<p>These days it's possible to hash a file client-side, send the hash to the server, and have the server check whether or not that file is already uploaded. If it is, we can skip the file upload and make it appear to upload almost instantly to the user. This can also save have oodles of bandwidth for a large site.</p>

<p>This has some important security implications, however.</p>

<ol>
<li><p>If the user is clever, he can use this information to determine what files are already on the server, including illegal or sensitive documents</p></li>
<li><p>He can produce millions of fake hashes, send them to the server, and hope for a collision to gain access to random documents</p></li>
<li><p>There is a legitimate but unintentional collision where the hashes are the same, but the file is actually different</p></li>
</ol>

<p>My question is: is it worth the trade-off? Can we mitigate some or all of these problems? How?</p>
","7390","","7390","","2014-05-22 01:23:14","2014-05-22 01:23:14","Hashing + security as it pertains to a theoretical file sharing site","<security><theory><hashing>","2","0","","","","CC BY-SA 3.0"
"130224","1","","","2012-01-12 02:06:49","","6","2531","<p>After following buffer overflow examples and reading on them in various books/websites it seems there are lots of preventative measures in place to protect against them these days. ASLR, /GS flag security cookie, stack-protector in linux, etc, etc...</p>

<p>Some of the examples I have looked at give instructions on how to disable certain security features so that the examples will run...This seems like a really stupid idea to me - when running code against a real system you are not going to have the luxury of disabling its security features.</p>

<p>So what is the deal with buffer overflows these days, have them been rendered redundant by advances in security or are they still of use?</p>
","","John McDonald","","","","2012-01-15 04:59:25","Are buffer overflows no longer a threat these days?","<security>","3","3","","","","CC BY-SA 3.0"
"240965","1","","","2014-05-23 19:23:31","","1","636","<p>I was just reading this slightly older post on <a href=""http://martinfowler.com/bliki/VersionControlTools.html"" rel=""nofollow"">choosing a good source control system</a> when I started thinking about how different projects use source control. Where I work we've essentially moved completely to Git and things have been mostly good.</p>

<p>I have wondered about high security projects such as military software projects. Using something like Git there would fundamentally be unsafe; even allowing repo clones under restricted circumstances could be problematic. Using SVN or TFS may not even provide enough security in itself. </p>

<p>Are there any VCS systems that have any stronger security considerations? Or are there additional considerations that go into using VCS for high security projects?</p>
","36853","","","","","2014-05-23 21:12:45","What Kind of Source Control Do High Security Projects Use?","<version-control><security>","1","7","0","2014-05-23 21:58:13","","CC BY-SA 3.0"
"51979","1","52047","","2011-02-25 16:24:32","","5","467","<p>We know of Linus' law:</p>

<blockquote>
  <p>With enough eyeballs all bugs are shallow</p>
</blockquote>

<p>In general, people seem to say that open-source software is more secure because of that very thing, <strong>but</strong>...</p>

<p>There are many small OSS projects with just 1 or 2 developers (the cathedral model, as described by ESR). For these projects, does releasing the source-code actually lower the security? For projects like the Linux kernel there are thousands of developers and security vulnerabilities are quite likely going to be found, but when just some few people look through the source code, while allowing crackers (black hat hackers) to see the source as well, is the security lowered instead of increased?</p>

<p>I know that the security advantage closed-source software has over OSS is security through obscurity, which isn't good (at all), but it could help to some degree, at least by giving those few devs some more time (security through obscurity doesn't help with the if but with the when).</p>

<p><strong>EDIT:</strong> The question isn't whether OSS is more secure than non-OSS software but if the advantages for crackers are greater than the advantages for the developers who want to prevent security vulnerabilities from being exploited.</p>
","12750","","16637","","2011-02-25 21:17:26","2011-02-25 21:17:26","Small projects using the cathedral model: does open-source lower security?","<open-source><security><vulnerabilities>","4","0","","","","CC BY-SA 2.5"
"241307","1","","","2014-05-28 11:01:15","","2","651","<p>So I'm working on my first password reset mechanism. I'm going with what I understand to be a fairly common procedure:</p>

<ol>
<li>User clicks ""Forgot Password""</li>
<li>User is prompted for email address</li>
<li>If the entered email address is valid, send an email with a reset link to it</li>
<li>Reset link uses a token of some kind to identify the user account and keep its details secure</li>
<li>When password is reset, generate a new token and save it to the user account</li>
</ol>

<p>I feel like this should be pretty secure, but I was wondering if anyone could provide any insights that I may not be considering at this point.</p>
","129602","","","","","2016-12-31 13:40:19","Password reset process","<security><passwords>","1","4","0","","","CC BY-SA 3.0"
"130870","1","130913","","2012-01-19 12:30:10","","1","717","<p>Which approach makes most sense to use, the destructive one or the non-destructive one? Does anyone have real-world experience with one, both or even a different approach?</p>

<p><strong>Model</strong></p>

<p>A permission scheme has a set of permissions linked to it. It can also have a parent from which it inherits permissions.</p>

<p><strong>Destructive</strong></p>

<p>Taking away permissions from a parent scheme also takes away those permissions in any child scheme.</p>

<p>Reason to use this: when later re-enabling those permissions for a parent scheme, they are not automatically re-enabled for child schemes.</p>

<p>Reason to not use this: accidently taking away permissions from a parent scheme means the permissions for child schemes have to be restored separatly.</p>

<p><strong>Non-destructive</strong></p>

<p>Taking away permissions from a parent scheme has no effect on child schemes. The parent and child schemes are combined to determine the correct permissions.</p>

<p>Reason to use this: accidently taking away permissions from a parent scheme does not require the child schemes to be restored separatly.</p>

<p>Reason to not use this: when later re-enabling those permissions for a parent scheme, they are automatically re-enabled for child schemes.</p>
","34484","","34484","","2012-01-19 13:10:42","2012-01-19 19:07:28","Parent and child permission schemes","<security><users><permissions>","2","4","","","","CC BY-SA 3.0"
"52402","1","52410","","2011-02-26 16:31:59","","2","2951","<p>I'm writing a library to generate and check CSRF tokens. </p>

<p>I would like to do it without having to use sessions and/or cookies. What I've come up with is this:</p>

<ol>
<li><p>A token generated from the current time and a unique token id (unix-timestamp.unique-token-id). </p></li>
<li><p>The token would then be hashed using the HMAC method. The returned value would be: hmac-hash.unix-timestamp.unique-token-id. This could then be hidden in a form.</p></li>
<li><p>The library would then test the returned token by extracting the HAMC hash, time and unique token id from it and then compare the returned HAMC hash to one generated using the returned time and unique token id.</p></li>
</ol>

<p>As long as the HMAC secret on the server stays secret it should be secure or did I missed something?</p>
","18542","","","","","2012-05-01 17:25:00","Generating CSRF tokens without using sessions & cookies","<security>","3","1","","","","CC BY-SA 2.5"
"241506","1","","","2014-05-30 12:27:30","","0","87","<p>How to approach securing webservices? I can think of using one of the two approaches below</p>

<ol>
<li>sending a user name password in every request for validation</li>
<li>Sending a time based token (GUID or some similar long string)</li>
</ol>

<p>In the first approach I have to query a database every time in most cases an RDBMS to authenticate a user.</p>

<p>In the second I now make a user name password authentication only once and then return to the user a time based token. All future business requests are authenticated via this token. On expiry this token will need to be recreated by the calling client.</p>

<p>Both approaches seem to have their own pros and cons. Which one would you recommend in which circumstances and what would be your reasons for the same? Perhaps a specific condition where one favors the other.</p>
","30757","","5099","","2014-05-30 13:11:36","2014-05-30 13:11:36","Securing web services","<security><web-services>","1","6","0","2014-05-31 00:47:36","","CC BY-SA 3.0"
"52818","1","","","2011-02-28 07:38:12","","0","75","<p>We have a lot of services, some that demand some security, some that don't.
We want an easy way of telling, in code, if a service will be secure or not.</p>

<p>What would be the better way: Annotation or inheritance?</p>

<pre><code>public class SomeServiceImplementation : BaseSecureService, ISomeService
</code></pre>

<p>or </p>

<pre><code>[SecureService]
public class SomeServiceImplementaion : ISomeService
</code></pre>
","9655","","","","","2011-02-28 10:01:48","Marking services for secure handling; Annotation or inheritance?","<security><web-services><aspect-oriented><inheritance>","2","0","","","","CC BY-SA 2.5"
"356529","1","356532","","2017-08-30 14:52:02","","0","168","<p>I am planning creating a small personal blog application that handles only one user - the content author, let's call that user <em>admin</em>.
There would not be any registration option, only a hidden login page that only the admin is aware of. There would not be any options that requires registration (no commenting, no posting, no voting, etc.).
Normally I would store user data in a database and use that data during authentication process but in this case I am thinking of hard coding a username/password combination the admin can log in with, and create blog posts.
I know this way there won't be chance to add more users later and the admin cannot modify the password without modifying the code or a properties file and redeploying the app. But besides these are there any more cons of this ""quick and dirty"" solution, especially from security point of view?</p>
","281898","","","","","2017-08-31 10:47:07","Handling one-user-only applications","<security><authentication><login>","3","0","","","","CC BY-SA 3.0"
"243229","1","243252","","2014-06-06 17:18:06","","7","4135","<p>Among computer scientists and programmers, there's the common habit of naming people in the context of security protocols e.g. <code>Alice</code>, <code>Bob</code> or <code>Eve</code>. Descriptions of more elaborate attack vector sometimes refer to <code>Charlie</code> (as does this <a href=""http://xkcd.com/1323/"">XKCD strip</a>), but is there a convention for additional participants?</p>
","21184","","","","","2014-10-29 21:20:11","Naming in Security Protocols: Alice, Bob and Eve","<security><naming><culture>","1","2","","2015-09-04 19:46:39","","CC BY-SA 3.0"
"356603","1","","","2017-08-31 20:54:20","","0","119","<p>Role based security is a very common model for software nowadays. It is very powerful but requires careful configuration to leverage the benefits of shared roles. It is easy for a mess to be made for example when the admin user simply creates a role every time a change is needed (instead of leveraging existing roles).</p>

<p>Very broad question here but as the designer of the role based security software application, how can I assist the user in avoiding this problem? How can I detect duplication or detect ways the security role setup can be normalized?</p>

<p>Edit: I would like to emphasize that customizable security roles is a vital feature in the product. Also, the problem at hand here is to normalize existing configurations that have gotten out of control for existing customers. Discussion on design of the software itself is not what I am after.</p>
","154572","","154572","","2017-09-01 00:13:55","2017-09-01 00:13:55","Programatically normalizing role based security systems","<database-design><security>","1","2","","","","CC BY-SA 3.0"
"243319","1","","","2014-06-08 09:52:12","","2","1024","<p>I have spent quite a few days reading up on Oauth and token based security measures for REST API's and I am currently looking at implementing an Oauth based authentication approach almost exactly like the one described in this post (<a href=""https://softwareengineering.stackexchange.com/questions/214003/oauth-alternative-for-a-2-party-system"">OAuth alternative for a 2 party system</a>).</p>

<p>From what I understand, the token is to be verified upon each request to the resource server.  This means the resource server would need to retrieve the token from a datastore to verify the clients token.  Given this would have to happen upon every request I am concerned about the speed implications of hitting a datastore like MySQL or NoSQL upon every request just to verify the token.  </p>

<p>Is this the standard way to verify tokens by having them stored in a RDBMS or NoSQL database and retrieved upon each request?  Or is it a suitable solution to have them cached (baring in mind that we are talking millions of users)?</p>
","134926","","-1","","2017-04-12 07:31:39","2014-09-18 13:07:38","Access Token Verification","<java><security><rest><oauth>","1","8","","","","CC BY-SA 3.0"
"243326","1","","","2014-06-08 11:50:16","","2","326","<p>In a windows forms payroll application employing <code>MVP</code> pattern (for a small scale client) I'm planing user permission handling as follows (permission based) as basically its implementation should be less complicated and straight forward.</p>

<p><strong>NOTE</strong> : System could be simultaneously used by few users (maximum 3) and the database is at the server side.</p>

<p>This is my <code>UserModel</code>. Each user has a list of permissions given for them.</p>

<pre><code>class User
{
    string UserID { get; set; }
    string Name { get; set; }
    string NIC {get;set;}
    string Designation { get; set; }
    string PassWord { get; set; }
    List &lt;string&gt; PermissionList = new List&lt;string&gt;();
    bool status { get; set; }
    DateTime EnteredDate { get; set; }
}
</code></pre>

<p>When user login to the system it will keep the current user in memory.  </p>

<p>For example in <code>BankAccountDetailEntering</code> view I control the controller permission as follows.</p>

<pre><code> public partial class BankAccountDetailEntering : Form
    {
        bool AccountEditable {get; set;}

        private void BankAccountDetailEntering_Load(object sender, EventArgs e)
        {
            cmdEditAccount.enabled = false;

            OnLoadForm (sender, e); // Event fires...

            If (AccountEditable )
            {
                cmdEditAccount.enabled=true;
            }
         }
    }
</code></pre>

<p>In this purpose my all relevant presenters (like BankAccountDetailPresenter) should aware of <code>UserModel</code> as well in addition to the corresponding business <code>Model</code> it is presenting to the <code>View</code>.</p>

<pre><code>class BankAccountDetailPresenter
{    
    BankAccountDetailEntering _View;
    BankAccount _Model;
    User _UserModel;
    DataService _DataService;

    BankAccountDetailPresenter( BankAccountDetailEntering view, BankAccount model, User userModel, DataService dataService )
    {
        _View=view;
        _Model = model;
        _UserModel = userModel;
        _DataService = dataService;
        WireUpEvents();
    }

    private void WireUpEvents()
    {
        _View.OnLoadForm += new EventHandler(_View_OnLoadForm);
    }

    private void _View_OnLoadForm(Object sender, EventArgs e)
    {

        foreach(string s in _UserModel.PermissionList) 
        { 
            If( s ==""CanEditAccount"")
            {
                _View.AccountEditable =true;
                return;
            }
        }
    }

    public Show()
    {
        _View.ShowDialog();
    }
}
</code></pre>

<p>So I'm handling the user permissions in the presenter iterating through the list. Should this be performed in the <code>Presenter</code> or <code>View</code>? Any other more promising ways to do this? </p>
","134943","","","user40980","2014-06-08 15:54:49","2014-06-08 15:54:49","Handling permissions in a MVP application","<c#><.net><security><mvp><permissions>","0","1","","","","CC BY-SA 3.0"
"356816","1","356817","","2017-09-05 01:20:50","","20","20496","<p>I want to implement a more robust authentication service and <code>jwt</code> is a big part of what I want to do, and I understand how to write the code, but I'm having a little trouble understanding the difference between the reserved <code>iss</code> and <code>aud</code> claims. I understand that the one defines the server that is issuing out the token and the one refers to the application that is intended for use. But the way I understand that is that my audience and issuer are the same thing <code>myserver.com</code> is issuing the token so that people who come to <code>myserver.com</code> can be authorized and authenticated. I guess I don't see the differentiation between the two claims, although I know there is one.<br>
There was a <a href=""https://docs.microsoft.com/en-us/azure/active-directory/develop/active-directory-token-and-claims"" rel=""noreferrer"">good article</a> written at <code>msdn</code> on all of the reserved claims and that's where I got most confused because they had their issuer and audience completely different.</p>
","281809","","222996","","2017-09-05 07:25:55","2017-09-05 07:25:55","Difference between 'aud' and 'iss' in jwt","<security><authentication><authorization><jwt>","1","1","","","","CC BY-SA 3.0"
"244485","1","","","2014-06-10 00:42:11","","8","289","<p>I'm trying to add data from a webhook (from a web cart) to a local Microsoft SQL Server. It seems like the best route for me is to use a PHP script to listen for new data (POST as json), parse it, then query to add to MSSQL.</p>

<p>I'm not familiar with security concerning the connection between the PHP script (which would sit on a shared-host website) and the local MSSQL database. I would just keep the PHP script running on the same localhost (have Apache running on Windows), but the URI for the webhook needs to be publicly accessible.</p>

<p>Alternately, I assume that I could just schedule a script from the localhost to check periodically for updates through the web carts API, though the webhooks seem to be more fool-proof for an amateur programmer like myself.</p>

<p>What steps can I take to ensure security when using a PHP on a remote, shared-host to connect to MSSQL on my local machine?</p>
","136115","","","user40980","2014-06-10 02:10:05","2014-06-12 17:49:29","Securely sending data from shared hosted PHP script to local MSSQL","<php><security><sql-server><server><server-security>","1","5","","","","CC BY-SA 3.0"
"54008","1","54035","","2011-03-02 20:25:41","","11","1380","<p>I'm about to write the company guidelines about what must never appear in logs (trace of an application). In fact, some developers try to include as many information as possible in trace, <strong>making it risky to store those logs, and extremely dangerous to submit them</strong>, especially when the customer doesn't know this information is stored, because she never cared about this and never read documentation and/or warning messages.</p>

<p>For example, when dealing with files, some developers are tempted to trace <strong>the names of the files</strong>. For example before appending file name to a directory, if we trace everything on error, it will be easy to notice for example that the appended name is too long, and that the bug in the code was to forget to check for the length of the concatenated string. It is helpful, but <strong>this is sensitive data, and must never appear in logs</strong>.</p>

<p>In the same way:</p>

<ul>
<li><strong>Passwords</strong>,</li>
<li>IP addresses and network information (MAC address, host name, etc.)Â¹,</li>
<li>Database accesses,</li>
<li>Direct input from user and stored <strong>business data</strong></li>
</ul>

<p>must never appear in trace.</p>

<p>So what other types of information must be banished from the logs? Are there any guidelines already written which I can use?</p>

<hr>

<p><sup>Â¹ Obviously, I'm not talking about things as IIS or Apache logs. What I'm talking about is the sort of information which is collected with the only intent to debug the application itself, not to trace the activity of untrusted entities.</sup></p>

<hr>

<p><strong>Edit:</strong> Thank you for your answers and your comments. Since my question is not too precise, I'll try to answer the questions asked in the comments:</p>

<ul>
<li>What I'm doing with the logs?</li>
</ul>

<p>The logs of the application may be stored in memory, which means either in plain on hard disk on localhost, in a database, again in plain, or in Windows Events. In every case, the concern is that those sources may not be safe enough. For example, when a customer runs an application and this application stores logs in plain text file in temp directory, anybody who has a physical access to the PC can read those logs.</p>

<p>The logs of the application may also be sent through internet. For example, if a customer has an issue with an application, we can ask her to run this application in full-trace mode and to send us the log file. Also, some application may sent automatically the crash report to us (and even if there are warnings about sensitive data, in most cases customers don't read them).</p>

<ul>
<li>Am I talking about specific fields?</li>
</ul>

<p>No. I'm working on general business applications only, so the only sensitive data is business data. There is nothing related to health or other fields covered by specific regulations. But thank you to talk about that, I probably should take a look about those fields for some clues about what I can include in guidelines.</p>

<ul>
<li>Isn't it easier to encrypt the data?</li>
</ul>

<p>No. It would make every application much more difficult, especially if we want to use C# diagnostics and <code>TraceSource</code>. It would also require to manage authorizations, which is not the easiest think to do. Finally, if we are talking about the logs submitted to us from a customer, we must be able to read the logs, but without having access to sensitive data. So technically, it's easier to never include sensitive information in logs at all and to never care about how and where those logs are stored.</p>
","6605","","6605","","2011-03-02 22:12:35","2011-03-03 03:53:59","What information must never appear in logs?","<security><information>","7","5","","2015-10-19 14:55:19","","CC BY-SA 2.5"
"132314","1","132315","","2012-01-29 00:03:41","","10","758","<p>I'm developing a web application with a strong focus on security. What measures can be taken to prevent those who work on the application (programmers, DBAs, quality assurance staff) from capturing user entered values that should be well-protected, such as passwords, social security numbers, and so forth?</p>
","14294","","4","","2012-03-19 20:49:55","2015-03-07 18:54:38","How can I prevent programmers from capturing data entered by users?","<security>","2","3","","","","CC BY-SA 3.0"
"357049","1","","","2017-09-08 14:32:47","","0","156","<p>I am looking to build and host a website for a client. Their existing site has a facility that allows customers to make donations and they want the new site to have it too.</p>

<p>My manager has told them that we can just lift their existing code and data and put it onto our servers and has asked me to go ahead and do this.</p>

<p>I am wary of doing it because I don't actually know how the code works and can't vouch for it being reliable or even safe. My manager says it must be safe because it has been working ok on their site already. Moreover he cannot afford for me to spend time reading through it and trying to understand it. He just wants me to copy and paste it.</p>

<p>Is it safe for me to proceed? </p>

<p>N.B. I guess this is sort of an ethical/legal question. But I wanted to post it here to understand the technical reasons too.</p>
","31430","","","","","2017-09-08 15:02:23","Should I use unknown code from a third party?","<security><legal><source-code>","2","4","","2017-09-12 11:06:29","","CC BY-SA 3.0"
"244723","1","244724","","2014-06-11 23:06:17","","3","142","<p>There are many situations where the validity of the timestamp attached to a certain post (submission of information) might be invaluable for the post owner's legal usage. I'm not looking for a service to achieve this, as requested <a href=""https://softwareengineering.stackexchange.com/questions/195958/service-to-prove-authorship-with-trusted-timestamp"">in this great question</a>, but rather a method for the achievement of such a service.</p>

<p>For the legal (in most any law system) authentication of text content and its submission time, the owner of the content would need to prove:</p>

<ul>
<li><p>that the timestamp itself has not been altered and was accurate to begin with.</p></li>
<li><p>that the text content linked to the timestamp had not been altered</p></li>
</ul>

<p>I'd like to know how to achieve this via programming (not a language-specific solution, but rather the methodology behind the solution). </p>

<hr>

<ol>
<li><p><strong>Can a timestamp be validated to being accurate to the time that the content was really submitted?</strong></p></li>
<li><p><strong>Can data be stored in a form that it can be read, but not written to, in a proven way?</strong></p></li>
</ol>

<p>In other words, can I save &amp; store a user's submission in a way that proves that the data has not been altered, and that the timestamp is accurate?</p>

<p>I can't think of any programming method that would make this possible, but I am not the most experienced programmer out there. Based on MidnightLightning's answer to the question I cited, this sort of thing is being done.</p>

<hr>

<p><strong>Clarification:</strong> I'm looking for a method (hashing, encryption, etc) that would allow an average guy like me to achieve the desired effect through programming.</p>

<p>I'm interested in this subject for the purpose of <a href=""http://en.wikipedia.org/wiki/Defensive_publication"" rel=""nofollow noreferrer"">Defensive Publication</a>.</p>

<p>I'd like to learn a method that allows an every-day programmer to pick up his computer, write a program, pass information through it, and say:</p>

<blockquote>
  <p>I created this text at this moment in time, and I can prove it.</p>
</blockquote>

<p>This means the information should be protected from the programmer who writes the code as well. Perhaps a 3rd party API would be required. I'm ok with that.</p>
","","user129679","-1","user129679","2017-04-12 07:31:39","2014-06-12 02:04:47","Can I save & store a user's submission in a way that proves that the data has not been altered, and that the timestamp is accurate?","<security><validation><encryption><hashing><time-stamp>","4","3","","","","CC BY-SA 3.0"
"244867","1","246251","","2014-06-13 02:22:06","","8","12583","<p>Currently working on a web based CRM type system that deals with various Modules such as Companies, Contacts, Projects, Sub Projects, etc.  A typical CRM type system (asp.net web form, C#, SQL Server backend).  We plan to implement role based security so that basically a user can have one or more roles.  </p>

<p>Roles would be broken down by first the module type such as:</p>

<p>-Company</p>

<p>-Contact</p>

<p>And then by the actions for that module for instance each module would end up with a table such as this:</p>

<pre><code>Role1 Example:

    Module   Create  Edit        Delete   View
    Company   Yes    Owner Only    No     Yes
    Contact   Yes    Yes           Yes    Yes
</code></pre>

<p>In the above case <code>Role1</code> has two module types (Company, and Contact).  For company, the person assigned to this role can create companies, can view companies, can only edit records he/she created and cannot delete.  For this same role for the module contact this user can create contacts, edit contacts, delete contacts, and view contacts (full rights basically).</p>

<p>I am wondering is it best upon coming into the system to session the user's role with something like a:</p>

<p><code>List&lt;Role&gt; roles;</code></p>

<p>Where the <code>Role</code> class would have some sort of <code>List&lt;Module&gt; modules;</code> (can contain Company, Contact, etc.).?  Something to the effect of:</p>

<pre><code>class Role{
string name;
string desc;
List&lt;Module&gt; modules;
}
</code></pre>

<p>And the module action class would have a set of actions (Create, Edit, Delete, etc.) for each module:</p>

<pre><code>class ModuleActions{
List&lt;Action&gt; actions;
}
</code></pre>

<p>And the action has a value of whether the user can perform the right:</p>

<pre><code>class Action{
string right;
}
</code></pre>

<p>Just a rough idea, I know the action could be an enum and the ModuleAction can probably be eliminated with a <code>List&lt;x, y&gt;</code>.  My main question is what would be the best way to store this information in this type of application: Should I store it in the User Session state (I have a session class where I manage things related to the user).  I generally load this during the initial loading of the application (global.asax).  I can simply tack onto this session.</p>

<p>Or should this be loaded at the page load event of each module (page load of company etc..).  I eventually need to be able to hide / unhide various buttons / divs based on the user's role and that is what got me thinking to load this via session.</p>

<p>Any examples or points would be great.</p>
","13870","","","","","2014-06-27 16:27:48","How to store Role Based Access rights in web application?","<web-development><security><session>","4","1","","","","CC BY-SA 3.0"
"132648","1","","","2012-01-31 11:25:24","","2","152","<p>I'm building a site that lets users schedule interviews/conferences with third parties and I'm wondering what's the best way to provide security around the participant experience while providing the smallest usability barrier possible.</p>

<p>Currently, I send an email with a link and a 5 digit auth-code. The link opens a page, the participant types in the auth-code and is temporarily logged in for the duration of the interview/conference.</p>

<p>From a security standpoint, I think the auth-code is redundant and introduces friction for the participant, who may never have cause to visit my site again and may not be technically proficient. The link I send as part of the invitation contains a random string, so I could just increase its length by 5 characters and have the same size search space for potential attackers.</p>

<p>The downside is that I would potentially have to rate-limit the responses for the invitation URLs, so I'm not sure there's any benefit from a complexity/lines-of-code perspective.</p>

<p>The non-auth-code feels less secure, but I know that's irrational. Any thoughts on what the best approach would be? </p>
","18205","","","","","2012-02-01 01:15:46","Authentication for 'participants' vs 'users'","<security><usability><authentication>","3","0","","","","CC BY-SA 3.0"
"54784","1","","","2011-03-04 17:53:20","","15","7476","<p>I am setting up a new RESTful web service and I need to provide a <a href=""http://en.wikipedia.org/wiki/Role-based_access_control"" rel=""noreferrer"">role-based access control</a> model. I need to create an architecture that will allow users to provide their username and password to get access to the services and then restrict how they can use the services (which services they can use, read vs read/write, etc) based upon the roles assigned to that users.</p>

<p>I have looked around at other questions and found pieces of what I want.  For example there are several great discussions about how to handle passing credentials to REST services <a href=""https://stackoverflow.com/questions/319530/restful-authentication"">restful-authentication</a>, <a href=""https://stackoverflow.com/questions/7551/best-practices-for-securing-a-rest-api-web-service"">best practices</a>.  There are also some great pointers on what programmers should know when creating websites (<a href=""https://softwareengineering.stackexchange.com/questions/46716/what-should-a-developer-know-before-building-a-public-web-site"">what every developer should know before building a public web site</a>).</p>

<p>But I haven't been able to find a good post, article, book on best practices and patterns for the software architecture that implements these solutions.</p>

<p>Specifically:</p>

<ul>
<li>How should user details and access rights be stored? (data model, location, format)</li>
<li>What are good design patterns for representing and tracking these in the server? (sessions in memory, db lookups each time, etc)</li>
<li>What are good patterns for mapping these rights to the services in a secure way in the code base?</li>
<li>What architectural choices can help keep the system more secure and reliable?</li>
<li>What lessons learned do people have from the trenches?</li>
</ul>

<p>I am looking for are design patterns and recommendations for the software architecture outside of any specific technologies.</p>

<p>(If the technologies matter, I am planning to implement this using python, twisted, and a postgresql database)</p>
","18962","","-1","","2017-05-23 12:40:14","2011-04-03 19:39:22","Software architecture for authentication/access-control of REST web service","<web-development><design-patterns><security><web-services><rest>","1","4","","","","CC BY-SA 2.5"
"357625","1","358637","","2017-09-18 15:31:49","","23","688","<p>How should an open source project with a public repository best handle pull requests (PRs) that address securely reported but not yet publicly disclosed security vulnerabilities?</p>

<p>I'm involved in an open source project with several hundred contributors. We publish security notices and vulnerabilities several times a year as part of a regularly scheduled monthly release. We don't publish information about the vulnerabilities until we make the patched version available. We are able to securely manage security issues in our project management system (JIRA). But we haven't got a good process for obscuring the PRs that fix security vulnerabilities as they are submitted to GitHub. We're concerned that people can find these fixes before they are released and create zero day exploits.</p>

<p>We've considered using private repos that fork the main repo, but much of our currently review and QA workflow occurs on the PRs. If we moved the workflow to a security team only private repo, that would reduce the window when the fix is public down to the hours it takes to generate the tarballs and publish them on sourceforge, which would be a big improvement. We'd also likely need to avoid merging the PRs into our public beta.</p>

<p>Before going in that direction, I'd like to know what is the best practice for handling pre-release security bug fix patches in open source projects with open repos? If the problem can be better addressed by using a different platform than GitHub, I should mention we are evaluating migrating to GitLab.</p>
","283572","","283572","","2017-10-04 19:28:32","2017-10-05 17:47:29","What is best practice for handling PRs addressing security vulnerabilities in public repo?","<open-source><security><github><gitlab>","1","9","","","","CC BY-SA 3.0"
"133277","1","","","2012-02-04 10:41:36","","4","1775","<p>After using Django's excellent admin interface, I was pondering creating a similar system which wasn't as tied to an ORM.</p>

<p>Now, while considering this, I thought that overcoming webapps limitations (basic widgets, sessions, text/HTTP-based forms, distinct client-side/server-side languages in most cases with a limited communication mechanism, etc.) were a big timewaster, and that maybe traditional GUI development was a better option.</p>

<p>So that brought me to using a desktop app, and then a server part which connects to the database and exposes it via RPC (web services, whatever) to the desktop app, handling security in the traditional webapp fashion.</p>

<p>However, nowadays you can connect to databases remotely securely using SSL, and supposedly databases do provide sufficient role-based authorization (GRANT/REVOKE), so why not connect directly to the database and avoid having to code a server?</p>

<p>Is that a good idea? Are there unassailable problems with this approach? [I think that coupled with good database introspection, one could write a relatively simple framework which would enable very nice RAD of database-based apps)? Which are theoretical problems and which ones are problems with specific implementations?</p>

<p>bonus question: do databases provide enough authorization? While doing my research, I came across the following discussion thread:</p>

<p><a href=""http://archives.postgresql.org/message-id/4AE02DF0.40101@enterprisedb.com"" rel=""nofollow"">http://archives.postgresql.org/message-id/4AE02DF0.40101@enterprisedb.com</a></p>

<p>which pokes some holes into traditional view-based row access control in the PostgreSQL implementation.</p>
","8082","","25936","","2012-02-04 10:53:47","2012-02-04 13:17:14","Is a traditional client app which connects directly to a database a good idea?","<web-development><security><sql><desktop-development>","2","0","","","","CC BY-SA 3.0"
"245769","1","245778","","2014-06-23 11:57:36","","2","1724","<p>I'm working on a messaging application, based on a server/client architecture.
Now I am thinking about the way how to store the user credentials.
It's not a huge number, just about 20 entries with their User-IDs, Usernames and hashed passwords.</p>

<p>Storing it with a SQL Server in my opinion is overkill.
Is it better to store it in sort of a text file or in a SQLite database file?
These methods would keep the server portable and the installation simple.</p>

<p>And is password hashing enough to keep the passwords secret?</p>

<p>What is the best way to handle this?</p>
","138423","","","","","2014-06-24 04:18:34","Best way of storing a small number of user credentials","<c#><security><data-structures>","2","0","","","","CC BY-SA 3.0"
"133590","1","","","2012-02-06 18:53:41","","2","2487","<p>Do you have any pointers on how one should go about implementing the oAuth2 protocol itself? That is, the server side or the &quot;provider&quot; facet of OAuth2?</p>
<p>If you have tried to implement (a part of) it, please share the issues and the solutions. Note that this is completely technology and programming language agnostic - except, of course, for the de-facto standard cryptological technologies that might be involved. The IETF draft (v23) for oAuth2 is located <a href=""https://datatracker.ietf.org/doc/html/draft-ietf-oauth-v2-23"" rel=""nofollow noreferrer"">here</a></p>
","34281","","-1","","2021-10-07 07:18:56","2013-03-27 19:52:13","Implementing oAuth 2 server","<security><web><oauth>","2","0","","","","CC BY-SA 3.0"
"133952","1","134123","","2012-02-08 14:36:13","","4","441","<p>Today I found what looked to be my supervisor's password in some code in version control. The password is to a database. He is very experienced and has explained before how to avoid having passwords in the source code.</p>

<p>How should I handle this situation? Is there a best practice about preserving evidence of a security flaw, or should I remove such data as soon as I see it? </p>

<p>Even if I remove the data in the current revision, there's still the revision history. Should I just alert my supervisor instead? </p>
","25849","","","user8","2012-02-08 23:49:17","2012-02-09 07:20:16","What should I do when I find sensitive information in version control?","<version-control><security><code-security>","2","12","","","","CC BY-SA 3.0"
"134073","1","134080","","2012-02-08 23:42:20","","6","121","<p>I would like to create a budget app for Android. Obviously, to be competitive, I would need to allow users to get data from their bank. For [huge] security reasons, this stuff is not just freely given to any would be developer, but I know it can be done. There are budget apps that connected to users banks.</p>

<p>My question is, what do I need to do to poll users bank data? Do I need to contact every bank that I wish my app to deal with? Do I need to write the app and present it the the bank(s)? Or am I just too ignorant to take on a challenge of this magnitude?</p>

<p>I ask because I obviously don't know the standards that are needed here and would like to learn about them, even if it ends up that I cannot write the bank interface section of my app.</p>
","25686","","25936","","2012-02-08 23:54:39","2012-02-09 00:16:30","How does one request / handle personal or financial information?","<licensing><security><coding-standards><applications>","1","0","","","","CC BY-SA 3.0"
"358377","1","358385","","2017-09-30 11:21:34","","0","828","<p>I am currently working on a project where I am developing a library which will do HTTP POSTs to a backend service on my server. The data that the backend service receives is processed and stored in a database and allows the user using the library to see the data. </p>

<p>I want to ensure that the backend service only processes requests from the library, if anything else tries, such as bots etc, the request is rejected. </p>

<p>I was thinking I could achieve this by the library sending an encrypted string in a header in the HTTP request, then when the backend services receives the request, it checks if the header exists and if not rejects the request, if it does, it decrypts the header and then checks if the decrypted string matches what the backend service expected, if so, continues processing, otherwise rejects it. </p>

<p>I was thinking that the library could have the validation token hard coded in the library (the library won't be open sourced) however, I was thinking that this could be problematic if the validation token ever gets compromised, I would need to release a new library version with the new token, and anyone using the library, would then need to update their apps to use the new library. </p>

<p>I was then thinkin the token could be stored on the server and the library requests what the token is and then sends the token to the backend service, but I then have the same problem I'm trying to avoid, how do I make sure only the library retrieves the token and not anyone else. </p>

<p>Is there a recommended best practice for doing what I am trying to achieve. </p>

<p>Thanks for any help you can provide. </p>
","284639","","","","","2017-09-30 17:29:37","Validating requests to API have come from a valid source","<api><security><validation><sdk>","2","1","","","","CC BY-SA 3.0"
"56437","1","56459","","2011-03-09 18:44:35","","8","1370","<p>I would like to get into computer security in my career. What are the best ways to learn how to program securely?</p>

<p>It seems to me that, besides textbooks and taking classes in the subject, perhaps learning how to ""hack"" would be one of the best ways to learn. My reason for thinking this is the thought that the best way to learn how to prevent someone from doing what you don't want them to is to learn what they're capable of doing. </p>

<p>If this is the case, then this poses another question: How would you go about learning to hack in an ethical manner? I definitely don't want to break laws or cause harm in my quest.</p>
","15466","","591","","2013-08-26 18:55:06","2013-08-26 18:55:06","What is the best way to learn how to develop secure applications?","<security><hacking>","3","6","","","","CC BY-SA 3.0"
"358675","1","","","2017-10-06 09:14:38","","-2","203","<p>I am thinking how to implement the login of a new web application and as I search the net, most search result as about authentication instead of encryption.</p>

<p>Assumption: The web application is designed for corporate purpose. The web application are going to use REST api to communicate with backend.</p>

<p>The first two search result from a google search with ""rest api spring https"" are about authentication instead of encryption, although I have added keyword https. Isn't REST api based on HTTP, and HTTP is not encrypted?</p>

<p>We have some business data which are not very sensitive, such as account number. If I do not use encryption on the API return value, wouldn't all of it be plaintext and is available across the internet?</p>
","15309","","","","","2017-10-10 14:11:29","Is authentication equally important to encryption?","<rest><security><http>","3","0","","","","CC BY-SA 3.0"
"358892","1","358893","","2017-10-10 10:47:56","","1","220","<p>I'm trying to develop a small solution with the possibility of user authentication. Because this will be later hand over to other developers, i want the first iteration of the solution secure as possible for user data.</p>

<p>After reading some stuff about security and hashing, i'm decided to store hash + salt in a single field in the database. Most of the time salt's in the examples are 16 byte's long. But technical they could have had any size.</p>

<p>That leads to my question:</p>

<ul>
<li>If it isn't public how long my salt and my hash are and i set them to a 'random' value, is this an extra step for protecting user data?</li>
</ul>

<p><em>If somehow the database gets in wrong hands, the attacker wouldn't know at which point the salt ends and the hash starts.</em></p>

<hr>

<p>Given example in <code>.net Core 2.0</code> which allows me to set the length of salt and hash:</p>

<pre><code>static Dictionary&lt;string,string&gt; _memDict = new Dictionary&lt;string,string&gt;() {{""username"",""password""}};

static int _amountOfHashBytes = 32;
static int _amountOfSaltBytes = 16;
static int _amountOfIterations = 10000;

static void Main(string[] args) 
{
    string passphrase = ""passphrase""; 
    string usrName = ""dotnetcoreuser"";

    // 1) Create the salt value with a cryptographic 
    byte[] salt; 
    RandomNumberGenerator.Create().GetBytes(salt = new byte[_amountOfSaltBytes]); 
    Console.WriteLine(""Salt: "" + Convert.ToBase64String(salt)); 

    // 2) Create the Rfc2898DeriveBytes and get the hash value
    var pbkdf2 = new Rfc2898DeriveBytes(passphrase, salt, _amountOfIterations); 
    byte[] hash = pbkdf2.GetBytes(_amountOfHashBytes); 
    Console.WriteLine(""Hash: "" + Convert.ToBase64String(hash)); 

    // 3) Combine the salt and password bytes for later use
    byte[] hashBytes = new byte[_amountOfSaltBytes + _amountOfHashBytes]; 
    Array.Copy(salt, 0, hashBytes, 0, _amountOfSaltBytes); 
    Array.Copy(hash, 0, hashBytes, _amountOfSaltBytes, _amountOfHashBytes); 

    // 4) Turn the combined salt + hash into a string for storage
    string savedPasswordHash = Convert.ToBase64String(hashBytes); 
    Console.WriteLine(""Combine: "" + savedPasswordHash); 
    _memDict.Add(usrName, savedPasswordHash);

    // 5) Verify the user-entered password against a stored password.
    string tryInput = ""1234"";
    Console.WriteLine(""Try: {0} Result: {1}"", tryInput, IsValidPassword(tryInput, usrName));
    tryInput = ""password"";
    Console.WriteLine(""Try: {0} Result: {1}"", tryInput, IsValidPassword(tryInput, usrName));
    tryInput = ""passphrase"";
    Console.WriteLine(""Try: {0} Result: {1}"", tryInput, IsValidPassword(tryInput, usrName));
}

static bool IsValidPassword(string userInput, string userName)
{
    string savedPasswordHash = _memDict[userName];
    byte[] hashBytes = Convert.FromBase64String(savedPasswordHash);
    byte[] salt = new byte[_amountOfSaltBytes];
    Array.Copy(hashBytes, 0, salt, 0, _amountOfSaltBytes);
    var pbkdf2 = new Rfc2898DeriveBytes(userInput, salt, _amountOfIterations);
    byte[] hash = pbkdf2.GetBytes(_amountOfHashBytes);
    for (int i=0; i &lt; _amountOfHashBytes; i++)
    {
        if (hashBytes[i+_amountOfSaltBytes] != hash[i]) { return false; }
    }
    return true;
}
</code></pre>
","134545","","","","","2017-10-10 19:50:05","Is the length of a 'salt' a safety factor?","<design><security><.net-core>","2","2","","","","CC BY-SA 3.0"
"57627","1","","","2011-03-13 22:05:54","","-1","579","<p>I'm making a small social networking web site for a specific university's students (where I study) and I'm concerned about security (access to the database). What should I do? What I have to check for last time until I went online?</p>

<p>(Yeah, Facebook Facebook. Facebook don't have that community sense. You cannot find all your department mates on Facebook. You cannot see all foreign students on Facebook. You cannot hide your identity on Facebook while commenting, etc etc. Just please don't compare it with Facebook, we had a great <em>local</em> social network until it went <em>public</em> . <a href=""http://replay.waybackmachine.org/20070416113041/http://www.hoccam.com/"" rel=""nofollow"">*</a> ))</p>
","2410","","2410","","2011-03-13 22:41:26","2011-03-14 10:04:11","My very first serious project and I'm concerned about security","<web-development><security>","7","3","","2014-01-01 16:39:43","","CC BY-SA 2.5"
"134975","1","","","2012-02-14 07:00:31","","14","755","<p>Where I work, we have a lot of developers and an awful lot of code running our proprietary applications used by staff &amp; customers alike.</p>

<p>We also have a lot of smart support staff that like to understand the inner workings of our systems to better support our customers, and perhaps even submit a patch from time to time.</p>

<p>Should we open up our code for our non-development staff to be able to read?  What factors should we take into account when making this decision?  I have come across a bunch of arguments and counter-arguments each way &amp; would like to make a decision based on the experience of others as well as well-understood risks.</p>

<p>Some arguments thus far:</p>

<ul>
<li>Passwords in VCS are exposed (solution: get rid of the passwords - they shouldn't be there to begin with)</li>
<li>Code is open to white-box security attacks (counter-argument: this only keeps out the honest/lazy attackers)</li>
<li>Support staff can ask developers ""how"" things work (counter: teach a man to fish, etc)</li>
</ul>

<p>Does anyone open their code to staff at their organisation?  Has it caused any problems?</p>
","9570","","","user34530","2012-02-14 23:32:52","2012-02-14 23:32:52","Should internal code be shared with non-developers in an organisation?","<open-source><security><enterprise-development><risk>","4","10","","","","CC BY-SA 3.0"
"57909","1","57917","","2011-03-14 17:13:54","","2","1654","<p>I'm writing a mobile app &amp; web service combo that requires user to login. The web service will be using SSL, so are there any reasons against sending the user name and password in every web request? </p>

<p>I know some sites generate a token after the user logs in, that they can use for authentication, but the token seems equivalent to the username/password pair - so I'm not sure there's much point in doing that.</p>

<p>Am I about to make a big mistake in terms of security?</p>
","3844","","","","","2011-03-14 17:25:09","Sending username and password in every request from iPhone app","<iphone><security><web-services>","2","0","","","","CC BY-SA 2.5"
"359400","1","359406","","2017-10-19 12:17:45","","0","66","<p>I'm developing an APP that has a API and a database that holds user permissions and user projects, among other things.</p>

<p>Certain stored procedures must be protected, and for that I have to check the scopes available for the user.</p>

<p>Should I check the user permissions inside the stored procedures (calling a second proc or function that would check if the user has a certain scope) or should I do two database calls from my endpoint, one to check if the user has the necessary scopes and a different one to execute the protected procedure?</p>
","278339","","","","","2017-10-19 13:21:42","Checking permissions with multiple database calls or in stored procedure?","<database><api><security>","1","0","","","","CC BY-SA 3.0"
"249893","1","250026","","2014-07-15 03:49:58","","2","140","<p>Question: Is there any standard model or industry defacto implementation for modeling and implementing Access Control in (i.e.) a Document Management System?</p>

<p>Note: I studied a bit the security mechanism of Windows (which I do not want to use), and I saw Users and Groups and Policies. </p>

<p>But I can't understand: </p>

<p>1 - How a single policy object can contain all information about allowed/denied actions on a subject for all users and groups, at a specific moment of time.</p>

<p>2 - How multiple policies on a specific subject, merge into one to provide least possible access.</p>

<p>3 - What is the mechanism (data structures, database, caching, implementation) of hierarchical resources like folders? Those king of queries are usually slow.</p>
","8450","","","","","2014-07-16 00:45:14","Privilege (Access/Permission) Control for Hierarchial Structured Resource","<security><access-control><document-management>","1","0","","","","CC BY-SA 3.0"
"359805","1","359811","","2017-10-27 00:36:29","","11","486","<p>This question came up today while discussing with a colleague about the 'create account' page for the website we're working on.</p>

<p>My colleague's opinion is that we should make the registration as quick and seamless as possible, therefore we should just ask the user for his email and take care of the rest.</p>

<p>I agree with the intention, but I have a few concerns about it:</p>

<ul>
<li>Since we generate the password, we <em>have</em> the responsibility to make sure the password is strong enough</li>
<li>In my experience, when confronted with an unintelligible password, users are likely to write it down on a post it</li>
<li>The users who do not write the password down, are pretty likely to forget it. Which means they'll have to ask for a new password regularly, and that's not fun for anyone</li>
</ul>

<p>However, considering the general quality of passwords created by users, and the fact that too many people tend to use the same password for everything ('shudders'), I can see how it would make sense to generate a strong password for them.</p>

<p>I still feel torn about it. We are working on a merchant website where the user has the option to save his credit card details, so it is obviously very important that we use most secure approach.</p>
","246885","","246885","","2017-10-31 04:41:34","2017-10-31 04:41:34","During account creation, is it better to generate the password automatically and send it to the user, or to let the user create his own password?","<security><passwords>","1","7","","","","CC BY-SA 3.0"
"359873","1","359874","","2017-10-28 04:11:02","","2","279","<p>Is it bad practice to use an incrementing primary key to refer to a real world field, such as an id number for an employee?</p>
<p>Suppose that 1 is a valid id number for an employee. I am really tempted to use the incrementing primary key as the id number. But I might have ignored some potential problems it might cause. I've read that it is not bad to expose the primary key to the user (just like what SO does).</p>
<p>Is what I'm doing a bad practice?</p>
","144461","","379622","","2022-04-14 01:05:47","2022-04-14 01:05:47","Using incrementing primary keys on real world data","<security><sql>","3","1","","","","CC BY-SA 4.0"
"359882","1","","","2017-10-28 09:35:53","","14","1049","<p>We are trying to determine the best way to authorise users in a microservice architecture, while ensuring microservices have limited permissions. Our architecture uses a central authorisation service to handle issuing of JWT tokens.</p>

<p>We have the following requirements:</p>

<ol>
<li><p>Users should be limited to perform certain roles. e.g. a user should only be able to create/modify/read content that he owns.</p></li>
<li><p>Microservices should be limited to only the permissions they require. e.g. a microservice that only needs to read data from another service should be explicitly forbidden from writing data to that service.</p></li>
</ol>

<p>As an example, suppose we have a system where users can upload pictures to an image store service. We have a tagging service that automatically tags pictures with a location. Users can only CRUD their own pictures. The tagging service can read any image from the image store service, however should not be able to modify/delete.</p>

<p>What is a good way to achieve the above using JWT tokens? Some solutions that we've discussed are: </p>

<ol>
<li><p>The image store service expose 2 APIs, one that is available externally (giving user CRUD access), and one that is available internally (giving internal read-only access). Seems inflexible - what if another internal service needs read/write access to all images (e.g. one that automatically deletes explicit images)?</p></li>
<li><p>We set up two permissions in the user's JWT, one being CRUD_OwnImages, the other being READ_ForAnalysis. The tagging service can see if the user has READ_ForAnalysis permissions, and if so, make the appropriate request. We have another microservice that checks to see if user has CRUD_OwnImages for CRUD operations on the user's own images. This puts the responsibility on each microservice to ensure that the user is restricted to the actions he requires. The image store has no way to restrict each microservice with this approach, so it is potentially flakey and error prone.</p></li>
<li><p>We give the tagging microservice its own user, with READ_ForAnalysis as a permission. Then, when the tagging service requests images from the image store, it is given access to those, but is forbidden from modifying them. The user's user only has CRUD_OwnImages permission, so he is able to retrieve and get access to only his images from the frontend. If another service needs CRUD to all data, we can give it CRUD_AllData or similar. We like this approach as each service is now responsible for its own data (rather than that logic being duplicated across multiple services), but what if the service requires both user permissions and microservice permissions? Can we send two JWT tokens (both the user's and the microservice's) securely? Is there a way to combine permissions securely and send that through? e.g. the tagging service can read all images but can also write the user's images with the location?</p></li>
</ol>

<p>The problem is exacerbated if the user information is needed further downstream (2 or 3 microservices away). Do we just assume that it is up to individual microservices to restrict themselves to the actions that they need, and not make that explicit? </p>
","287014","","1204","","2017-10-28 16:30:05","2017-10-28 17:46:40","Should microservices be users?","<security><microservices><jwt>","1","2","","","","CC BY-SA 3.0"
"136006","1","136018","","2012-02-20 19:50:39","","4","118","<p>I've been thinking a lot lately about the need for better form security, and good ways to accomplish that.</p>

<p>We currently use captcha codes to screen for bots, but that's annoying to users and may not work forever.</p>

<p>I think that we need a more intuitive, organic system for screening bad comments/contact form submissions.</p>

<p>One option that has come to mind would be trying to screen comments for things that are obviously not words, in addition to screening for duplicate comments.  E.g., when a spammer on Facebook, Twitter, or a comments section is stopped from just posting the same thing a lot of times, they add garbled letters and or numbers somewhere in the post to make it ""unique"". </p>

<p>If it was possible to screen out obvious not-text, this could be overcome. If you could go a step further, and screen out posts that obviously have words placed in for no reason except to make the post ""unique"", you could force the spammer/scam artist down to only use repetitive post options which actually make gramatical sense.</p>

<p>At the very least, you could have posts be flagged for moderator attention if they looked similar but which just had random garbage added in for no reason. This would significantly reduce a spammer's ability to keep spamming, even across multiple accounts.</p>

<p>Could it be possible to screen form field results for random word and number combinations, and words thrown in just to make a post ""unique""?</p>
","48135","","","user34530","2012-02-20 23:16:01","2012-02-21 05:27:15","Would it be hard to screen form submissions (e.g., comments) for non-words/non-sentences?","<security><validation>","2","1","","","","CC BY-SA 3.0"
"250314","1","252895","","2014-07-18 03:10:01","","0","4397","<p>I've just put together my first app using Zend_Authenticate. According to some tutorials I've read they store the user's ""email"" column. Is this recommended? I've read to store the ID only, then on each request fetch the user by ID. That way, only the ID is stored in the session. Is this recommended with Zend too?</p>

<p>Anyway here is my handling of user login, I'd appreciate any feedback. Basically I'm authenticating. If that passed, I then store the ID in auth storage and a custom flash message. The script then redirects to the homepage (upon which the login form will be replaced with a user panel - e.g. ""Welcome back John"" - and my flash message will display.</p>

<p>Below is my loginAction method:</p>

<pre><code>public function loginAction()
{
  $form = new LoginForm();

  $form-&gt;get('submit')-&gt;setValue('Login');

  $request = $this-&gt;getRequest();

  if ($request-&gt;isPost()) {

      // check the users credentials and authenticate
      $this-&gt;getAuthService()
        -&gt;getAdapter()
        -&gt;setIdentity($request-&gt;getPost('email'))
        -&gt;setCredential($request-&gt;getPost('password'));

      $result = $this-&gt;getAuthService()-&gt;authenticate();

      if ($result-&gt;isValid()) {

        // set the user id in storage
        $resultRow = $this-&gt;getAuthService()-&gt;getAdapter()-&gt;getResultRowObject();
        $this-&gt;getAuthService()-&gt;getStorage()-&gt;write($resultRow-&gt;id);

        // set flash messenger
        $this-&gt;flashMessenger()-&gt;addMessage('You are now logged in');

        // redirect to the home page
        return $this-&gt;redirect()-&gt;toUrl('/');
      }

  }

    return new ViewModel(array(
      'form' =&gt; $form,
    ));
  }

}
</code></pre>
","142254","","31673","","2014-07-18 09:25:32","2014-08-10 16:51:01","Zend framework 2 authentication - only storing the user ID in session","<php><security><zend-framework>","1","0","","","","CC BY-SA 3.0"
"360159","1","","","2017-11-02 18:51:18","","2","146","<p>We're trying to build a solution where we have a requirement to check password compliance of a user with respect to all the systems that he has to.</p>

<p>For example, if system 1 mandates that password should have 4 alphabets and system 2 has a requirement of 5 alphabets, if the user happens to have access to both systems 1 &amp; 2 , we need to make sure that his current password has 5 alphabets. We have similar password composition requirements like number of special characters, number of digits, min length etc.</p>

<p>Systems are at liberty to change password composition at any time so when the user logs in to any of the systems that he has access to, we need to calculate effective password policy  (basically a union of all individual system policies) and prompt the user to change his password if it's not compliant.</p>

<p>We want to do this without having to store/ remember the user's password in plain text anywhere and in a secure fashion.</p>

<p>Our current option is,</p>

<p>Get password composition (just the no of digits, alphabets, special characters, length) during login and pass that information to a service that can tell us whether it's compliant or not.</p>

<p>Is there any better way to do this ?
Appreciate any help on this.</p>

<p>Note: If you think that this should be asked in a different site in stack exchange, please let me know.</p>
","287450","","","","","2017-11-02 19:24:29","Password policy compliance design","<java><design><security>","1","2","","","","CC BY-SA 3.0"
"360214","1","360216","","2017-11-03 22:57:03","","5","5452","<p>I have a route in a RESTful API where I need to pass a single username (email address) but not password. The route is designed to have GET method, so my options are either query parameters or a custom HTTP headers. </p>

<p>I read that sending usernames via query parameters is not a good practice, but could not find any related information concerning custom header.</p>

<p>Could you please share your suggestion regarding this?</p>
","278534","","","","","2021-07-29 19:05:23","Is sending username via custom HTTP header good idea?","<rest><security>","2","1","","","","CC BY-SA 3.0"
"250530","1","250558","","2014-07-20 18:28:52","","0","416","<p>I'm currently in the process of creating a Skype-like program, that uses a hybrid peer to peer system to communicate between users (i.e. server contains all users IPs, a client that wants to connect to a friend will tell the server, that will then send each client the other's IP so they could start hole punching to establish a connection between them).</p>

<p>I know that with Skype, there are many websites that allow you to enter a username and easily get his IP address. My question is, what is the best way of preventing such an exploit?</p>

<p>Here are a few solutions I could think of:</p>

<ul>
<li>save each and every users' friends lists on the server (so the server can just drop IP requests from users that aren't in the requested client's friends list)</li>
<li>whenever the server is asked for a client's IP, ask that client if the asker is on their friends list (if not, don't reply)</li>
<li>have each client use some secret key to communicate with the server (so only registered clients will be able to send IP requests)</li>
</ul>

<p>Feel free to add a different solution, again, these are just solutions I could think of off the top of my head while writing this question.</p>

<p>In addition, a related question that I wanted to ask - what would be the best practice in such a program:</p>

<p>Have each client store his friends' IPs and make the server notify him whenever they are changed</p>

<p>-VS- </p>

<p>Have the client ask the server for a friend's IP whenever he wants to start a direct connection with him (keep in mind that the client anyway has to tell the server whenever he's trying to connect to someone, in order for the hole punching to work).</p>

<p>P.S. I've never created such a program and I'm not following any tutorial or such. If there's any better way of doing something I wrote, or if I got anything wrong, I'd be very glad if you could mention it.</p>
","143378","","","","","2014-07-22 00:40:54","Preventing ip resolvers in a skype-like program","<design><programming-practices><security><code-quality><p2p>","2","0","","","","CC BY-SA 3.0"
"60030","1","","","2011-03-20 00:15:42","","17","4444","<p>A lot of the basic network protocols that make up the infrastructure of the Internet are built in to most major Operating Systems.  For example, TCP, UDP, and DNS are all built into Linux, UNIX and Windows, and are made available to the programmer through low-level system APIs.  </p>

<p>But when it comes to SSL or TLS, one has to turn to a third-party library such as OpenSSL or Mozilla NSS.  </p>

<p>SSL is a relatively old protocol, and it's basically an industry standard as ubiquitous as TCP/IP, so why isn't it built into most Operating Systems?</p>
","17252","","17252","","2011-03-20 01:02:17","2013-09-19 20:48:45","Why isn't SSL/TLS built into modern Operating Systems?","<security><operating-systems><protocol><ssl>","7","6","","","","CC BY-SA 2.5"
"250806","1","260513","","2014-07-23 02:28:20","","0","374","<p>I'm attempting to build a browser-based HTML5 application that has the ability to store data locally on a PC (not mobile device) when offline. This data is sensitive and must be secure.</p>

<p>Of course the trick is trying to find a way to be able to access the secure data with Javascript. </p>

<p>I've ruled out browser local storage since its not secure. Could this be accomplished with a local database? If so, where could the DB credentials be stored? Javascript obviously doesn't seem like a good option to store them since its user-readable. </p>
","98056","","","","","2014-10-21 06:39:53","secure offline PC storage accessible through javascript","<web-development><web-applications><security>","2","4","","","","CC BY-SA 3.0"
"437148","1","","","2022-03-04 19:35:27","","-3","247","<p>We want our developers to be able to diagnose production issues in staging. For the sake of this, we are planning to make an exact replica of production into staging. We are thinking however, if we scrub the non-encrypted data, that it could no longer represent issues that may be present in production.</p>
<p>What is the best practice in this situation? Should they have full read access to staging? Should it be scrubbed? How should the staging environment be implemented for customer security but also to allow developers to diagnose production issues?</p>
","411665","","","","","2022-03-05 11:54:27","How much access should a developer have to a Staging database","<architecture><database><security><sql>","1","2","","2022-03-07 15:08:18","","CC BY-SA 4.0"
"250925","1","","","2014-07-23 23:00:19","","-1","1610","<p>Let's say that hypothetically you wanted to build a website that delivered content to the visitors entirely using HTML and Javascript (AJAX to fetch server side data). The site would require login for certain functions. Let's also say, for the sake of discussion, you have the ability to create necessary web service methods that would be called from AJAX (for authenticating a user, getting data from a database, etc). </p>

<p>What would be the best way to implement this site? Would there be any advantages / drawbacks compared to building a site using a server side language like ASP.NET or PHP?</p>

<p><strong>EDIT 1</strong></p>

<p>First, thanks to everyone that has replied so far. I didn't properly phrase my question so I'm getting responses that aren't addressing my question. I've built many sites using traditional methods - a database backend and a frontend that was a mix of server side languages (.NET or PHP) and client side scripting JavaScript / jQuery. </p>

<p>Let's say I'm going to build an environment that has a database server, a web services server, and a web server. My web services server has all the methods I need to interact with the database (authentication, CRUD operations, reporting, etc). The web server does not support any server side languages (like PHP or ASP.NET). </p>

<p>I know it would be possible to build the site entirely in HTML, CSS, and JavaScript (jQuery). A user could be authenticated via AJAX, the authentication token could be stored in a cookie, and then token could be used on all subsequent AJAX requests. </p>

<p>My questions are:</p>

<ol>
<li>What would be the advantages / drawbacks of such an approach?</li>
<li>What challenges would be faced with authentication and security?</li>
<li>Would this solve any of the problems typically faced when building a website?</li>
<li>If your boss was asking you to use this environment, would you argue against it? Why or why not?</li>
</ol>
","143861","","143861","","2014-07-24 20:09:43","2014-07-24 20:09:43","Whats the best way to build a HTML/AJAX site that requires login?","<javascript><programming-practices><security><ajax>","2","1","","2014-07-25 14:08:54","","CC BY-SA 3.0"
"250979","1","","","2014-07-24 10:23:31","","0","113","<p>We're close to start new project using <code>sf2</code>, and, probably, <code>FosUserBundle</code>. </p>

<p>Keeping that in mind - what's the best strategy to define roles? App will be used by multiple divisions inside our company (every division has it's manager and regular employees), as well as external users, that can be divided into 3 groups (for now).</p>

<p>I'm comming up with two possible solutions:</p>

<ol>
<li><p><strong>each role represents specific action in app</strong>, i.e.: adding new task action is described as <code>task_new</code> role. Selected users get this role to be able to add new task.</p></li>
<li><p><strong>each role represents user ability and every action checks if user has this ability</strong> i.e.: when new task is being added, controller checks if current user has role <code>task_access</code> role.</p></li>
</ol>

<p>I <strike>really</strike> somehow like approach to this problem in our current app - there's one place where only admin has access granted, with list of all registered actions. Users are divided into about 10 groups and all you have to do is to check that this group has access to this action. In this case no code-juggling is required, but I'm afraid it will generate some limitations or roles overgrowing in new app.</p>

<p>What I'm really afraid of is spending too much time changing the security code in specific controller/action, I mean, when new user has to get access to specific place, I will have to go to the code, handle new role, code will grow, and so on. I want to keep this time as low as possible, and as flexible as possible. </p>

<p>I believe there are some great solutions to this problem. Am I right?</p>
","106019","","","","","2014-07-24 12:32:36","Roles configuration strategy","<php><security><roles><symfony>","1","0","","","","CC BY-SA 3.0"
"360538","1","","","2017-11-09 16:40:28","","0","136","<p>Premise: I'm asked to develop a system that will trace sensitive data. The data are gathered by an intermediate operator (let's call him IO) on an office terminal. The final user (EU) will show up to the office, identify itself via an ID document, the operator will acquire the information and send it to the system.
On request, given the not anonymous ID, the IO be able to consult the history of all the information acquired for that ID.</p>

<p>Objective: store the data on a centralized server in a completely anonymous way using an anonymous ID as an alias of the real ID. I want to make hard even for the technical operators of the server to retrieve the original ID.</p>

<p>My solution since now: as a first step toward the solution I thought of generating a salt hash starting from the password inserted by the IO, and use this salt for hashing the not anonymous ID, then send to the server the hashed ID instead of the real ID (there is the possibility of a hash collision, but, in my scenario it is an acceptable risk).</p>

<p>The problem is that every time the IO will change the password, he will lose access to the history of all the ID inserted (the same, not anonymous ID, will be translated as x before password change and as y after).</p>

<p>An improvement should be that the system will generate a salt on the IO machine at first login attempt, crypt it using the IO password and store it on the server. The salt will be retrieved at every future access, decrypted on the IO machine and used to generate the ID. If the user will change his password it will send, during the normal change password procedure also the hash encrypted with the new password. If the user forgot the password, the procedure to generate a new one will be started and IO will lose access to the history (this is acceptable given the sensitive nature of this data, it will be IO responsibility to store his password in the safest way possible).</p>

<p>At the moment I see a flawless on this procedure, on server side, every time a new encrypted hash will be sent to the server, technical operator will have access to a sequence of encrypted hash, they know this is the same number encrypted with different passwords, this will be a useful information tha will help to crack the salt. How can I protect against this? There are others weaknesses?</p>

<p>But there is more: the perfect solution will allow 2 or more IO to gather data for the same, not anonymous ID, and store it on the server with the same anonymous ID not allowing server operator to retrieve the original ID.</p>

<p>There is a way to achieve this result?</p>

<p>Thank you</p>

<p>PS: as observed in one of the answers one of the challenges of this project is that not anonymous ID are very limited (in the order of billions) and can be easily enumerated.</p>
","287999","","287999","","2017-11-09 22:16:13","2017-11-10 03:48:08","How generate an anonymous (even for system administrator) identification number from a non anonymous identification number","<security><privacy>","2","0","","","","CC BY-SA 3.0"
"137129","1","","","2012-02-27 15:32:15","","-1","2782","<pre><code>&lt;HTML&gt;
&lt;HEAD&gt;&lt;TITLE&gt;Login Page&lt;/TITLE&gt;&lt;/HEAD&gt;
&lt;BODY&gt;
&lt;CENTER&gt;
&lt;FORM method=""POST"" action=""http://yourserver/cgi-bin/login.py""&gt;
&lt;paragraph&gt; Enter your login name: &lt;input type=""text"" name=""login""&gt;
&lt;paragraph&gt; Enter your password: &lt;input type=password name=""password""&gt;
&lt;paragraph&gt; &lt;input type=""submit"" value=""Connect""&gt;
&lt;/FORM&gt;
&lt;/CENTER&gt;
&lt;HR&gt;

&lt;/form&gt;
&lt;/BODY&gt;
&lt;/HTML&gt;
</code></pre>

<p>login.py:</p>

<pre><code>#!/usr/local/bin/python
import cgi

def header(title):
   print ""Content-type: text/html\n""
   print ""&lt;HTML&gt;\n&lt;HEAD&gt;\n&lt;TITLE&gt;%s&lt;/TITLE&gt;\n&lt;/HEAD&gt;\n&lt;BODY&gt;\n"" % (title)

def footer():
   print ""&lt;/BODY&gt;&lt;/HTML&gt;""

form = cgi.FieldStorage()
password = ""python""

if not form:
   header(""Login Response"")
elif form.has_key(""login"") and form[""login""].value != """" and form.has_key(""password"")       and form[""password""].value == password:
header(""Connected ..."" )
   print ""&lt;center&gt;&lt;hr&gt;&lt;H3&gt;Welcome back,"" , form[""login""].value, "".&lt;/H3&gt;&lt;hr&gt;&lt;/center&gt;""
   print r""""""&lt;form&gt;&lt;input type=""hidden"" name=""session"" value=""%s""&gt;&lt;/form&gt;"""""" % (form[""login""].value)
   print ""&lt;H3&gt;&lt;a href=browse.html&gt;Click here to start browsing&lt;/a&gt;&lt;/H3&gt;""

else:
   header(""No success!"")
   print ""&lt;H3&gt;Please go back and enter a valid login.&lt;/H3&gt;""

footer()
</code></pre>

<p>I would like to make this login form vulnerable to RCE (remote code execution), is this possible with the function <code>eval()</code> or <code>exec()</code>.</p>

<p>I am looking for functions that introduce a vulnerability within the login form. Are there whole classes/modules that contain dangerous functionally? Also would it be possible to make this login form vulnerable to remote code execution?</p>
","48603","","","user34530","2012-02-28 04:10:12","2012-02-28 04:10:12","python login form vulnerability?","<web-development><python><security><web>","1","2","","","","CC BY-SA 3.0"
"360631","1","360633","","2017-11-11 12:02:06","","2","953","<p>I have a client side android app which needs to send an encrypted string to a server implemented in PHP. For this I have chosen an asymmetric algorithm (RSA).</p>

<p>Should I:</p>

<ul>
<li>Save a public key in client side and use this for encryption and then
send the private key and encrypted string to the backend</li>
</ul>

<p>or:</p>

<ul>
<li>Get the public key from backend first and then do the encryption and then 
send the encrypted string only to the backend</li>
</ul>

<p>If neither one is enough good, can anyone suggest the most followed practice?</p>
","282748","","214828","","2017-12-01 16:32:52","2017-12-01 16:32:52","encrypting a string with public key in client side and decrypt it in backend using private key","<algorithms><security><android><encryption>","1","2","","","","CC BY-SA 3.0"
"360689","1","","","2017-11-13 05:58:49","","4","1129","<p>In most web application which deals with a database, one has to enter the DB creds in a settings or config file, like <code>DATABASES</code> variable in <code>settings.py</code> in <code>Django</code>. What is the general practice to secure the creds such that only a selected few in the team knows the creds and even they are not able to connect to the DB with same creds(even from the same machine on which application is being run)?</p>
","112414","","","","","2017-11-13 10:45:46","securing database username and password in a web framework","<design-patterns><web-applications><security><code-security>","3","0","","","","CC BY-SA 3.0"
"137319","1","","","2012-02-28 13:52:28","","2","197","<p>My team is going to add new team members and my manager doesn't want to take any risks. I don't think it's a large problem but my manager is concerned that a new programmer would sabotage and accidentally destroy parts of the code or the data e.g. cause data disaster. I say that probability is not very high but still I've been told that it's important to limit the rights of what new collaborators can do.</p>

<p>But this is not practical and we can't eat the cake and have it - adding a collaborator to source control gives the new collaborator access to all the source code and even if there was a way to only let a new member in to parts of the source code (we're using bitbucket for source control) it still wouldn't work since technically the whole project is usually needed to build it so one can't just take a part of the code and expect it to work and able to build on independently.</p>

<p>We're using Google App Engine and nor is it a working idea to create a clone of the app that my collaborator can build on.</p>

<p>I said that we are not the first ones with this problem and that a solution that works for someone else should work for us but my manager seemed not satisfied with that answer.</p>

<p>Can you comment on my situation or give concrete advice what could be done about the ""problem"" / scenario since it's just a scenario that a newly added developer accidentally deletes the whole datastore, but we don't want it to be possible.</p>
","12893","","20065","","2012-02-28 14:12:10","2012-02-28 15:39:54","How to not take risks with new collaborators?","<security><collaboration>","4","1","","","","CC BY-SA 3.0"
"61263","1","","","2011-03-23 22:21:40","","1","307","<p>I've been discussing with my colleges about logging in by using your OpenID account, Google account etc. in our customers CMS and/or the internal systems we use, as we've had a few requests regarding this from both existing customers and new. </p>

<p>What are your approaches on this? Is this a bad idea? Especially for our customers, in their customized content management systems? I really think it can be a major security issue, but would a normal login, provided by us, in the reality, be as much of a security risk?</p>
","20993","","20993","","2011-03-23 22:57:14","2011-03-24 02:35:32","Is it a good idea to implement OpenID services in internal and/or customer applications?","<security><cms><openid>","2","0","","","","CC BY-SA 2.5"
"137603","1","137651","","2012-02-29 16:17:51","","0","1651","<p>My program uses the following define statements:</p>

<pre><code>#define LOWEST_PATIENT_ID 10000
#define HIGHEST_PATIENT_ID 99999
#define LOWEST_CRITICAL_STATUS 1
#define HIGHEST_CRITICAL_STATUS 100
</code></pre>

<p>used in this type of code:</p>

<pre><code>do{
   scanf(""%d"", &amp;c_status);
   }while((c_status&lt;LOWEST_CRITICAL_STATUS)
           ||(c_status&gt;HIGHEST_CRITICAL_STATUS));
</code></pre>

<p>I'm unclear about how this is more secure. or is it the typedef statement that is secure?</p>
","29032","","20065","","2012-02-29 17:35:52","2012-02-29 19:37:03","How does using #define for loop and condition bounds in C increase security?","<c><programming-practices><security>","4","2","","","","CC BY-SA 3.0"
"137664","1","137675","","2012-02-29 20:24:40","","2","2408","<p>I am implementing RSA encryption on a Android App so that I can send SMS message securely, each phone will have its own public and private key generated by the App. </p>

<p>But am stuck deciding the best way to store the keys, my options are: </p>

<ol>
<li>Create a keystore and hold the public and private key in the keystore.</li>
<li>Save the public and private key to separate files.</li>
<li>Use sharedpreferences to store keys.</li>
</ol>

<p>I was also thinking of encrypting the private key with blowfish if just stored in a file.</p>

<p>Can anyone help explain to me which is the most secure option?</p>
","48820","","44303","","2012-02-29 23:28:19","2012-02-29 23:28:19","Implementing RSA into an Android Messaging App","<android><security>","1","1","","","","CC BY-SA 3.0"
"61773","1","","","2011-03-25 04:07:19","","4","2117","<p>I'm looking for good reference on patterns that apply to user security and ACLs for multi-user network applications.</p>

<p>I'm re-writing a fairly large application from scratch. Now I'm looking at the user management and security. I'm not so interested in user meta data, but rather ACLs and security. Right now the application has users, groups, and roles. Users and roles have ACLs. Groups do not. A user can belong to none or any number of groups and/or roles. I cannot find a good reason not to combine roles and groups. However, I'd like to hear the various opinions on the subject.</p>

<p>It would be nice to be pointed to some design patterns and references on the subject.</p>
","16729","","","","","2017-03-26 10:56:43","user security pattern recommendation/best practice","<design-patterns><security><users>","2","7","","","","CC BY-SA 2.5"
"61798","1","","","2011-03-25 06:22:36","","17","15546","<p>So I've worked in many different workplaces as a developer and my level of access to the database has been varied. I typically don't have production db access. </p>

<p>Most of the time I have access to the test database, but it varies. Sometimes I can do and change database and data as I please, but usually there are other arrangements. Like I may only have read access to the data.</p>

<p>I worked in one place where a DBA team would manage the databases, we couldn't make changes at all unless we submitted a form with the sql script for them to ""inspect"". They typically didn't have much to do with the project itself so most of the time, it was just to press F5.</p>

<p>Honestly, I can understand why prod needs to be locked down but I prefer to have as much database access in the dev and test environments. I think most devs are reasonably capable of knowing their way around a database. But I would like to hear opinions though? How much database access should developers have? Can we be trusted to not break anything up there?</p>
","3214","","","","","2011-04-04 06:29:10","How much database access should developers have?","<database><security><access>","9","4","","2014-09-23 19:30:49","","CC BY-SA 2.5"
"361276","1","361285","","2017-11-26 00:54:32","","0","287","<p>I work for a finance startup managing the technical stuff. The COO decided to create a new web site using a contract developer and the owner of the company paid for it ($9k). I'm asked to use the new site (Joomla + plenty of custom PHP code), but it appears to be of very low quality and insecure. For example:</p>

<ul>
<li>It doesn't use source control or a framework.</li>
<li>It doesn't use MVC. The PHP source files are 30k - 98k in size. They embed HTML, CSS, PHP, JS into one file.</li>
<li>It uses the session id as an email verification token, allowing anyone who eavesdrops the email to hijack the session. <code>verifyaccount=true&amp;token="".session_id().""&amp;eml="".$_POST[""form_email""].""'&gt;</code></li>
<li>It doesn't use salts in the passwords. <code>$hashedPassword =  hash('sha256', $_POST['form_pswd']);</code></li>
<li>It doesn't escape user input in SQL queries. <code>WHERE u_password='"".$hashedPassword.""' &amp;&amp; u_username='"".$_POST[""username""].""'"");</code></li>
<li>It doesn't encrypt personal information or financial information.</li>
<li>It doesn't escape user input in HTML output. <code>&lt;input placeholder='Name' type='text' name='form_name' value='"".$row[""profile_name""].""'</code></li>
<li>The database password is hardcoded in the source code. <code>$mysqli = new mysqli(""localhost"", ...</code></li>
<li>The CRUD design does not even have R-Read. There is no display of user info that is entered! I asked to make sure I wasn't missing something. The demo used a sham wrapper of a static CMS page. This is interpreted as ""poking holes in it"".</li>
<li>It has 7 vulnerabilities according to a security scanning app, including XSS and clickjacking. I've shown the report.</li>
</ul>

<p>I'm certain it's only a matter of time before it's hacked and I don't want my name on it. So I've tried to warn against it. Unfortunately the COO seems to have made his mind and believes my position is a personal issue.  Most of my co-workers are non-technical and none has development skills, so nobody spotted the real issue.  </p>

<p><strong>How can I explain the boss/owner that it's not OK to use such an insecure and unmaintainable software, when the reasons are technical but knowing he spent a lot of money on it ?</strong>  </p>

<p>Regardless of the objective arguments, I figure my options are:</p>

<ol>
<li>State the facts and walk away.</li>
<li>Try to explain why it's bad. If success, continue with old Ruby on Rails site. If fail, walk away.</li>
<li>Try to fix the code myself. I dread this as it's very messy. It could take longer than expected.</li>
<li>Make the old site look like the new site. The new site does have nice design elements I can copy. Even though no one may know the difference, this option seems a bit disingenuous.</li>
</ol>
","51832","","209774","","2017-11-26 20:30:57","2017-11-26 20:30:57","Shall I use low quality insecure software if I'm asked to?","<security><code-quality><teamwork><management>","1","4","","","","CC BY-SA 3.0"
"137970","1","137982","","2012-03-02 13:18:30","","4","1474","<p>This is the first time that I am working on a web application. I was going through the question <a href=""https://softwareengineering.stackexchange.com/questions/46716/"">What technical details should a programmer of a web application consider before making the site public?</a> and noticed one thing that I knew nothing of:</p>

<blockquote>
  <p>Make sure your database connection information is secured.</p>
</blockquote>

<p>I am confused about it because as per my knowledge the database info, password, etc will be on my server used in my coding to connect to the db. Then what does this line specifically mean?</p>
","36966","","-1","","2017-04-12 07:31:27","2012-03-02 14:06:51","Making sure database connection information is secured","<web-development><database><security>","2","0","","","","CC BY-SA 3.0"
"252052","1","","","2014-08-02 12:09:58","","1","441","<p>Each user has multiple sites they can access reporting data for in an application I am working on. To prevent having to go to the database on every single request, I validate that they have access to the site only when they change sites and I then store the the current site id in the session. </p>

<p><strong>I am trying to eliminate session state so that my async ajax requests are not synchronized and also so that the user can have a different site open on each browser tab. I also don't want to go back to calling the database on every request to validate that the user has access to the given site making a request.</strong> I've seen implementations where people will encrypt the id on the client, but it's not sure what would prevent a third party from looking over someone's shoulder (seeing the id on the query string perhaps) then using that same id with their own login to make a request.</p>

<p><strong>I have two ideas:</strong></p>

<p>1) Encrypt the id with the persons authenticated user name as the seed... Then encrypt it again with some private key. When the request comes in I would decrypt with the private key then try to decrypt with the current user name and get the id back. Or perhaps I would combine the user name with the id like username@username.com_[SITEID] then encrypt that with the private key and split them to see if the current username matches the first part. The problem with this though is that it never expires really, so they could in the future make a request even if they have lost access as long as they have the id around.</p>

<p>2) Similar to idea 1, but I would use the session id with encryption as a third key perhaps. The problem here though is if the session expires and they leave a tab open, all the requests would fail from the tab that was left open even though a session is active.</p>

<p>3) Use a cache so that async requests are not affected and just store keys like username@username.com_[VALIDATED_SITE_ID] then see if the key exists when the request comes in and if not, hit the database to establish the validation key.</p>

<p><strong>Has anyone addressed this type of scenario where you need to validate the user can make a specific type of request, yet you doing it without session or hitting the database every time a request is made?</strong></p>
","48960","","","","","2014-08-02 12:09:58","How to validate information on server without using database or session","<design-patterns><security><asp.net-mvc><session>","0","3","","","","CC BY-SA 3.0"
"138118","1","138196","","2012-03-03 02:54:50","","8","17251","<p>I recently moved a service from BasicHttpBinding to WSHttpBinding (i.e. <a href=""http://en.wikipedia.org/wiki/SOAP"" rel=""noreferrer"">SOAP</a> 1.1 -> SOAP 1.2). In <a href=""http://en.wikipedia.org/wiki/Windows_Communication_Foundation"" rel=""noreferrer"">WCF</a>, using WSHttpBinding() makes it start using some default security settings. I presume the same default security settings are also used by the WCF Test Client since the client and server can continue talking after switching to the 'secured' WSHttpBinding. In fiddler, I've confirmed this security setup since I can witness more complex security handshakes from the previously dead-simple request-response i.e.</p>

<p><strong>Before:</strong> (BasicHttpBinding)</p>

<ol>
<li><p>[HttpRequest ] (SOAP Request In Clear)</p>

<p>[HttpResponse] (SOAP Response In Clear)</p></li>
</ol>

<p><strong>After:</strong> (WSHttpBinding)</p>

<ol>
<li><p>[HttpRequest ] RequestSecurityToken</p>

<p>[HttpResponse] RequestSecurityTokenResponse</p></li>
<li><p>[HttpRequest ] RequestSecurityToken</p>

<p>[HttpResponse] RequestSecurityTokenResponse</p></li>
<li><p>[HttpRequest ] RequestSecurityTokenResponse</p>

<p>[HttpResponse] RequestSecurityTokenResponseCollection</p></li>
<li><p>[HttpRequest ] EncryptedData</p>

<p>[HttpResponse] EncryptedData</p></li>
<li><p>[HttpRequest ] EncryptedData <strong>(actual application level request)</strong></p>

<p>[HttpResponse] EncryptedData <strong>(actual application level response)</strong></p></li>
</ol>

<p>So I can safely assume security is being applied. Now to the questions:</p>

<p><strong>Question 1: What are the security settings?</strong>
I never told WCF of any membership provider. In fact I don't have any table (SQL or XML) of any usernames &lt;-> passwords. So what kind of authentication is happening? Although WCF Test Client can authenticate as above, SoapUI doesn't pick up these Microsoft .NET defaults and has issues. SoapUI attempts clear text communications and then the server responds with an incorrect security token error.</p>

<p><strong>Question 2: What is the most commonly practiced security model for SOAP 1.2?</strong>
Is it via certificates or username passwords or digest or _____? How are those credentials stored (SQL/XML?) and configured on the WCF server side?</p>
","46588","","591","","2015-07-21 19:53:11","2015-07-21 19:53:11","What security is used by default in WSHttpBinding (service side) or the WCF Test client (client side)?","<security><wcf><soap>","1","0","","","","CC BY-SA 3.0"
"138307","1","138316","","2012-03-05 05:46:31","","-1","163","<p>I want to check that people who registrates in my site and check in country box , for example, Argentina is really living in Argentina.
How can I make sure that people is really living in that country and not access to my site via proxy or VPN?</p>
","42969","","","user22815","2015-04-20 15:10:32","2015-04-20 15:10:32","How can I make sure that people changes his IP or not","<security><ip-address>","1","5","","","","CC BY-SA 3.0"
"252487","1","","","2014-08-06 14:02:03","","0","851","<p>I'm building a solution based on Domain Driven Design, I'm trying to implement the security system (authentication, authorization, roles, system configuration, connection strings, etc..) in a transversal layer (cross cutting concerns like Caching, Security, Logging, etc).</p>

<p>The tiers of my application are two projects (ContractsTransversal and Transversal), where the ContractsTransversal project only exposes the services of transversal layer using interfaces (ICaching, ILogging, ISecurity,etc..) but the implementation of those interfaces are in the Transversal project.</p>

<p>The design is based on the book ""Guia de arquitectura de Ncapas orienta al dominio"" by Microsoft, that suggests the implementation of transversal layer across IoC (Dependency Injection) and its relation with all parts of the system are decoupled. I'm doing this, I created my container to implement IoC. I have other projects which have only my business entities like UsersEntity, ProductEntity, etc.</p>

<p>Is it correct to have a references of my business entities project to my Transaversal and ContractsTransversal project?</p>

<p>I ask because in security project I need to know information about the user, roles, permissions, etc.. or what's the best practice to implement security in a domain driven design model?</p>
","145373","","31260","","2014-08-06 15:16:29","2022-12-05 06:19:34","Security in Transversal Layer in Domain Driven Design","<security><domain-driven-design>","0","3","0","","","CC BY-SA 3.0"
"138579","1","138584","","2012-03-06 21:28:49","","4","472","<p>I'm trying to understand if security is a real concern, or if distribution actually does a better job with security. See, the access to the main source repository could be layered and inherently managed by a network of trust, and could still have centralized user management integrating users from an LDAP/Active Directory, while the centralized version control system just relies on the later. With distribution, access could even be given to less users per repository in different countries and maintained easier.</p>

<p>I can see why it is easy to think that having tight &amp; centralized access management to a code repository translates to security, however, that doesn't mean that code cannot be accessed or redistributed other ways. But, is there a real argument/use case/scenario for security where the centralized model is just better than the distributed one?.</p>

<p><strong>Some context</strong>: I'm trying to make the case (with a whitepaper) to my company to switch to a DVCS (I already have other problems identified that are successfully addressed by most DVCSs) and security is one of the arguments I'm expecting to have to justify. My company is open minded though; they currently use perforce and are distributed geographically.</p>
","10869","","886","","2012-03-07 03:56:24","2012-03-07 03:56:24","Is security a real argument for centralized version control?","<security><dvcs><version-control>","2","0","","","","CC BY-SA 3.0"
"138682","1","138687","","2012-03-07 17:31:39","","1","689","<p><strong>FIRST, THE SCENARIO</strong></p>

<p>We have an internal system that is effectively split into 2 very separate parts across 2 sub-domains, our back-end administrative system for internal access only we will call this admin.example.com and our public-facing interface for customers via our website - lets call this www.example.com/customers</p>

<p>We have built a series of APIs with PHP in the back-end system for the public interface to access, the APIs are split into multiple files based around the type of activity that is being performed and are also used in the admin interface, these are held in admin.example.com/apis/activity_api.php we have no problems here.</p>

<p>We also have API keys that are in-use, 1 for the front-end and one for the back-end so we can determine access levels without thinking about it. </p>

<p><strong>SECOND, THE ISSUE</strong></p>

<p>Now you know the structure of the application here is the issue, we are using jQuery AJAX to call the APIs but I don't like placing the API keys here as they are publicly visible and anyone with a little programming knowledge will be able to pull a huge range of data, at the same time we need to use them. </p>

<p>Note that the issue is only in the public interface. </p>

<p>What I am thinking of doing is calling a connecting script in PHP with AJAX that is stored locally on our public facing server, this would do a few things</p>

<ol>
<li>Check the referrer, if it comes from example.com/customers/ or www.example.com/customers/ it continues, if not the request is killed with an unauthorized error</li>
<li>Gets the variables posted by the AJAX requests</li>
<li>Restructures the variables for the API (e.g. receives <code>$_GET['request']</code> then reconstructs as <code>$_GET['req']</code>)</li>
<li>Adds the API key that is held as a variable within the PHP to the string</li>
<li>Uses <code>file_get_contents()</code> to make the actual request to the API, this would in turn populate the connecting PHP script with the required returned API data to the site</li>
</ol>

<p>My questions are</p>

<ol>
<li>Have I missed anything in this concept? </li>
<li>Are there any flaws that haven't been thought about? </li>
<li>Are there any compelling reasons why this type of structure should not be used? </li>
</ol>

<p>I appreciate the input! </p>

<p><strong>WHAT I HAVE DONE</strong></p>

<p>I really want to thank you guys for your help and comments on this, you have pointed out what I missed and that was the purpose of posting the question in the first place. You also helped me spot the obvious weaknesses. </p>

<p>I have just written an algorithm that has taken into account HMAC principles. As with anything in this space there is room for unauthorized access but I believe my algorithm minimizes it. </p>

<p>The basic process we're going with is as follows</p>

<ol>
<li>2 keys have been created, a private and public key</li>
<li>The public key is hashed first </li>
<li>A base calculation is carried out on part of the current time stamp</li>
<li>2 random keys for the get request are generated that will be used to transport the access keys, to determine the request keys a mathematical calculation is carried out on the base calculation in step 3, the result is then split into 2 parts, the 2 parts are verified as unique and converted to the final values, 1 part belongs to the public access key and the other to the private access key key</li>
<li>9 unique public values, plus the private access key issued are then taken, they are re-ordered based on a final calculation on the base value in step 3 creating a ""signature"" so to speak</li>
<li>The signature is then hashed and assigned to the private get key generated in step 4</li>
</ol>

<p>On a quick calculation and basic testing, each request will be valid for approximately 27 seconds (give or take a few milliseconds) - enough time to process everything needed but not enough for much more. As the calculations are fairly basic the server load hasn't gone up an inch - I have only tested with 10 connections per second for 5 minutes however, I am going to run a series of load tests on it over the next 24-hours that will range from 20 request per second to 400 requests per second and compare with load test results taken last week. </p>

<p>So what my new algorithm does in a nutshell is disguises the public and private keys by hashing both - however after time the public access key will be obvious unless I assign an algorithm to randomize it, it assigns both access keys random get request keys and has a short validity time based on the request. It doesn't need to store any data in cookies or sessions. In addition, with exception to the login API, all requests are going via a PHP connector that requires the user to be logged in. </p>

<p>I spent more time explaining what I'm doing than actually creating it! </p>

<p>Thanks again for your help guys, it helped me open my eyes a bit more and reminded me about what I had forgotten. </p>
","47111","","47111","","2012-03-07 21:25:17","2012-03-07 21:29:28","API access question","<php><security><api><jquery><ajax>","3","4","","","","CC BY-SA 3.0"
"252758","1","","","2014-08-08 14:06:16","","1","132","<p>We've got a web application which is 99% complete prior to public beta, were currenlty securing the site from security perspective, locking down the server, db etc, one thing I'm concerned about but not really sure of the best way to test is for authentication loop holes. </p>

<p>For instance there a 3 user types - System admin, Staff, Client.</p>

<p>There are urls on the site that I would only want the System admin to be able to access, and there are other pages, that I would want everyone to access, but not view all of the data. System admin would be able to see everything, but Staff and Client would be able to see some content, similarly some pages would be read only for some users.</p>

<p>Is there a workflow for testing this, at the moment I've come up with a script that has the credentials of a each user type and goes to every url on the site trying to access pages and reports if it's able to see a page it's not meant to, similarly it checks for read / write data on the page. </p>

<ul>
<li>Is there anything else I should be checking for to make my authentication tests more robust ?</li>
</ul>
","101608","","61852","","2014-08-08 14:13:59","2014-08-09 04:04:54","Testing for Authentication loop holes / bugs","<unit-testing><testing><security><authentication>","1","3","","","","CC BY-SA 3.0"
"63549","1","63563","","2011-03-30 06:44:33","","15","1973","<p>In the real world , why do we need to implement method level security ?</p>

<p>We either have a web application or a desktop application , where the user accesses the user interface (and therefore directly cannot access the method) . </p>

<p>So where does accessing methods directly come into picture here ?</p>

<p>edit : I ask this question because I am experimenting with spring security , and I see authorizing users for accessing methods . </p>

<p>something like :</p>

<pre><code> @ROLE_ADMIN
public void update() {
      //update
}
</code></pre>
","17887","","17887","","2011-03-30 08:16:38","2015-07-22 08:12:50","Why do we need method level security?","<security>","5","1","","","","CC BY-SA 2.5"
"139298","1","139306","","2012-03-12 08:07:56","","8","183","<p>Are there any open-source tools to measure the standard of a web application project? I want to verify my project for:</p>

<ul>
<li>Possible security leaks (SQL Injection etc.)</li>
<li>Performance </li>
<li>Stability (in high concurrent environment)</li>
</ul>

<p>and other quality metrics.</p>
","6001","","","","","2012-03-12 09:33:44","Are there any free tools to measure web project's performance, security and other standards?","<web-applications><coding-standards><code-security>","1","1","","","","CC BY-SA 3.0"
"139450","1","139453","","2012-03-13 03:47:44","","26","13243","<p>I've heard people lecture here and there on the internet that it's best practice to obscure public facing database ids in web applications. I suppose they mainly mean in forms and in urls, but I've never read anything more than a mouthful on the subject.</p>

<p><strong>EDIT</strong>: Of course, now that I ask this, I find some resources on the subject:</p>

<ul>
<li><a href=""https://stackoverflow.com/questions/2374538/obscuring-database-ids"">https://stackoverflow.com/questions/2374538/obscuring-database-ids</a></li>
<li><a href=""https://stackoverflow.com/questions/1895685/should-i-obscure-primary-key-values"">https://stackoverflow.com/questions/1895685/should-i-obscure-primary-key-values</a></li>
<li><a href=""http://joshua.schachter.org/2007/01/autoincrement.html"" rel=""noreferrer"">http://joshua.schachter.org/2007/01/autoincrement.html</a></li>
</ul>

<p>These links satisfied some of my curiosity, but the SO posts don't have many votes and aren't necessarily centered around the topic in this context so I'm not sure what to make of it, and some of them claim that the third link is bogus. I'll leave the rest of my post intact:</p>

<hr>

<p>I understand the differences between obscurity and security, as well as how the two can work together, but I can't imagine why this would be necessary.</p>

<p>Is there any truth to this, is it just paranoia, or is it just totally bogus altogether? </p>

<p>I can think of ways to do it, but of course it adds a lot of complexity to the application code. Under what circumstances would this be useful? If this <em>is</em> something people frequently do, how is it usually deployed? Hashing the identifiers? Something else? It seems like a lot of work for not much extra security. I'm not looking for real solutions, I just want to get an idea of how/why people would do this in the real world.</p>

<p>Is this really considered a ""best practice"" or is it merely a micro-optimization of little value?</p>

<p><strong>NOTE</strong>: I think a few folks might have gotten the wrong idea: I'm not suggesting that difficult-to-guess ids would be the <em>only</em> security mechanism, obviously there would have be the usual access checks. Let's assume those are in place, and that simply knowing the id or hashed id of a record is not enough to grant access.</p>
","22985","","-1","","2017-05-23 12:40:18","2012-03-13 20:59:56","Is obscuring/obfuscating public-facing database ids really a ""best practice""?","<web-applications><security>","7","0","","","","CC BY-SA 3.0"
"253338","1","","","2014-08-14 19:18:31","","4","11038","<p>Situation:</p>

<p>We have a desktop application.
We also have a web application.</p>

<p>We need the two to interact with each other. So when a button is pushed in the web application, the desktop application needs to start running a process (pulling data from the cloud using an API we've created). With two local applications, this can be done with ports/listening, editing a flag somewhere locally, and the other application reading this flag, etc.</p>

<p>Can this be done from web -> desktop?</p>

<p>Ideally the web application would have direct communication with the desktop application and notify it to begin pulling data down from the cloud using our API. But if this is not possible, having the desktop app run a process that loops and checks for a flag in a file or something would be a good start.</p>

<p>After minimal research, I've found some stuff like HTML5 File Api which interacts with ""Sandbox"" directory on the local machine. I've also read that it is impossible to access any thing on the local machine for security reasons.</p>

<p>Also, I dont want the user to be prompted to request a download file everytime, we need things to happen behind the scenes. (Even if the user has to initally set up some lower security / permissions just for this situation)</p>

<p>Any input is appreciated!</p>
","85468","","","","","2019-03-05 20:16:51","How do I / what is the best way to interact with a desktop application from a browser web application?","<web-applications><security><file-handling><desktop-application>","3","4","","","","CC BY-SA 3.0"
"362393","1","","","2017-12-14 17:23:59","","-2","53","<p><br>
I am working on a system that needs to keep the data safe and not accessible to people without authorized access. The client is a web app that communicates with the servers via APIs. This is what I have so far:</p>

<pre><code> __________            _____________            __________
|  Server  |          |    Server   |          |  Server  |
|  (Keys)  |          | (Web Files) |          |  (Data)  |
|__________|          |_____________|          |__________|
     |                       |                      |
    SSL                     SSL                    SSL
     |                       V                      |
     |                  __________                  |
     ---------------&gt;  |  Client  |  &lt;---------------
                       |__________|
</code></pre>

<ul>
<li>Server (Web Files) servers the static files</li>
<li>Server (Data) connects to DB (Data) and servers the encrypted data</li>
<li>Server (Keys) connects to DB (Keys) and serves the userâ€™s data key</li>
</ul>

<p>The process would be:</p>

<ol>
<li>Client is served the static files by Server (Web Files) via SSL</li>
<li>Client authenticates using Username/Password with Server (Keys) and gets their data key via SSL</li>
<li>Client connects to Server (Data) and gets the encrypted data via SSL</li>
<li>Client decrypts data using the acquired data key</li>
<li>Client alters the data</li>
<li>Client encrypts the data using the acquired data key</li>
<li>Client sends the encrypted altered data to the Server (Data) via SSL</li>
</ol>

<p>This way each server is isolated, but if someone gains access to Server (Keys), they can work their way to decrypting the data in Server (Data). Is there a way to make this more tight, so as if one of the servers or DBs is compromised, it would not compromise the security of the data?
The current configuration is convenient but not set in stone.</p>

<p><strong>Edit:</strong></p>

<ul>
<li>The customized and obfuscated encrypt/decrypt library is out of the window.</li>
<li>The data would be private info and their security is mandated by the government with the very broad and vague â€œPrivate information should be protected against leakage and unauthorized accessâ€.</li>
<li>Up until now, the system was isolated and was operated within a closed network, locally (with the same design). We now need to allow broad remote access.</li>
<li>If we turn over the encryption key to the client users, they become responsible for its safety and if they lose it, the data becomes inaccessible. If we need to be able to retrieve the data, we need to save the key on our servers as well (maybe by encrypting it with a master key, and make the retrieval process manual, instead of automatic).</li>
<li>It is back to the drawing board.</li>
</ul>
","290993","","290993","","2017-12-15 15:16:56","2017-12-15 15:16:56","Security of data viewed and altered by a web app","<design-patterns><security><data>","2","1","","","","CC BY-SA 3.0"
"139672","1","139676","","2012-03-14 06:17:58","","2","882","<p>Recently I have project in which a directory listing is enabled, due to which some scripts can be seen by outside world. I asked website administrator and he said it's not his responsibility, its the programmer's job. I also asked programmer about this and he said that the script is actually a <a href=""http://en.wikipedia.org/wiki/Cron"" rel=""nofollow"">cron job</a>, and according to him, he has to test the script on webserver as there is a difference between development and production environment, so he placed there to test that. According to him, there was no direct link as he assumed directory listing is disabled and taken care by administrator. </p>

<p>Who is the right person to do this?</p>
","49708","","31260","","2012-03-14 07:49:09","2012-03-15 17:42:45","is it programmer's duty to disable directory listing?","<security><websites><server>","10","3","","","","CC BY-SA 3.0"
"139704","1","139705","","2012-03-14 10:45:41","","2","377","<p>I am basically asking this question to see if I am being unreasonable.  My current employer has locked down the machines of all developers so that we do not have access to the root or c: drive.  For example, I cannot write a directory under C:.  I also cannot install any software which touches the registry.  Is this an extreme action or am I overreacting to common security measures?</p>

<p>What is the extent of security on your company provided machine?  To add some scope to this question, I am a web application developer and I'm talking about a laptop owned by the company. </p>
","49731","","","","","2018-10-16 15:49:17","Right Amount of Security on Machine","<security>","7","3","","","","CC BY-SA 3.0"
"139959","1","139964","","2012-03-15 21:45:30","","2","210","<p>I read an article a while back (forgot from where) that essentially stated that someone wrote a virus and inserted it into an image. The end result allowed the cracker to have his way with the system.</p>

<p>How is this possible?</p>
","25686","","6695","","2012-03-15 22:24:40","2012-03-15 22:24:40","How is software installed from an image?","<security>","4","2","","","","CC BY-SA 3.0"
"253737","1","253807","","2014-08-19 03:47:47","","1","493","<p>I want to hash ""user + password"".</p>

<p>[EDIT: prehashing ""user"" would be an improvement, so my question is also for hashing ""hash(user) + password"". If cross-site same user is a problem then the hashing changed to hashing <code>""hash(serviceName + user) + password""</code>]</p>

<p>From what I read about salted hash, using ""user + password"" as input to hash function will help us avoid problem with reverse hash table hacking. The same thing can be said about rainbow table.</p>

<p>Any reason why this is not as good as salted hashing?</p>
","134583","","134583","","2014-08-20 04:34:15","2014-08-20 04:34:15","Is hashing of just ""username + password"" as safe as salted hashing","<security><passwords>","2","5","","","","CC BY-SA 3.0"
"140161","1","","","2012-02-14 05:02:01","","9","893","<p>Exchange 2010 has a delegation model where groups of <a href=""http://msdn.microsoft.com/en-us/library/windows/desktop/aa384426%28v=vs.85%29.aspx"" rel=""nofollow noreferrer"">winrm</a> cmdlets are essentally grouped into roles, and the roles assigned to a user.</p>

<p><img src=""https://i.stack.imgur.com/CYzCU.jpg"" alt=""Exchange Roles Image"">
(<a href=""http://eightwone.com/2009/12/08/exchange-2010-delegation-model/"" rel=""nofollow noreferrer"">Image source</a>)</p>

<p>This is a great &amp; flexible model considering how I can leverage all the benefits of PowerShell, while using the right low level technologies (WCF, SOAP etc), and requiring no additional software on the client side. </p>

<p><img src=""https://i.stack.imgur.com/G44ru.jpg"" alt=""image of how Exchange 2010 remote admin works"">
(<a href=""http://blogs.technet.com/b/heyscriptingguy/archive/2010/09/27/remotely-use-the-exchange-2010-powershell-cmdlets.aspx"" rel=""nofollow noreferrer"">Image source</a>)</p>

<p><strong>Question(s)</strong></p>

<ol>
<li><p>Is there a way for me to leverage Exchange's delegation model in my .NET application? </p></li>
<li><p>Has anyone attempted to imitate this model?</p></li>
<li><p>If I must start from scratch, how would I go about imitating this approach?</p></li>
</ol>
","175","makerofthings7","175","","2012-03-20 14:44:48","2012-03-20 14:44:48","Imitating Exchange Server's ""RBAC AuthZ"" in my own application... (is there something similar?)","<c#><security><wcf><authorization><iis7>","2","1","","","","CC BY-SA 3.0"
"140164","1","140165","","2012-03-17 07:20:11","","13","16704","<p>To start with the background, <a href=""http://www.codinghorror.com/blog/2008/10/preventing-csrf-and-xsrf-attacks.html"" rel=""noreferrer"">this post</a> is what Jeff Atwood says about CSRF tokens. In this very page, he goes on to say:</p>

<blockquote>
  <p>An even stronger, albeit more complex, prevention method is to
  leverage server state -- to generate (and track, with timeout) a
  unique random key for every single HTML FORM you send down to the
  client. We use a variant of this method on Stack Overflow with great
  success.</p>
</blockquote>

<p>But in this post itself, Jeff never remarks about when and how the tokens should be updated.</p>

<p>I was using a similar technique in a web-app I was working on. It works like this:</p>

<ol>
<li>Whenever the user will <code>POST</code> data to my server, a csrf token is sent along.</li>
<li>This CSRF token is stored in a cryptographically strong cookie in user's session.</li>
<li>If the token is valid, the user's request is processed and vice-versa.</li>
<li>If the request is valid, discard the old token on server side and create a new token. The response from server contains a new csrf token to be used in the next request. The old token on all the forms on a page is updated with the new one so that the next request is processed properly.</li>
</ol>

<p>Is it wise to update the tokens after ever <code>POST</code> request or should the updation be done only whenever the user makes a <code>GET</code> request and keep the same token till the next GET request is made?</p>
","36966","","","","","2012-03-17 08:21:41","How frequent should the Token Updation in CSRF security be?","<web-development><programming-practices><security><patterns-and-practices>","1","1","","","","CC BY-SA 3.0"
"363270","1","","","2018-01-02 10:38:16","","1","276","<p>I'm specifying an API for a REST service. The REST service will be primarily accessed by web browsers using XHR requests running code hosted from remote origins. Therefore, I'll need to add CORS support, such as the <code>Access-Control-Allow-Origin</code> header to allow for XSS.</p>

<p>Should I add CORS headers to non-200 responses, such as 400, 401 and 5xx?</p>
","148189","","","","","2018-01-02 10:38:16","CORS headers for non-200 HTTP responses","<security><http>","0","3","0","","","CC BY-SA 3.0"
"254370","1","","","2014-08-25 12:07:52","","2","154","<p>I am writing a simple flask application to submit scientific tasks to remote HPC resources. My application in background talks to remote machines via SSH (because it is widely available on various HPC resources). To be able to maintain this connection in background I need either to use the user's ssh keys on the running machine (when user's have passwordless ssh access to the remote machine) or I have to store user's credentials for the remote machines.</p>

<p>I am not sure which path I have to take, should I store remote machine's username/password or should I store user's SSH key pair in database?</p>

<p>I want to know what is the correct and safe way to connect to remote servers in background in context of a web application.</p>
","28994","","","","","2014-08-25 16:16:38","Security Pattern to store SSH Keys","<security><authentication><secure-coding><flask>","1","0","","","","CC BY-SA 3.0"
"363385","1","363387","","2018-01-03 21:40:40","","4","321","<p>For example, for Firefox the cookies are kept as an SQLite DB in user's folder. Any program can read these cookies. So, for example, can't an .exe program read the contents of a cookie and pretend to the web site of that cookie as if it is the logged in user and start sending requests on behalf of that user?</p>
","292403","","","","","2018-01-04 12:27:09","Isn't it unsafe that any program can access cookies of a browser?","<security><cookies>","2","3","","","","CC BY-SA 3.0"
"66027","1","","","2011-04-07 15:46:50","","8","7625","<p>People in the UK will probably better understand what a <a href=""http://en.wikipedia.org/wiki/Sort_code"">sort code</a> is and how sort code &amp; account numbers are used for transfers etc, but the question is relevant to anyone I'm sure.</p>

<p>Just to clarify:</p>

<p>Giving someone your sortcode and account number allows them to transfer money to your bank... AFAIK there is no way to draw money out of someone's account.</p>

<p>So do you still need such a high level of security on a site as you would say for credit card numbers etc? Would the same care you take over this data as you would for card numbers? </p>

<p>I ask as a client has requested storing the data in their db - they have no SSL certificate to handle this data, but does that matter? Seeing as all someone could do is transfer you money...? Right?</p>
","12555","","","","","2020-03-26 20:58:30","Storing sort code / account number on website. Security?","<security>","6","10","","","","CC BY-SA 2.5"
"254597","1","","","2014-08-27 14:16:58","","0","454","<p>I have an ElasticSearch search engine and an internal web application.  Prior to applying the security model, search results were very fast.  The security model restricts some users from accessing certain pages.  We have 7 ""types"" of pages.</p>

<p>Our process is currently this:</p>

<ol>
<li>Search engine queries all records</li>
<li>For each type of result, I get all recordIds of that type from the database that the user is allowed to access. This ensures I only call the database a max of 7 times (once per type)</li>
<li>I do an intersect between the records the user can access and the records search is returning</li>
</ol>

<p>The above approach isn't fast enough. I have an autosuggest search and each query takes up to 2 seconds now.  </p>

<p>What is a typical way to make a search engine return results that adhere to security?  Another developer has recommended I store the security permissions directly in ElasticSearch itself(essentially mirroring what our sql server has).  </p>

<p>Edit: Each record has a page. We can assume 200-500 users and 25000+ records.</p>
","63646","","63646","","2014-08-27 15:19:43","2015-11-12 13:35:17","Making internal search engine return results that adhere to local permissions on an internal web application","<security><search-engine>","3","8","","","","CC BY-SA 3.0"
"254709","1","","","2014-08-28 16:32:00","","-1","179","<p>How would the following solution be implemented?  Would you need to put this code in each library assembly or just in the main assembly that is determining whether it is safe to call the library assembly based on whether or not it originates from a given intranet Web site?  Also, who should call the CheckSite method - each library assembly or the main app?
Here is the example and solution from a practice exam for the C# Specialist Exam 70-483 that I am referring to:</p>

<blockquote>
  <p>You are an application developer for a company.  You are creating an
  application on the companyâ€™s Web server that will manipulate
  confidential data from business partners.  The application relies on
  many library assemblies in the company intranet to complete its work.
  You are required to verify that every assembly originates from the
  same intranet Web site. Which code should you use to verify the
  current assembly originates from the company intranet?</p>
</blockquote>

<pre><code>public bool CheckSite () {
    SiteMembershipCondition site = new
        SiteMembershipCondition( â€œhttp://intranet.company.comâ€ );
    return site.Check( Assembly.GetCallingAssembly().Evidence );
}
</code></pre>
","147586","","147586","","2014-08-28 18:50:05","2014-08-28 18:50:05","How to verify that library assemblies originate from a given Web site?","<c#><web-applications><libraries><code-security><evidence-based>","1","2","0","","","CC BY-SA 3.0"
"254796","1","","","2014-08-29 09:39:30","","1","678","<p>I've written a <code>database</code> model class in PHP and have written a controller class that specifically validates the data before sending it to db. I'm getting criticism that I should handle the data in <code>database</code> model class rather than <code>controller</code> class.</p>

<p>I wanted to write a generic db class which can be used anywhere for CRUD operations. Now can you guys please help me out in sorting this out? Whether I should validate the data in db model class or in db controller class?</p>
","147581","","31260","","2014-08-29 09:43:28","2015-02-16 10:01:17","Database Handler and SQL injection prevention","<php><database><security><sql-injection>","4","5","","","","CC BY-SA 3.0"
"66616","1","","","2011-04-06 15:45:43","","19","10699","<p>I'm building a fairly complex interpreted program in Python. I've been working on most of this code for other purposes for a few months, and therefore don't want my client to be able to simply copy and try to sell it, as I think it's worth a fair amount.</p>

<p>The problem is that I need the script to run on a server that my client is paying for, so is there any way I can secure a particular folder on the machine from root access, or make it so only one particular use can access the directory? The OS is Ubuntu. </p>
","","James Eggers","34183","","2011-11-15 19:27:05","2011-11-15 20:51:48","How can I prevent a client from seeing my code written in an interpreted language?","<python><code-security>","6","6","","","","CC BY-SA 3.0"
"363842","1","","","2018-01-11 17:57:49","","-1","88","<p>I understand <a href=""https://docs.microsoft.com/en-us/aspnet/core/security/authorization/roles"" rel=""nofollow noreferrer"">Role Based</a> Security.
I have read about <a href=""https://docs.microsoft.com/en-us/aspnet/core/security/authorization/policies"" rel=""nofollow noreferrer"">Policy Based</a>.
I have read what <a href=""https://lostechies.com/derickbailey/2011/05/24/dont-do-role-based-authorization-checks-do-activity-based-checks/"" rel=""nofollow noreferrer"">others</a> call <a href=""http://ryankirkman.com/2013/01/31/activity-based-authorization.html"" rel=""nofollow noreferrer"">Activity Based</a>.</p>

<p>What I want to know is if I do Policy-Based, am I avoiding what Role-Based requires and what Activity-Based seems to avoid - hardcoding security, refactor because of some new requirement, hardcode some more, and so on.</p>

<p>I see the difference between Role and Activity based.  And my goal is to not have groups hard-coded in a method like Admin, SuperAdmin, SuperSuperAdmin, etc.</p>

<p>I think but am no sure if Policy Based does what I want, but I cannot understand how.  How are these three different?</p>

<p>If I use the Under21 example for Policy Based I have seen many times on various blogs, I have:</p>

<pre><code>[Authorize(Policy = ""AtLeast21"")]
</code></pre>

<p>How is <a href=""https://stormpath.com/blog/tutorial-policy-based-authorization-asp-net-core"" rel=""nofollow noreferrer"">this</a> different from:</p>

<pre><code>[Authorize(Roles = ""SuperAdministrator, ChannelAdministrator"")]
public class ChannelAdministrationController: Controller
{
}
</code></pre>

<p>And Activity Based (is this <a href=""https://en.wikipedia.org/wiki/Context-based_access_control"" rel=""nofollow noreferrer"">Context Based</a>?) is different but appears more ""semantically"" accurate.  You have an <code>UpdateUser</code> Activity, and it is probably not likely you'd have SuperUpdateUser Activity.  But with policies, it seems you could have the same as multiple roles.  I know there can be many Claims used the authentication and authorization, but all I can think is there might be a better name than Over21 for my policy and create a role that my Claim needs.  But somewhere in the back, I have to create those activities and roles and users.  Even Role Based has policies I can use in .NET Core Middleware, so I am confused.</p>

<p>For example, I could just as easily require an additional policy,</p>

<pre><code>[Authorize(Policy = ""AtLeast21"", ""ExceptInTenneseeWithParent"", ""ExceptInChurch"")]
</code></pre>

<p>Is this my answer (from the MS page)?</p>

<pre><code>services.AddAuthorization(options =&gt;
{
    options.AddPolicy(""BadgeEntry"", policy =&gt;
        policy.RequireAssertion(context =&gt;
            context.User.HasClaim(c =&gt;
                (c.Type == ClaimTypes.BadgeId ||
                 c.Type == ClaimTypes.TemporaryBadgeId) &amp;&amp;
                 c.Issuer == ""https://microsoftsecurity"")));
});
</code></pre>

<p>I am back to hardcoding requirements again.</p>

<p>My question is how are these different?</p>

<p>Additionally, does policy-based security keep me from having to add a new role or policy everytime something new comes along (see my examples above).  Activity based does (it seems).</p>

<blockquote>
  <p>""Why do you believe that Role-Based Security is tightly coupled, while Policy-Based Security is not?""</p>
</blockquote>

<p>I am not sure it isn't.  That is why i am asking because something isn't adding up to me.  While this isn't good,</p>

<pre><code>[Authorize(Roles=""Administrator, SuperAdministrator, 
CertainBosses, SomeGuyinHR, SuperDuperAdministrator"")]
</code></pre>

<p>I am not convinced policy is better,</p>

<p>because I have to change my handler with conditionals.  The only thing I can think of is in the Policy-Based you can have a more self-documenting set of code that doesn't change based on a new security role.</p>

<pre><code>[Authorize(Policy=""UpdateUser"")]
</code></pre>

<p>and in your policy you either,</p>

<pre><code>...administrator || some_user || something else
</code></pre>

<p>or some new policy stacked</p>

<pre><code>[Authorize(Policy=""UpdateUser"")]
[Authorize(Policy=""UpdateUserIfYouAreX"")]
</code></pre>

<p>or in the database</p>

<pre><code>...is the user in the database that has my roles
</code></pre>

<p>and change all my role information in the database.</p>

<p>Activity-Based seems most similar to the last policy design:</p>

<p>(from lostechies)</p>

<pre><code>[HandleError]
 public class HomeController : Controller
 {
     [Authorize(Activity = ""Administrators Only"")]
     public ActionResult AdministratorsOnly()
     {
         return View();
     }
 }
</code></pre>
","8802","","1204","","2018-01-11 19:42:31","2018-01-11 20:41:36","Does Policy-Based authentication remove refactoring security?","<security><authentication><authorization>","1","4","","","","CC BY-SA 3.0"
"67291","1","67364","","2011-04-11 19:56:58","","10","554","<p>I have heard of security firms who consult on the security of a clients systems. All of the people I know in this field are network engineers, but I know programmers get involved in security as well.  What do security programmers who perform audits/consulting actually do? Do they literally go through the codebase looking for every vulnerability in peopleâ€™s legacy systems? I have always assumed that is what they did, but it seems like this would be highly unreliable and not do much more than providing a false sense of security. Note: Iâ€™m not talking about programmers who write encryption algorithms or anything like that, only those concerned with software security audits/consulting.</p>
","3792","","","","","2011-04-12 13:19:45","What do programmers at security firms do?","<security><freelancing>","3","2","","","","CC BY-SA 3.0"
"141936","1","141943","","2012-03-28 15:18:57","","1","2050","<p>A colleague is pushing clearing the client browser's history (i.e. back-button) when they logout of our web application. Is this considered a good practice? It strikes me as a really intrusive. If only conditionally, what conditions need to be in place for this practice to be useful?</p>
","","user25791","","","","2012-03-28 15:49:22","Is programmatically clearing the browser's history an accepted best practice?","<security>","3","4","","","","CC BY-SA 3.0"
"141998","1","141999","","2012-03-28 20:59:49","","2","882","<p>I am developing a web site and a web service for a small on-line game. Technically, I'll be using Express (node.js) and MongoDB+Redis for the databases. This the structure I came up with:</p>

<ul>
<li>One Express server that will server as the Web Service. This will connect to  the databases. </li>
<li>One Express server that will provide the web site. It will connect to the Web Service to retrieve and push the information.</li>
<li>iOS and Android application will be able to interact with the WebService.</li>
</ul>

<p>Taking into account:</p>

<ul>
<li>It is a small game. The information transferred is not critical.</li>
<li>There will NOT be third party applications. At least for the moment.</li>
</ul>

<p>My concern is about which level of security I should use in each of the scenarios:</p>

<ul>
<li>Security of the user playing through web browser</li>
<li>Security of the applications and the Web Server connecting to the WS.</li>
</ul>

<p>I have take a look at the different options and:</p>

<ul>
<li>OAuth and/or Https is too much for this scenario, isn't it?</li>
<li>Will be a good option to hash the user and password with MD5(or similar) and some salt?</li>
</ul>

<p>I would like to get some directions and investigate by my own rather than getting a response like ""you should you use this node.js module...""</p>

<p>Thanks in advance,</p>
","32976","","","","","2012-05-27 22:17:40","Security in a private web service","<security><authentication>","1","0","","","","CC BY-SA 3.0"
"364321","1","","","2018-01-20 00:50:19","","1","987","<p>I have built simple auth for REST servers in academic projects. I always used the headers to pass the credentials. This is probably just because every tutorial I've ever seen did it this way. Initially, I'd have header fields for <code>user</code> and <code>password</code>, but I eventually switched to basic auth. Anyway, whatever it was, I always had it passed in the headers. My impression was that this was the single correct way.</p>

<p>I am told by the platform team at my work, that we are required to log all headers of each request received, no exceptions, and so, I should not be using headers to accept any sensitive information, such as a password. I was shown an example of a REST API built by another team. For POST and PUT methods, the auth string was accepted in the message body. For GET and DELETE methods, it was in the URL query. This seems wrong to me, but I can't exactly explain why.</p>

<p>I am trying to figure out if I should fight against this policy. I'd like to find out if my position is correct, and, if so, how to support it when I speak to leadership.</p>

<ul>
<li>Am I correct in my thinking that HTTP headers is the single correct way to pass auth credentials in a stateless REST API?</li>
<li>Am I correct that using the URL query params is dangerously insecure, or otherwise inadvisable?</li>
<li>If I am correct, is there some authoritative source that I can reference when I make the case to my leadership? (other than RFC 7235, I've read it. It is too technical for the people I need to convince.)</li>
</ul>
","293829","","","","","2018-01-20 15:29:50","Is there a valid alternative to HTTP headers for sending auth credentials","<rest><api><security><authentication><authorization>","2","2","","","","CC BY-SA 3.0"
"142177","1","142179","","2012-03-29 23:11:28","","0","2875","<p>I just read about Caja, which is a ""sanitized"" version of JavaScript. But I'm wondering - what is the big problem with JavaScript(it seems so widely used )? Just how dangerous is it?</p>
","29032","","","","","2012-03-29 23:33:01","How is JavaScript insecure, and what are the main methods used to deal with that?","<javascript><security>","1","1","0","2014-09-01 00:52:32","","CC BY-SA 3.0"
"67442","1","67484","","2011-04-12 09:16:55","","3","4439","<p>As many of you know WordPress uses ""secret key"" like thing for every AJAX request. Making each request unique and also 'somewhat' secure (just a step ahead than nothing). How would I implement the same using PageMethods (webservice methods inside aspx page) in asp.net application. Some things I have already taken care of are authentication and authorization to access the page.</p>

<p>I would like to know How to generate the same nonce/secret key whatever in C# for asp.net application?</p>

<p>Also doesn't this affect the performance of the application like 100 thousand users use it and each time the method has to go through encryption, random number generation etc..?</p>

<p>Is there any way I can check if posted data is what was actually posted. Checking the integrity of posted data?</p>

<p>Do you need to follow design patterns to secure application logic? Does one exist to make your application at the least somewhat secure?</p>
","13146","","47","","2011-04-12 09:55:13","2011-04-12 14:54:19","How to generate nonce for Ajax web requests","<c#><asp.net><javascript><security><ajax>","1","0","","","","CC BY-SA 3.0"
"142253","1","142256","","2012-03-30 14:19:01","","3","2069","<p>How do software applications keep track of whether the user already installed the application before in it's Windows system?</p>

<p>Say you install app X, trial version, remove it, then re install it, and when you run it again it detects you had already installed it before. If you uninstall and clean all registry information it shouldn't know you had already installed it before...</p>

<p>Disclaimer: I'm not trying to ""hack"" any application, just thinking about how this is implemented.</p>
","22672","","","","","2012-03-30 17:23:41","How to detect if an app was already installed before","<security><windows>","1","0","","","","CC BY-SA 3.0"
"255918","1","","","2014-09-10 12:46:10","","3","95","<p>I have built an android game - I would like to add a ""high score"" leaderboard to it, such that people can show off how high they managed to score. How should I design it so that people can't ""hack"" it by decompiling it and sending a fake score? I don't believe android has a TPM module yet for most devices, so I can't store a password there (even if I could, how could I insert it there without it being detected in transmission?). </p>

<p>I could obfuscate the code, but that isn't going to prevent hacking, only deter it.</p>

<p>I will be using a secured connection, so I shouldn't have any network-sniffing issues. </p>

<p>I am not sure if it would be better to post it under android or security instead of here, but I think this is the correct place since I am asking for a design. </p>
","143229","","7422","","2014-09-10 12:48:17","2014-09-10 12:48:17","How to limit users of a service to a specific program","<security><client-server><android-development>","0","7","","","","CC BY-SA 3.0"
"255921","1","","","2014-09-10 13:09:49","","1","1844","<p>We wrote a simple .NET (C#) desktop application in Wpf. We also used WIF (Windows Identity Framework) to get a list of claims for the authenticated user. Some examples are:</p>

<ul>
<li>CanOverrideSalesAmount</li>
<li>CanAddContact</li>
<li>etc.</li>
</ul>

<p>This works fine and all, the client seems very protected. But, when I was debugging the application it occurred to me that all of the authorization is happening on the client side. A devious person could use a tool such as Snoop to hook into the application and make changes to the domain model that s/he isn't supposed to do.</p>

<p>We thought about moving the authorization checks on the property setters, but even that isn't good enough because when we serialize the object graph to send over the wire, the serialized data can be altered (far fetched, but still possible).</p>

<p>It seems to me that the only true way to protect my object graph is to have it only reside on the server and to have the client make calls to update it, but that seems like such an overkill. Is there a better way to handle this situation? I want our application to be as secure as possible.</p>
","130171","","","","","2014-09-11 13:43:39","How do you make sure a .net client application is not being hacked to bypass authorization claims?","<c#><security><authorization><code-security><client-server>","2","5","","","","CC BY-SA 3.0"
"255957","1","255964","","2014-09-11 02:42:25","","1","1470","<p>I have a public website that does not require authentication. It's a lighting calculator  for indoor cultivation. Anyone can enter and complete the process and ultimately save your settings for future use sharing it on Facebook or twitter. </p>

<p>The configuration is saved as a document in a database, using a REST api. At this time nothing prevents someone make a bot and fill my hard disk in a few hours. </p>

<p>What steps can I take to give protection to my service?</p>
","122594","","","","","2014-09-11 05:51:58","Anonymous access to api REST, protection","<web-development><security><rest>","1","0","","","","CC BY-SA 3.0"
"256121","1","260666","","2014-09-12 16:33:49","","6","5431","<p>As an <a href=""https://en.wikipedia.org/wiki/Independent_software_vendor"" rel=""nofollow"">ISV</a>, what is considered best practice for implementing application role based security? In other words, only allow users to access certain features in the application based on what roles they belong to.</p>

<p>We currently just use a table in our database to store this, but it has been suggested that for maximum <a href=""https://en.wikipedia.org/wiki/Health_Insurance_Portability_and_Accountability_Act"" rel=""nofollow"">HIPAA</a> compliance, this isn't secure enough.</p>

<p>My first thought was to just use <a href=""http://en.wikipedia.org/wiki/Active_Directory"" rel=""nofollow"">Active Directory</a> groups, as it would seem that is what they are designed for, however, it just doesn't seem practical to rely on our clients IT departments to create groups and assign users to them for groups that are specific only to our application. This can't be best practice for ISVs...</p>

<p>At this point it my research, it seems that possibly the best solution might be to use something like <a href=""https://en.wikipedia.org/wiki/Active_Directory#Lightweight_Directory_Services"" rel=""nofollow"">Active Directory Application Mode</a> (ADAM) (Active Directory Lightweight Directory Services) and possibly AzMan (Windows Authorization Manager)?</p>

<p>Again, this is for a <a href=""http://en.wikipedia.org/wiki/Windows_Forms"" rel=""nofollow"">Windows Forms</a> application, not a Web application or in an ""in house"" solution.</p>

<p>If it matters, we are also in the process of transitioning our home-baked authentication to instead use active directory for authentication.</p>

<p>Also of note is this needs to be secure (HIPAA compliant).</p>

<p>All the information I can find on these subjects seems to be for developing applications for in house use, or for web applications, and neither of these approaches feels appropriate for a Windows Forms application.</p>

<p>(We are using .NET for development.)</p>
","46117","","591","","2016-06-02 18:06:10","2016-06-02 18:06:30","How to securely implement roles in a Windows Form application?","<security><windows><application-design><roles><active-directory>","3","8","","","","CC BY-SA 3.0"
"142923","1","","","2012-04-04 11:06:56","","2","1219","<p>I've always validated my user input based on a list of valid/allowed characters, rather than a list of invalid/disallowed characters (or simply no validation). It's just a habit I picked up, probably on this site and I've never really questioned it until now.</p>

<p>It makes sense if you wish to, say, validate a phone number, or validate an area code, however recently I've realised I'm also validating input such as Bio Text fields, User Comments, etc. for which the input has no solid syntax.</p>

<p>The main advantage has always seemed to be: <strong>Validating allowed chars reduces the risk of you missing a potentially malicious character, but increases the risk the of you not allowing a character which the user may want to use. The former is more important.</strong></p>

<p>But, providing I am correctly preventing SQL Injection (with prepared statements) and also escaping output, is there any need for this extra barrier of protection? It seems to me as if I am just allowing practically every character on the keyboard, and  am forgetting to allow some common characters.</p>

<p>Is there an accepted practice for this situation? Or am I missing something obvious?</p>

<p>Thanks.</p>
","39003","","","","","2012-04-11 09:42:15","Validating allowed characters or validating disallowed characters","<security><validation><forms>","3","1","","","","CC BY-SA 3.0"
"143040","1","143055","","2012-04-04 20:12:53","","1","414","<p>I have an idea for a SaaS product I want to create, however, this product will store extremely sensitive data that needs to be encrypted at rest. The trouble is not so much the encryption, but the problem of securely storing the keys so that in the event the server was somehow compromised, the keys couldn't just be recovered and used to decrypt the database.</p>

<p>Are there any decent books to guides regarding database encryption, and in particular secure key storage? This seems to be a less than straightforward topic and something that is difficult to get right. I'm seeing multiple ways to attack such a system, but unable to come up with one that is secure enough to store highly confidential information.</p>
","28114","","","","","2012-04-04 22:11:47","Books or guides regarding secure key storage and database encryption","<database><security><encryption><keys>","1","2","0","2012-04-05 17:27:13","","CC BY-SA 3.0"
"256521","1","256533","","2014-09-17 15:32:08","","-2","347","<p>Can I somehow protect a source available (you can see the source, but you don't have rights to use it) application against piracy? Is it even theoretically possible?</p>

<p>Not all of the application has to be available, ""security module"" or how to call it can be closed source, no licensing issue here.</p>
","147742","","31260","","2016-02-26 04:24:00","2016-02-26 04:24:00","Protecting application against piracy","<security>","2","12","0","2014-09-17 20:03:45","","CC BY-SA 3.0"
"143311","1","143312","","2012-04-06 16:20:20","","10","401","<p>I've been reading some literature on security, specifically password security/encryption, and there's been one thing that I've been wondering: is the 3-strike rule a perfect solution to password security? That is, if the number of password attempts is limited to some small number, after which all authentication requests will not be honored, will that not protect users from intrusion? I realize gaining access or control over something doesn't always mean going through the authentication system, but doesn't this feature make dictionary/brute-force attacks obsolete? Is there something I'm missing? </p>
","7959","","","","","2012-04-06 17:22:16","Weaknesses of 3-Strike Security","<security>","2","3","","","","CC BY-SA 3.0"
"68785","1","92894","","2011-04-16 03:52:42","","0","666","<p>I have an authentication system(ASP.Net library) that I want to make sure is secure. What companies/resources can I use to make sure of this? Also, what should I make sure to do before sending it off to be ""broken""? </p>

<p>A bit more background: Basically, I'm wanting to make a little bit of money by selling this system, but I don't have a whole lot to invest in it(USD $100-$200). I'm wanting to make sure I'm selling something secure, and that buyers know it's secure. I personally have looked over the code multiple times just staring trying to find a security flaw and cannot find one. This is of course not to say there isn't one. This is where I want to pay someone to come in and look at my code and how it all works and basically tell me if it's secure or not</p>
","483","","483","","2011-04-16 20:20:31","2011-07-14 15:25:00","What is the best way to have security auditing done?","<asp.net><security><freelancing><libraries><commercial>","2","1","","","","CC BY-SA 3.0"
"256741","1","256742","","2014-09-19 13:59:27","","0","407","<p>When an SSL certificate is installed on a website, but the page also calls content from another website without an SSL certificate, the SSL certificate icon will turn grey instead of green:</p>

<p><img src=""https://i.stack.imgur.com/A04iC.png"" alt=""""></p>

<p>instead of:</p>

<p><img src=""https://i.stack.imgur.com/ZdXPk.png"" alt=""""></p>

<p>Their site Google Images is also protected with an SSL certificate, but it stays green:</p>

<p><img src=""https://i.stack.imgur.com/ZdXPk.png"" alt=""""></p>

<p>even though they call content (the images that are shown in the results) from websites without an SSL certificate.</p>

<p>How is this possible?</p>

<p>(Screenshots from <a href=""https://webmasters.stackexchange.com/questions/68251/how-can-i-make-a-browser-trust-my-ssl-certificate-when-i-request-resources-from"">my own question at Webmasters.SE</a>)</p>
","144859","","-1","","2017-04-13 12:33:25","2014-09-19 14:15:29","How does Google manage their Google Images SSL certificate?","<security><google><ssl>","2","1","","","","CC BY-SA 3.0"
"365404","1","","","2018-02-06 03:38:24","","-3","511","<p>How can we safeguard REST API to be accessed only from trusted clients? Let me explain the scenario, lets say there is an API which will be accessed from mobile application MA and web application WA. Besides these two applications, this API should not (and must not) be accessed by any other client.</p>

<p><strong>Key Points:</strong></p>

<ul>
<li>I cannot use token based authentication here, as user is not required to login to application to access (or just read) the information.</li>
<li>Embedding any secret information inside the application, to be sent along with the API request, is not secure, as that secret can be leaked (though using SSL) to potential user using reverse engineering.</li>
</ul>

<p>In this scenario, what is the best way to secure REST API?</p>
","237932","","","","","2018-02-06 06:22:24","How to make REST API to be accessed only from trusted (my) application?","<rest><api><security><api-design>","3","1","","2018-02-06 10:42:41","","CC BY-SA 3.0"
"69164","1","69208","","2011-04-17 22:37:42","","4","4409","<p>I recently found the need to do recurrent billing. I am extremely averse to storing people's credit card information and I refuse to take risks in that area.</p>

<p>I am stuck between a rock and a hard place, however. Using a gateway in my local area and currency is prohibitively expensive. Basically, as things stand, we can't do business through a gateway. Yet we need recurrent billing and the need to store credit card information has arisen.</p>

<p>I thought of storing the credit card numbers (encrypted), partially or wholly, then saving the CCV number locally on an unwired machine. To bill customers, I would generate temp billing tables, and fire off a form manually for each customer that needs to be billed. I would manually populate the CCV and pipe a form to my payment processor (they will not store the data, unfortunately--only process the payment).</p>

<p>It's a manual PITA, and defeats the point of automation, but it's my best bet outside of storing the data outright.</p>

<p>Can you give me any advice on my scheme?</p>
","17171","Mohamad","","","","2015-02-16 17:38:20","Storing credit card information: Looking for a creative solution","<security><storage>","4","7","","","","CC BY-SA 3.0"
"69364","1","69436","","2011-04-18 22:49:25","","17","1920","<p>I recently used a government service that I had an account for from years ago. I couldn't remember my password for the service so I used the ""forgot password"" link and was astonished to see that this government website sent my password to my email address in plain text.</p>

<p>I'm personally aware of how to handle user passwords, and I sent some comments about my concerns through a feedback form (this is a government website. People use other online gov. services which deal with sensitive information, as well as the fact that most people use the same password or handful of passwords for everything (I know I do) and I suspect the same security practices are used throughout) which I got a prompt response for. They simply reassured me that ""the Ministry has taken the necessary steps to protect password information, including storing them with the proper encryptions in place.""</p>

<p>I'd like to just say ""well obviously you haven't taken the necessary steps if you're able to email my password to me"" but I'm not trying to be rude, and I don't think my message would ever reach somebody who knows what I mean anyway.</p>

<p>So I'd like to just state that ""the necessary steps haven't been taken according to [some official security standard]"" which might prompt someone to look into it. I did a quick search on OWASP but only found an article regarding plaintext storage.</p>

<p>Is there a security standard regarding user password handling out there which prohibits (as I think it probably would) storage of retrievable password information? Even better: is there such a standard which <em>must</em> be followed by websites dealing with sensitive information such as banks and government web services?</p>

<p>I know I probably won't change anything but it's worth a shot IMO.</p>
","54","","","","","2015-06-29 11:01:32","Is there an official standard regarding user password storage practices?","<security><standards><passwords>","1","4","","","","CC BY-SA 3.0"
"365818","1","365823","","2018-02-12 21:47:02","","0","569","<p>Say I have an MVC .net core website where 100% of the controllers/methods are behind [Authorize] attributes (complete with policies and all).
Would it be taboo, to carve out a set of un-authorized/anonymous controller/methods to handle user requests for access to the site.  It seems perfectly reasonable to me, and outside of developer error, I can't see it introducing a new security risk.</p>
","291003","","","","","2018-02-12 23:22:23","Anonymous Controller/Action within Authorized Site","<mvc><security><authorization><asp.net-core>","1","0","","","","CC BY-SA 3.0"
"365896","1","","","2018-02-13 20:24:20","","3","99","<h1>Backstory</h1>
<p>I am writing a library that accesses the kernel module, <a href=""https://www.kernel.org/doc/html/v4.12/input/uinput.html"" rel=""nofollow noreferrer""><code>uinput</code></a> which allows you to create or take control of devices in <code>/dev/input/event#</code>, and insert events into them.</p>
<p>A simple usecase would allow someone to write a script that would move a mouse cursor to the center of your display, and perform a left click.</p>
<p>As such, it needs root priveleges in order for it to function, and I am not sure what tangible risks I am taking here, and exactly what precautions I need to employ.</p>
<hr />
<p>I asked about this in <code>##kernel</code>, and one response I got was:</p>
<p><a href=""https://i.stack.imgur.com/SZQ6p.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/SZQ6p.png"" alt=""I do a lot of security-related stuff - and I also write a lot of code that I don't bother doing too much security checking on because an attacker can't get at it unless he's already pwned the box - in other words, zero real risk of privilege escalation."" /></a></p>
<h1>Questions</h1>
<ol>
<li>Is what he says true, that my library will be fine to the extent that my system is not &quot;pwned&quot;?</li>
<li>To that, how do I know my library will not become a vector for my system to be &quot;pwned&quot;? I am not a hacker so I would not know what exposes my library to such a thing.</li>
<li>I want my code to be presentable to potential employers, so even if it is true that I need not worry, what security practices should I employ just to demonstrate that I am astute and conscious of potential security risks?</li>
<li>Would a best practice in this case involve me creating a user with a special permission group that limits his exposure to the system?</li>
</ol>
<p>Thanks.</p>
","136084","","-1","","2020-06-16 10:01:49","2018-02-13 20:58:52","What security practices do I employ when building a library that requires low level root access to certain devices and files?","<programming-practices><security><coding-standards><code-security><linux-kernel>","1","6","","","","CC BY-SA 3.0"
"144128","1","144136","","2012-04-12 15:01:48","","10","3738","<p>I need to design a database that will contains information about personal disease of users.</p>

<p>What can be the approach in order to implement the columns of the DB's tables: encrypt the information, separate data within two differents DB, one for sensitive data and another for not sensitive data, or both or another approach?</p>
","51741","","47","","2012-04-12 16:47:55","2015-05-20 13:21:09","How to separate sensitive data in database(MySql)","<security><database-design><mysql>","3","10","","","","CC BY-SA 3.0"
"366129","1","","","2018-02-17 19:35:21","","1","1364","<p>I have seen this pattern that allows web pages to interact with local system resources through a HTTP interface and I have a couple questions about it:</p>

<ol>
<li>What is this pattern called?</li>
<li>What recommendations exist for implementing this pattern?</li>
<li>What are the security implications?</li>
</ol>

<p>Basically, the requirement is to access a local resource on the users machine, such as a USB device. The pattern is as follows:</p>

<ol>
<li>The user is prompted to download an executable.  </li>
<li>The executable exposes a service on <a href=""http://localhost:port"" rel=""nofollow noreferrer"">http://localhost:port</a>.  </li>
<li>The controlling web page handles the UI/UX and communicates with the service through http.</li>
</ol>

<p>The Bose update service is one example. Navigate to <a href=""https://btu.bose.com"" rel=""nofollow noreferrer"">https://btu.bose.com</a> and you are prompted to download and install the Bose updater.</p>

<p><a href=""https://i.stack.imgur.com/9jkyH.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/9jkyH.png"" alt=""Bose download prompt""></a></p>

<p>The page begins polling localhost and receiving a timeout error. After installation, the connection succeeds and the page changes:</p>

<p><a href=""https://i.stack.imgur.com/5CzoO.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/5CzoO.png"" alt=""Bose ready""></a></p>

<p>Here is one of the URLs and the response:</p>

<pre><code>http://localhost:49312/updater/getUpdaterVersion?callback=BoseUpdater.remoteCallback&amp;token=T187369b21bf6

BoseUpdater.remoteCallback(""T187369b21bf6"",{""version"" : ""3.0.1.1891""},0);
</code></pre>
","186233","","","","","2018-08-21 01:27:23","Web page accessing local system via localhost HTTP API","<web-applications><security><http><architectural-patterns>","1","2","","","","CC BY-SA 3.0"
"366143","1","","","2018-02-18 07:08:34","","3","2971","<p>I want to implement the ""shopping cart"" feature on my website. Both anonymous/unauthenticated and authenticated can have it. </p>

<p>While it's clear how to implement it for an authenticated user, it's not completely clear for the anonymous/unauthenticated user case. I believe that I'll have to create a <strong>long</strong> id, such as GUID or the like, in a database and install a cookie with that <strong>long</strong> id/GUID, right? <strong>Not</strong> just integer 32/64 id, because an integer id will be easy to guess or bruteforce, correct?</p>

<p>On the other hand, the threat model of guessing an integer id of a shopping cart isn't high -- it's not a big issue if I guess a shopping card id of some anonymous/unauthenticated user, I think. Right?</p>

<p>Your advice?</p>
","296474","","","","","2018-02-19 13:09:05","Storing an id of a shopping cart in a cookie for unauthenticated user","<database><security><authentication><user-experience><cookies>","1","2","","","","CC BY-SA 3.0"
"366176","1","","","2018-02-19 03:32:59","","6","1454","<p>Currently we are debating over securing our multiple micro-services.
The major concern is that the JWT token provided to us will expire before the call is finished. (This is in the synchronous design)
Here are three proposals:</p>

<ol>
<li>Client App has an 'ensure(int minutes)' method before lengthy calls, calling token provider if necessary. Let JWT expire if it hits security filter.</li>
<li>Client App sends both JWT and Refresh Token. If JWT expires, use refresh token to get new one and place on response headers via token provider.</li>
<li>Create ""login"" service. Login caches refresh info and returns JWT. Send old JWT to get a refreshed JWT via token provider.</li>
</ol>

<p>Thoughts?
Note: My vote is for #1. The rest seem insecure, but convenient.</p>
","296534","","296534","","2018-02-19 03:55:18","2022-12-19 14:37:41","How do you handle JWT expiration for long running calls?","<web-development><security><web-services><authentication><jwt>","3","4","","","","CC BY-SA 3.0"
"258042","1","258048","","2014-10-04 04:01:56","","0","105","<p>Our web application sends a one-time use generated token, in the form of an URL, to clients who forget their passwords. This works except for the case where the client is sitting behind another server (i.e. the spam server) that scans their email for URLS and does a GET on the URL. I'm assuming the server is checking for a malicious payload.</p>

<p>The client opens the email and clicks on the link, but obviously nothing happens because the token is invalid at that point.</p>

<p>I can think of some ways of handling this:</p>

<p>â€¢ Instead of expiring immediately, allow the token to be valid for a certain time period. Disadvantage: This circumvents the whole point of a one-time use token since the token can be used multiple times. Plus it may not solve the problem if the user decides to open their email PAST the expiration time.</p>

<p>â€¢ Make the token good for two uses. Disadvantage: similar to the above. What if the spam checker ""checks"" the URL again... Sigh.</p>

<p>Anyways, I'm looking for some wisdom here on how to handle this. If there are better ideas than what I've proposed I'd love to hear them.</p>
","17944","","","","","2014-10-05 06:12:19","How do I handle a spam server invalidating my tokens?","<security><client-relations><email>","2","3","","","","CC BY-SA 3.0"
"366503","1","","","2018-02-24 18:04:04","","-1","147","<p>I'm working on an application which can be added to third party websites. This means that this app runs in the browsers of the users of a third party and I don't have control over what runs in their server.</p>

<p>My problem is that my app needs to load data from my own server. How can I secure my server so it does not leak data to malicious users who try to scrape my database though the REST endpoints of my server?</p>

<p>I can't use whitelists since the user can be anywhere. Currently I use <a href=""https://en.wikipedia.org/wiki/Hash-based_message_authentication_code"" rel=""nofollow noreferrer"">hmac</a>s but this will only stop script kiddies from disassembling the client code and sending their own encrypted messages.</p>

<p>Is there a best practice for this problem?</p>
","297062","","","","","2018-02-24 18:14:36","How to secure my browser application against malicious requests?","<security><networking><browser><hmac>","1","1","","","","CC BY-SA 3.0"
"70981","1","","","2011-04-25 08:43:42","","1","420","<p>I'm debating the value of putting remote disable (or destruct) functions into my software before delivering it to clients...</p>

<p>As a hypothetical example, consider the development of a Silverlight app where you're worried about the client not paying you. You create a function which when a specific query string is entered it deletes everything in the database.</p>

<p>Destroying data might be a bit of an extreme example. Making the application either partially or completely unusable would be another example.</p>

<p>What are the benefits and risks of doing this? If you've done it, why did you do it, and how did you go about it?</p>
","23757","Chris","63","","2011-04-25 17:23:18","2011-04-25 21:40:47","Should I provide some way to disable my software post-delivery?","<security><licensing><client-relations><distribution>","10","13","","","","CC BY-SA 3.0"
"366683","1","","","2018-02-27 16:29:16","","2","3893","<p>I'm working in a Electronic Funds Transfer (EFT) system and need be very careful with sensitive data like credit card numbers.</p>

<p>We need this information do mount the ISO 8583 data before sending to EFT Gateways.</p>

<p>We use char[] and byte[] to keep sensitive data and use Array.fill when We don't need this information anymore.</p>

<p>Thinking in improve security a thought in create a class to wrap this sensitive information and maybe keep data encrypted until needed.</p>

<p>Here's the code I plan to use with a random generated key.</p>

<pre><code>import java.nio.ByteBuffer;
import java.nio.CharBuffer;
import java.nio.charset.Charset;
import java.security.InvalidKeyException;
import java.security.NoSuchAlgorithmException;
import java.security.SecureRandom;
import java.util.Arrays;

import javax.crypto.BadPaddingException;
import javax.crypto.Cipher;
import javax.crypto.IllegalBlockSizeException;
import javax.crypto.KeyGenerator;
import javax.crypto.NoSuchPaddingException;
import javax.crypto.SecretKey;
import javax.security.auth.Destroyable;

public final class SensitiveChars implements CharSequence, Destroyable {

    private static final int KEYSIZE = 56;
    private static final String DES = ""DES"";
    private static final String DES_ECB_PKCS5_PADDING = DES + ""/ECB/PKCS5Padding"";

    private byte[] data;
    private Charset charset;
    private int lenght;

    private SecretKey secretKey;

    public SensitiveChars(char[] data) {
        super();
        this.charset = Charset.defaultCharset();
        ByteBuffer byteBuffer = charset.encode(CharBuffer.wrap(data));
        lenght = data.length;

        try {
            KeyGenerator keyGenerator = KeyGenerator.getInstance(DES);

            SecureRandom secureRandom = new SecureRandom();
            int keyBitSize = KEYSIZE;
            keyGenerator.init(keyBitSize, secureRandom);
            secretKey = keyGenerator.generateKey(); 

            setRawData(byteBuffer.array());
        } catch (NoSuchAlgorithmException e) {
            throw new IllegalStateException(e);
        }
    }

    public static SensitiveChars of(byte[] bytes) {
        return of(bytes, Charset.defaultCharset());
    }   

    public static SensitiveChars of(byte[] bytes, Charset charset) {
        return of(bytes, charset, false);
    }

    public static SensitiveChars of(byte[] bytes, Charset charset, boolean cleanBytes) {
        char[] chars = toChar(bytes, charset, cleanBytes);
        return new SensitiveChars(chars);
    }

    @Override
    public int length() {
        return lenght;
    }

    @Override
    public char charAt(int index) {
        char[] tempArray = getChars();
        char c = tempArray[index];
        clearData(tempArray);
        return c;
    }

    @Override
    public CharSequence subSequence(int start, int end) {
        char[] dataTmp = getChars();
        char[] range = Arrays.copyOfRange(dataTmp, start, end);
        clearData(dataTmp);
        return new SensitiveChars(range);
    }

    public char[] getChars() {
        if (lenght == 0) {
            return new char[0];
        } else {
            byte[] rawData = getRawData();
            ByteBuffer byteBuffer = ByteBuffer.wrap(rawData);
            CharBuffer charBuffer = charset.decode(byteBuffer);
            char[] result = Arrays.copyOf(charBuffer.array(), lenght);
            clearData(charBuffer.array());
            clearData(rawData);
            return result;
        }
    }

    public void append(char[] chars) {
        char[] dataTmp = getChars();
        int lengthData = dataTmp.length;
        char[] newData = Arrays.copyOf(dataTmp, lengthData + chars.length);
        clearData(data);

        int posIni = lengthData;
        for (int i = 0; i &lt; chars.length; i++) {
            newData[i + posIni] = chars[i];
        }

        CharBuffer charBuffer = CharBuffer.wrap(newData);
        ByteBuffer byteBuffer = charset.encode(charBuffer);
        byteBuffer.compact();
        setRawData(byteBuffer.array());
        lenght = newData.length;

        clearData(dataTmp);
        clearData(newData);
    }

    private void setRawData(byte[] data) {
        this.data = encrypt(data);
    }

    private byte[] getRawData() {
        return decrypt(data);
    }

    @Override
    public void destroy() {
        clearData(data);
        data = new byte[0];
        lenght = 0;
    }

    private byte[] encrypt(byte[] bytes) {
        try {
            Cipher cipher = Cipher.getInstance(DES_ECB_PKCS5_PADDING);
            cipher.init(Cipher.ENCRYPT_MODE, secretKey);
            return cipher.doFinal(bytes);
        } catch (InvalidKeyException | NoSuchAlgorithmException | NoSuchPaddingException | IllegalBlockSizeException
                | BadPaddingException e) {
            throw new IllegalStateException(e);
        }
    }

    private byte[] decrypt(byte[] bytes) {
        try {
            Cipher cipher = Cipher.getInstance(DES_ECB_PKCS5_PADDING);
            cipher.init(Cipher.DECRYPT_MODE, secretKey);
            return cipher.doFinal(bytes);
        } catch (InvalidKeyException | NoSuchAlgorithmException | NoSuchPaddingException | IllegalBlockSizeException
                | BadPaddingException e) {
            throw new IllegalStateException(e);
        }
    }   

    private static void clearData(byte[] cs) {
        Arrays.fill(cs, (byte) 0); 
    }   

    private static void clearData(char[] cs) {
        CharsUtils.clearData(cs);
    }       

}
</code></pre>

<p>It's a good idea or I must use another approach?</p>

<p>Edit 1: 
Our application need be comply with <a href=""https://www.pcisecuritystandards.org/"" rel=""nofollow noreferrer"">https://www.pcisecuritystandards.org/</a></p>
","169422","","169422","","2018-02-27 16:57:50","2018-02-27 20:29:45","Keeping sensitive data encrypted in memory","<java><security><data><encryption>","2","1","","","","CC BY-SA 3.0"
"366863","1","366872","","2018-03-02 08:26:31","","0","918","<p>I'm currently working on a desktop application in Java (using JavaFX).</p>

<p>This application stores some user information, parts of which are sensitive. For example, if the user configures a proxy, it will store it into a file with encryption. Moreover, my application is calling a web API to execute auto-updates (with a basic authentication scheme).</p>

<p>Currently my application is closed source, and is used in a context that doesn't require high security. The implementation basically contains all the credentials needed to authenticate in the API, or to encrypt user settings. Basically, it contains something like (simplified, it's not ""that obvious"").</p>

<pre><code>String login = ""mysuperlogin"", password = ""mysuperpassword"";
authenticateToApi(login, password);

String encryptionKey = ""mysuperencryptionkey"";
encryptDataToFile(data, file, encryptionKey);
</code></pre>

<p><strong>But</strong>: I know that this way of doing things is not secure at all! I know that it's possible to ""decompile"" Java and see the credentials/methods used by the application, and then use them to gain access to the ""sensitive"" information.</p>

<p>I'm planning to open-source my project this year, so I know I have to get the things done to provide a better security level, here are the options I see:</p>

<ul>
<li>Using <strong>properties filled on build time</strong> to include my credentials directly in the code, without including them into the source: this doesn't solve the ""decompile"" problem</li>
<li>Using a key entered by user to secure every information: I don't like this solution because my application needs to be used with the lowest user ""technical"" intervention. Moreover, this doesn't solve the API credentials problems.</li>
<li>Generate a key from the current system to encrypt data. But in open-source version, it will be possible to find the current system key, and then use it to access encrypted data.</li>
</ul>

<p>I suppose that they are a lot of closed/open source programs that have this problems, but I can't figure out what's the ""least worst"" solution.</p>
","297578","","200203","","2018-03-02 09:10:56","2018-03-20 12:20:36","Open source desktop application and security","<java><security><encryption><applications><client>","2","2","","","","CC BY-SA 3.0"
"71623","1","71629","","2011-04-27 03:44:23","","6","3151","<p>Firstly, a disclaimer. This question is not because I'm a disgruntled employee planning to hide some malicious code which I can later blackmail my employer with. I actually quite like the people I work with - just simply curious.</p>

<p>So if an old employer needed a password for some resource that only I had. Would I be obliged to give it to them or could I (probably unwisely) stick it to them and either refuse or charge an outrageous ""consulting"" fee for providing that password?</p>

<p>Or what if I designed some component for them like some sort of underlying encrypted security layer that required some a hash key that only I had, would I be obliged to give it to them?</p>

<p>These two scenarios are generally the fault of the employer, but what if in the third scenario, I built this component in stealth, without them actually knowing? I don't necessarily mean the component was built with the sole intention of locking the employer out in the future, it may have actually served a good purpose - it just never got documented how it functioned because company had poor documentation processes or developers were too busy etc.</p>

<p>In that scenario, when they finally need this hash key, would I be obliged to provide it?</p>
","3214","","31260","","2015-09-04 15:27:28","2017-07-06 14:34:33","Are you obliged to provide old employers with access to protected resources?","<security>","8","8","","2015-04-11 09:49:34","","CC BY-SA 3.0"
"71638","1","","","2011-04-27 03:35:08","","-1","938","<p>Since the Legal site of Stack Exchange isn't ready quite yet, I figured this would be the best place to ask this question.</p>

<p>What are, if any, the legal requirements (or online resources for finding this info out) that I must uphold if I wish to sell an application that acts as a Personal Account/Information Manager, which:</p>

<ol>
<li><p>Stores (optionally, but preferably) personally identifiable information, and; </p></li>
<li><p>Stores (optionally) bank account information, such as existing and current balance, and transaction history, entered by the user.</p></li>
</ol>

<p>With regards to encryption, is there a legal standard of encryption that we as developers must use for securing this type of information?</p>
","","Î²Ó”á¸ºá¹ªáº¶â±«ÅŒÅ”","","","","2011-04-27 05:08:10","Legal Requirements for Software Makers","<security><language-agnostic><encryption><applications><legal>","1","0","","","","CC BY-SA 3.0"
"145704","1","145858","","2012-04-23 22:22:50","","14","6073","<p>What would be the best approach to achieving private communication between my iOS app and its server component? Is having a single unchanging â€œsecret keyâ€ baked into the app source enough, or do I need to set up generations of such â€œhandshakeâ€ keys dynamically somehow?</p>

<p>The server by itself doesnâ€™t have access to any sensitive data, so even if the user hits some private endpoints, it wonâ€™t get them anywhere, but I just want those to be hidden from the public. Basically, I want to ignore all requests hitting particular routes, unless they are coming from my iOS app.</p>

<p>The server component runs on RoR, if thatâ€™s important.</p>
","50730","","","","","2012-04-24 20:25:05","Safe iPhone app â†” server communication","<security><ruby-on-rails><ios><server>","3","0","","","","CC BY-SA 3.0"
"71842","1","","","2011-04-27 17:20:43","","14","11637","<p>There are many security risks coming from having close contact to the hardware as opposed to using well-tested and proved APIs from high level programming languages. It is much easier to cause a buffer overflow in C than in a language such as Java.</p>

<p>What are the risks or vulnerabilities (e.g. buffer overflows) that every C programmer should be aware of (I.E. vulnerabilities relevant to C programmers)? What problems could these lead to? How to avoid them, and what are common mistakes causing these to occur in programs?</p>
","12750","","12750","","2011-04-27 21:13:39","2016-01-12 09:31:10","What are the security risks/vulnerabilities every C programmer must be aware of?","<c><security><low-level><vulnerabilities>","4","8","","2016-01-12 21:49:27","","CC BY-SA 3.0"
"367066","1","","","2018-03-05 15:03:02","","0","72","<p>Most people as they surf the web would get a warning by their browser if they approach a website with an SSL certificate issued by an unnknown authority, or even known as malicious place.</p>

<p>Now, thousands of developers  - <a href=""https://devops.stackexchange.com/questions/3463/mitigating-maven-central-risks-as-seen-from-the-devsecops-perspective"">over 80% of Java related projects using Maven Central - download software components known to have vulnerabilties</a>, sometimes there are even judicial conseqences.</p>

<p>Then, I thought to discuss a plugin for a binary repository coupled with the NVD database to issue a warning HTTP header if a client requests a component with a known vulnerability.</p>

<p>Which <a href=""https://en.wikipedia.org/wiki/List_of_HTTP_status_codes"" rel=""nofollow noreferrer"">HTTP code</a> is to use for that - if a non-opiniated option is anyhow possible? I fail to identify it myself in the list of known codes.</p>

<p>UPD the answer of the server is basically file download, if this happens you see Maven log like ""download ok"" and if this is not ok, the build would break. So  search for a ""soft"" method to filter out problematic resources.</p>
","270756","","270756","","2018-03-05 16:11:24","2018-03-05 16:11:24","Most appropriate HTTP code to issue a warning about insecure content","<security>","1","0","","","","CC BY-SA 3.0"
"71870","1","71887","","2011-04-27 19:38:49","","10","442","<p>Malware uses interesting techniques for hiding themselves from anti-malware software and more. They can ""polymorph"" themselves: practically change the code while it continuing to mean pretty much the same to the executing machine, making antivirus definitions invalid etc.</p>

<p>I wonder if there is anything (non-malicious) developers could learn from studying the source of such, or reversing them and studying whatever you get from that process if the source isn't available, that could be useful outside this (dark?) realm.</p>

<p><strong>I am <em>not</em> interested in writing malware.</strong> (at least not for non-educational purposes) This question isn't meant to be a question about how to write malware or such, but what you could learn from already written malware.</p>

<p>Also, maybe a bit unethical (I hope not), would there be any gains from writing your own piece of malware, just for better understanding of vulnerabilities/exploits/security, or the underlying operating system?</p>
","12750","","12750","","2011-04-27 20:17:20","2011-04-27 20:26:53","Could developers learn anything from studying malware?","<learning><security>","4","5","","2015-05-22 02:59:54","","CC BY-SA 3.0"
"367170","1","","","2018-03-06 20:22:49","","3","222","<p>I'm building a web extension that will be a wrapper for a public API. There aren't any paid tiers for the API currently, but I'm trying to secure the API key so it doesn't get stolen and used outside of my app. I'd like to avoid having my permissions denied.</p>

<p>I currently have 2 ideas that would allow me to do such a thing:</p>

<ol>
<li><p>Have the API key in plaintext in the web extension and hope that people are nice enough to not steal it using <a href=""https://chrome.google.com/webstore/detail/chrome-extension-source-v/jifpbeccnghkjeaalbbjmodiffmgedin"" rel=""nofollow noreferrer"">CRX Viewer</a> (unlikely).</p></li>
<li><p>Proxy all API requests through a web server and append the API key server side, returning the results from the API via my proxy to the client.</p></li>
</ol>

<p>I'm a fan of Node.js and would like to pursue number 2. How do I go about securing <em>my</em> API in Node.js so that people can't just reroute their requests through my server to the API instead of directly to the API with a stolen key?</p>
","277144","","","","","2018-05-06 01:56:09","Securing an API key in a web extension","<api><security><node.js>","2","7","","","","CC BY-SA 3.0"
"72004","1","","","2011-04-27 07:51:34","","23","3978","<p>On some companies I've worked for, managers have spent quite a lot of money on it-security consultants. Primarily because they're afraid we're gonna get the source code stolen by a rival company. 
However, as a programmer, I see it as a minor concern that a rival company would find the actual source code useful. After all, just having access to our application is enough, and that can be done without breaking the law.
In my opinion, the data handled by the business people would much more useful than source code.</p>

<p>My question is; <em>are there any known examples where source code has gotten stolen AND a rival company have used it extensively?</em></p>

<p>I know some game engine (quake 1 and half life 2 if I remember correctly) source code has gotten stolen, but I can't really see that really hurt their business.</p>

<p>(I know, this question might be more appropriate for other forum at stackexchange)</p>
","158716","Viktor Sehr","","","","2011-07-23 23:10:27","Source code stolen\hacked by rival company","<security>","11","6","","","","CC BY-SA 3.0"
"72036","1","72039","","2011-04-28 08:56:36","","3","175","<p>When people post code on forums they tend to change or blur out parts of their code. Probably because they want to protect certain parts that might be exploited if it ends up in the wrong hands, I guess?<br>
But is it really necessary to do this?  </p>

<p>Here are a couple of things I see a lot:  </p>

<ul>
<li>Renaming id's and class names in html and css</li>
<li>Renaming variables and functions in code</li>
<li>Bluring out parts of a folder structure  </li>
<li>Changing stored procedure names and it's parameters</li>
<li>Posting of example code rather than real code</li>
</ul>

<p>Passwords and connection strings to the DB are obvious things you shouldn't post but how a bout the rest?  Is it ok to give out a DB name? Is there anything in the web.config you shouldn't post? How about the .htaccess file on Apache or a folder structure on the system, etc...</p>

<p>Basically what I'm asking is which parts are safe to post and which are not?</p>
","24044","Niklas","","","","2011-04-28 13:43:39","What parts of my configuration and my code should I not post?","<security>","3","3","","","","CC BY-SA 3.0"
"367318","1","","","2018-03-08 16:51:22","","1","672","<p>I am looking to create a website.</p>

<p>There will be a portal, from which the user (and thier associated users) can create/access one or more databases. There will be many different databases in the background (for historical reasons, please just go with that bit).</p>

<p>It must obviously be as secure as possible.</p>

<p>I thought it probably needs a database that then has links for the other databases to be accessed. So, the portal might have a schema like simplified example below.</p>

<p><a href=""https://i.stack.imgur.com/S18Jb.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/S18Jb.png"" alt=""enter image description here""></a></p>

<p>When the user clicks a database link, the 'initialAccessKey' would create a session token with which the database could be accessed.</p>

<p>My questions are:</p>

<ol>
<li>Is this a reasonable way to approach the task? </li>
<li><p>Is there a better way? </p></li>
<li><p>Is it secure? It seems like all the sensitive info is in one
place! A bug could enable access to someone elses database, which
would be catastrophic.</p></li>
</ol>

<p>Any help much appreciated.</p>

<p>EDIT: Ben Whyall's answer is good for an environment where AD can be used (have upvoted). If anyone has a suggestion without AD, I'd be interested to know.</p>
","156440","","156440","","2018-03-09 08:51:04","2018-03-09 08:51:04","Creating a web portal to access multiple databases (security and best practice?)","<security><sql-server><patterns-and-practices><websites>","1","2","","","","CC BY-SA 3.0"
"260182","1","","","2014-10-16 17:04:40","","5","3790","<p>I have never used Snapchat and do not intend to but I have been reading up about what happened to them with respect to the recent media coverage about pictures being leaked especially because I am also writing an api for my app right now and I want to avoid this from ever happening to me.</p>

<p>Having looked into what happened it seems Snapchat has not actually done anything wrong. It appears a third party web app sniffed out their api calls - not something to be surprised about, anyone can do it, and that's why apis should require authentication, how this is done can vary but probably through some kind of token.</p>

<p>In any case, Snapchat api did require authentication so I thought they would have been safe but it turns out that the third party apps got users to voluntarily enter their usernames and passwords into the app, thereby allowing login and authentication.</p>

<p>Remember this was a third party app, not the official snapchat app. I would never have expected users to do something like this, it's like giving away the keys to your car to anyone who passes by instead of the hotel valet. </p>

<p>Now to the point, are they any techniques to avoid this from happening that I can apply for my api? I am not sure how I can prevent myself from ending up in the same situation.</p>
","153255","","","","","2014-10-24 17:48:15","How to prevent third party misuse of what is intended to be a private api (avoiding what happened to Snapchat)?","<security><api><authentication>","2","7","","","","CC BY-SA 3.0"
"146140","1","146180","","2012-04-26 18:12:45","","19","4691","<p>After reading <a href=""https://softwareengineering.stackexchange.com/questions/49550/what-hashing-algorithm-is-good-for-uniqueness-and-speed"">this</a> interesting question, I felt like I had a good idea of which insecure hashing algorithm I'd use if I needed one, but no idea why I might use a secure algorithm instead.</p>

<p>So what is the distinction?  Isn't the output just a random number representing the hashed thing?  What makes some hashing algorithms secure?</p>
","5109","","-1","","2017-04-12 07:31:40","2015-02-27 21:24:46","What makes a hashing algorithm ""secure""?","<security><hashing>","6","3","","","","CC BY-SA 3.0"
"72435","1","","","2011-04-29 13:55:28","","8","10442","<p>The question is based on <a href=""http://code.google.com/p/chromium/issues/detail?id=40787"" rel=""noreferrer"">this issue</a> in Chromium. It is marked as <code>Won't Fix</code>.</p>

<p>Do you see any reason to block a local html file from accessing another local html file located in the same folder?</p>
","859","","226","","2011-04-29 14:04:16","2012-04-05 19:57:32","Why is Google blocking users from accessing their local file system in Chromium?","<security><google><chrome>","2","8","","2012-04-06 01:10:36","","CC BY-SA 3.0"
"367621","1","367629","","2018-03-14 02:41:28","","1","214","<p>I'm writing a slack bot that interfaces end users with an API.
That API only method of identification is the raw ""login:password"" encoded to base64 (it doesn't answer back a token) ...</p>

<p>Currently in test mode, I'm just asking users to send their credentials to the bot and then the server can make requests to the API with their credentials.</p>

<p>I can't change the http request to the API, but what can I do on my side to store the credentials so the user doesn't have to re-enter their password for every request ?</p>

<p>Is a reversible encryption any good ?</p>

<p>update: my last idea is to store the password for only a short period of time</p>
","298715","","298715","","2018-03-20 02:21:17","2018-03-20 02:21:17","securely store credentials for an unsecure API","<security><encryption>","2","2","","","","CC BY-SA 3.0"
"260651","1","","","2014-10-22 15:50:31","","3","1492","<p>So I have different seniors taking different positions on this.  Some saying hide nothing, those codes are there for a reason.  Others saying to hide most status codes, reducing the number to a much smaller group (like only 400 and 404).  Even RFC 2616 suggests a few substitutions are allowed (403 being treated as a 404 for a resource the web server will never deliver and will never explain why).</p>

<p>I'm not talking about the error page the user sees.  Of course that should look nice for the user and should not dump a stack trace, ect.  I'm talking about the http status included in the response.  Meaning if they try to access a resource they aren't authorized for, instead of giving a 401/403, actually making the response be a 404 so that there is no way to know there was something there they weren't authorized for.</p>

<p>Is there a clear cut answer on which is the better practice (kinda like how it is best practice to not reroll your own password hashing)?</p>
","96141","","","","","2015-01-25 14:12:37","Should I hide certain HTTP status codes?","<web-development><security><http>","1","2","","","","CC BY-SA 3.0"
"260679","1","260691","","2014-10-22 23:12:03","","0","51","<p>I have a log-in service that runs a CPU-intensive hash multiple times when a user logs in. In order to reduce the effect of a login DDOS, is there any sort of function that I can ""ask"" that the client to run that would be somewhat CPU heavy and verify it's result (via a light-weight operation), prior to running my password hash?</p>

<p>I was thinking something along the lines of brute-forcing a weak security (where I generate say a 128 bit RSA key or similar) and giving the client the public key and asking it to find the private key.</p>

<p>Has anything like this been done? would this be a reasonable implementation? are there better alternatives?</p>
","143229","","","","","2014-10-23 03:55:12","How to create work for a client on login","<security><login>","1","1","","","","CC BY-SA 3.0"
"367695","1","367707","","2018-03-15 06:59:14","","-6","245","<p>I made WPF application for a client-side and hosting database in a server side , </p>

<p>I know there is something called REST API to transfer data between a client and server</p>

<p>I don't know this method and also i don't have a time to learn it because the project should finish less than one month,</p>

<p>I am thinking to make client access to database directly by stored procedures. </p>

<p>I don't know if it's safe method or not, if it's not secure what should i do then?....any suggestion please!</p>
","298843","","177980","","2018-03-15 12:18:52","2018-03-15 12:27:13","It's safe to access to the database and querying from it directly if it's on the server side, if not what should i do?","<security><wpf><client-server><query>","2","3","0","2018-03-15 15:19:40","","CC BY-SA 3.0"
"260806","1","","","2014-10-24 06:10:33","","2","647","<p>I would like some advice on how best to architect a website comprising the following:
tool</p>

<ul>
<li><p>a landing page, open to the public, main marketing tool</p></li>
<li><p>the main website/app, that people can access only if registered, where users can access certain modules depending on their level of registration (free/casual/premium user)
I'm thinking of using AngularJS for front-end for the double-binding and to bring UI interaction</p></li>
<li><p>an admin part: </p>

<ul>
<li>where we can either interact with the database</li>
<li>check user analytics</li>
</ul></li>
</ul>

<p>I'm afraid that if I use Angular for the 3 parts, the admin part might be accessible to even the public/free users as basically everything is stored as static files on the client.
Is it just a routing problem on the server side? should I use Jade/handlebars for the admin part/landing page (helps for the SEO) and Angular just for the app? is there a best practice in this regard?</p>
","153942","","161664","","2014-12-28 16:36:15","2014-12-28 16:36:15","NodeJs website webapp architecture","<architecture><security><node.js><websites><angularjs>","1","1","","","","CC BY-SA 3.0"
"73000","1","73033","","2011-05-02 13:51:24","","2","288","<p>For a fresh graduate with quite a bit of development (mainly web) background - what is the easiest way to break into the security field? </p>

<p>Are certifications a necessity? Is it possible to get intern jobs doing this kind of stuff?</p>

<p>Thanks</p>
","24325","","","","","2011-05-02 18:32:07","Dive into Field of Information Security?","<security>","1","7","","","","CC BY-SA 3.0"
"73024","1","73042","","2011-05-02 15:53:09","","28","20353","<p>I am wanting to re-write my login scripts for clients websites to make them more secure. I want to know what best practices I can implement into this. Password protected control panels are in their abundance, but very few seem to impliment best practices in terms of code writing, speed and security.</p>

<p>I will be using PHP and a MYSQL database.</p>

<p>I used to use md5, but I see that sha256 or sha512 would be better (together with secure hash and salt). </p>

<p>Some login scripts log the ip address throughout the session or even the user agent, but I want to avoid that as it isn't compatible with proxy servers.</p>

<p>I am also a little behind the best practice in using sessions in PHP 5 (last time I read up was PHP 4) so some best practices with this would be helpful.</p>

<p>Thanks.</p>
","24334","","24334","","2011-05-03 08:23:21","2015-05-20 08:57:40","What best practices should be employed in a PHP login script?","<web-development><php><security>","5","2","","","","CC BY-SA 3.0"
"147009","1","147014","","2012-05-03 00:32:22","","3","1902","<p>Google released <a href=""http://code.google.com/p/google-caja/"" rel=""nofollow"">Caja</a> around 2008(Capability JavaScript). It is still mainly a laboratory language. But XSS and other attacks would be prevented if there was widespread integration of Caja.</p>
","53202","","","","","2012-05-03 02:34:02","Why hasn't Caja been popular?","<javascript><security><google>","1","2","","2013-07-29 12:02:26","","CC BY-SA 3.0"
"73467","1","73472","","2011-05-03 23:32:28","","34","2038","<p>I've currently inherited an application at work and to my dismay, I have realized that the user passwords stored in the database are encrypted using an in house encryption function, which also includes the ability to decrypt.</p>

<p>So all someone really needs to do is copy the user table and copy the encryption assembly (anyone with database production access) and then they would have access to 100,000 email addresses and potential passwords for them.</p>

<p>I'm trying to explain to the business why this is not a good idea, but the security concepts seem to go over their head as they are not that technically minded (it's for government). Plus there are actually existing functionality within the application for admin users to retrieve user's passwords in order to log in as them and do stuff (which they have said, they require).</p>

<p>So they don't understand the security implications. And in order to implement a stronger security policy (hashing passwords so they can't be easily retrieved), I have to remove existing functionality for them.</p>

<p>What should I do? I didn't build the password system in the first place, so it's not like I can be blamed if anything does go wrong. On the other hand, I don't feel good about it and I also don't want to have access to 100,000 potential email logons.</p>
","3214","","","","","2017-10-26 22:23:01","What if the client needs the ability to retrieve passwords?","<security><client-relations><passwords>","14","13","","","","CC BY-SA 3.0"
"147254","1","147259","","2012-05-04 13:00:16","","3","6382","<p>The team I work with handles large amounts of consumer survey, and internal company metric data. Primarily the data is stored in a database, and we utilize various platforms and to work with that data, including MS Excel. </p>

<p>My peer has developed a suite of Excel/VBA files to take the raw data we get and upload it into a database. Unfortunately, after a code review we identified that the database password was displayed in the VBA code, in plain text, in several places per file. Being in a large enterprise organization we had a number of concerns about those files being available to more than just our team, and the database password being compromised. </p>

<hr>

<p>The problem is, I feel the <em>solution</em> is just as bad, if not worse than the original problem. The plaintext passwords have been removed in the code of all of the VBA files, and an ancillary, helper file was created that requires the user to authenticate through our organizations LDAP system before gaining access to the database password. Being a scripting language (and being Excel), I feel there really aren't adequate precautions in place to secure the users password in the helper file. I feel that now instead of compromising access to a single database, we are potentially compromising access to the logins of anyone who uses these files. </p>

<p>To be fair, my peer has implemented a number of security minded techniques for securing the data in helper file. I just feel each one can easily be circumvented:  </p>

<ul>
<li>locking the VBA code <em>[<a href=""http://www.google.com/#q=vba%20password%20recovery&amp;fp=1"" rel=""nofollow"">google search for vba password recovery</a>]</em></li>
<li>using a custom ""masked"" password entry box <em>[the password box may be masked, but it is still passed out of the box as plaintext]</em></li>
<li>not actually storing the user password in the file itself (he passes it on directly to the LDAP call) <em>[a break point or <code>stop</code> statement can easily reveal the contents of what was passed]</em></li>
<li>setting the sheets to <code>VeryHidden</code> to prevent direct access <em>[append <code>.zip</code> to filename, and ALL data in ALL worksheets is accessible]</em></li>
</ul>

<hr>

<p>As I'm not one to complain without a solution in mind, our organization already employs Active Directory/LDAP for authentication into our individual machines. My thought is that checking the logged in user (not a full user/password, just the user) against a white list of users on the database should be a sufficient alternative for authentication. </p>

<p><strong>So My Question...</strong><br>
Am I being too paranoid about this? Is there another, more appropriate solution? I am pushing back fairly hard on this <em>fix</em> and I just wanted a sanity check before I start to involve others in yet another solution.</p>
","52109","","","","","2014-07-23 16:14:31","Security Concerns with password storage in Scripting Languages (VBA)","<passwords><excel><code-security>","4","1","","","","CC BY-SA 3.0"
"261510","1","261512","","2014-11-01 08:58:26","","2","1349","<p>I want to generate a 6 digits serial number, ranged from A-Z (only uppercase allow), e.g.</p>

<pre><code>serial = ""ABCDEF""
</code></pre>

<p>the problem is, some letters are considered confusing to others letters/numbers, e.g.</p>

<pre><code>U &lt;-&gt; V
O &lt;-&gt; 0 (number)
I &lt;-&gt; 1 (number)
</code></pre>

<p>So, are there any existing set of safe letters can be used as seed to generate a safe serial number?</p>
","3415","","","","","2014-11-01 10:25:02","Safe serial numbers generation","<algorithms><security>","1","0","","","","CC BY-SA 3.0"
"74155","1","","","2011-05-05 16:19:25","","35","47233","<p>The question says it all really. I want to provide a service but I do not want to store any of the data myself in a database. With all the recent news of hacking etc it seems to me that it is nicer that clients have complete control over their data.</p>

<p>The problem is that the data stored is potentially sensitive. What I was going to do was... when a client visits the website there would be a question asking 'are you on a personal computer or a public computer'. If they are on a public computer the site would refuse access.</p>

<p>If they were on a personal computer it would then prompt them to set a password. All their data would then be encrypted with this password. Now obviously this is not too secure. The encryption method would be in JavaScript and their password in plain text so I assume it would be possible for a savvy user to locate the password in the localStorage and access the data.</p>

<p>I feel though that this isn't too much of a problem. If you are using a personal computer the chances of this happening are remote as... someone else would need access to their specific user account on the computer, someone else would need to know about the site... someone else would need to understand localStorage and how to access it. The sensitive data isn't any that will compromise their identity or much else. It just records something most people wouldn't like publicly published.</p>

<p>So really the question is, is localStorage secure enough?</p>

<p>Additional question.. how difficult is to wipe your localStorage? I wouldn't want users to 
accidentally wipe their data.</p>

<p>Finally - is it even worth encrypting / decrypting their data as if you have the password you can access the site..</p>
","11598","JasonS","","","","2016-08-11 15:17:40","How secure is localstorage?","<javascript><security>","6","1","","","","CC BY-SA 3.0"
"368615","1","368620","","2018-03-30 20:13:31","","5","167","<p>I currently am in charge of networked linux based hardware that exposes HTTP connections. I want to be able to connect to these through HTTPS,  but the hardware deployment has 1000's of installations.  I've read about problems with self-signed certificates and am unsure how to proceeed.   Furthermore, some of these may or may not be on private LANs, so I can't guarantee that there is Internet connection, but I would like  to encrypt the traffic because it might be exposed to the Internet depending on the deployment type. </p>

<p>I've had thoughts about possibly forwarding HTTP traffic over a SSL socket with a shared key, and proxying all of this traffic to a main proxy connection, but I'm unsure if this is actually the way to go.</p>

<p>Thanks</p>
","236036","","300493","","2018-03-31 07:47:05","2018-03-31 07:47:05","How to configure HTTPS for deployments without a host name","<security><ssl><https>","1","0","","","","CC BY-SA 3.0"
"147816","1","147818","","2012-05-09 02:24:02","","13","771","<p>I have found a major security hole in one of my company's public facing site. This is our first public facing site that was converted from an intranet site. I brought this issue up to my boss and they essentially shrugged it off, saying that it would take a good deal of work to re-architecture the site to make it secure.</p>

<p>This has really bothered me and I have thought about exploiting the hole to show the effects that this could happen if an actual hacker got to it. This is probably not the best idea as the effects could cost me my job if not something worse.</p>

<p>What are some things I can do to show the magnitude of the situation to management?</p>
","6854","","","","","2012-05-09 04:05:28","What to do when you find a security hole in your company's site","<security><ethics>","2","1","","","","CC BY-SA 3.0"
"74500","1","","","2010-02-04 11:29:43","","11","18562","<p>Do you think it's a good practice to implement a possibilty to allow an administrator user  to login in as another user, by-passing password? This could by implemented by a master password or a function inside the user administration, ""Login as this user"".</p>

<p>Administrators are asking for a such function to be able to try to reproduce a reported problem or to check if grants are ok, for example.</p>
","","Francois Zbinden","2673","","2011-05-07 14:46:57","2011-05-07 15:01:30","Allow Administrator users to login as other users","<security><problem-solving>","5","7","","","","CC BY-SA 2.5"
"369004","1","","","2018-04-07 13:33:08","","0","245","<p>I've written a User class like this:</p>

<pre><code>&lt;?php

class User{

    private $id;
    private $username;
    private $password;
    private $name;
    private $email;
    private $key;
    private $phone;
    private $is_verified;
    private $last_login;
    private $last_ip;
    private $language;
    private $is_loggedIn;

    function __construct()
    {

    }

    public function __set ($property , $value){
        $this-&gt;$property = $value;
    }

    public function __get($property){
        return $this-&gt;$property;
    }

    public function check_login(){

    }
}

?&gt;
</code></pre>

<p>Now, I'm thinking to set all the private parameters in <code>check_login()</code> function with user data. This function will be called on top of each and every file. Will it be a good idea to load all user data including password, email, phone etc on top of each file?</p>
","291796","","","","","2018-06-04 22:16:35","Is it a good idea to load all user data on top of each file including sensitive information?","<object-oriented><php><security><class-design>","1","8","","","","CC BY-SA 3.0"
"369233","1","","","2018-04-12 00:30:23","","7","4814","<p>I've seen a couple other posts about people trying to run untrusted user inputted code into a eval or exec statement.
My implementation checks the code before hand for any import statements, makes sure there are no builtins on the exec statement and clears all the global variables. I also put checks in place for the use of __ in the code to make sure users couldn't input dangerous code that way</p>

<p>Does this fix the problem, or are there other ways of users being able to import dangerous modules and breaking out of the shell or doing some malicious?</p>
","302793","","","","","2018-05-18 08:09:48","Running untrusted python code safely","<python><security>","2","5","","","","CC BY-SA 3.0"
"75430","1","","","2011-05-11 09:43:50","","2","1537","<p>I'm coding a new site. Ä°t's like StackExchange, a social site and a blog. I try to create a multi-language site, however I can't decide how to do it.</p>

<p>I have to use modules, so I must use OOP, while having multilanguage interface. How can I do that? </p>

<p>There are two language options (Turkish and English), used continuously (example: home page etc.) or not (some errors; example : ""please enter your mail"" etc.)</p>

<ol>
<li><p>I can use a class and I use array (for used continuously),</p></li>
<li><p>I can use a class and an XML page (for errors),</p></li>
</ol>

<p>or I can have a class and three language pages: Turkish, English and errors.</p>

<p>Which one gives the best performance?</p>

<hr>

<p>Other problem is php-mysql security.</p>

<p>I'm using mysqli. I use <code>mysqli_real_escape_string</code> to block HTML characters, but it is not enough. So I additionally use stored procedures.</p>

<p>What else can I do? What is your advice?</p>
","25030","","6059","","2016-06-16 08:53:31","2016-06-16 08:53:31","multi-language system and security with php","<php><security><stored-procedures>","2","3","","","","CC BY-SA 3.0"
"262807","1","","","2014-11-14 17:03:56","","1","1042","<p>I am learning Database connection from <a href=""http://dev.mysql.com/doc/connector-python/en/connector-python-example-cursor-transaction.html"" rel=""nofollow"">MySQL Connector/Python Developer Guide</a>.</p>

<p>This is the code I am using to insert data:</p>

<pre><code>conn = mysql.connector.connect(user=""user"", password=""password"", host=""127.0.0.1"", database=""db"")
cursor = conn.cursor()
query = (""INSERT INTO test(name,email) VALUES(%s,%s)"")
data = (""cool"", ""cool"")
cursor.execute(query, data)
conn.commit()
cursor.close()
conn.close()
</code></pre>

<p>Is this type of data insertion safe and can stop sql injection?</p>
","136717","","31260","","2014-11-14 17:10:59","2014-11-14 17:10:59","Is this type of data insertion safe and can stop sql injection in Python?","<python><security><python-3.x><sql-injection>","1","0","","","","CC BY-SA 3.0"
"75800","1","75801","","2011-05-12 10:30:09","","2","607","<p>apparently, some of our websites have been hacked by a hack bot. The reason: bad input sanitzation. Our boss is giving us this file to put on all our servers to secure them: <a href=""http://pastebin.com/0gJ19TQG"" rel=""nofollow"">http://pastebin.com/0gJ19TQG</a></p>

<p>Personally, i just do this on my personal websites: <code>filter_var(mysql_real_escape_string($_POST['Nom']), FILTER_SANITIZE_STRING);</code>. So you tell me, which one is better and why?</p>
","10282","","13156","","2011-05-12 13:34:08","2011-05-12 13:38:27","which input sanitization function is better?","<php><security>","2","3","","","","CC BY-SA 3.0"
"369645","1","369647","","2018-04-19 16:12:37","","4","962","<p>My question regards the best practice / industry standards to prevent rogue users/admins from directly logging into the database console and updating sensitive information such as financial info / balances, etc as opposed to using the software which would otherwise validate the user's actions.</p>

<p>I ask this because the software I maintain has a rudimentary anti-tamper mechanism. A set of fields from each table are check-summed prior to insertion or updating and the resulting signature is stored in each record.  When the record is next loaded from the database, the signature is recalculated and compared to the signature previously persisted in the database. If the signatures differ, then an alarm is raised.</p>

<p>There are some challenges with this approach, for instance in the event that new fields need to be added to the signature, this renders all existing signatures outdated.  Thus, they either need to be migrated or somehow versioned.  Migrating millions of records is not an option. I guess for me, its a case that the mechanism needs to be reworked to encode the version identifier in the signature.  Additionally this approach won't catch deleted records. The biggest flaw with this approach is that a user with an initial high balance (ideal record state) could transact and replace his/her record back to its ideal initial state after each transaction. No alarm would be raised as the signature does not take into account previous record states.</p>

<p>I have found so many holes with the concept and implementation of this mechanism that its got me wondering, how does the rest of the world handle this? Banks? Insurance Companies? Financial Institutions?<br>
I imagine that keeping ssh and database access on lock-down is entirely sufficient. </p>

<p>Essentially my question is: Am I correct in saying that this solution smacks of over engineering, or is the basis of the idea sound?</p>
","303611","","","","","2021-01-13 14:30:38","Preventing in database record tampering?","<security>","4","6","","","","CC BY-SA 3.0"
"263085","1","263134","","2014-11-18 01:58:32","","1","304","<p>I'm currently developing a web application (using laravel) where I have a form that edit a resource. Something like this:</p>

<pre><code>&lt;!-- URL: /editResource/3 --&gt;
&lt;form action=""/editResource/3"" method=""POST""&gt;
     &lt;!-- Input fields --&gt;
&lt;/form&gt;
</code></pre>

<p>When I send the form the web application will update the resource 3.</p>

<p>But how I can prevent something like using developer tools to modify /editResource/3 to /editResource/4 and edit the wrong resource?</p>

<p>I'm not asking how to prevent some user editing other user resources; this can be accomplished by a simple validation, but I'm asking how to prevent user modifying this kind of data, since HTTP is stateless. </p>

<p>Thank you</p>

<p>EDIT: The question was misleading, I want to clarify that what I'm trying to find is a way to keep some information between requests, without user modifying it. I'm sending the information: <strong><em>3</em></strong> to the client so in the next request, the server knows that the user is editing the resource 3, but I want to do this without the risk generated by user changing this data.</p>
","106203","","106203","","2014-11-18 02:15:37","2014-11-18 15:35:22","How to send data between HTTP requests without user modifying it?","<web-applications><security>","2","3","","","","CC BY-SA 3.0"
"76171","1","76172","","2011-05-13 16:57:07","","5","506","<p>Despite what it <em>might</em> look like this is a serious question. After that story with Android OS and Chrome browser submitting to Google the details of the WiFi access points they see in the neighborhood which has nothing even remotely to do with their main function I'm inclined to expect everything. But the specific question I have today concerns the following matter.</p>

<p>The situation. I'm developing a web application running on a locally installed web server. Naturally I'm testing and debugging it on the same development machine in various browsers such as Internet Explorer, Firefox, Opera, Safari and Chrome. The development machine has a permanent connection to the Internet.</p>

<p>Now. Is there any situation or circumstance when any of those browsers would take it upon itself to send the opened web pages from <code>http://localhost:port/*</code> to its company or any other third party? For now I seriously suspect if there is a browser crash or an OS crash the browser would submit a report perhaps with the content of my HTML, CSS and JavaScript. What if a browser would submit pages used actively and opened over a prolonged period of time just out of the company's curiosity - what is this nasty programmer working on?</p>

<p>Can you confirm that hypothesis? Are you aware of any other situations when a browser would sent out a local resource details? How safe is it to develop on a machine with a permanent Internet connection?</p>
","","user8685","","","","2011-05-13 17:04:50","Is there any risk of web browsers spying away localhost applications on an Internet-connected PC?","<security><browser><privacy>","2","3","","","","CC BY-SA 3.0"
"369736","1","369738","","2018-04-21 05:13:46","","1","305","<p>Suppose I have created an application that makes remote connections and does stuff, how does an anti-virus/anti-malware program decide if my app is harmful?</p>

<p>I know there is a signature they check for to identify a program as either good or bad but it seems to me that would result in a lot of false positives because a lot of code will be common practice.</p>

<p>I mean, how is Team Viewer different from my hypothetical backdoor application?</p>
","169587","","209665","","2018-04-21 06:02:16","2018-04-22 22:37:48","How does anti-malware decide if my application is harmless or not?","<security>","4","0","","","","CC BY-SA 3.0"
"76229","1","76241","","2011-05-13 21:36:12","","24","14145","<p>I've read in numerous sources that the output of PHP's rand() is predictable as its a PRNG, and I mostly accept that as fact simply because I've seen it in so many places.</p>

<p>I'm interested in a proof-of-concept: how would I go about predicting the output of rand()? From reading <a href=""http://improved-security.com/wiki/Randomization_%28PHP%29#Why_not_use_rand.28.29_and_mt_rand.28.29.3F"">this article</a> I understand that the random number is a number returned from a list starting at a pointer (the seed) -- but I can't imagine how this is predictable.</p>

<p>Could someone reasonably figure out what random # was generated via rand() at a given moment in time within a few thousand guesses? or even 10,000 guesses? How?</p>

<p>This is coming up because I saw a auth library which uses rand() to produce a token for users who have lost passwords, and I assumed this was a potential security hole. I've since replaced the method with hashing a mixture of <code>openssl_random_pseudo_bytes()</code>, the orignal hashed password, and microtime. After doing this I realized that if I were on the outside looking in, I'd have no idea how to guess the token even knowing it was a md5 of rand().</p>
","2862","","","","","2015-11-10 18:52:56","Predicting the output of PHP's rand()","<security><random>","4","7","","","","CC BY-SA 3.0"
"149230","1","149231","","2012-05-18 19:19:00","","5","1581","<p>Are there good means for allowing scripts from two or more domains to collaborate in the same browser page? I want to create an extensible platform, where I provide the model and some views, but also allowing third parties to create their own views as well. The idea is that all model manipulation will be done through its API, and only the model will communicate to the (main) server, but users will be allowed to include scripts from other domains that also use that API (those scripts might ""call home"" if they want to though).</p>

<p>I know many sites already do that, for instance when they use a CDN to provide libraries like jQuery. However, I also recall reading that those libraries had to be ""tweaked"" somehow so they won't be mistaken by XSS attacks, though I couldn't find more info on the subject. I have only superficial knowledge of how browsers isolate contents for different domains, and to what extent that isolation occurs, so some pointers in that direction would be very welcome.</p>

<p>I'm also aware of the method of using iframes to load ""less-than-trusted"" contents, and it seems that communication between the main page and its iframes is <a href=""https://stackoverflow.com/q/251420/520779"">quite straightforward</a>. I'd rather not use that method, but will do if there are good security benefits of doing so. However, I'm unsure if that's the case, since the iframe can call arbitrary methods on the parent page... (<em>Edit</em>: from what I understood of Florian Margaine's comment, the method in the linked question only works for same-origin iframes, is that correct? In that case, I can see the security benefits now) Can anyone with experience on the subject tell me how it works?</p>

<p>These are the only options I know of, other suggestions are welcome too. I'd also like to note that, while there must be some level of trust between the user and the third party providing the script (since its very purpose is manipulating the model owned by that user), each user will be free to choose extensions at his leisure (i.e. the available scripts won't be restricted to ones I previously evaluated and endorsed), so any means to mitigate security problems to the users are also welcome.</p>

<p><strong>Edit:</strong> Let me clarify the question a bit. The goal here is not to make HTTP requests to other domains, merely to have a better control of what the different scripts do to the same page. From what I understood so far of the same origin policy, <strong>different pages</strong> can not communicate to each other unless they come from the same domain, but scripts <strong>in the same page but coming from different domains</strong> can do whatever they want. Is that correct? (if it is, then I guess my question is moot...)</p>
","44542","","-1","","2017-05-23 11:33:35","2012-05-18 20:25:48","Means for (legit) cross-site scripting","<javascript><security><browser>","1","5","","","","CC BY-SA 3.0"
"369907","1","369938","","2018-04-24 22:25:02","","3","7274","<p>I read a lot that you can't restrict your Public REST API to only your mobile application, but I have an idea and I want opinions on it:</p>

<p><strong>Variable App Key Method</strong></p>

<p><strong>Mobile App</strong></p>

<ol>
<li>Get IP address of current connection</li>
<li>Use a secret algorithm to generate a hashed AppKey from IP address.</li>
<li>Send the AppKey with each API request</li>
</ol>

<p><strong>Server Side</strong></p>

<ol>
<li>Check the IP address of incoming request</li>
<li>Generate AuthKey from that IP address using same secret algorithm.</li>
<li>Compare AuthKey with AppKey, if they match then you know that your
Application is talking to you, because only the application knows
the secret algorithm.</li>
</ol>

<p><strong>When IP address changes:</strong></p>

<ul>
<li>On mobile App regenerate the AppKey using the new IP address</li>
<li>Server side will always generate same key because it depends
on IP address of the request</li>
</ul>

<p>The main advantage of this is that the AppKey will always change, which is better than hardcoding 1 application key inside the code, which can be easily stolen by reading request headers. And even if you stole the AppKey from a user you must be using the same IP address where that key was generated.</p>

<p>Any thoughts?</p>

<hr>

<p><strong>Conclusion:</strong></p>

<p>Relying on the IP address is problematic because you will need to call an external API to return back your correct IP address, and you will have to do that before every request because IP addresses change all the time.</p>

<p>Second problem is that internet connection on mobile switches a lot from WiFi to 3G to 4G, which will lead to unstable application behavior.</p>
","304019","","304019","","2018-04-27 22:07:31","2018-04-27 22:07:31","Proposed Method to Restrict API Access to Mobile App Only","<rest><api><security><android><mobile>","3","3","","","","CC BY-SA 3.0"
"370097","1","370131","","2018-04-28 10:56:56","","1","41","<p>Currently I am working on an open source server control panel similar to cPanel, Plesk but I am not sure what would be the best approach to make system changes which require root permissions.</p>

<p>I was thinking to create scripts (with root permissions) which validate and execute commands sent by the app modules (which don't have root permissions). The problem with this is how to validate the call properly.</p>

<p>Maybe someone has a better solution. Please let me know your opinion on this.</p>
","302427","","302427","","2018-04-28 11:51:13","2018-04-29 11:56:28","Architecture for a secure server control panel","<architecture><security>","1","0","","","","CC BY-SA 3.0"
"76939","1","","","2011-05-17 14:26:23","","50","61308","<p>There are many sites on the Internet that require login information, and the only way to protect against password reusing is the ""promise"" that the passwords are hashed on the server, which is not always true.</p>

<p>So I wonder, how hard is to make a webpage that hashes passwords in the client computer (with Javascript), before sending them to the server, where they would be re-hashed? In theory this doesn't give any extra security, but in practice this can be used to protect against ""rogue sites"" that don't hash your password in the server.</p>
","1671","","","user7519","2018-09-07 18:14:04","2018-09-07 19:25:31","Why almost no webpages hash passwords in the client before submitting (and hashing them again on the server), as to ""protect"" against password reuse?","<javascript><security><client-relations><hashing><client-side>","8","16","","","","CC BY-SA 4.0"
"149698","1","149722","","2012-05-22 17:57:54","","2","1862","<p>I posted this question on DBA, but it got closed and was never reopened even after I rewrote the whole thing to be more specific. I think its more appropriate for programmers anyway :)</p>

<h2>Background Information</h2>

<p>I have a CouchDB server (Server B) that is accessed by another server running PHP (Server A). My web app (Client-side Javascript) makes a request for a file to Server A. Server A sends requests to Server B with the access credentials (username:password). Server B returns JSON objects that correspond to matched files, then Server A returns that data to the client. The response includes some meta data about the file and a URL to the file on Server B. The actual file data itself is not included in the response. </p>

<h2>The Problem</h2>

<p>The URL to the document attachment included in the JSON response from Server B includes access credentials (username:password). Server A responds to the client-side request by returning those JSON objects. </p>

<p>The client now has this information:</p>

<pre><code>https://username:password@host:port/dbname/path/to/file.whatever
</code></pre>

<p>Currently all data contained within Server B resides in one database instance. If the client has access to the username:password to the CouchDB then all data could be queried with those access credentials. Like so,</p>

<pre><code>https://username:password@host:port/dbname/_all_docs
</code></pre>

<h2>Server-side considerations</h2>

<p>CouchDB on Cloudant</p>

<h2>Client-side considerations</h2>

<p>The Javascript running on the client requires a URL string to the file. The files that are being referenced are KML layers for Google Maps. A new KML layer is created using <a href=""https://developers.google.com/maps/documentation/javascript/reference#KmlLayer"" rel=""nofollow"">this</a> constructor.</p>

<h2>What I am looking for</h2>

<p>Essentially my solution would come if I can provide a link to a CouchDB document attachment without giving the username/password. </p>

<pre><code>https://host:port/path/to/file.whatever
</code></pre>

<h2>What I did</h2>

<p>I had to enable cURL for PHP on Server A.</p>

<pre><code>sudo apt-get install curl libcurl3 libcurl3-dev php5-curl
sudo /etc/init.d/apache2 restart
</code></pre>

<p>Got a bit of code from David Walsh's <a href=""http://davidwalsh.name/download-urls-content-php-curl"" rel=""nofollow"">blog</a>.</p>

<p>My Javascript client code gets a list of JSON file meta data from Server A. This data includes unique DB IDs and file names (No passwords or API keys). I then pass the document ID and filename to another service on Server A which echoes the value of,</p>

<pre><code>get_data('https://username:password@Server B:port/dbname/path/to/file.whatever');
</code></pre>

<p>I can now serve out the files to the client without revealing username or password for CouchDB on Server B.</p>
","50642","","50642","","2012-05-22 23:32:44","2012-05-22 23:32:44","Provide a URL to a CouchDB document attachment without giving the username/password?","<php><javascript><security><couchdb>","2","0","","","","CC BY-SA 3.0"
"77143","1","77168","","2011-05-18 08:33:53","","5","1612","<p>I've been thinking about this problem recently and it really doesn't seem like it's possible, but I figured that I'd ask just in case.</p>

<p>Assume a simple program, in pseudocode:</p>

<pre><code>run hash on an executable we think is mimicing the true executable
check the value against the hash that's hard coded into this executable
if it matches, do x
if not, do y
</code></pre>

<p>In theory it should be quite secure, since only the true executable would be able to produce the same hash that's coded into the executable, but the minute that hash is compiled into that executable the hash would change. </p>

<p>Do you think it's even possible to hard code the resulting hash in any realistic way?</p>

<p>On to the question that has a more likely answer; what would be the most secure way to make sure that an executable is in fact the same executable that was distributed with a program and not some impostor executable trying to hijack the system?</p>
","25533","","","","","2011-05-18 12:06:11","Is it possible to insert the hash of an executable into the executable itself without changing the resulting hash? What's the best alternative?","<security><hashing>","5","2","","","","CC BY-SA 3.0"
"263851","1","263889","","2014-11-26 17:01:27","","4","396","<p>The title should be fairly self-explanatory.</p>

<p>We need to update our coding standards, and as part of this process we've been asked to try and follow an industry standard from a recognised/knowledgeable body rather than just rolling our own. It allows us to demonstrate that we're using widely recognised ""best practice"" and avoid the accusation that what we've adopted it a pointless waste of time.</p>

<p>I found a few examples, but they mostly seem to be quite loose and generic. </p>

<p><a href=""https://security.berkeley.edu/content/application-software-security-guidelines"" rel=""nofollow"">https://security.berkeley.edu/content/application-software-security-guidelines</a></p>

<p><a href=""https://www.securecoding.cert.org/confluence/display/seccode/Top+10+Secure+Coding+Practices"" rel=""nofollow"">https://www.securecoding.cert.org/confluence/display/seccode/Top+10+Secure+Coding+Practices</a></p>

<p>We do both web and desktop development, using the Microsoft stack. So something widely applicable across environments but targeted at MS languages would be especially helpful.</p>
","22742","","","","","2019-05-30 19:26:12","Are there any widely accepted sets of standards/practices for secure coding?","<security><coding-standards><standards><iso>","2","5","0","2014-11-29 16:27:54","","CC BY-SA 3.0"
"370342","1","","","2018-05-02 15:03:38","","3","848","<p><strong>Background:</strong></p>

<p>There are three different applications <code>A</code>, <code>B</code> and <code>C</code> and they all share same user details but I had to implement authentication in each of them which was duplication of effort.</p>

<p>After some research I decided to go micro service way and implemented an authentication service. The service stores the <code>secret</code> for each app and prepares a JWT token when the user tries to login to given app. This is working fine as expected.</p>

<p><strong>Current:</strong></p>

<p>Now, there is a need to have roles and permissions for each application
and I finding a way to implement it without creating much coupling. I have few questions regarding my current situations:</p>

<p><strong>Questions:</strong></p>

<ol>
<li>Should I add authorisation login in the same service or create another service with <code>roles</code> and <code>permission</code> tables in it.</li>
<li><p>The end result will be to send a <code>JWT</code> token which would contain payload defining user details and permission so for example:</p>

<pre><code>{
  uid: 1,
  name: '...',
  email: '...'
  permissions: [{
    'edit': ['post', 'user'],
    'delete': ['post'],
    'read': ['post', 'user'],
    ...
  }]
}
</code></pre></li>
</ol>

<p>On paper the this structure seems good to me. It will save additional network calls from the client side. But is it safe and reliable enough?</p>

<p>PS: I don't have enough experience in building real applications but I hope I am going in the right direction.</p>
","198298","","-1","","2018-05-02 15:24:48","2018-05-03 22:59:29","Designing authentication and authorisation micro service","<security><microservices><authentication><enterprise-architecture><authorization>","1","1","","","","CC BY-SA 4.0"
"150127","1","","","2012-05-25 03:16:00","","1","1771","<p>OK, I am creating a game using JavaScript and HTML5. The variables such as <code>map</code>, <code>x</code>, <code>y</code>, <code>level</code>, <code>exp</code>, etc are stored in JavaScript to keep track. On my client page, the JavaScript variables are stored to play along with the game. Every 5 seconds, the client page sends a POST AJAX call to the MySQL database and it successfully updates it.</p>

<p>However a user can easily modify the JavaScript variables and cheat their way in the game. Then once they edit the JavaScript variables, the POST grabs that and updates it even though they edited it unethically.</p>

<p>So, how do I prevent this from happening?</p>
","11270","","","","","2012-05-25 04:37:49","Securing client->database game","<javascript><security><html>","2","1","","","","CC BY-SA 3.0"
"150146","1","154070","","2012-05-25 06:32:27","","2","280","<p>I have 2 apps. They both have accounts, and each account has users.  </p>

<p>These apps are going to share the same users and accounts and they will always be in sync.</p>

<p>I want to be able to login automatically from one app to the other.</p>

<p>So my solution is to generate a login_key, for example: <code>2sa7439e-a570-ac21-a2ao-z1qia9ca6g25</code> once a day. And provide a automated login link to the other app... for example if the user clicks on:</p>

<p><code>https://account_name.securityhole.io/login/2sa7439e-a570-ac21-a2ao-z1qia9ca6g25/user/123</code></p>

<p>They are logged in automatically, session created.</p>

<p>So here we have 3 things that a intruder has to get right in order to gain access; account name, login key, and the user id.</p>

<p>Bad idea? Or should I can down the path of making one app an oauth provider? Or is there a better way?</p>
","12606","","","","","2012-06-24 15:35:06","Security of logging people in automatically from another app?","<web-applications><security><login>","2","2","","","","CC BY-SA 3.0"
"370707","1","370724","","2018-05-10 07:10:18","","-2","311","<p>I work as a backend developer in a financial organisation and the organisation has demanded that we migrate all our technical documentation (e.g. info about batches like the names and their scheduling and dependencies, the way calculations are done, which transactional systems are connected with the batches, etc.) to a new -transparent- system. I'm looking for guidelines, principles, possibly risk assessment, about sharing of technical documentation to a wide audience. I have some reservatons about whether it is such a good idea to make everthing transparent to everyone (especially some who might want to do harm now or in the future), but right now my reservations are based on gut feelings and not backed up with arguments.</p>

<p>Does anyne has some ideas and/or links to additional info which can help me in theorising about the best approach?</p>

<p>PS: the current system for the documentation is only accessible to the teams of our own business unit. The new system would be accessible to much more business units and autorisation can only be done on individual users, not on groups. Which makes autorisation actually very hard to administrate. Access based on role/group is no option.</p>
","305320","","305320","","2018-05-10 13:41:49","2018-05-10 21:26:36","What technical documentation to share and not to share to a wide public?","<security><documentation>","1","4","","","","CC BY-SA 4.0"
"150525","1","150529","","2012-05-28 17:37:20","","14","8915","<p>For about 10 years I've worked on various in-house desktop client applications with SQL Server data stores.  Rarely did I start these projects - most are takeover work.</p>

<p>One thing that seemed constant everywhere was that there was a single global SQL Server user account that this application used that granted it permission to the common database, and yes in some naive situations it used the <code>sa</code> user account, which I generally tried to fix when possible.</p>

<p>You can't really effectively hide this username and password that the application uses to access the database.  They're usually stored in an <code>ini</code> or <code>config</code> file, or possibly baked into the executable itself.  In all cases, they're visible to the user if they do a little digging.  In one case we actually used a <code>config</code> file but encrypted it, but of course the encryption key had to be stored in the executable (we weren't naive to the limitations of this, but it did effectively stop people from poking around who were savvy enough to look in <code>config</code> files).</p>

<p>All of these systems had a user-authentication system built into the application, but of course they were all managed through the application itself, meaning the user information was stored in the database.  The application restricted what things you could do based on your access level, but it's all kind of moot if you can just connect to the database and run ad-hoc queries.</p>

<p>I'm interested to know what other systems do to get around this problem.  Here are the options I know of:</p>

<ol>
<li>Use SQL Server's security mechanism to maintain a user and roles list, and make the desktop application add and remove users through T-SQL queries.</li>
<li>Instead of connecting directly to the database, create some kind of web service that runs on the server and put the authentication logic in there.  Make every request do security validation.</li>
</ol>

<p>The first options is a bit ugly because you're separating users from the database so users are no longer first class entities and you can't reference them with foreign key relationships, etc.</p>

<p>The second just seems like a major performance problem, and a lot of extra work, plus you can't as easily use ORM mappers like NHibernate (I think).</p>

<p>Does anyone have experience with this?  Best practices?</p>

<p><strong>Edit</strong></p>

<p>Thinking a bit more, can SQL Server Authentication actually solve this problem?  For instance, if your user must be able to insert and update timesheet records so you can edit your timesheet, there's no way SQL server can disallow access to other rows in the timesheet details table, meaning you can read and write <em>other</em> people's timesheets too.</p>
","5512","","5512","","2012-05-28 18:20:24","2018-05-24 17:13:42","How do you handle database security from a desktop application?","<database><security>","7","6","","","","CC BY-SA 3.0"
"78032","1","78082","","2011-05-21 05:25:30","","0","277","<p>I have a simple encryption/decryption application that I am testing to learn more about security. I found out that if the user modifies the encrypted file, then decryption fails because the hashing algorithm doesn't generate back the original content. What are the common practices that deal with the problem of encrypted files modified by users either intentionally or unintentionally? The only thing I can think of is timestamp checking, but I am not sure how useful that is. </p>

<p>About my last statement, I guess I am not sure if there is a way to trick the OS so that the new timestamp is set back to the exact old time stamp although the content is modified. </p>
","13817","","13817","","2011-05-21 05:34:45","2015-06-19 12:36:11","How to handle the problem of modified encrypted files","<security><encryption>","5","2","0","2015-06-19 15:35:09","","CC BY-SA 3.0"
"264538","1","264552","","2014-12-04 09:19:18","","62","9738","<p>I have an enterprise application running that uses both <a href=""http://en.wikipedia.org/wiki/MySQL"">MySQL</a> and <a href=""http://en.wikipedia.org/wiki/MongoDB"">MongoDB</a> datastores. My development team all have <a href=""http://en.wikipedia.org/wiki/Secure_Shell"">SSH</a> access to the machine in order to perform application releases, maintenance, etc.</p>

<p>I recently raised a risk in the business when users started storing highly sensitive data on the application that the developers have indirect access to this data which caused a bit of a storm, so I have now been mandated with securing the data so that it is not accessible.</p>

<p>To me this does not seem possible because if the application has access to the database then a developer with access to the machine and application source will always be able to access the data.</p>
","158196","","101927","","2014-12-07 00:38:40","2014-12-08 17:26:54","Securing sensitive data from developers","<server-security>","8","19","","","","CC BY-SA 3.0"
"370943","1","371006","","2018-05-14 22:11:43","","2","619","<p>I have a fairly simple problem currently but I cannot get a solution, maybe someone here has a good idea.</p>

<p>I am working on an open source CMS for artists called Jinya CMS. The whole project originated in a friend of mine needing a new website for her artwork so I started to build her a website fitting her needs. One of those needs was that it is based on PHP, that is why I chose Symfony as base.</p>

<p>Right now I am developing version two and I would like to add an option to submit ideas on how to make things better in the administration. My idea is a simple bug and feature request form and then the data is added to the public trello board. Apart from that an email is going to be sent, which goes to the developers of the project (currently me) who can then react.</p>

<p>My problem is now the following, I need to store credentials for the trello board access and the email account sending the data.</p>

<p>Here are the ideas I had by now and why I think they are not good.</p>

<ul>
<li>Integrate ionCube Loader

<ul>
<li>ionCube is nothing bad but it just doesn't feel right to encrypt data in an OpenSource project, also I don't know if it runs on her webspace stable enough, I read it doesn't.</li>
</ul></li>
<li>Separate web api for that purpose

<ul>
<li>This idea is my current favorite, cause it would eliminate the issue of encrypting OpenSource software and it would solve the issue I have. By putting all the credentials in the configuration I would also be able to license that code under MIT on Github, like the rest of the project.</li>
</ul></li>
</ul>

<p>Now comes the question, is this a viable way to go or are there better ways? I think there must be a better way. Does anyone know?</p>

<p>To clarify, the credentials I am talking about are only known by me no one else. </p>
","82918","","82918","","2018-05-15 10:27:43","2018-05-16 10:00:32","Store password in open source project","<open-source><security>","3","10","","","","CC BY-SA 4.0"
"370985","1","370987","","2018-05-15 21:22:54","","1","100","<p>i have some experience (mostly as a student) with react and redux, and on the other hand i also have some experience with express, normally for my apps (all of them are really simple) i make a rest api with express, make express interact with mongo or any db im using and then retrieve the data to react. That's kinda all the experience i have with them.</p>

<p>Now, i want to make an app with an accounts system: register + login + authorization stuff (accounts levels and stuff like that) but i'm kinda lost on where to begin</p>

<p>the only thing i ever did related to this was sending the user and password to the express server, verificate and then send some data back and store it in a cookie, and that way check if a user is authorized to do something or not</p>

<p>i know that this is the most unsafe way of doing it, so that's why i ask what the correct way should be, what technologies should i be using? how should i architect my apps?</p>
","305795","","","","","2018-05-15 22:01:52","How to make a secure web-app account system?","<javascript><security><react>","1","1","","","","CC BY-SA 4.0"
"371020","1","","","2018-05-16 14:50:43","","0","206","<p>Our application had a few vulnerabilities detected by AppScan and we had to add  <strong>server-side validation</strong> to catch SQL injection attempts.</p>

<p>But my question is, how far do you go in server-side validation? In theory there's no end to how complicated you can make it.</p>

<p>Suppose I'm just validating there are no special chars in my model, which is the bare minimum</p>

<pre><code>public boolean validateModel(Model model) {
    // Email address has no special chars
    try {
      InternetAdress emailAddr = model.getEmailAddr();
      emailAddr.validate();
    } catch (Exception e) {
       return false;
    }

    // FirstName has no special chars
    if (!StringUtils.isAlphanumeric(model.getFirstName())
         return false;

    // LastName has no special chars
    if (!StringUtils.isAlphanumeric(model.getLastName())
         return false;
    }
    // ...  
    return true;
}
</code></pre>

<p>But why stop there? In any CRUD operation, we also have to protect against invalid IDs or numbers, so any Insert can check that the ID doesn't exist yet; that you belong or don't belong to whatever area you claim to be affiliated with (e.g. the ID is a valid ID for you); or any Update/Delete can check that the ID must exist first. To be really secure, we can really parse user input because hackers can substitute invalid data even without invalid chars.</p>

<p>My point is, to achieve a proper level of server-side security, there's a tremendous of checking you can do on the server-side. Where do you stop? What are the best practices?</p>
","286252","","286252","","2018-05-16 15:01:15","2018-05-17 10:41:29","How far do you go in server-side validation of POST/GET requests?","<web-development><web-applications><security><validation><http-request>","3","10","","","","CC BY-SA 4.0"
"371165","1","","","2018-05-19 01:55:15","","-2","226","<p>It's often convenient to hire a remote contractor for front-end development. Frameworks, like Laravel, use <a href=""https://laravel.com/docs/5.6/blade"" rel=""nofollow noreferrer"">PHP to render front-end</a> so it would make sense to give the front-end developer rights to edit PHP views files that render the HTML. </p>

<p>I can think of two possible security risks:</p>

<ol>
<li><p>Can the developer use PHP to copy the entire database?</p></li>
<li><p>Can the developer use PHP to traverse up the directory tree and access the entire back-end source code.</p></li>
</ol>

<p>If any of the above are possible, is there anything I can do to mitigate these risks? Minor risks are acceptable, but I'm concerned about the scenario when the developer copies the entire source code or database or both.</p>
","275049","","","","","2018-05-19 05:49:11","How much damage can a rogue PHP developer do?","<php><security>","2","1","","","","CC BY-SA 4.0"
"264715","1","272434","","2014-12-05 23:27:47","","6","2741","<p>Banned.h is a list of ANSI C functions that Microsoft is trying to persuade programmers to deprecate. I already know how to enforce automatic inclusion of banned.h (such as the answer to <a href=""https://softwareengineering.stackexchange.com/questions/198537/ensuring-that-headers-are-explicitly-included-in-cpp-file"">Ensuring that headers are explicitly included in CPP file</a>). Unfortunately, that answer has an important drawback.</p>

<p>Forced inclusion in project settings always includes the forced header <em>first</em>. Unfortunately, most of Microsoft's own system header files are not banned.h compliant, and many third party library headers are also not banned.h compliant. Microsoft claims that <em>their</em> usage of the banned APIs are safe, and has no intention of changing this situation. The primary way to use the system headers, then, is to include them before banned.h.</p>

<p>One way to solve this is to make a kind of meta_banned.h, which includes all possible system headers that are used anywhere in your project, as well as all the headers for any non-compliant third-party libraries, prior to including the regular banned.h. This is the first thing I did, but it causes an unfortunate hit to compile time because some of the third-party libraries have extensive headers.</p>

<p>We ended up with a hybrid approach--the meta_banned.h includes <em>some</em> system headers, and then the project settings for certain exceptional CPP files include the third-party headers as part of the force-include settings on that particular file. This works, but it's ugly and painful to maintain. The per-CPP-file forced includes in particular seem ugly.</p>

<p>What I really want is a method to ensure that banned.h is included <em>somewhere</em> in each file, not necessarily at the top. As long as it's included at some point, I consider the file compliant. If it's not included, I want to generate a build error. Any suggestions?</p>
","158408","","-1","","2017-04-12 07:31:31","2015-02-07 21:00:43","Enforcing manual inclusion of a specific header file (banned.h)","<c++><programming-practices><visual-studio><code-security>","3","1","","","","CC BY-SA 3.0"
"150986","1","","","2012-05-31 12:13:37","","1","665","<p>I'm (still) working on a template-based XML editing program. It's a GUI-based XML editor that only allows users to add certain tags and attributes based off the requirements. You can see the current version <a href=""http://jsweeneydev.net84.net/apps/javascript/xmltemplateeditor/index.html"" rel=""nofollow"">here</a> for an idea.</p>

<p>Now, I'd like to allow users to upload their own data templates, but I'm concerned about potential XSS hacks. Currently, the <a href=""http://jsweeneydev.net84.net/apps/javascript/xmltemplateeditor/JSON.js"" rel=""nofollow"">template file</a> is in Javascript object literal notation, which unsurprisingly is a security nightmare if the user can upload their own. I was thinking of using XML instead, but is there an even better alternative?</p>
","49923","","","","","2012-06-08 08:48:56","Javascript: Safely upload a client data file","<javascript><security><data-structures><xml>","1","2","","","","CC BY-SA 3.0"
"78571","1","78586","","2011-05-23 18:05:20","","13","9843","<p>I got a question today from my manager asking me my thoughts on what is considered an acceptable design for authentication of a web form application, especially in regards to the nature of many popular browsers to ""Remember Password"" for your typical user name password login fields.</p>

<p>I am having trouble coming up with an answer that I feel is acceptable.  In light of Sony's embarassing security flaws, I really want to be careful, even though the data being stored on people is of a lower sensitivity.  We are not storing social security numbers or even addresses however we are storing phone numbers, email addresses and a photo of a visitor.</p>

<p>He is concerned that a user can simply Remember Password on a public terminal, then someone can simply jump on this terminal and begin viewing or modifiy data in an unauthorized way.  I am fairly certain however that at least on Windows workstations that the browser will not ""Remember Password"" across Windows user accounts.</p>

<p>Beyond this I am implementing a one way password encryption at the server side (store encryped password in the database, encrypt user supplied password on the server, compare to encrypted string from database).  There are no immediate plans to incorporate SSL encryption however this is still an option.</p>

<p>Are there are any major security flaws with this approach?  Do you have any better suggestions?</p>
","25476","","25708","","2011-05-23 19:00:48","2011-05-23 19:00:48","Best practices for web application Authentication/Security (Any Platform)","<web-applications><security><browser><authentication>","5","3","","","","CC BY-SA 3.0"
"371410","1","","","2018-05-23 11:51:18","","1","957","<p>So, let's say I have a standard set up for application, that is:<br>
- split into micro services<br>
- and is running in a cluster (<code>kubernetes</code> or <code>docker swarm</code>, I guess specific implementation does not matter, just the main idea),<br>
- there's a API gateway, that faces internet and authenticates all the incoming external requests.</p>

<p>So far, so good, now what to do with communication between services? </p>

<p>Do I need to encrypt communication between micro services in same cluster, do I need to perform authentication/authorization between them or I should trust cluster's networking and doing this would be not needed redundancy?</p>
","23435","","","","","2018-05-23 12:16:50","Do I need to secure communications between microservices in a cluster?","<security><microservices><docker><server-security>","1","3","","","","CC BY-SA 4.0"
"151266","1","151272","","2012-06-02 09:44:47","","7","963","<p>Let's say you're creating a website for a customer. This website has its own registration (either combined with OpenID or not). The customer asks you to be able to see the passwords the users are choosing, given that the users will probably be using the same password on every website.</p>

<p>In general, I say:</p>

<ul>
<li><p>either that it is impossible to retrieve the passwords, since they are not stored in plain text, but hashed,</p></li>
<li><p>or that I have no right to do that or that administrators must not be able to see the passwords of users, without giving any additional details.</p></li>
</ul>

<p>The first one is false: even if the passwords are hashed, it is still possible to catch and store them on each logon (for example doing a strange sort of audit which will remember not only which user succeeded or failed to logon, but also with which password). The second one is rude.</p>

<p>How to refuse this request, without being either unprofessional or rude?</p>
","6605","","","","","2021-10-27 08:05:21","How to refuse to give an access to passwords to a customer without being unprofessional or rude?","<security><customer-relations><passwords>","6","3","","","","CC BY-SA 3.0"
"79271","1","","","2011-05-26 05:37:03","","5","1361","<p>Chrome 11 is now asking user permission to run both signed and unsigned Applets (yes, for signed applets the user is asked twice). Chromium team decided that this measure is needed even when the user is using an up-to-date JRE.
Here's my bug report (which reflects solely my opinion: <a href=""http://code.google.com/p/chromium/issues/detail?id=84001"" rel=""nofollow"">http://code.google.com/p/chromium/issues/detail?id=84001</a>).</p>

<p>My question is, how do you guys see it? Is Java Sandbox dated and unsafe? Do browsers need to impose a second layer of protection by default?</p>

<p><strong>Update:</strong> </p>

<p>I'm also curious about how many of you guys have a clean record experience with Java against how many every hit a piece of malicious software? As a Java Power User for more than 10 years, the only time my antivirus ever complained about something related to Java was a false positive (I was downloading some libraries from Maven Central repository).   </p>
","26238","","26238","","2011-05-27 23:38:14","2011-05-27 23:38:14","Is blocking java applets a necessary security measure?","<java><security><chrome>","3","0","","","","CC BY-SA 3.0"
"151698","1","151701","","2012-06-05 22:09:47","","7","4847","<p>I find it really hard to find resources about computer security. I asked questions on message boards about key loggers and viruses and I got negative assumption from people assuming the the worse. Also, I don't think that I can trust random message boards.</p>

<p>I know that it is a broad topic, but are there any good websites that I can follow and learn from that are targeted to beginner with some samples? </p>

<p>I am a developer (or at least want to be one) and I have a CS degree if that helps.</p>
","49355","","7426","","2012-06-05 22:26:19","2012-06-06 04:29:45","Where can I safely learn about computer security?","<self-improvement><security>","2","8","","2013-07-20 16:48:36","","CC BY-SA 3.0"
"371760","1","371770","","2018-05-29 18:19:04","","-2","661","<p>Is it, at least theoretically, possible to convert a Java application into native code that can be run by something else written in Java? One example of this could be a Minecraft Spigot server. You can code plugins and stick them in the plugins folder of the Spigot server. The server then runs and then runs the plugins which interact with the server. Would it be possible to compile it to native code? If so, how (Spigot plugins don't have a main method, which is why excelsior jet won't convert it; is there a way around that?)? And would the plugin interact normally with the Java server, considering that the Java server would have to interact with native code? </p>

<p>One additional question is since the native code ends up running in the JVM, is it any more secure than a normal Java application running in memory? What I mean is when you run a Java application, it's in memory and you can dump the bytecode. Would the native code be any different than if it weren't native?</p>

<p>Am I thinking about any of this wrong? I ask that you also include any references or articles in your answers.</p>

<p>Thanks</p>

<p>EDIT: When I'm talking about converting Java to native code, I am talking about using something like <a href=""https://www.excelsiorjet.com/"" rel=""nofollow noreferrer"">Excelsior Jet</a>, explained <a href=""https://www.excelsiorjet.com/internals"" rel=""nofollow noreferrer"">here</a>, which is essentially an AOT compiler which also has a JIT compiler for anything that needs to be run on the fly. </p>

<p>My specific questions are as follows:</p>

<ul>
<li>Can I convert something that needs to be run by something else written in Java?</li>
<li>Will the converted plugin interact the same way with the server than if it weren't native code?</li>
<li>Is the native code then run in the JVM? Or is it exclusively interacted with by the JVM?</li>
<li>Can the bytecode then be dumped the same way that normal bytecode can be dumped? (<a href=""https://reverseengineering.stackexchange.com/questions/14675/extracting-classes-from-running-jvm"">example here</a> or by modifying the OpenJDK)</li>
<li>And, finally, would the native code be as easily reverse engineered or as readable as normal Java code?</li>
</ul>
","306979","","306979","","2018-05-29 19:28:43","2018-05-29 20:50:11","Converting Java code run by dependency to native code","<java><jvm><code-security><bytecode><native>","2","12","","","","CC BY-SA 4.0"
"371859","1","","","2018-05-31 10:25:43","","1","449","<p>So I'm trying a few token based authentication in Laravel, each user have token they can use to access certain database. But there is something I still don't understand from these tutorial. The tutorials seem to only check whether a user have token, if yes then authenticate the profile to do certain api call, but obviously this is not secure.</p>

<p>When let's say a user ""Andrew"" has his own token and say he can see his own profile (in a 'profile' table), he can also see other people's profile providing he have his own token,  if he can guess the api call for that other profile. Let's say he simply seen the api call for his profile <code>example.site/getprofile?id=22</code> and try changing the id to see other's profile, and he will be authenticated because he has token.</p>

<p>How do I make sure that he can't see other's profile? what is the best practice?</p>
","263647","","","","","2018-05-31 13:12:15","token authentication security best practice","<database><security><authentication><users>","2","0","","","","CC BY-SA 4.0"
"371912","1","371913","","2018-06-01 08:03:50","","3","290","<p>When installing application on client's server at the end of the project, how to give admin's password to client? (On paper, by word?) Client may not be very technical so script generating password could be to hard for him.</p>

<p>And should I keep other/same admin credentials for myself for later support?</p>
","201412","","","","","2018-06-01 13:05:41","How to pass credentials to client","<security><client-relations><passwords>","3","2","","","","CC BY-SA 4.0"
"151938","1","151999","","2012-06-07 14:55:46","","0","222","<p>I need to write several passages of text in an offer to the client about the security layer in ASP.NET MVC web solution.</p>

<p>I am aware of security that comes along with MVC 3 and an improvements in MVC 4. But all of them are non conceptual, except for <code>AntiForgeryToken</code> (AntiXSS) and built-in SQL Injection immunity (with a little of encoding needed by hand).</p>

<p>What would be the main point of ASP.NET security I can ""show off"" in an offer to the client? </p>
","33579","","31260","","2016-01-26 10:23:50","2016-01-26 10:23:50","Security aspects of an ASP.NET that can be pointed out to the client","<architecture><security><asp.net>","1","3","","","","CC BY-SA 3.0"
"151963","1","151964","","2012-06-07 21:06:01","","3","165","<p>SO I'm building an application for uploading files. We're paying scientists to contribute information on pests, diseases and bugs (for Plants). We need the ability to drag and drop a file to upload it. </p>

<p>The question becomes since the users will be authicentated and setup by us, will it be necessarcy to include a virus scanner to prevent the uploading and insertition of malicious files. </p>

<p>How important is this? </p>
","29398","","7426","","2012-06-07 21:10:55","2012-06-07 21:16:11","File Upload Forms: Security","<web-development><security>","1","1","","","","CC BY-SA 3.0"
"266777","1","","","2014-12-18 08:00:09","","3","3590","<p>I'm currently working on a service that is supposed to aggregate data from a number of APIs, unify the data, and offer it through another API to the users. I had a couple of ideas for solving this, but I'm not confident my best solution is the best possible solution.</p>

<p>Solutions I considered:</p>

<ul>
<li>Let the browser poll our API through javascript, which in turn polls the third party APIs. This introduces quite a bit of lag between the request and the user seeing the data, but doesn't waste resources on users that rarely log in.</li>
<li>Let the browser poll the third party APIs and afterwards send the data to our API. This is potentially insecure, and requires me to provide extra API endpoints and a lot more data cleanup.</li>
<li>The option I currently consider the most optimal is letting a service on the server (an actual executable) periodically poll the third party APIs. I would, for example, poll some endpoints every 30 minutes, and others maybe once a day. This is the safest option, and introduces little lag to user requests, and prevents users from reaching the request limit of the API. But data will only be up-to-date right after polling.</li>
</ul>

<p>Are there any alternatives? If not, is my current optimal solution good enough?</p>
","26681","","31260","","2014-12-18 08:06:52","2015-01-17 16:12:52","Periodically polling an API, are there alternatives?","<security><performance><api><polling>","2","1","","","","CC BY-SA 3.0"
"79755","1","","","2011-05-27 18:00:55","","15","736","<p>A chap I'm bidding to do some development for has a social network he wrote himself.
Not the next facebook by any stretch. But a few thousand local users.</p>

<p>I went to have a look at it to see what level of knowledge he had so I knew how to position myself for this potential job.</p>

<p>I tapped a single quote into the login box on the front page and up pops a SQL error.
So I tried a simple "" a' or 'a'='a "" in each box and was immediately logged in as the administrator.</p>

<p>He had written a fairly comprehensive administration site by the looks of things.
At the bottom of the page a ""Download SQL Backup"" button.
This is where I stopped.</p>

<p>My question is this.
What do I do?</p>

<p>As a developer myself I would appreciate the heads up. But as someone who's hopefully going to be paid to do some work for him I wouldn't want to throw all sorts of trust issues into the mix.</p>

<p>Any ideas?</p>
","26434","bencoder","","user22815","2015-04-09 02:50:18","2015-04-09 02:50:18","Discovered large security hole in someone elses website... What to do?","<security><ethics><sql-injection>","6","4","","2015-04-28 02:14:56","","CC BY-SA 3.0"
"266904","1","266905","","2014-12-19 13:50:42","","0","94","<p>Which is preferable for both solid technique and secure coding?</p>

<p>Example #1:</p>

<pre><code>function_one()
    blah;
    function_two()
        blah;
        print blah;
        exit;
</code></pre>

<p>... </p>

<p>Example #2:</p>

<pre><code>function_one()
    blah;
    function_two()
        blah;
        return blah;
    return blah;
print blah;
</code></pre>

<p>Obviously this is a simplified version, and I am looking for an answer which is universal for larger function trees, if possible. </p>

<p>-1: I liked Example #1 because it seemed faster to terminate as soon as it is done doing what it does, instead of returning to the original call to lives out its natural life. Also, Example #1 seems to compartmentalize code, helping to prevent unintended code from executing further on down (which should be detected during testing, but I prepare for the worst). However, this model has proven difficult to maintain, and doesn't seem to scale well. For instance, I had a web page which I wrote to echo out what it was supposed to and then terminate, but this caused problems down the road with making sure that the http headers were inserted before the output; this would require sending the headers as a function parameter.<br><br>
-2: Example #2 seems to maintain a standard order of doing things because not all functions will terminate as soon as possible. Also code can be combined easier without passing additional parameters as in Example #1. However, Example #2 requires more return statements, and will continue out the rest of the program. What do you think?</p>
","160860","","160860","","2014-12-19 14:02:55","2014-12-19 14:02:55","Sending Out Functions To Return Or To Die","<programming-practices><security><secure-coding>","1","7","","","","CC BY-SA 3.0"
"80069","1","80098","","2011-05-29 06:15:26","","31","3109","<p>I volunteered to instruct an after school computer club at my son's middle school. There has been a lot of interest in computer viruses. I was thinking about showing them how to create a simple batch file virus that will infect other batch files in the same directory. Also show how creating a batch file with the same name, but that is closer in the path, can replace another program.</p>

<p>It could also allow for discussion of anti-virus techniques - recognizing viruses and virus like behavior. </p>

<p>I mentioned the idea to my wife and she thought it was a terrible idea. Compared it to giving them loaded weapons. I don't see it as dangerous since this technique wouldn't be immediately applicable for any real mischief on any modern operating systems.</p>

<p>Am I being too cavalier or is she being too concerned? This isn't a settle this argument for me question, I am just trying to get another opinion. </p>

<p><strong>Update</strong>: I don't plan to cover moving between systems (or even directories) or any malicious behavior. And lest anyone think I am revealing any deep dark secrets, here is a <a href=""http://vxheavens.com/lib/vml00.html"">book from 1996</a> I found at the library that goes into a lot more detail than I planned to cover. If some is motivated to be malicious they will find a way.</p>
","433","","25936","","2015-05-07 17:27:33","2015-05-07 17:27:33","Is it ethical to teach teens about software viruses?","<security><ethics>","14","12","","2015-05-04 01:19:37","","CC BY-SA 3.0"
"80219","1","80229","","2011-05-30 04:49:45","","2","2349","<p>I don't like writing open-ended questions but I have a quick security question. I have a PHP login script that shows a CAPTCHA on the third failed login attempts. The way I'm counting failed logins is by using session data. Is this secure? Is there a better way to do this? Maybe store the IP in a database table? I'm not really sure how bots and programs that try to use word list actually work. </p>

<p>Thanks</p>
","20341","","","","","2011-05-30 09:03:17","Are sessions secure for captcha on failed login?","<php><security><captcha>","2","1","","","","CC BY-SA 3.0"
"372315","1","372321","","2018-06-08 23:26:44","","2","137","<p>I was reading about bruteforce login attack and one of the solution to prevent users from trying too many passwords in short amount of time is to add exponential delay for every failed login. But someone might do a DoS attack by keep trying to login with certain username.</p>

<p>I was thinking to do a <code>window.location.reload()</code> every say 5 failed login attempts, because it takes time reloading a page, and use a static one second delay before posting each login, assuming a normal user will take one second or more to type their password anyway.</p>

<p>Is this a good approach? what are the potentials for this to go wrong?</p>
","263647","","","","","2018-06-09 05:00:57","Is it a good idea to reload the page every few failed login attempt?","<security><authentication>","1","2","","","","CC BY-SA 4.0"
"152763","1","152768","","2012-06-13 18:36:35","","5","20363","<p>I'm looking for a way to have a website remember sensitive data, but without actually storing it server side.  And I was looking at HTML5 <code>localStorage</code> to do it.  Here's the plan as I see it.</p>

<ol>
<li>User enters sensitive data into form, and submits.</li>
<li>Server encrypts data via AES-256 with a strong key that is kept in private source control.</li>
<li>Server responds, providing encrypted data to rendered page.</li>
<li>Page runs javascript to save encrypted data to <code>localStorage</code></li>
</ol>

<p>Later...</p>

<ol>
<li>User visits a page that uses javascript to fetch encrypted data from <code>localStorage</code> and sends it to the server.</li>
<li>Server decrypts encrypted data, gaining access to sensitive information for that request.</li>
</ol>

<p>My thinking is that that allows either the client or server to compromised, and things stay secure.  If the client is compromised, then the hacker can read only an encrypted string they do not have the key to decrypt.  If the server database is compromised, the data is simply not stored there so it obviously can't be accessed by the hacker.</p>

<p>(Obviously some types of server hacking could read sensitive data as it's coming in initially, but such a hack would work whether client storing it or not, so that doesn't apply to this discussion. Also client hacks that log keys and whatnot would still work, I'm simply talking about data storage getting compromised on either side here)</p>

<p>But I'm no security expert, so I am wondering if my plan has any holes in it? Any glaring security vulnerabilities I am missing here?</p>
","56726","","56726","","2012-06-13 18:44:01","2018-09-05 11:24:19","HTML5 localStorage and encrypted sensitive data","<security><html5><encryption>","2","0","","","","CC BY-SA 3.0"
"267366","1","","","2014-12-25 15:29:45","","2","2172","<p>I'm practicing around building e-commerce asp.net applications that allows for users to register to the site and their user credentials are stored in a MySQL database. In my sample project the registration asks for the users username, password, full name, phone #, email, home address (for shipping of products purposes).</p>

<p>I know its good practice to store the user's password as a salted hash.  But is there any other info that should be stored the same way or not?  For example should the username also be stored as a salted hash or even encrypted?</p>

<p><strong>I guess I'm just wondering what kinds of information is it ok to be stored in plain text in MySQL database for an asp.net web app? And which items are recommended to be stored in a salted hash? And which items should be stored using encryption?</strong></p>
","161303","","161303","","2014-12-25 18:08:52","2020-03-25 09:55:38","What kind of user info is ok to be stored as plain text in SQL Database?","<c#><security><asp.net><sql>","5","4","","","","CC BY-SA 3.0"
"80582","1","80585","","2011-05-31 18:15:43","","12","784","<p>Being the creator of a program, you are probably in a better position than anyone to be aware of security vulnerabilities and potential hacks. If you know of a vulnerability in a system you wrote, is that a sign that increased security MUST be added before release, or should this be evaluated on a case by case basis to determine the severity of the security gap?</p>
","3792","","","","","2014-03-20 12:54:32","Should you ever release something that you yourself could hack?","<security><release>","5","3","0","","","CC BY-SA 3.0"
"267459","1","267462","","2014-12-27 17:47:35","","2","336","<p>With some platforms, like LinkedIn, you can see a list of all sessions where you are logged in, and you can even log them out on a distance.</p>

<p><img src=""https://i.stack.imgur.com/m969T.jpg"" alt=""enter image description here""></p>

<p>How would you implement something like that? I'm not talking about specific code, but more about general flow.</p>

<p>I am using ASP.NET myself, but I think a general approach would be more useful for others.</p>

<p>Right now I'm thinking about something like this:</p>

<ul>
<li>User logs in, validate email/password combination</li>
<li>Generate GUID, save to database together with UserId and Browser information.</li>
<li>Put Cookie in a serverside-read-only cookie.</li>
<li>When user wants to sign out from a distance, we remove the GUID in the database.</li>
</ul>

<p>One of the security issues here would be that the GUID can get intercepted, and an attacker could use this to login.</p>

<p>So how to do this properly?</p>
","92306","","","","","2014-12-27 18:02:32","How do you implement an active sessions system like LinkedIn?","<security><authentication><session><login>","1","1","0","2015-01-07 19:52:40","","CC BY-SA 3.0"
"267469","1","","","2014-12-27 20:24:48","","0","165","<p>The tutorials I find to setup OS-X for web developer programming (installing x-code ruby js cocoapods sql c asm etc) leave out if it should be done from an admin account, or standard (managed) user.</p>

<p>Some methods I've seen used: Setup dev environment from admin account, then change admin to managed user. Or install dev environment from managed user, using sudo or otherwise editing settings to get things to install.</p>

<p>What's the consensus for using Terminal from a managed &amp; parental controlled account? What's the correct procedural way to setup a fresh 10.10 install? Thanks.</p>
","","user161600","","","","2014-12-27 21:17:00","Developer account in OSX, admin or managed user with our without sudo access?","<programming-practices><security>","1","0","","","","CC BY-SA 3.0"
"80925","1","80932","","2011-06-01 22:07:14","","2","529","<p>I'm developing an ASP.NET 2.0 web service that serves XML data from a database.  Almost all data traffic is one-way, from server to client, and there is no user-specific data.  All clients will receive the same data.  But I only want approved clients to be able to consume the data.  In this situation, what are the best options for encrypting the data produced by the web service?</p>

<ul>
<li>I've looked at SSL, but I've been told by management to find another way, so that we can either avoid the hassle of setting up an SSL certificate on the site or implement both SSL <em>and</em> my solution.</li>
<li><a href=""http://msdn.microsoft.com/en-us/library/ms972410.aspx"" rel=""nofollow"">SOAP encryption</a> has been suggested, but I want to have good support for iOS clients, and there does not appear to be SOAP support built into the iOS SDK or available open-source.</li>
<li>Because no data is being modified server-side, and we have no user-specific data or user accounts, I don't think OAuth is necessary.  It will become necessary in the future, but we'll cross that bridge when we come to it.  Am I wrong here?</li>
<li>I've suggested encrypting the content of the XML data so that <code>&lt;Prop1&gt;StringData&lt;/Prop1</code> becomes <code>&lt;Prop1&gt;EncryptedGarbageHere&lt;/Prop1&gt;</code>, but I've been told that's not as secure an approach as SOAP encryption.</li>
</ul>

<p>EDIT: In either case, I'm also planning on adding a sort of ""password"" parameter that is required by all WebMethods in the web service, and will be required of each unique client application.</p>
","14955","","14955","","2011-06-01 22:52:56","2011-06-02 14:43:59","Security for data produced by ASP.NET web serivce","<asp.net><security><web-services>","3","12","","","","CC BY-SA 3.0"
"267701","1","267710","","2014-12-30 22:04:09","","2","725","<p>I'm writing a Java desktop application that will be available to the public. It will contact backend APIs via HTTPS using Jersey client.</p>

<p>I don't know anything about using certificates in desktop apps but from what I've found out so far I'll need to create an SSLContext that reads a public certificate from a KeyStore that is protected by a password. </p>

<p>I'm assuming I can distribute the contents of the KeyStore by packaging it in the Jar of my app. But I don't see how I can securely make the key store password available to the app. I don't want the users to have to enter it manually.</p>
","15555","","15555","","2014-12-31 22:35:25","2014-12-31 22:35:25","How to access secure web services from a desktop application?","<java><security><desktop-application>","1","2","","","","CC BY-SA 3.0"
"81062","1","","","2011-06-02 15:04:20","","32","10644","<p>Data input validation always was quite an internal struggle to me.</p>

<p>On the verge of adding a real security framework and code to our legacy application rewrite project (which so far pretty much keeps the card-castle-strong legacy security code and data validation), I'm wondering again about how much should I validate, where, etc.</p>

<p>Over my 5 years as professional Java developer, I created and refined my personal rules for data input validation and security measures. As I like to improve my methods, I'd like some hear some ideas from you guys. General rules and procedures are fine, and Java-specific ones too.</p>

<p>Summarized, these are my guidelines (exposed on a 3-tier web application style), with brief explanations:</p>

<ul>
<li><p>1st tier client side (browser): minimal validation, only invariable rules (mandatory email field, must select one item, and the like); use of additional validation like ""between 6 and 20 characters"" less frequent, as this increases maintenance work on changes (may be added once the business code is stable);</p></li>
<li><p>1st tier server side (web communication handling, ""controllers""): I don't have a rule for this one, but I believe only data manipulation and assembly/parsing errors should be handled here (birthday field is not a valid date); adding further validation here easily makes it a really boring process;</p></li>
<li><p>2nd tier (business layer): rock solid validation, no less; input data format, ranges, values, internal state checking if method cannot be called anytime, user roles/permissions, and so on; use as little user input data as possible, retrieve it again from database if needed; if we consider retrieved database data as input too, I would only validate it if some specific data is known to be unreliable or corrupted enough on the DB - strong typing does most of the job here, IMHO;</p></li>
<li><p>3rd tier (data layer/DAL/DAO): never believed much validation is needed here, as only the business layer is supposed to access the data (validate maybe on some case like ""param2 must not be null if param1 is true""); notice however, that when I mean ""here"" I mean ""code that access the database"" or ""SQL-executing methods"", the database itself is completely the opposite;</p></li>
<li><p>the database (data model): needs to be as well thought, strong and self-enforcing as to avoid incorrect and corrupt data on the DB as much as possible, with good primary keys, foreign keys, constraints, data type/length/size/precision and so on - I'm leaving triggers out of this, as they have their own private discussion.</p></li>
</ul>

<p>I know early data validation is nice and performance-wise, but repeated data validation is a boring process, and I admit that data validation itself is quite annoying. That's why so many coders skip it or do it halfway. Also, every duplicated validation is a possible bug if they are not synchronized all the times. Those are the main reasons that I'm nowadays preferring let most of the validations up to the business layer, at the expense of time, bandwidth and CPU, exceptions handled on a case-by-case basis.</p>

<p>So, what do you think about this? Opposite opinions? Do you have other procedures? A reference to such topic? Any contribution is valid.</p>

<p>Note: if you are thinking the Java way of doing things, our app is Spring based with Spring MVC and MyBatis (performance and bad database model rule out ORM solutions); I plan to add Spring Security as our security provider plus JSR 303 (Hibernate Validator?)</p>

<p>Thanks!</p>

<hr>

<p>Edit: some extra clarification on the 3rd layer.</p>
","15017","","15017","","2011-06-02 17:19:31","2011-06-03 01:10:38","Data input validation - Where? How much?","<development-process><language-agnostic><security><data><validation>","5","3","","2013-08-06 13:50:20","","CC BY-SA 3.0"
"372829","1","","","2018-06-19 17:02:38","","-1","28","<p><a href=""https://i.stack.imgur.com/kRkwn.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/kRkwn.png"" alt=""enter image description here""></a></p>

<p>Hi I am working on application 2. 
My application interacts with application 1 and 3.
Clients of application 1 need to be to share their linkedin profile information with application 3. 
I have created a simple authorization to linkedin and presented it to application 1 as api. 
I now would want to build :
1) Either data sharing functionality between application 1 and 3 
OR
2) be able to forward authentication request from application 3 and 1.</p>

<p>Goal : is user to be able to share linkedin profile information with consent from application 1 to 3 which are connected by application 2.</p>

<p>It would be great if you could suggest me the best and most secure and easy way to implement this. </p>

<p>Your views will be much appreciated.</p>
","308493","","","","","2018-06-20 12:29:00","How to implement linkedin authentication/data sharing with multi party?","<design><architecture><security><software><authorization>","1","0","","","","CC BY-SA 4.0"
"81271","1","81410","","2011-06-03 11:22:18","","7","481","<p>If I have a database that stores the login credentials of 1,000,000 users in PLAINTEXT, how much effort will it take me to md5 hash these passwords? </p>
","10282","","101","","2011-06-03 12:16:05","2011-06-03 22:02:02","Converting a 1,000,000 rows database","<database><security><coding-standards>","3","6","","","","CC BY-SA 3.0"
"81355","1","81356","","2011-06-03 16:02:27","","15","1431","<p>Sony was recently hacked with a SQL injection and the passwords of their user's was stored in plain text. These are rookie mistakes. In such a large company, how does this pass QA? How do they not have better teams than to know better than this?</p>

<p>The sheer size of the company that was hacked makes this different. It affects all of us because we all may one day find ourselves on a team that is responsible for something like this, and then we get the ax. So what are the factors that lead to this, and how do we prevent them?</p>
","14969","","26034","","2012-08-06 19:59:02","2012-08-06 19:59:02","How does a large company make rookie mistakes which leave security holes?","<security><qa><mistakes>","6","4","","2011-06-04 04:37:56","","CC BY-SA 3.0"
"267981","1","267984","","2015-01-04 00:59:18","","30","9040","<p>The title says it all, the more I do research about piracy and the tools used to crack an app the more I think it is just wasted time.</p>

<p>My biggest threat is that my app is being cracked and uploaded again within minutes after I released it. But I'm not sure how harmful it will be to my revenue, if there even will be revenue. Maybe someone can come up with some experience, it's my first app which I'm going to publish and I have no experience with that. My app is going to be free with ads. I think this is another line of defense because in my opinion, the main focus is on paid Apps due they are not available in a lot of countries..</p>

<p>My current approach is that I will just use proguard not really to make it harder to crack (more likely understand the code), because you don't even need to understand the code if you just simply resign it and upload the same application to the playstore, you will just need to change the package name. My main point of using proguard is just to shrink the app.</p>

<p>Is this a ""good"" approach?</p>
","157863","","31260","","2016-02-26 14:40:22","2016-02-26 14:40:22","Should I spend time preventing piracy of my app?","<security><android><obfuscation>","8","9","","2015-01-05 14:00:50","","CC BY-SA 3.0"
"373089","1","373093","","2018-06-25 07:50:15","","12","11415","<p>Should information about the permissions and roles of the client be included in JWT? </p>

<p>Having such information in JWT token will be very helpful as everytime a valid token comes, it would be easier to extract the information about the permission about the user and there will be no need to call the database for the same. <strong>But does including such information and not double checking the same in the database will be a security issue?</strong></p>

<p>Or,</p>

<p>Information like the one mentioned above should not be a part of JWT ever, and only the database should be used for checking the access roles and permissions of a user?</p>
","288287","","","","","2022-04-07 11:08:06","Should access permissions and roles be included in payload of JWT?","<security><authentication><jwt>","3","0","","","","CC BY-SA 4.0"
"373109","1","373111","","2018-06-25 13:19:06","","6","18096","<p>While creating/assigning the JWTs to users, should we also store them in our databases?</p>

<p>The negatives/cons of storing tokens in database would be, that all the data in the payload of the JWT token is already stored in the database, hence storing the token will storing the redundant data, also the verification of JWTs happens through the signature keys which do not change for a longer period of time but,</p>

<p>The positives/pro I can see of storing the JWT token in our database would be that even after assigning the token we will have the power to invalidate or deactivate the existing the tokens even before the expiry.</p>

<blockquote>
  <p>One of the use-cases for storing the tokens would be that tokens will be invalidated when there is an update in the auth scheme and all the old tokens have to be invalidated.</p>
</blockquote>
","288287","","","","","2018-06-25 14:14:48","Should we store JWTs in database?","<security><jwt>","2","2","","","","CC BY-SA 4.0"
"373223","1","373262","","2018-06-27 09:49:48","","3","496","<p>We use quite a few external open source libraries in our projects, pulled in from Maven Central etc. </p>

<p>I was wondering what is best practice to ensuring that you don't introduce some sort of security risk by using these dependencies.  We have quite a few and it's unrealistic to re-write these libraries.  </p>

<p>I'm not sure that it's relevant but I'm specifically talking about mobile development - IOS and Android apps</p>
","309057","","","","","2018-06-27 21:58:09","How do you ensure external dependencies aren't a security risk?","<security><code-security>","1","8","","","","CC BY-SA 4.0"
"269306","1","","","2015-01-07 13:44:20","","2","344","<p><strong>Situation</strong></p>

<p>Mobile application store owners are known to explicitly forbid some application extensibility scenarios.</p>

<p>Apple:</p>

<blockquote>
  <p>2.7 Apps that download code in any way or form will be rejected</p>
  
  <p>2.8 Apps that install or launch other executable code will be rejected</p>
  
  <p><a href=""https://developer.apple.com/app-store/review/guidelines/#functionality"" rel=""nofollow noreferrer"">https://developer.apple.com/app-store/review/guidelines/#functionality</a></p>
</blockquote>

<p>Microsoft:</p>

<blockquote>
  <p>3.9 All app logic must originate from, and reside in, your app package
  Your app must not attempt to change or extend the packaged content through any form of dynamic inclusion of code that changes how the application behaves with regard to Store certification requirements. Your app should not, for example, download a remote script and subsequently execute that script in the local context of the app package.</p>
  
  <p><a href=""http://msdn.microsoft.com/en-us/library/windows/apps/hh694083.aspx"" rel=""nofollow noreferrer"">http://msdn.microsoft.com/en-us/library/windows/apps/hh694083.aspx</a></p>
</blockquote>

<p>Google (not sure if it is as restrictive):</p>

<blockquote>
  <p>An app downloaded from Google Play may not modify, replace or update its own APK binary code using any method other than Google Play's update mechanism.</p>
</blockquote>

<p><a href=""https://play.google.com/about/developer-content-policy.html"" rel=""nofollow noreferrer"">https://play.google.com/about/developer-content-policy.html</a></p>

<p><strong>Problem</strong></p>

<p>Some applications such as Minecraft and Codea are meant to let users produce content (not just consume it). Codea projects are obviously an executable code and Minecraft is <a href=""https://gaming.stackexchange.com/questions/20219/is-minecraft-turing-complete"">known to be Turing-complete</a>.</p>

<p>Now they don't have any built-in online community gallery capabilities, but it would be easy to imagine them added in future. This is something users would definitely appreciate:</p>

<p><a href=""https://gaming.stackexchange.com/questions/148549/how-to-transfer-minecraft-pocket-edition-world-between-ipads"">https://gaming.stackexchange.com/questions/148549/how-to-transfer-minecraft-pocket-edition-world-between-ipads</a></p>

<p><a href=""http://codea.io/talk/discussion/527/best-way-to-share-code-straight-from-ipad/p1"" rel=""nofollow noreferrer"">http://codea.io/talk/discussion/527/best-way-to-share-code-straight-from-ipad/p1</a></p>

<p>Microsoft has already done this with their Project Spark (PC/Xbox) and Media Molecule/Sony have this in their Little Big Planet (PS, <a href=""http://beza1e1.tuxen.de/articles/accidentally_turing_complete.html"" rel=""nofollow noreferrer"">also Turing-complete</a>).</p>

<p><strong>Questions</strong></p>

<p>1) Obviously specific store owners make their own, often random and unfair decisions, but generally where is the line between 'code' and user-created content?</p>

<p>2) Is it a conscious decision to favour security over experience or a simple case of  short-sightedness?</p>

<p>3) What can be done to work around today? I am aware of the browser technology but am only interested in application development.</p>
","13154","","-1","","2017-04-13 12:09:35","2016-01-20 17:41:08","How to let users share custom code content under the mobile app store restrictions?","<security><business><scripting><mobile><appstore>","2","0","","","","CC BY-SA 3.0"
"154225","1","","","2012-06-26 00:21:53","","0","1437","<p>I am working with developers right now that write code the way they want and when i tell them to do it other way they respond that its just matter of preference how to do it and they have their way and i have mine.</p>

<p>I am not talking about the formatting of code, but rather of way site is organized in classes and the way the utilize them. and the way they create functions and process forms etc.</p>

<p>Their coding does not match my standards, but again they argue that its matter of preference and as long as goal achieved the can be different way's to do it. I agree but their way is proven to have bugs and we spend a lot of time going back and forth with them to fix all problems security or functionality, yet they still write same code no matter how many times i asked them to stop doing certain things.</p>

<p>Now i am ready to dismiss them but friend of mine told me that he has same exact problem with freelance developers he work with. So i don't want to trade one bad apple for another.</p>

<p><strong>Question is is there some world wide (or at least europe and usa) accepted standard or compliance on how write secure web based applications. What application architecture should be for maintainable application.</strong></p>

<p>Is there are some general standard that can be used for any language ruby php or java govern security and functionality and quality of code? Or at least for PHP and MySQL i use for my website. So i can make them follow this strict standard and stop making excuses.</p>
","57621","","57164","","2012-06-26 03:26:23","2012-06-27 07:56:47","Standards & compliances for secure web application development?","<php><productivity><web-applications><security><coding-standards>","5","6","","","","CC BY-SA 3.0"
"373603","1","373610","","2018-07-05 11:05:39","","9","1707","<p>I know this topic has been covered quite a lot but I can't find an answer to my specific situation. </p>

<p>Currently, I'm using <code>.gitignore</code> to exclude sensitive content and keeping it (config files, etc) seperately. As my codebase expands into more and more projects, this is becoming quite difficult to manage and I also have no real way to track changes or back up the files properly.</p>

<p>There are some tools for this problem, like <code>git-secret</code>, <code>Hashicorp Vault</code> and <code>git-crypt</code> but none of these work with Windows, where I do all of my development (for various reasons).</p>

<p>Currently, I am the only developer working within my firm with no plans to expand. Source control (Gitlab) is mainly used for my own reference and ability to record changes. Would pushing a few connectionstrings or config files into source control be a huge problem or risk? That information is currently sitting in a network drive, unsecured (except for NTFS permissions)</p>

<p>I get the idea is that best practice is not to push this stuff to source control but I do have a privately hosted Gitlab instance which is not accesible outside of the local network - does this mean there is less risk?</p>
","267261","","","","","2018-07-05 14:49:10","Best practice for sensitive information in source control","<git><security>","2","6","","","","CC BY-SA 4.0"
"82371","1","82382","","2011-06-08 01:20:04","","37","8265","<p>When working with a resource-based site (such as an MVC application or REST service), we have two main options when a client tries to <code>GET</code> a resource that they don't have access to:</p>

<ul>
<li><strong>403</strong>, which says that the client is <em>unauthorized</em>; or</li>
<li><strong>404</strong>, which says that the resource <em>does not exist</em> (or couldn't be located).</li>
</ul>

<p>Common wisdom and common practice seems to be to respond with the truth - that is, a 403.  But I'm wondering if this is actually the right thing to do.</p>

<p>Secure login systems never tell you the reason for a login failure.  That is to say, as far as the client is concerned, there is no detectable difference between a non-existent user name and an incorrect password.  The purpose is of this is to not make user IDs - or worse, e-mail addresses - discoverable.</p>

<p>From a <em>privacy</em> standpoint, it seems a lot safer to return a 404. I'm reminded of the incident wherein someone reportedly found out the winners of a reality show (Survivor, I think) by looking at which resources <em>didn't</em> exist on the site vs. which ones did.  I'm concerned about a 403 potentially giving away sensitive information like a serial number or account number.</p>

<p>Are there compelling reasons <em>not</em> to return a 404?  Could a 404 policy have negative side effects elsewhere?  If not, then why isn't the practice more common?</p>
","3249","","","","","2018-07-31 09:17:43","Should MVC/REST return a 403 or 404 for resources belonging to other users?","<web-development><web-applications><security><web-services><privacy>","4","3","","","","CC BY-SA 3.0"
"154406","1","154407","","2012-06-26 09:24:31","","8","2243","<p>I have the following : </p>

<pre><code>public class doCheck(){

    public void performCheck(){
        try {
            perform all checks......
        }
        catch(Exception e){
            logger.error(""Exception occured in class doCheck in method performCheck"");
            thrown new MyNewException(e.getMessage());
        }
    }
}
</code></pre>

<p>Is it safe to log the class and method name?</p>
","35848","user470184","","","","2012-07-02 15:17:59","Is it a security flaw to log the class and method name when an exception occurs?","<java><security><exception-handling>","3","0","","","","CC BY-SA 3.0"
"203360","1","","","2013-07-01 19:07:01","","4","372","<p>I developed many applications with registered user access for my enterprise clients. In many years I have changed my way of doing it, specially because I used many programming languages and database types along time.</p>

<p>Some of them not very simple as <code>view</code>, <code>create</code> and/or <code>edit</code> permissions for each module in the application, or light as <code>access</code> or <code>can't access</code> certain module.</p>

<p>But now that I am developing a very extensive application with many modules and many kinds of users to access them, I was wondering if there is an standard model for doing it, because I already see that's the simple or the light way won't be enough.</p>
","58513","","","","","2013-07-05 10:31:42","Is there an industry standard for systems registered user permissions in terms of database model?","<security><database-design><users><model>","1","3","","","","CC BY-SA 3.0"
"203626","1","","","2013-07-04 02:36:54","","1","100","<p><strong>Question</strong></p>

<p>Given two cloud services, Sender A &amp; Receiver B, communicating over HTTPS, what options do I have to ensure that Receiver B only response to Sender A?  For the purposes of </p>

<p><strong>Background</strong></p>

<p>The receiver is generating activation keys for some hardware from a serial number.  Our support team is using Salesforce and we're making callouts from Salesforce to an Azure service to generate the key.  Since neither are behind a firewall we want to make sure that only request from our Salesforce instance can generate an activation key.</p>

<p>My thought was just to create a nice long key stored on both sides that could be used to validate the request, but I'm not a security expert and don't know if there is anything else I should be considering.</p>
","32468","","","","","2013-07-04 13:34:25","How ensure secure two cloud services can only talk to each other?","<security><software-as-a-service><https>","2","0","","","","CC BY-SA 3.0"
"324392","1","","","2016-07-08 22:35:04","","-1","1853","<p>There is an internal API, REST client over DB,  all of which methods require User ID as parameter. 
User ID is an integer value - numeric PK in User table.</p>

<p>Also there is an public API, that is like a Auth+Proxy Gateway: it checks the JWT token, extract User ID and then redirect to internal API.
So right now  User ID is passed as part of JWT token, so everyone can extract/know it value - the problem that I want to solve.</p>

<p>The thirst what I thought was to change public API to work with an External User ID (GUID for example): 
- add additional mapping table to have mapping between external and internal ID;
- external API  takes external ID from JWT, makes query to retrieve corresponding  internal user ID
- call internal API using internal user ID</p>

<p>What I do not like in this approach is an additional query to DB with each request. Using caching can reduce number of queries, butâ€¦</p>

<p>Another option, that I see, is to use JWE token instead of JWT. At least one disadvantage of this approach is the encryption/decryption expenses.</p>
","225156","","225156","","2016-07-09 17:23:21","2018-05-25 04:07:51","External User ID to Internal User ID","<security><api><microservices>","2","3","","","","CC BY-SA 3.0"
"92119","1","","","2011-07-12 06:25:29","","0","532","<p>I have a popular web-based app, and now suddenly my main developer has disappeared. Although I've found other great developers but I don't want to distribute the source code to everyone. Is there any way I can have them work on it while keeping the source code safe? </p>

<p>Thanks</p>
","74304","Nimbuz","","","","2011-07-12 17:33:07","Hiring Developers - Securing Source Code","<web-development><security><source-code>","5","8","","2014-12-04 13:19:48","","CC BY-SA 3.0"
"92199","1","","","2011-07-12 12:12:49","","13","1228","<p>I'm thinking about limiting the rights of users who choose insecure passwords (insecurity of a password being determined by length, how many types of characters (upper/lower case, numbers, symbols, etc.) are used, and whether it can be located in a rainbow table) to limit how much damage their account can do if compromised.</p>

<p>I don't have an application for this idea yet, but say I'm writing a forum or something: Users who use 1234 as a password might have to fill out a captcha before posting, or be subject to rigorous anti-spam measures such as timeouts or Bayesian filters rejecting their content. If this forum is very hierarchical, allowing for ""promotion"" to moderators or whatever by some means, this would either stop them from gaining privileges at all or telling them they have privileges, but not letting them exercise them without a change to a more secure password.</p>

<p>Of course this couldn't be the only measure of security, but it might go well next to otherwise good security practices.</p>

<p>What do you think? Is this just overdoing it, stealing focus away from more important security practices, or is it a good way to limit risk and encourage users to use safer passwords (and hopefully convince people you are using good security practices)?</p>
","54","","","","","2011-07-12 16:24:38","Punishing users for insecure passwords","<security><passwords><authorization><risk><permissions>","8","13","","2013-04-17 14:22:57","","CC BY-SA 3.0"
"92444","1","92447","","2011-07-12 22:46:23","","5","790","<p>I just read an article on MSDN about reasons for declaring classes as <code>sealed</code>. In the last paragraph, Eric Lippert says:</p>

<blockquote>
  <p>4) Secure. the whole point of polymorphism is that you can pass around
  objects that look like Animals but are in fact Giraffes.  <strong>There are
  potential security issues here</strong>.</p>
</blockquote>

<p>I tried to look on the Google about this topic, but I didn't manage to find anything other that OOP tutorials, so if anybody could point me in the right direction where to look, or even say a few words on this topic, it would be great.</p>

<p>Thanks.</p>
","23221","","","","","2022-07-16 17:27:04","Polymorphism and the potential security issues","<object-oriented><security>","2","0","","","","CC BY-SA 3.0"
"204313","1","204321","","2013-07-10 12:59:15","","1","213","<p>I want to build a website that will contain a lot of images. I don't want users who visit the website to be able to save the images.  </p>

<p>I have blocked the right click option, but is there any other way to keep users from saving the images?</p>
","95996","","","user53019","2013-07-10 14:26:09","2013-07-10 14:26:09","Protect Images in a Webpage","<web-development><javascript><web-applications><security>","3","4","","","","CC BY-SA 3.0"
"204320","1","204326","","2013-07-10 13:29:09","","0","1566","<p>Here's the scenario...</p>

<p>I have a web site that has a generic handler written in asp.net (.ashx file) that accepts http requests, gets relevant data, converts the result into xml and then passes that back via the response.</p>

<p>This will eventually be used so that a windows application can make data requests to this web site.</p>

<p>My concern is that anyone who knows how to put together the request can then access potentially personal data.  The data isn't anything as sensitive as financial information, but it will have names and addresses so I obviously need to think about securing it.</p>

<p>My initial thought was to encrypt the information before responding, and maybe even encrypt the request as well, and I'm happy to do this, but I just wanted to ask some other boffins for their opinion on the matter.</p>

<p>Is this something that has a ""standard"" way of doing it, or is it simply a case of thinking of something suitable and implementing it.</p>

<p>Incidentally, the windows app will be distributed all over the country so the requests will come from many places.  Using the IP address is not only a laborious way of doing it, but it also doesn't help as you could obviously send the message from an IP without using the application.</p>

<p>TL;DR</p>

<p>How do I make sure that it was my windows app that asked my web app for information?</p>
","96258","","","user53019","2013-07-10 13:50:01","2013-07-10 17:01:58","How can I secure a request handler so I only respond to the correct clients?","<web-development><security>","3","0","","","","CC BY-SA 3.0"
"204576","1","204579","","2013-07-12 03:48:41","","1","1224","<p>I am working on a tool (Python, may or may not be important) that will allow a user to maintain a configuration file containing arbitrary shell and/or language code to be executed on particular events and intervals. The code will potentially involve multiple statements.</p>

<p>I understand there are potential behavioral and security risks associated with executing arbitrary code from a file, but I don't think this is a concern because the configuration file is managed only by the end user. However, let me know if I'm overlooking something major.</p>

<p>My main question: what is the best way to store this code in a configurable way?</p>

<hr>

<p>Some concepts I'm considering to store the code...</p>

<p>In a shared config file (which many Python libraries already look for):</p>

<pre><code># setup.cfg
[my_program]
command_1 = cd /tmp &amp;&amp; touch foobar
</code></pre>

<p>In a YAML file:</p>

<pre><code># my_program.yaml
command_1: cd /tmp &amp;&amp; touch foobar
</code></pre>

<p>In a source file as arguments to <code>subprocess.call()</code>:</p>

<pre><code># settings.py
command_1 = [['cd', '/tmp'], ['touch', 'foobar']] # requires special handling of 'cd'
</code></pre>

<p>In a source file as a function:</p>

<pre><code># settings.py
import os
import subprocess
def command_1():
    os.chdir('/tmp')
    subprocess.call(['touch', 'foobar'])
</code></pre>
","96319","","96319","","2013-07-15 00:56:30","2013-07-15 00:56:30","What is the best way to store configurations of shell/script code to execute later?","<python><security><configuration><shell><permissions>","3","5","","","","CC BY-SA 3.0"
"204605","1","204608","","2013-07-12 12:00:43","","3","7069","<h2>Background</h2>

<p>One of the advantages of decoupled components in systems is that you can extend the system without having to touch the existing code.</p>

<p>Sometimes you don't even have to recompile the old code because you can dynamically load classes from disk like this:</p>

<pre><code>clazz = Demo.class.getClassLoader().loadClass(""full.package.name.to.SomeClass"");
</code></pre>

<p>That allows for a kind of plug-in architecture of sorts (give or take).</p>

<h2>Question</h2>

<p>How do you prevent malicious code from running when dynamically loading a class from disk using <code>ClassLoader</code> ?</p>
","61852","","61852","","2013-07-12 13:57:00","2013-07-12 19:51:33","Avoid malicious code while dynamically loading classes with ClassLoader","<java><security><class><malicious-code><plugin-architecture>","3","2","","","","CC BY-SA 3.0"
"92847","1","92855","","2011-07-14 13:38:18","","6","1890","<p>A recent previous question of mine had an answer that sparked a different and unrelated question in my mind:</p>

<p><a href=""https://softwareengineering.stackexchange.com/questions/92581/customer-wants-to-modify-the-properties-files-packaged-in-our-war-file/92584#92584"">Customer wants to modify the .properties files packaged in our WAR file</a></p>

<p>The question that I thought of after reading this answer is, just how low-risk is the data being collected on people (non-users, lets just say, ""people"") in my application?</p>

<ul>
<li>A first name and last name</li>
<li>Company or organization that person currently is employed at.</li>
<li>(Optional) An email address</li>
<li>(Optional) A persons phone number</li>
<li>A photograph of the persons face</li>
<li>An digitally signed PDF document physically signed with electronic signature pad (a persons hand written signature)</li>
</ul>

<p>No other sensitive data like social security numbers, credit card numbers or anything that can accurately identify a person with 100% accuracy.  How sensitive would you rate the data types listed above?  Is identity theft even remotely possible with the above information?</p>

<p>In light of all the recent news outbreaks of hacking successes and data breaches, if such a thing were to happen to my application (assume that I have reasonable security measures, SSL, encrypted passwords with salt, account lock after so many failed attempts, etc...), what kind of a response would be appropriate for my organization in your opinion?  Should every attempt be made to notify the persons that this information has been compromised?  Is it worth it?</p>

<p>Thanks for sharing your thoughts.</p>
","25476","","-1","","2017-04-12 07:31:34","2011-07-20 06:27:35","What would you define as sensitive user data?","<security>","6","2","0","","","CC BY-SA 3.0"
"324976","1","","","2016-07-15 23:32:55","","7","244","<p>As a comment on a response to <a href=""https://stackoverflow.com/questions/10054318/how-to-provide-username-and-password-when-run-git-clone-gitremote-git"">this question</a>, someone says:</p>

<blockquote>
  <p>It is not advisable to put the password in the URL for this file is saved on the .git/config . Is not safe, it is better to use ssh key</p>
</blockquote>

<p>Why?  Understanding the password will be visible if I type <code>git remote -v</code>, that it'll show up in my bash history, and that anyone with access to my machine would easily be able to get the password, why is it ""better"" to use SSH keys?  SSH keys are no more secure assuming that someone has access to my machine -- the SSH keys are still stored on disk locally.</p>
","73217","","-1","","2017-05-23 12:40:22","2016-10-28 20:43:32","Why is it more unsafe to store your password in the URL of a git repo?","<git><security><passwords>","1","0","","","","CC BY-SA 3.0"
"325095","1","","","2016-07-18 05:56:59","","0","454","<p>I have a MCU-based design that essentially controls other hardware and this MCU is controlled through an app. I was hoping someone could help me figure out how to secure this communication between the app and MCU. I've tried something like SipHash which essentially appends a hash of the message with a plain text message and this is particularly useful against man-in-the-middle attacks. The other method I tried is encrypting the command packets between the two using AES. However both these methods require storing a secret key on the app and the device. Assuming this goes into production, there will be multiple devices and app downloads. It would be quite insecure to have the same key on all the MCU devices. Is there a way to get a random key on the device and then somehow have the app get this key?</p>
","237567","","","","","2016-07-18 06:41:34","Secure communication between a mobile app and a microcontroller","<security><communication><hashing><encryption>","1","3","","","","CC BY-SA 3.0"
"204929","1","","","2013-07-15 16:36:05","","5","1658","<p>I am working on a set of REST APIs that needs to be secured so that only authenticated calls will be performed. There will be multiple web apps to service these APIs. Is there a best-practice approach as to where the authentication should occur?</p>

<p>I have thought of two possible places.</p>

<ol>
<li><p>Have each web app perform the authentication by using a shared authentication service. This seems to be in line with tools like Spring Security, which is configured at the web app level.</p></li>
<li><p>Protect each web app with a ""gateway"" for security. In this approach, the web app never receives unauthenticated calls. This seems to be the approach of Apache HTTP Server Authentication. With this approach, would you use Apache or nginx to protect it, or something else in between Apache/nginx and your web app?</p></li>
</ol>

<p>For additional reference, the authentication is similar to services like AWS that have a non-secret identifier combined with a shared secret key. I am also considering using HMAC. Also, we are writing the web services in Java using Spring.</p>

<p><strong>Update:</strong> To clarify, each request needs to be authenticated with the identifier and secret key. This is similar to how AWS REST requests work.</p>
","84894","","84894","","2013-07-16 14:53:33","2014-06-11 08:12:49","Where to Perform Authentication in REST API Server?","<architecture><security><rest><server-security>","2","2","","","","CC BY-SA 3.0"
"205038","1","","","2013-07-16 12:21:06","","7","23970","<p>I have some experience in building PHP based websites with MySQL access, storing encrypted user details, but all other fields being plain text. My most recent project will require sensitive data to be stored in the database. All of which I'm hosting myself.</p>

<p>I want to set up a system where a user can access his own entries and see the plain text results, but even if he was able to access someone else's they would be encrypted, unintelligible strings.</p>

<p>I have an idea of how to accomplish this, but perhaps it's not optimal or there exist tools to do this already in a more efficient way.</p>

<ol>
<li>Store username as plain text, and password encrypted with sha1(). Or both encrypted with sha1().</li>
<li>Take the user's password (not the encrypted one, but the one he typed in and use it do define a key specific to that username and password, which will then be stored as a session variable.</li>
<li>Encrypt, or decrypt all of that users data with that key.</li>
</ol>

<p>In my opinion even if someone gained access to the database and saw a list of plain text usernames and encrypted passwords they couldn't figure out the specific key since it's not stored anywhere. Therefore even if access was gained, they couldn't decipher the content of the sensitive database fields. Of course I'm building in ways to stop them accessing the database anyway, but as a catch-all effort this seems like a good set of steps. </p>

<p>Could the experts please comment on this, and offer some advice? Thanks a lot.</p>
","96813","","95456","","2013-07-16 12:56:22","2014-01-30 18:59:45","Building a web app with encrypted MySQL database entries?","<php><database><security><web><encryption>","5","4","","","","CC BY-SA 3.0"
"1969","1","2075","","2010-09-09 17:31:42","","3","749","<p>I'm posting this here since programmers write viruses, and AV software.  They also have the best knowledge of heuristics and how AV systems work (cloaking etc).</p>

<p>The EICAR test file was used to functionally test an antivirus system.  As it stands today almost every AV system will flag EICAR as being a ""test"" virus.  For more information on this historic test virus please click <a href=""http://www.eicar.org/anti_virus_test_file.htm"" rel=""nofollow"">here</a>.</p>

<p>Currently the <a href=""http://www.eicar.org/anti_virus_test_file.htm"" rel=""nofollow"">EICAR</a> test file is only good for testing the <strong>presence</strong> of an AV solution, but it doesn't check for engine file or DAT file <strong>up-to-dateness</strong>. In other words, why do a functional test of a system that could have definition files that are more than 10 years old.  With the increase of zero day threats it doesn't make much sense to functionally test your system using EICAR.</p>

<p>That being said, I think EICAR needs to be updated/modified to be effective test that works in conjunction with an AV management solution.
This question is about <strong>real world testing</strong>, without using live viruses... which is the intent of the original EICAR.</p>

<p>That being said I'm proposing a new EICAR file format with the appendage of an XML blob that will conditionally cause the Antivirus engine to respond.</p>

<pre><code>X5O!P%@AP[4\PZX54(P^)7CC)7}$EICAR-EXTENDED-ANTIVIRUS-TEST-FILE!$H+H*
&lt;?xml version=""1.0""?&gt;
&lt;engine-valid-from&gt;2010-1-1Z&lt;/engine-valid-from&gt;
&lt;signature-valid-from&gt;2010-1-1Z&lt;/signature-valid-from&gt;
&lt;authkey&gt;MyTestKeyHere&lt;/authkey&gt; 
</code></pre>

<p>In this sample, the antivirus engine would only alert on the EICAR file if both the signature  or engine file is equal to or newer than the valid-from date. Also there is a passcode that will protect the usage of EICAR to the system administrator.</p>

<p>If you have a backgound in ""Test Driven Design"" TDD for software you may get that all I'm doing is applying the principals of TDD to my infrastructure.  </p>

<p>Based on your experience and contacts how can I make this idea happen?</p>
","175","","25936","","2015-05-07 17:22:43","2015-05-07 17:22:43","Should EICAR be updated to test the revision of Antivirus system?","<testing><security><tdd>","2","1","","","","CC BY-SA 2.5"
"205130","1","","","2013-07-17 05:19:40","","2","1364","<p>One of the fundamental ways of handling user login authentication &amp; session management is by storing variables in Session space plus setting some data in cookies on client computer while sometimes in database as well.</p>

<p>I have been using this simpler technique in many of my academic as well as a few online projects. But I am a little unsure about it.</p>

<p>Do security critical websites like Amazon, Gmail or Facebook use the very same technique for user login &amp; session management or is there more to it than I have known?</p>

<p>This could turn out to be a very general question but I'd really like to know if there are other or mix of multiple ways used (like at gmail, stackexchange or myspace) for handling user login authentication &amp; session management in particular.</p>
","20106","","","","","2013-07-17 10:07:44","User Authentication & Session Management","<security><authentication><login><session>","1","2","","","","CC BY-SA 3.0"
"205359","1","205362","","2013-07-19 00:26:13","","13","21604","<p>We are working on a new project, we are two lead developers and got on a crossroad on how to use a token to secure the communication between the server and the client.</p>

<h1>First Suggestion: (The one time token AKA Static Token)</h1>

<ol>
<li><p>the client requests a primary token, by sending the username and password and the current_time (this variable will be saved in the server's database and the client side too) to the api, the server interprets the input, and renders a hashed token (e.g. : 58f52c075aca5d3e07869598c4d66648) saves it in the database and returns it to the client.</p></li>
<li><p>The client now saves the primary token, and creates new hashed token using the primary token + the current_time variable sent in the authentication request (lets call this new token, main_token) also the server does the same and create the same token using the same algorithm.</p></li>
<li><p>Each time the client queries the server API, it sends the main_token to the server, now the server compares the token generated in it, with the main_token sent by the client, if it matches, it means the user is real</p></li>
</ol>

<h1>Second Suggestion: (Dynamic Token)</h1>

<ol>
<li><p>The client generates two random keys ($key1 = rand(10000,90000); $key2 = rand(10000,90000);) On each request on the API, the client creates a hash using the query type, and the two keys with a complex algorithm, and sends these two keys + the hash to the server</p></li>
<li><p>The server, using the same Algorithm used in the client, creates a hash, and compares is to the one sent by the client, if it matches, the server proceeds to deal with the query</p></li>
</ol>

<hr>

<p>Now, the question is, Which one is the most logical, and secure way to use for securing the API requests?</p>
","25771","","190130","","2016-02-08 14:12:36","2016-02-08 14:12:36","API Authentication, One time token VS Dynamic tokens","<security><api>","1","2","","","","CC BY-SA 3.0"
"325806","1","325821","","2016-07-26 15:24:00","","134","20124","<p>I want to expose a resource on the web. I want to protect this resource: to make sure it is only accessible to certain individuals.</p>

<p>I could set up some kind of <strong>password-based authentication</strong>. For example, I could only allow access to the resource through a web server that checks incoming requests for correct credentials (perhaps against some backing database of users) before serving up the file.</p>

<p>Alternately I could just use a <strong>private URL</strong>. That is, I could simply host the resource at some impossible-to-guess path, for example <code>https://example.com/23idcojj20ijf...</code>, which restricts access to those who know the exact string.</p>

<p>From the perspective of an evildoer who wants to access this resource, are these approaches equivalent? If not, what makes them different? And as far as maintainability, are there pros and cons to either approach that I should be aware of before implementing one or the other?</p>
","92609","","34181","","2016-07-28 13:40:13","2016-07-31 01:11:45","Are private, unguessable URLs equivalent to password-based authentication?","<security><authentication>","7","13","","","","CC BY-SA 3.0"
"3033","1","","","2010-09-12 12:04:12","","7","313","<p><strong>When writing software for yourself, your company or third parties, do you always consider certain principles, values, standards, or rules of behavior that guide the decisions, procedures and systems in a way that contributes to the welfare of its key stakeholders, and respects the rights of all constituents affected by its operations?</strong> </p>

<p>And can this code of conduct sometimes be overruled by business requirements, lack of technical skills or other friction during the development process? </p>

<p>Some random examples in order of severity. (yes that is controversial) :</p>

<ul>
<li>Do you accept known bugs as a risk for the end-user?</li>
<li>When writing applications, do you always give the end user the chance for a complete de-install?</li>
<li>Do you always secure and encrypt private data delivered end-users in your web application?</li>
<li>Do you alwask ask the end-user before submitting his entered data to the server?</li>
<li>Did you ever wrote an application that sends unwanted e-mails?</li>
<li>Did you ever work on harvesting or scraping projects only for the benefit of the business?</li>
<li>Did you ever write software that is legal but moraly controversial, like  for weapons industry.</li>
<li>Did you ever wrote software that ( can intentionally) or is be used for criminal activities</li>
</ul>

<p>It would be nice if you can get a good case with explanation on your moral and ethical decisions. </p>

<p>note: <em>Since ethics and law are quite local and cultural dependent, it would be interesting if you add the location of the ""crime scene"" with it</em>.</p>
","545","","545","","2010-09-12 18:06:58","2017-10-26 22:27:45","Do you apply a code of conduct on accepting jobs, projects or requirements?","<business><ethics><security>","2","1","","","","CC BY-SA 2.5"
"325929","1","326437","","2016-07-27 15:23:56","","6","2914","<p>I have a few services that sign some data with an asymmetric cryptography algorithm (like RSA).
I need to spread some secret (private) keys between all instances of the service.</p>

<p>I've found a few ways to do that:</p>

<ul>
<li>Share keys as configuration (looks insecure when I need to spread <em>private</em> keys)</li>
<li>Embed keys into apps/images when it's build (what if I need different keys? Would it complicate build automation?)</li>
<li>Use some special key management service (what service?)</li>
</ul>

<p>Is there a right way (or devops-way) to spread secret keys between microservices without compromises in security or automation?</p>
","230570","","61852","","2016-08-09 20:12:17","2016-08-09 20:12:17","Right way to spread secret keys between microservices","<security><microservices><configuration-management><keys><devops>","2","3","","","","CC BY-SA 3.0"
"205679","1","205703","","2013-07-22 15:57:19","","6","6011","<p>ASN.1 is a data format used on HTTPS certificates, and various other critical pieces of infrastructure.</p>

<p>I need to analyze some <a href=""https://security.stackexchange.com/q/16713/396"">potentially hostile ASN.1 data</a>, and want to ensure my code is safe from any programmer error.  I think the best way to do this is to use a managed language that does not use unsafe code.</p>

<p>Are there any managed implementations (C#) of an ASN.1 parser that is well tested and safe from buffer overflows.  Even better if there was a way to detect such an overflow to begin with.</p>
","175","","-1","","2017-03-17 13:14:46","2013-07-22 18:55:59","Any ASN.1 parsers written completely in managed code & safe from buffer overflows","<c#><security><parsing><asn.1>","1","4","","","","CC BY-SA 3.0"
"205700","1","205701","","2013-07-22 17:52:00","","28","1106","<p>I have been assigned to develop an integration to one of my employer's applications to an external system developed by our client. Our client's specification for the integration that has some blatant flaws related to security. The flaws would allow an unauthorized user access to the system to view restricted data.</p>

<p>I have pointed out the flaws and their potential security risks if they are implemented as designed, and provided an alternative without the flaw, but (in short) have been told ""do it the way we specified"" by the client.</p>

<p>Does a programmer have an ethical responsibility NOT to implement code with known security risks? At what point do a client's requirements outweigh the ethical responsibility we have as software developers to create secure applications?</p>
","34585","","34585","","2013-07-22 18:05:04","2013-07-22 18:05:04","If the spec is flawed, should it still be followed?","<architecture><security><ethics><specifications>","1","7","","","","CC BY-SA 3.0"
"326024","1","326027","","2016-07-28 14:08:43","","2","879","<p>I recently had engaged in a security discussion with my companies cyber security risk lead, discussing security controls and standards they would be holding the project to.  The expectation of the Risk Lead was that these controls would trace back to architecturally driven Non-Functional Requirements defined for the project.  It would be my responsibility for defining these Non-Functional Requirements for the development team to accomplish in Design or in Sprint.</p>

<p>This made sense for many of the controls defined, however some of the controls are less about qualities and properties of the system and more about expectations and requirements of the SDLC process itself.  Eg. Production data should be masked and anonymized before cycling to a Test or QA system.</p>

<p>I argued on the call that it doesn't make sense for a Non-Functional requirement to define anything but a quality attribute of the System, and that the Software Development Lifecycle process is not a component of the system but of the project team.</p>

<p>Their reaction was that I have no idea what I am talking about and that I should do more research about Non-Functional Requirements.</p>

<p>Their conviction led me to question if I really understand Non-Functional Requirements correctly?  The literature I read never mentions the scope of quality attributes extending to SDLC processes like cycling production data to a test system.  I am not saying that capturing such requirements of the SDLC process is NOT important, I was just arguing that these are not Non-Functional Requirements.  Am I wrong?</p>
","25476","","","","","2016-07-28 14:20:56","Do Non-Functional Requirements for Security make sense for defining SDLC?","<architecture><security><non-functional>","1","0","","","","CC BY-SA 3.0"
"94554","1","","","2011-07-20 15:16:35","","1","147","<p>When creating a webservice/api that is intended to be used by javascript/flash/mobile clients, what is a good method for making sure that a paying client's credentials are not stolen and reused. </p>

<p>To clarify further, lets say I want to charge $1 for every 10,000 requests against my API. If someone wants to farm my data for free, they would just need to find another client app that already uses my API and construct requests using the credentials of the paying customer.</p>

<p>I don't see any way that I can ""hide"" what is going on the client, someone will always be able to easily reverse engineer the ""auth"" scheme. So what are good ways to mitigate abuse?  </p>

<p>EDIT</p>

<p>More in depth example of the scenario...</p>

<p>Lets say my data service is bus schedules. The purpose of the services is for developers to write apps consuming the data. There's nothing personal about the data, it is the same for everyone. The intention is for the developer to write javascript/flash/mobile apps <strong>directly against</strong> the api (I'm aware of cross domain restrictions). But the developer has to pay when users of his app make requests against the bus schedule api. How do I keep another developer going to the original developer's site and just lifting the credentials that are used by his browser to talk to the bus schedule api, and writing his own app using those credentials?</p>
","1954","","1954","","2011-07-20 16:12:02","2011-07-20 16:12:02","Strategy for securing paid Data as a Service API","<security><web-services><software-as-a-service>","1","0","","","","CC BY-SA 3.0"
"94560","1","94562","","2011-07-20 15:50:35","","1","1663","<p>I'm running Coldfusion 8 and SQL server 2008. </p>

<p>I've been building serveral forms that insert data into the database from external users, we have a custom built security module built by the guy who I've  taken his job. </p>

<p>1) How can we test our HTML forms to ensure that we're protected from SQL injection attacks? </p>

<p>2) How do I secure CFqueries in CFC's? </p>

<p>3) What are some best practices in terms of SQL &amp; Coldfusion for security? </p>

<p>-- A lot I know! </p>
","29398","","61852","","2015-01-26 16:42:09","2015-01-26 16:42:09","SQL injection attacks, how do I test and secure coldfusion queries?","<security><sql><sql-injection><coldfusion>","2","1","","","","CC BY-SA 3.0"
"94772","1","","","2011-07-21 10:21:46","","13","950","<p>All I have seen on SQL injection attacks seems to suggest that parametrized queries, particularly ones in stored procedures, are the only way to protect against such attacks. While I was working (back in the Dark Ages) stored procedures were viewed as poor practice, mainly because they were seen as less maintainable; less testable; highly coupled; and locked a system into one vendor; (<a href=""https://softwareengineering.stackexchange.com/questions/65742/stored-procedures-a-bad-practice-at-one-of-worlds-largest-it-software-consulting/65748#65748"">this question</a> covers some other reasons).</p>

<p>Although when I was working, projects were virtually unaware of the possibility of such attacks; various rules were adopted to secure the database against corruption of various sorts. These rules can be summarised as:</p>

<ol>
<li>No client/application had direct access to the database tables.</li>
<li>All accesses to all tables were through views (and all the updates to the base tables were done through triggers).</li>
<li>All data items had a domain specified.</li>
<li>No data item was permitted to be nullable - this had implications that had the DBAs grinding their teeth on occasion; but was enforced.</li>
<li>Roles and permissions were set up appropriately - for instance, a restricted role to give only views the right to change the data.</li>
</ol>

<p><strong>So is a set of (enforced) rules such as this (though not necessarily this particular set) an appropriate alternative to parametrized queries in preventing SQL injection attacks? If not, why not? Can a database be secured against such attacks by database (only) specific measures?</strong></p>

<p><strong>EDIT</strong></p>

<p>Emphasis of the question changed slightly, in the light of the initial responses received. Base question unchanged.</p>

<p><strong>EDIT2</strong></p>

<p>The approach of relying on paramaterized queries seems to be only a peripheral step in 
defense against attacks on systems. It seems to me that more fundamental defenses are both desirable, and may render reliance on such queries not necessary, or less critical, even to defend specifically against injection attacks.</p>

<p>The approach implicit in my question was based on ""armouring"" the database and I had no idea whether it was a viable option. Further research has suggested that there are such approaches. I have found the following sources that provide some pointers to this type of approach:</p>

<p><a href=""http://database-programmer.blogspot.com"" rel=""nofollow noreferrer"">http://database-programmer.blogspot.com</a></p>

<p><a href=""http://thehelsinkideclaration.blogspot.com"" rel=""nofollow noreferrer"">http://thehelsinkideclaration.blogspot.com</a></p>

<p>The principle features I have taken from these sources is:</p>

<ol>
<li>An extensive data dictionary, combined with an extensive security data dictionary</li>
<li>Generation of triggers, queries and constraints from the data dictionary</li>
<li>Minimize Code and maximize data</li>
</ol>

<p>While the answers I have had so far are very useful and point out difficulties arising from disregarding paramaterized queries, ultimately they do not answer my original question(s) (now emphasised in bold). </p>
","31937","","-1","","2017-04-12 07:31:31","2013-06-26 14:38:48","Is reliance on parametrized queries the only way to protect against SQL injection?","<design><security><sql><sql-injection>","3","4","","","","CC BY-SA 3.0"
"326291","1","327536","","2016-08-01 12:39:05","","10","4178","<p>There are a lot of questions on here that deal with the mechanics of authentication and authorization of RESTful APIs but none of them appear to go in to details of how to implement secure services at the application level. </p>

<p>For example let's say that my webapp (I've got Java in mind but this applies to any backend really) has a secure authentication system that allows users of the API to login with a username and password. When the user makes a request, at any point during the request processing pipeline I can call a <code>getAuthenticatedUser()</code> method which will return either the null user if the user isn't logged in, or a User domain object that represents the logged in user. </p>

<p>The API allows authenticated users to access their data e.g. a GET to <code>/api/orders/</code> will return that user's list of orders. Similarly, a GET to <code>/api/tasks/{task_id}</code> will return data relating to that specific task.</p>

<p>Let's assume that there are a number of different domain objects that can be associated with a user's account (orders and tasks are two examples, we could also have customers, invoices etc.). We only want authenticated users to be able to access data about their own objects so when a user makes a call to <code>/api/invoices/{invoice_id}</code> we need to check that the user is authorized to access that resource before we serve it up. </p>

<p>My question is then, do patterns or strategies exist to deal with this authorization problem? One option I'm considering is creating a helper interface (i.e. <code>SecurityUtils.isUserAuthorized(user, object)</code>), which can be called during request processing to ensure that the user is authorized to fetch the object. This isn't ideal as it pollutes the application endpoint code with lots of these calls e.g.</p>

<pre><code>Object someEndpoint(int objectId) {
    if (!SecurityUtils.isUserAuthorized(loggedInUser, objectDAO.get(objectId)) {
        throw new UnauthorizedException();
    }
    ...
}
</code></pre>

<p>...and then there's the question of implementing this method for every domain type which could be a bit of a pain. This might be the only option but I'd be interested to hear your suggestions!</p>
","211229","","211229","","2016-08-01 12:57:54","2016-08-15 15:11:47","REST API authorization strategies","<java><rest><security><backend>","3","1","","","","CC BY-SA 3.0"
"206125","1","","","2013-07-26 08:50:56","","1","105","<p>I was going through the answers to this question:</p>

<p><a href=""https://softwareengineering.stackexchange.com/questions/54008/what-information-must-never-appear-in-logs"">What information must never appear in logs?</a></p>

<p>And noticed that nobody mentioned this particular attribute. It's something I find useful- whenever any logging is added to the system as a result of tracing a particular issue raised in the bug tracker, or adding a feature, <strong><em>I tend to include the ticket number of the related helpdesk element.</em></strong></p>

<p>This means that when going through the log, any programmer can cross reference each log message with the associated ticket number. Now I understand that using proper VCS/helpdesk integration means most commits are attached to a ticket number anyway- but over time it makes it easy for us to diagnose problems on inspection whenever a log message comes up. </p>

<p>However it still makes me a bit uneasy leaving this in the logs. The problem is, I can't think of a scenario where this could become a problem. I'm hoping SE can help me out.</p>

<p>By the way- I'm talking about the ""verbose"" log level. This is never done in a logging level that will appear in production. </p>
","97776","","-1","","2017-04-12 07:31:33","2013-07-26 09:55:43","Is there any reason not to include issue numbers in debug logs?","<security><coding-standards><logging>","1","0","","","","CC BY-SA 3.0"
"206224","1","","","2013-07-27 05:00:35","","1","72","<p>Up until now it seems that when you register on a random web site you do so with blind trust. </p>

<p>You assume that the site isn't harvesting information and passwords. You assume the site is reasonably secure. And you also assume that the information you've submitted isn't used in an undesireable way.</p>

<p>More recently, it's become possible to connect up to a site with a Google+ or Facebook account. But that brings along another problem. Anyone that has access to the social account can access anything that's linked to it.</p>

<p>So, has any thought gone into making something that's truly independant ? Something like an information locker a person could set up themselves. Do any relevant projects exist ?</p>
","3170","","","","","2013-08-11 13:27:34","Information protection when registering on web sites","<security><ethics><passwords><privacy>","1","1","","","","CC BY-SA 3.0"
"206303","1","206305","","2013-07-28 11:24:26","","4","376","<p>These days password hashing algorithms are designed to be slow. While it prevents black hats from guessing the password (at least partially), it also gives additional work for the server.</p>

<p>I can imagine that, if someone wanted to make server run extremely slowly, they could simply send many log-in requests which would lead to many password hash calculations therefore dramatically increasing CPU usage.</p>

<p>What is the common practice for preventing such attacks? And how is it called?</p>
","53462","","53462","","2013-07-28 11:41:57","2013-07-28 13:24:01","Preventing password hashing algorithm from overloading CPU","<security><server><hashing>","4","0","","","","CC BY-SA 3.0"
"206558","1","206564","","2013-07-30 16:11:09","","121","13241","<p>I know some people that are currently working on a project for the US military (low security level, non-combat human resources type data).</p>

<p>An initial state of the project code was submitted to the military for review, and they ran the program through some sort of security analyzer tool. It returned a report of known security issues in the code and required changes that needed to be implemented before delivery of the final product.</p>

<p>One of the items that needed to be resolved was removal of part of the project that was written in <a href=""http://en.wikipedia.org/wiki/Ruby_%28programming_language%29"">Ruby</a> as it is a dynamic language.</p>

<p>What is the background/reason for not allowing a dynamic language to be used in a secure setting? Is this the government being slow to adopt new technologies? Or do dynamic languages pose an additional security risk compared to static languages (ala <a href=""https://en.wikipedia.org/wiki/C++"">C++</a> or <a href=""http://en.wikipedia.org/wiki/Java_%28programming_language%29"">Java</a>)?</p>
","9479","","591","","2013-07-31 22:37:48","2016-03-04 18:27:05","Why does the US government disallow dynamic languages for secure projects?","<code-security><dynamic-languages><government>","8","17","","","","CC BY-SA 3.0"
"206606","1","373619","","2013-07-31 03:24:38","","5","1238","<p>So I am creating a web api for an app I am making. The data is sanitized before it is sent to my web api and then encrypted before it is stored in my MySql server. </p>

<p>The phone app sanitizes then behind the scenes calls -> web php api which encrypts aes style with a hard coded salt then calls -> server</p>

<p>My question is if I hard code a salt value into the php page is it at risk on a go daddy server? </p>

<p>I mean I know NOTHING is truly secure however what are the odds that someone would be able to hack a go daddy server and see my php source code. Assuming they disassemble my app and see the URL call to the api.</p>

<p>Since php code executes on the server I am assuming that there is no way to extract it?</p>
","98141","","","","","2018-07-05 16:59:03","Is a PHP file secure enough on a GoDaddy Server to hard code an AES salt into the file?","<php><security><web-services><api-design><encryption>","2","2","","","","CC BY-SA 3.0"
"327805","1","","","2016-08-07 22:16:56","","3","8171","<p>Here's the scenario I'm trying to solve:</p>

<p>In my application, users provide files to other users.</p>

<p>I want to provide a way of verifying that files have not been tampered with.</p>

<p>I wonder if this means some sort of third party, independent online data store of file signatures can be referenced to ensure all is OK.</p>

<p>I don't know much about this, what's a good way to do it?</p>
","89453","","61852","","2016-08-07 23:14:48","2018-06-29 16:47:46","How to verify that a file has not been tampered with?","<security>","6","3","","","","CC BY-SA 3.0"
"95567","1","","","2011-07-24 19:45:24","","1","375","<p>I have designed my first website recently. I created my own blog like thing in PHP. I write articles and below the articles there is a place to add comments.</p>

<p>Sometimes I get random comments something like 'sd$^&amp;(87&amp;(*2d10hsdasko' with no meaning. There are hundreds of them. I think some silly person with lots of time must be playing with my website for fun. I am thinking of finding his IP address and blocking it.</p>

<p>Has someone faced such a problem? How do you prevent people from playing with your website?</p>
","32272","","31260","","2015-05-03 19:47:51","2015-05-03 19:47:51","How to prevent people from playing with your website?","<security><websites>","2","6","","2015-05-04 11:45:01","","CC BY-SA 3.0"
"206859","1","206868","","2013-08-01 20:31:15","","3","2049","<p>I'm getting pushback from operations for having a server process listen on a dynamically-assigned port number (i.e. it binds a socket to a port number of 0, triggering a dynamic assignment by the OS, which it retrieves using getsocketname()).  The argument was that is ""creates all kinds of issues for firewalling, routing, ACL, and security purposes"".  I haven't run across anything about this.  </p>

<p>This is CentOS, our applications are in-house and restricted to a set of machines on a LAN that's heavily firewalled from the outer world.</p>

<p>Can someone knowledgeable weigh in on the subject?</p>

<p><strong>UPDATE 1</strong>: FTP dynamically assigns a port number, too, although I don't know if it's from the same range of numbers that I've seen elsewhere (32768-61000?).  How do firewalls etc. deal with this?</p>
","30470","","30470","","2013-08-01 21:24:32","2023-10-07 00:03:26","Are there security implications to using dynamically-assigned TCP port numbers?","<security><sockets><dynamic>","2","5","","","","CC BY-SA 3.0"
"7008","1","7018","","2010-09-24 11:57:04","","4","358","<p>What different types of security do there exist? Why and when should they be implemented?</p>

<p>Example: SQL Injection Prevention</p>
","666","","666","","2010-09-24 12:14:59","2013-07-23 06:10:03","What security practices should you be aware of when writing software?","<comparison><security>","4","1","0","2013-07-23 11:12:02","","CC BY-SA 2.5"
"328689","1","328704","","2016-08-18 11:26:26","","3","2664","<p>We are currently working on a micro-service based system. The idea behind it is to split our monolithic system to small domains (micro-service per domain).</p>

<p>All services will be used by our internal applications, but we have plans to expose it to public.</p>

<p>One of the services would be identity management service, which would be responsible for issuing and validating tokens.</p>

<p>For shared references, we are using SharedKernel. One of libraries in shared kernel is a custom <code>AuthorizationAttribute</code>, which will be used by all micro-services. Basically what the attribute does, is forwarding Bearer token to authorization service, and authorization service responds with information such as token validity, user information and a set off allowed endpoints/resources for the given token.</p>

<p>If the current endpoint is not listed, 401 HTTP response is returned.</p>

<p>Now, I have 2 concerns:</p>

<ol>
<li>Are we on the right track and is this a valid approach? If not, what can be done to improve it?</li>
<li>We are still having problems with UserTypes/Roles concept. We will probably have 3 types of users. Admins, Agents and End-Users and yet again, if some 3rd party company decides to use our API, roles which were created for our needs, might not be suitable for their needs.
The problem is that not all agents will have set of same permissions. For an example we might have an agent who is responsible for accounting and he would have access only to accounting related micro-services, but we might also have an agent who is responsible only for booking. Should this require us to set a UserType for each agent type, fe. AccountingAgent, BookingAgent etc, and assign multiple <code>UserTypes</code> to user, or there is a simpler approach to solve this? </li>
</ol>
","198708","","31260","","2016-08-18 11:42:37","2016-08-18 17:03:00","Microservices and authorization","<security><microservices><authorization>","2","2","","","","CC BY-SA 3.0"
"328784","1","329564","","2016-08-19 10:51:23","","17","9569","<p>We plan to refactor our company system into a micro-service based system. This micro-services will be used by our own internal company applications and by 3rd party partners if needed. One for booking, one for products etc.</p>

<p>We are unsure how to handle roles and scopes. The idea is to create 3 basic user roles such as Admins, Agents and End-Users and let the consumer apps to fine-tune scopes if needed.</p>

<ul>
<li><strong>Admins</strong> can create, update, read and delete all
resources by default (for their company). </li>
<li><strong>Agents</strong> can create, update and read data for their company. </li>
<li><strong>End-Users</strong> can create, update, delete and read data, but cannot access same endpoints as agents or admins. They will also be able to create or modify data, just not on a same level as agents or admins. For example, end users can update or read their account info, same as agent will be able to do it for them, but they can't see or update admin notes.</li>
</ul>

<p>Let's say that agents by default can create, read and update each resource for their company and that is their maximum scope which can be requested for their token/session, but developers of client (API consumer) application have decided that one of their agents can read and create only certain resources.</p>

<p>Is it a better practice to handle this in our internal security, and let them write that data in our database, or let clients handle that internally by requesting a token with lesser scope, and let them write which agent will have which scope in their database? This way we would have to track only token scopes.</p>

<p>The downside of this, is that our team would also need to create fine-tuned access mechanisms in our internal applications.</p>

<p>With this way of thinking, micro-services and their authorization system should not be bothered with clients needs, because they are only consumers and not part of the system (even though some of those consumers are our own internal apps)?</p>

<p>Is this delegation a good approach? </p>
","198708","","61852","","2016-08-29 03:20:17","2019-12-01 16:45:51","Authorization and authentication system for microservices and consumers","<security><authentication><microservices><authorization>","5","0","","","","CC BY-SA 3.0"
"329097","1","","","2016-08-23 08:57:12","","4","92","<p>I am developing an online medical website (similar to a HIS) whose users are hospitals specifically hospital administrators, doctors, and other staff authorized by the hospital to use the system. There are many hospitals that would use the website. </p>

<p>There is a feature in my website where the authorized user is able to type in certain symptoms for a patient, which has an autocomplete function, which comes from my symptoms_list table. I do not have a medical database to reference every illness and symptom in the autocomplete, so I decided to allow the user to bypass the autocomplete just in case the symptom they wanted was not present, and then add that new symptom as a record in the symptoms_list table. The newly added symptom would then show up in the autocomplete of all other users as well.</p>

<p>Is this a good idea though to actively let users add to the list of symptoms? If not, what is a better alternative?</p>
","243267","","61852","","2016-08-24 12:11:35","2016-08-24 13:40:12","Should authorized users be allowed to add autocomplete suggestions to the list of symptoms?","<security><users><data-integrity>","3","0","","","","CC BY-SA 3.0"
"8119","1","8122","","2010-09-29 05:26:15","","9","578","<p>In what circumstances should an IT Consultant encrypt their hard drive to protect their code/data of their clients?</p>

<p>I am thinking that if it does not add much to your work load you might as well use full disc encryption with a 'weak' password to at least prevent someone from accessing your email files and other documents if your laptop is stolen, even if they will not get access to any database files or other very sensitive data. </p>
","1835","","","","","2012-02-14 15:16:46","When should an IT consultant use full disc encryption?","<security>","3","3","","","","CC BY-SA 2.5"
"97437","1","105500","","2011-07-31 20:08:15","","17","8833","<p>I'm a long time Java developer and finally, after majoring, I have time to study it decently in order to take the certification exam... One thing that has always bothered me is String being ""final"". I do understand it when a read about the security issues and related stuff... But, seriously, does anyone have a true example of that? </p>

<p>For instance, what would happen if String weren't final? Like it's not in Ruby. I haven't heard any complaints coming from the Ruby community... And I'm aware of the StringUtils and related classes that you have to either implement yourself or search over the web to just implement that behavior (4 lines of code) you're willing to.</p>
","32892","","","","","2015-06-17 13:29:52","What would truly happen if java.lang.String weren't final?","<java><security>","6","3","","","","CC BY-SA 3.0"
"208263","1","","","2013-08-14 14:55:03","","3","240","<p>Is there a ""scientific"" method to determine how much resources/money should be spent on improving the security of a piece of software?</p>

<p>I work in a team where our work is prioritized by a product owner (ala Scrum). The product owner is kind of sales driven and focuses on new functionality requested by customers and less on the infrastructure. I think I need a way to convince him that we need to spend more time on improving the security.</p>

<p>Of course I don't want to convince him by spreading fear and I'm not sure myself how much money we should spend on improving security. Of course, the security of our software is improved all the time but I suspect - without knowing for sure - that it would be sane to double the efforts in the area.</p>

<p>I have a weak memory reading about this, where something like the following was suggested:</p>

<ol>
<li>Think about a weak point in the security in the system</li>
<li>Estimate what a succesfull attack would cost in terms of lost/dis-satisifed customers (X)</li>
<li>Estimate how likely that it is that this would occur in a given year. (Y)</li>
<li>Calculate how much should be spend on fixing the weak points, based on X and Y. We don't have to solve the issue immediately, but we should spend Z percent on it.</li>
</ol>
","90440","","","","","2023-01-25 20:38:56","How much should we spend on improving software security?","<security><planning>","1","5","","","","CC BY-SA 3.0"
"208318","1","208320","","2013-08-15 03:17:37","","0","120","<p>I was thinking of creating some login code (probably to work with BrowserID so users don't need to store their passwords with my site while also ensuring the supplied email account belongs to them) which required any user accounts to be an email address in the "".name"" or possibly "".me"" TLD (or in any other TLD that was intended for individuals or individual corporate employees only--i.e., not open to public registration) and perhaps disallowing subdomains (as it might be tempting for some companies to purchase a generic domain and lease out the personalized subdomains); of course it wouldn't stop a company from leasing out names like user123@spam-friendly-site.name, but as the TLD is intended for individuals, it would hopefully be easier to blacklist any such bad behavior-enabling sites wholesale.</p>

<p>The purpose would be two-fold:</p>

<ol>
<li>Raise the threshold for spammers as they would have to either purchase a new domain any time they wanted a new spam account (and any abusing <em>domains</em> could be blacklisted and shared as a public list) or obtain control of a legitimate user's email account or browser/system.</li>
<li>Encourage people to throw off the yoke of dependency on fixed third parties for emails as well as website hosting, chatting, etc. by getting their own domains. One wouldn't want a phone number like 555-123-1234@att.com because one could not freely change providers. And there are no doubt many would-be content creators who would share more freely if they had a site belonging to them. If one wanted to be anonymous, one could reserve domains like anonymous567.name (e.g., me@anonymous567.name) -- and this would be fine with me as my purpose is not to positively ID people outside of the context of confirming they control the email address they give me but to raise barriers to spammers. It would add a small price to do content creation on the site as users would have to purchase a domain and configure email on it and would cost more so to become truly anonymous (e.g., to purchase separate domains for each site to avoid tracking between sites), but I think the burden should not lie on content websites to deal with spam registrations.</li>
</ol>

<p>If this really gets going, one might also be able to set up one's email filters to block anyone not belonging to such a personalized domain as well, giving an auto-reply of how to register for one.</p>

<p>Does anyone have feedback on the idea, specifically any unexpected barriers I might encounter (such as ways it could be circumvented)? I know of course that it will raise barriers for some users, but any potential technical challenges?</p>
","21948","","21948","","2013-08-15 04:09:33","2013-08-15 04:16:20","Possible holes in a spam-registration prevention approach?","<security>","1","3","","","","CC BY-SA 3.0"
"208319","1","","","2013-08-15 03:44:25","","0","727","<p>I have experience developing software and web applications and I have decided to do some freelance work on the side. Well, I met with my first client and they are requesting a relatively simple, custom system that (without being long winded) tracks clientâ€™s paperwork as it progresses through the businessâ€™s different manual processes.  </p>

<p>It is a small business that has about 10 employees, but all of the employees will interact with the clientâ€™s paperwork, therefore everyone would need access to the new system. When I say <strong>track</strong> I literally mean that the employees will <strong>check as complete</strong> on a simple page the increases a progress bar at different stages for the paperwork.  </p>

<p>Now I am %110 capable of coding the custom system that meets their needs, but I am unsure about how I should go about doing it.
The information that is being tracked in the new system and stored in the DB is confidential information that they are very protective of. My main question is how should I be developing this to be as secure as I can?</p>

<ul>
<li>They have their own server in house, so should I develop an application (VB and SQL) for the server and require employees to log on remotely to use it? Can more than one person access/use the application at a time?</li>
<li>Or should I develop a web application (ASP.Net/VB and SQL) that is only accessible on their network to their employees? They plan to expand offices, could they set up a VPN to access the site?</li>
</ul>

<p>Iâ€™m leaning towards a web application, but I have not done too much in term of security. What specific options do I have for security that aren't too complex.   </p>

<p>Basically Iâ€™m looking for pros and cons for either option or any suggestions on what I should.</p>
","99651","","35276","","2013-09-06 15:35:11","2013-09-06 15:35:11","VB stand alone application or ASP web application","<asp.net><security><web><applications><visual-basic>","3","0","","","","CC BY-SA 3.0"
"8758","1","8765","","2010-10-01 14:04:46","","22","34137","<p>Disclaimer: I by no means condone the use of pirated software.</p>

<p>Have you ever witnessed the use of pirated software for development purposes? May be a company didn't have enough money to buy a piece of software and there were no free alternatives? May be a company wanted to try something out before buying and there were no trial licenses for that product. Whatever the circumstances, have you worked at a company where using pirated/cracked software was accepted? Were there any consequences to doing this?</p>
","3262","","47","","2016-02-27 16:20:29","2016-02-27 16:20:29","Use of pirated/cracked software for development","<security><ethics>","19","15","","2011-10-18 14:41:40","2011-01-23 07:24:28","CC BY-SA 2.5"
"208901","1","","","2013-08-20 07:19:25","","15","1216","<p>On reliable websites I always see claims such as ""All data is encrypted"" or ""All passwords are encrypted using 128bit encryption"" and etc. However I have never come across a claim such as ""All passwords are hashed.""</p>

<p>On my website, I will be storing all user passwords in a database after using SHA-512 (most likely) hashing with a random salt. I want to add a snipet assuring users that their passwords are secure so they will not be deterred from using my website because it requires a password. I want users to feel secure but I do not think everyone knows what hashing is.</p>

<p>MY QUESTION:
Is it okay to provide a message saying that ""All passwords are encrypted and secure"" since I do not think that the average user will know what the difference between hashing and encryption is, and will more likely feel secure just because they see the comfort word ""encryption""? Or is there an alternative message I should provide?</p>

<p>On a side note, I am new to encryption and password hashing and I was wondering if this would be safe enough for now as I launch my site. I do not want to tell users it is secure if it is not. Any information would be greatly appreciated. Thanks.</p>
","100053","","","","","2013-08-21 08:08:25","How to assure users that website and passwords are secure","<security><ethics><encryption><passwords><hashing>","6","10","","2015-05-04 13:15:10","","CC BY-SA 3.0"
"329905","1","","","2016-09-01 10:53:18","","1","2266","<p>I have been asked to implement refreshing a token. A token ID is the same as a session ID. I have considered resetting the session's idle time to 0 and continue using the same session ID for the session.</p>

<p>Does this violate security best practice? Is it security best practice to return a new token ID in this case to prevent session fixation attacks?</p>
","242689","","","","","2016-09-01 14:10:24","Refreshing a token best practice","<security><session>","2","0","","","","CC BY-SA 3.0"
"329925","1","329930","","2016-09-01 15:27:43","","1","1041","<p>I have two sites and an API that sends data back and forth between the two. The API is only used on the back end, and the user will not interact with it at all. What I would like to do is ensure that any requests made to this API (on either site) came from the other site and no where else.</p>

<p>Right now I have an API key stored on each site that must be sent with the request; without the key the request will be rejected. Still I feel that this is not secure enough because the API key can become compromised. </p>

<p>What steps can I take to verify that my API requests are coming from the correct source? The language is PHP.</p>
","244188","","167734","","2016-09-01 16:39:10","2016-09-02 01:02:46","Securing a private API","<security><api><api-design>","1","9","","","","CC BY-SA 3.0"
"209052","1","","","2013-08-21 18:11:32","","3","2088","<p>I was reading <a href=""http://rads.stackoverflow.com/amzn/click/059600656X"" rel=""nofollow"">Essential PHP Security</a> and chapter 8 talks about problems with hosting your PHP app in a shared hosting environment.</p>

<p>Some of the problems he mentions are:</p>

<p><strong>- Exposed source code and File system browsing.</strong></p>

<blockquote>
  <p>a web server must be able to read the source code in order to execute it. Since the web server is shared a PHP script written by another developer on the server can read arbitrary files. An attacker can also create a script that browses the file system.</p>
</blockquote>

<p><strong>- Exposed session data and Session injection.</strong></p>

<blockquote>
  <p>By default, PHP stores session data in /tmp which is writable by all users, so Apache has permission to write session data there. A simple script can allow other users to read, add, modify, or delete sessions.</p>
</blockquote>

<p>It's like everything is exposed and vulnerable if I used shared hosting this way.</p>

<p>My questions:</p>

<ol>
<li>Considering the book was published 8 years ago, are they problems still occurring or were they mitigated somehow in the last few years?</li>
<li>Why would one opt for shared hosting if it going to cause these huge security concerns?</li>
<li>I understand that shared hosting is cheap, but there must be a safer alternative to it and cheaper than dedicated hosting?</li>
<li>In case a customer ask me to develop an application that will be hosted on a shared hosting, is there a full proof way to develop a secure application or is it just a recipe for disaster? </li>
</ol>
","50440","","50440","","2013-08-21 18:56:46","2013-08-23 21:49:30","Shared hosting for a PHP application","<php><security><hosting>","3","2","","","","CC BY-SA 3.0"
"330021","1","","","2016-09-02 14:52:41","","0","172","<p>Let's say I have two web applications that are independent of each other.</p>

<p>App1 is written in Python and<br>
App2 is written in Java.</p>

<p>After some logic is done in App1 by normal user, App1 needs to create a realm which can only be done by admin in App2.</p>

<pre><code>curl -H ""Content-Type: application/json"" \
     -H ""Token: admintokenblabla"" \
     -X POST \
     -d '{""realm"":""myrealm""}' http://localhost/app2/realm/create
</code></pre>

<p>I can create realms through the REST API provided that I present the right admin token. The token is created after a success login in App2 (meaning I need to know the username and password)</p>

<p>How can App1 trigger creation of realm in App2 without any admin token? Do I need to hardcode admin's password in App1 and just HTTP request it? (sounds like a very bad solution)
What is the industry standard solution to this?</p>
","70237","","61852","","2016-11-01 17:24:04","2017-08-28 22:39:59","App1 through REST API create something that only admins in App2 can do","<rest><security>","1","1","","","","CC BY-SA 3.0"
"209313","1","209484","","2013-08-23 19:38:35","","3","241","<p>We know there are several moving parts to a system like the apple store or google play. At the very least;</p>

<ul>
<li>The device has a unique hardware id or sim card</li>
<li>The user has a login/pass</li>
<li>The ""store"" site has some crypto</li>
</ul>

<p>In what order and format (cypher/plaintext) is this data exchanged between the device and store software before content is installed?</p>
","37265","","31260","","2013-08-24 00:34:07","2013-08-26 04:32:31","What is the identification procedure that registers a mobile device on a subscriber account and installs purchased content?","<security><mobile><copy-protection>","1","0","","","","CC BY-SA 3.0"
"10340","1","10343","","2010-10-07 22:06:13","","38","26565","<p>Is it still worth it to protect our software against piracy? Are there reasonably effective ways to prevent or at least make piracy difficult?</p>
","4809","","31260","","2016-02-27 05:50:44","2016-02-27 05:50:44","How do you prevent the piracy of your software?","<security>","19","8","","2013-09-26 03:22:36","2011-04-15 15:44:36","CC BY-SA 3.0"
"330682","1","333594","","2016-09-10 01:44:37","","2","1487","<p>I'm designing a JWT authentication workflow for a RESTful API which uses  two kinds of tokens:</p>

<ul>
<li><strong>Phone token</strong>, a short-lived token - issued by completing an One-Time-Password challenge. Its task is to prove ""ownership"" of a phone. It carries the phone number.</li>
<li><strong>Access token</strong>, a long-lived token - issued by providing a valid phone token. Its task is to provide the identity of the phone owner. It carries the user's ID.</li>
</ul>

<p><a href=""https://i.stack.imgur.com/5yALS.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/5yALS.png"" alt=""Authentication flow""></a></p>

<p><strong>My question is how to structure those two tokens correctly and whether I should use two distinct signing keys for them?</strong></p>

<p>From my understanding the subject (<code>sub</code>) of the phone token should be the phone number and the subject (<code>sub</code>) of the access token should be the user's ID. (<strong>Edit</strong>: I'm not even sure about that, how would the controller know how to interpret the number, i.e looking up the right resource? Wouldn't it be better to use strings like 'phone' and 'identity' for the subject and provide an additional 'id' field?)</p>

<p>What about the issuer field (<code>iss</code>), should this be something like <code>http://example.com/phone</code> and <code>http://example.com/identity</code> ?</p>

<p>What about the audience field (<code>aud</code>)? The phone token has a small audience, i.e only one or two services, should I specify them explictly? Like <code>aud: ['identity', 'xyz']</code>? </p>

<p>In case of of the access token the audience is quite broad, i.e many services which consume this token, and the audience might grow so I don't want to hardcode them into the token, otherwise I would have to issue new tokens everytime I add a service. How could I circumvent this?</p>

<p>I'd be very glad if you could suggest a possible structure and the reasoning behind it.</p>
","150861","","150861","","2016-09-10 01:57:00","2016-10-14 09:47:11","How to structure JWT correctly","<design><security><web-services><json><authentication>","1","0","","","","CC BY-SA 3.0"
"209943","1","","","2013-08-30 11:30:40","","2","117","<p>I'm looking at Azure Mobile Services, particularly the Authentication part (which I believe relies exclusively on OAUTH 1 or 2).</p>

<p>I want to make sure that my application isn't tightly coupled to the service and I can bring authentication back in-house using either of the following methods:</p>

<ol>
<li><p>I use a version of Azure Mobile Services built for 2012 R2 (which may include support for AMS + OAUTH)</p></li>
<li><p>I use a local DLL such as .NET Open OAuth to handle the authentication.</p></li>
</ol>

<p>My theory is that UIDs are portable between all three scenarios (the third being Azure Mobile Services itself), because I manually would be typing in the same secret into each provider.</p>

<p>My second gut reaction is that any Windows Live IDs will not have the same URL and aren't portable in these scenarios (based on my Azure ACS and LiveID experience).  However since I've noticed OAuth support in .NET OpenID I think I could be mistaken.</p>

<p><strong>Question</strong></p>

<p>Could someone more well versed in authentication, and Microsoft products let me know if authentication can be ""moved"" to and from Azure Mobile Services if needed?</p>

<p>The main contention point I believe will be differing user IDs after the switch which would mean that after migration, users will loose their previous history, etc. in my application.</p>
","175","","","","","2013-08-30 11:30:40","Switching between Azure Mobile Services vs my own implementation. Will UIDs change?","<security><azure><oauth><openid><oauth2>","0","0","","","","CC BY-SA 3.0"
"210080","1","","","2013-08-31 16:35:50","","2","821","<p>I'm putting together some notes for a dev team on how to write secure Perl code - especially taking into account the current OWASP top 10 web application vulnerabilities. For cross-site scripting I've included information on ensuring that all output to the browser is checked and escaped where necessary, but I'm looking for more automated mechanisms that would mean a developer doesn't have to think about every output statement and, potentially, miss one. Perl's 'taint' function sounds like it should be a help because it distrusts all user input, but it doesn't complain on tainted data being output to the browser. Apart from checking all output statements individually (probably by calling a generic sanitizing function) does anyone have any ideas on how Perl can help with this with existing libraries or techniques?</p>
","101043","","","","","2013-11-24 13:08:36","Checking for cross-site scripting vulnerabilities in Perl web applications","<security><perl>","1","2","","","","CC BY-SA 3.0"
"330850","1","330851","","2016-09-12 14:04:32","","60","13913","<p>The way I see it, SQL injection attacks can be prevented by:</p>

<ol>
<li>Carefully screening, filtering, encoding input (before insertion into SQL)</li>
<li>Using <a href=""https://en.wikipedia.org/wiki/Prepared_statement"">prepared statements</a> / parameterized queries</li>
</ol>

<p>I suppose that there are pros and cons for each, but why did #2 take off and become considered to be more or less the de facto way to prevent injection attacks? Is it just safer and less prone to error or were there other factors?</p>

<p>As I understand, if #1 is used properly and all caveats are taken care of, it can be just as effective as #2.</p>

<p><strong>Sanitizing, Filtering, and Encoding</strong>  </p>

<p>There was some confusion on my part between what <em>sanitizing</em>, <em>filtering</em>, and <em>encoding</em> meant. I'll say that for my purposes, all of the above can be considered for option 1. In this case I understand that sanitizing and filtering have the potential to <em>modify or discard</em> input data, while encoding <em>preserves data as-is</em>, but encodes it properly to avoid injection attacks. I believe that escaping data can be considered as a way of encoding it.</p>

<p><strong>Parameterized Queries vs Encoding Library</strong> </p>

<p>There are answers where concepts of <code>parameterized queries</code> and <code>encoding libraries</code> that are treated interchangeably.  Correct me if I'm wrong, but I am under impression that they are different.</p>

<p>My understanding is that <code>encoding libraries</code>, no matter how good they are always have the <em>potential</em> to modify SQL ""Program"", because they are making changes to the SQL itself, before it is sent off to the RDBMS.</p>

<p><code>Parameterized queries</code> on the other hand, send the SQL program to the RDBMS, which then optimizes the query, defines the query execution plan, selects indexes that are to be used, etc., and then plug in the data, as the last step inside the RDBMS itself.</p>

<p>Encoding Library</p>

<pre><code>  data -&gt; (encoding library)
                  |
                  v
SQL -&gt; (SQL + encoded data) -&gt; RDBMS (execution plan defined) -&gt; execute statement
</code></pre>

<p>Parameterized Query</p>

<pre><code>                                               data
                                                 |
                                                 v
SQL -&gt; RDBMS (query execution plan defined) -&gt; data -&gt; execute statement
</code></pre>

<p><strong>Historal Significance</strong></p>

<p>Some answers mention that historically, parameterized queries (PQ) were created for performance reasons, and before injection attacks that targeted encoding issues became popular.  At some point it became apparent that PQ were also pretty effective against injection attacks.  To keep with the spirit of my question, why did PQ remain the method of choice and why did it flourish above most other methods when it comes to preventing SQL injection attacks?</p>
","119333","","119333","","2016-09-16 15:48:48","2023-04-14 17:56:14","Why did SQL injection prevention mechanism evolve into the direction of using parameterized queries?","<security><sql><history><hacking><sql-injection>","16","6","","","","CC BY-SA 3.0"
"330871","1","337162","","2016-09-12 18:12:52","","0","1020","<p>According to <a href=""https://www.quora.com/What-are-the-key-difference-between-ReactNative-and-NativeScript/answer/Valentin-Stoychev"" rel=""nofollow"">https://www.quora.com/What-are-the-key-difference-between-ReactNative-and-NativeScript/answer/Valentin-Stoychev</a> , ""ReactNative as using the notation found in React for inlining the UI declaration in a single file."" Is this supposed to mean that when writing React (or ReactNative) code you have to use inline JavaScript? </p>

<p>Would React therefore get blocked by default by a Content Security Policy (CSP)? </p>

<p>According to <a href=""http://www.asd.gov.au/publications/protect/protecting_web_apps.htm"" rel=""nofollow"">http://www.asd.gov.au/publications/protect/protecting_web_apps.htm</a> :</p>

<blockquote>
  <p>A Content Security Policy (CSP) provides security controls which can
  mitigate attacks such as cross-site scripting (XSS) and other attacks
  based on introducing malicious or otherwise undesirable content into a
  web application. A CSP achieves this by specifying a whitelist of
  content sources for a web application that a compatible browser then
  enforces. A large variety of content can be controlled using a CSP
  including scripts, images and audio or video.</p>
  
  <p>By default, a CSP also implements other mitigations beyond
  whitelisting content sources. The main additional mitigations are:</p>
  
  <ul>
  <li>Inline JavaScript will not execute: this mitigates the most common types of XSS attacks.</li>
  <li>JavaScript code will not be created from strings: this prevents attackers abusing JavaScript functionality to execute arbitrary
  JavaScript code.</li>
  </ul>
</blockquote>

<p>P.S. I'm totally new to React.</p>
","180719","","","","","2016-11-30 06:41:44","Is it necessary to use inline JavaScript with React? Would React therefore get blocked by default by Content Security Policies (CSPs)?","<javascript><security><reactjs>","1","0","","","","CC BY-SA 3.0"
"11546","1","11547","","2010-10-13 02:42:30","","3","396","<p>Take the example of the recent ASP.NET (and Java Server Faces) vulnerability disclosure at a Hacker conference in Brazil.  It's my understanding that the poet tool was demonstrated before Microsoft was even aware of the issue.</p>

<p>Are there laws to protect legitimate customers from people who encite the hacker community to start hacking all the ASP.NET servers they can?  Who knows how many legitimate businesses were compromised between when the tool was demoed and the patch was applied to the server.</p>
","175","","4982","","2010-10-19 18:06:03","2010-10-19 18:06:03","Are there laws to protect us from hackers who disclose vulnerabilities prior to alerting the vendor?","<security><asp.net><hacking><legal>","4","6","","","","CC BY-SA 2.5"
"11637","1","11702","","2010-10-13 10:52:00","","7","1651","<p>I'm in the planning stages of developing a web application that I want to make as secure as possible. I'm pretty clear about how to do that from a technical point of view, but there is one massive potential security hole: I want the site to have users. </p>

<p>As anyone who has ever been a user knows, users forget usernames, forget passwords, sometimes forget that they even had an account with your site. Users respond to phishing emails and give away their credentials. If you do anything that they find too complicated they won't use your site, it has to be simple and all happen in as few clicks as possible, but we have to balance that out by making it as hard as possible for users to accidentally give away their credentials and to keep access to the service as secure as possible.</p>

<p>What I'm particularly interested in are strategies that go beyond the standard username and password combination and ways of recovering or resetting passwords that make things easy for users but hard for anyone trying to steal their account. I know a lot of sites provide an extra user-set security question, but because I don't trust users not to create a stupid question like ""what is 1+1"" I don't see how this can guarantee security.</p>

<p>Are there strategies that could be useable to the most clueless user but challenging to a determined and targetted attack aiming to break into their account? If not what are the closest things we could get? As a user what are the best/worst sites for this you have encountered and why?</p>
","4027","","4027","","2010-10-13 11:00:42","2010-12-06 19:26:40","How to make security usable in a web application?","<web-development><security><users>","7","7","","","","CC BY-SA 2.5"
"210255","1","210266","","2013-09-02 22:03:06","","8","2761","<p>When I worked as a freelancer, I encountered lots of cases where customers were protecting their ideas and source code of their projects (such as web applications) as much as possible, no matter how unimportant, uninteresting and unoriginal were the projects and the concepts behind.</p>

<p>I've already posted <a href=""https://softwareengineering.stackexchange.com/q/33560/6605"">a question about keeping the ideas secret</a>, and received many great answers. Now, my concern is more about source code secrecy.</p>

<p>According to my observations of:</p>

<ul>
<li>The codebases I had to work on during my career,</li>
<li>My own willingness to keep some of my own source code secret, and:</li>
<li>A few articles like, for example, <a href=""http://tech.turbu-rpg.com/420/open-response-to-simon-stuart"" rel=""nofollow noreferrer"">Open response to Simon Stuart</a> by the popular Programmers.SE contributor <a href=""https://softwareengineering.stackexchange.com/users/935/mason-wheeler"">Mason Wheeler</a>,</li>
</ul>

<p>I conclude that source code is kept secret mostly for those reasons:</p>

<ol>
<li><p>Because the author is ashamed of the code of such a bad quality, or the company fears losing reputation if somebody sees such bad codebase, or that given the low quality of the codebase, it will not bring anything useful to anybody to open source it: even if somebody would be interested, he would hardly be able to run the solution (or, often, even compile).</p></li>
<li><p>Because parts of the code are stolen (mostly from open source projects covered by a license which restricts its usage in a given situation),</p></li>
<li><p>Because the code relies on security by obscurity and the author doesn't care about <a href=""http://en.wikipedia.org/wiki/Kerckhoffs%27s_principle"" rel=""nofollow noreferrer"">Kerckhoffs's principle</a>.</p></li>
<li><p>Because the product is so breakable that showing the code would cause too much harm: if a closed-source app with all those security leaks would withstand a newbie hacker, the same open sourced app would have far smaller chances, because even the beginner hacker would just have to study the code to discover all the holes.</p>

<p>If it's not clear what I'm talking about, here's an example:</p>

<pre><code>if (credentials.password === 'masterPassword12345')
{
    isLoggedIn = true
    currentUser = credentials.userName
}
else
{
    authenticate(credentials)
}
</code></pre></li>
<li><p>Because the author over-estimated the source code (and his own skills and expertise). Example: believing that a home-made cryptography-related algorithm (which was never reviewed by anybody) is better than any well-known one.</p></li>
<li><p>Because the author believes that the idea behind the code is great, and that it would be stolen.</p></li>
<li><p>Because of the ""It's not perfect enough"" syndrome. In other words, the developer is willing to release the source code to public when the code is ""good enough"", but day after day, there are still things to improve, so the code would never be released.</p></li>
</ol>

<p>All of those reasons give a rather negative image of people who are against publishing the source code.</p>

<p>Are there valid cases to not release to the public the high-quality code which follows Kerckhoffs's principle?</p>
","6605","","-1","","2017-04-12 07:31:37","2013-09-03 13:28:05","What are the cases where keeping source code secret is justified?","<open-source><security><hacking>","6","6","","","","CC BY-SA 3.0"
"330927","1","","","2016-09-13 09:37:10","","14","7420","<p>The <code>private</code> modifier is used to restrict access outside the class, but using reflection other classes  can access private method and fields. So I am wondering how we can restrict accessibility if it is part of requirement.</p>
","245930","","9113","","2016-09-13 14:35:54","2016-09-14 18:20:45","Is Reflection a disadvantage as private variables cannot be restricted?","<security><reflection>","6","8","","","","CC BY-SA 3.0"
"331079","1","331082","","2016-09-14 21:01:52","","6","3582","<p>I'm working on a web application where the server side makes calls to a foreign server's web service API. The data passed to this API could contain sensitive data (like a user's password) as part of the header and/or in the body of the request. I want to be able to log what's in the request (URI, header, body, response) for troubleshooting purposes but I don't want to expose any sensitive information. I have a single method that makes this API request which other methods call and that's where I've been putting the log statements. This of course reveals everything, including sensitive data. Is there a common way to do this?</p>
","246169","","","","","2016-09-14 21:51:45","How do you log potentially sensitive data?","<security><logging>","2","1","","","","CC BY-SA 3.0"
"331228","1","331268","","2016-09-16 11:08:53","","0","97","<p>In the company I'm working for we have a certain service where users can upload documents (text, sometimes document scans), it's nothing confidential but if those documents will be leaked, I'll get a lot of headache explaining why all of them are publicly available. Recently we had a breach of out network and while this time no one managed to get anything it raised some security concerns. </p>

<p>It's a vast legacy system, replacing it right now is out of the question. It exists within our corporate network and users can't access this data storage directly due to specific AD and Network security policies. As practice shows those policies can be overridden because of our IT dept negligence. So what I want is to add an additional layer of security by encrypting everything within the storage.</p>

<p>The storage acts as an archive. People dump old documents into it and those documents are rarely if ever accessed. Placing all of the incoming files into some encrypted containers is not an issue, easy to implement. The question is - how do I store keys for those containers? If I'll put them inside of the general service database, anyone who'd like to access those documents in an unauthorized manner will be able to do so by simply gaining access to the database (SQL Server, used by many apps, possibly compromised due to badly designed legacy services in the company). </p>

<p>I can theoretically store keys in some other database (dedicated server with a proper setup of SQL Server\ PostgreSQL), physically disconnected from the main one and send keys from there only when requested and prevent attempts to dump all of the keys, any 'unusual' behavior is very easy to detect because people rarely request anything. And I don't care how long it'll take to restore and decrypt those containers, 1ms or 1 hour don't make any difference when taking in account the overall system processes. However, this approach feels a bit convoluted.</p>

<p>Are there any sort of 'best practices' for solving such problems? </p>
","142717","","","","","2016-09-16 20:58:37","How to store keys for an encrypted storage in .NET in-house service","<database><.net><security>","1","2","","","","CC BY-SA 3.0"
"331244","1","331250","","2016-09-16 15:02:56","","3","9648","<p>I came across one of the books related to <strong>information security</strong> where i saw these two terms, <strong>fabrication</strong> and <strong>modification</strong> of data.</p>

<p>I can't figure out how they are different?</p>

<p>What is the difference between <strong>fabrication</strong> and <strong>modification</strong> of data? </p>

<p>Could anyone please explain me these, in very simple terms?</p>

<p>Update:</p>

<p><strong>fabrication</strong>: An unauthorized party inserts counterfeit objects into the system and basically attacks the authenticity of the system.</p>

<p><strong>modification</strong>:  An unauthorized party modifies the assets of the system and basically attacks the integrity of the system.</p>
","232368","","232368","","2016-09-16 16:15:49","2016-12-16 03:05:31","Difference between fabrication and modification","<security><data>","2","4","","","","CC BY-SA 3.0"
"331293","1","331301","","2016-09-17 09:42:21","","1","247","<p>I'm focusing my question on Windows OS, desktop applications.</p>

<p>What would be a decent way to get a unique identification for every machine?</p>

<p>obviously there many ways to do that, such as concatenating a hash from network card's MAC address, or hard drive serial number, or even generating my own GUI number on initial launch, and saving it on the hard-disk \ registry, reading it every time i need it, but would like to avoid ""inventing the wheel"" and go for a more robust and proven approach.</p>

<p>My target use-case is to query a webservice. I would like to save each machine's preferences to my database, and return it to them when they ask for it. (backing up their personal settings)</p>
","192745","","192745","","2016-09-17 10:07:16","2016-09-17 14:33:40","What would be a decent practice to get unique id for each MACHINE","<security><windows><desktop-application>","1","6","","","","CC BY-SA 3.0"
"12626","1","12665","","2010-10-18 05:13:57","","4","240","<p>For most open source project, there is a well-founded project team and corporate sponsorship, and a lot of active contributors. The procedure for filing bug reports are clearly documented.</p>

<p>However, there are also some open source project(s) that have been in existence for more than 10 years (maybe 15), and were included in all sorts of free and commercial products (OSes and linux distros, etc), and everyone just assumes it is correct, despite some parts of it in a state of despair and full of bugs.</p>

<p>It appears to me that the real users (programmers in-the-know) simply choose to use the library in a certain way as not to trigger the bug. Few choose to speak up.</p>

<p>There are also big-name companies that fix the bugs quietly (in their own products) without giving out any patches. And use that to their business advantage.</p>

<p>There is no leading developer. There is no information as to who are the active developers, except that you can browse the mailing list and see who has recently submitted patches, and assume that they might know someone who is helpful.</p>

<p>How should I handle a vulnerability case, without leaking information in a way that gives ammunition to the bad guys?</p>

<p><em>This question is a spin-off from: <a href=""https://softwareengineering.stackexchange.com/questions/5168/whats-the-biggest-software-security-vulnerabilty-youve-personally-discovered"">https://softwareengineering.stackexchange.com/questions/5168/whats-the-biggest-software-security-vulnerabilty-youve-personally-discovered</a></em></p>
","620","","-1","","2017-04-12 07:31:41","2010-10-18 11:17:51","How do I report software vulnerabilities found in an open source library that are widely used but have a dilapidated team structure?","<open-source><security><ethics>","4","0","","","","CC BY-SA 2.5"
"331538","1","331539","","2016-09-20 17:19:36","","-3","89","<p>As we all know, security is very important when making any kind of application. That's why I came up with this idea, or rather I already made it happen. Thing is I am not sure whether it is really securing my applications, or is it just extra weight.</p>

<p>To keep it simple: I made a simple function that enables ""admins/owners"" to change the names of folders within an app. Each folder is given an ID (through some file/controller that exists in the folder itself). That's the gist of it.</p>

<p>As I already mentioned, it is a working ""countermeasure"". I'm sure there are better alternatives, like HTACCESS. But, I don't have the guts to learn other methods (Sorry for that xD).</p>

<p>So, once again... What do you think of this idea? Is it fine to use it? or is it bad?</p>

<p>I know that I should consider running/execution time optimization, and it would be much appreciated if you could share some tips &amp; tricks or tutorials.</p>
","246844","","31260","","2016-09-20 17:38:18","2016-09-20 17:38:18","Your opinions about an idea for better php applications security?","<php><security><applications>","1","3","","","","CC BY-SA 3.0"
"12808","1","12829","","2010-10-18 20:05:50","","5","398","<p>Say you've started an open source project and are posting it on a public repository.  (like I have, using Codeplex.)</p>

<p>One of the key files just makes the connection to the database, contains the login/password, and is just included from any other source file that needs a database connection.</p>

<p>What's the best way to share the project without giving out your password?</p>

<p>So far I've specifically removed it before committing any changes, but I'm thinking there has to be a better way.</p>
","189","","","","","2010-10-18 20:36:47","Keeping a connection string secure when working with others","<open-source><security>","4","0","","","","CC BY-SA 2.5"
"101008","1","101010","","2011-08-14 13:39:39","","5","325","<p>In almost any security system I've ever seen, what is controlled is that <strong>which person has access to which part</strong>.</p>

<p>However, in real life, in many situations, security systems also consider <strong>when</strong> and <strong>where</strong> a person is permitted to do something. </p>

<p>For example, <strong>you can drive fast in day</strong>, but <strong>you can't drive fast in night</strong>, or <strong>you can marry a homosexual officially in X</strong>, but <strong>you can't marry the same gender in Y</strong>.</p>

<p>Does constraint-based security has any meaning in the context of software. For example, a system can prevent you from entering in certain times of the day (after work for example), or another system can let you stay signed in, only if you type fast enough, or another system can let you enter data, only if you are currently located in the USA (<a href=""http://www.thoughtresults.com/geolocation-api"" rel=""nofollow"">Geolocation API</a>), etc.</p>

<p>Why computer security systems don't match real life scenarios?</p>
","31418","","31418","","2011-08-14 17:16:15","2011-08-18 15:27:27","Why applications don't have constraint-based security?","<security>","2","6","","","","CC BY-SA 3.0"
"211274","1","","","2013-09-12 13:29:57","","2","1513","<p>How can I check if an Android application running on a not rooted device is ""secure"" without knowing its source? </p>

<p>I would look for:</p>

<ol>
<li><p>Plain text in Web-Requests (wireshark and emulator)</p></li>
<li><p>SQL-injection (in EditTexts...)</p></li>
<li><p>Doing stuff, that isn't always expected (i.e. fast clicking to check for race conditions)</p></li>
</ol>

<p>Question: What else could be interesting for auditing Android apps?</p>
","60396","","","","","2013-10-19 11:30:13","How to audit an Android application (not rooted) without having access to its source?","<java><security><android><audit>","1","3","","","","CC BY-SA 3.0"
"211404","1","211407","","2013-09-13 13:20:42","","0","221","<p>I have a typical MVC based website, and I'd like to give some registered users the abillity to extract data from the database (in a variety of formats). The workflow is very simple:</p>
<ul>
<li>User logs in,</li>
<li>User clicks export,</li>
<li>A file is generated,</li>
<li>User downloads the file.</li>
</ul>
<p>I'm trying to figure out a way to secure the last step and limit access to the file. In order for the user to be able to download the file, it should be in a publicly accessible folder. That, however, means that the file is accesible to everyone else that has access to its full url.</p>
<p>I thought of a few possible solutions:</p>
<ol>
<li><p>Email the export file</p>
<p>Instead of having the user download the file, I could simply email it to their email (the one they used to register on the site). This seems like a decent option when the export files are small, but I don't think it'll be optimal for larger files.</p>
</li>
<li><p>.htaccess magic</p>
<p>I could automagically generate an .htaccess in the export dir that would only let the user who requested the export access it. Also a decent option, but it's webserver specific and IP based. I don't know if Apache will always be the webserver of choice for the project, and I'm not sure an IP based solution is actually secure.</p>
</li>
<li><p>Store the export file in a private folder and have the user fetch it through ftp</p>
<p>Secure, but not particularly user friendly.</p>
</li>
</ol>
<p>All my options seem to have problems, and I'm at that point where I'm completely stuck and can't shake the feeling I'm missing something obvious. Am I? Is there a better workflow?</p>
<p>I'm more interested in a high level overview than technical details, the project is still in its early days and technical requirements haven't yet stabilized (e.g. we may not use Apache after all). The project is build in PHP, but I don't think that matters (does it?).</p>
<p>Thanks.</p>
","102136","","-1","","2020-06-16 10:01:49","2013-09-13 15:01:42","How can I limit access for automatically generated files to specific users in a MVC setup?","<web-development><web-applications><security><server-security>","2","0","","","","CC BY-SA 3.0"
"332321","1","","","2016-09-29 07:56:36","","0","62","<p>I've been toying with a project idea for a while now but can't quite settle on one important detail. The plan is to write a client that can author and upload WebMs to a server for global viewing (should the user wish), however, I only want to allow WebMs made with the official application for the sake of consistency. </p>

<p>My first thought was to embed a secret key into the exported <code>.webm</code> file that the server also knows about, but I worry it'd be easily extractable with the right tools.</p>

<p>Do securer strategies exist, if not at all?</p>

<p>Thanks in advance!</p>
","","user247948","","","","2016-09-29 09:29:12","Allowing only users of the official client to upload media to my server. Possible?","<security><server><client><cryptography>","2","1","","","","CC BY-SA 3.0"
"332434","1","","","2016-09-30 10:01:38","","3","108","<p>I have worked in company A for less than 1 year and I was given the task to do a security code review for a small project I was involved in the late 3 months. Until now I have been mainly been reading about common security culprits like SQL injection, XSS, etc. and trying to find these in the codebase.</p>

<p>During the review however I stumbled into something like:</p>

<pre><code>def user_id
  return (session[:user_id] ? session[:user_id] : NOT_LOGGED_IN)
end
</code></pre>

<p><code>NOT_LOGGED_IN</code> evaluates to <code>""WEBUSER""</code>. To me this seemed hazardous for various reasons so I started commenting the snippet:</p>

<pre><code># INSECURE: Although the function works fine it can be susceptive to 
#           misuse since under the hood it sets a username to a non-user.
</code></pre>

<p>And then I started thinking.. Is this actually something fitted in a <strong>security</strong> code review or the more common ""code review""?</p>

<p>I assume the main difference between the proper security issues like SQL injection and XSS is that they are very specific and thus objective. When it comes into naming of functions and variables, it involves what different people think and thus becomes subjective. Someone in this case might argue for example that <code>user</code> is anyone visiting the site - no matter if he is registered or not so in that case <code>WEBUSER</code> would be a valid guest id (but then again it is counter-intuitive that many such users would share the same id).</p>

<p>So how should someone approach the subjective versus objective issues battle?</p>
","107178","","","","","2016-09-30 11:58:07","Should security code review involve stylistic culprits?","<code-reviews><clean-code><code-security>","1","0","","","","CC BY-SA 3.0"
"211799","1","","","2013-09-17 20:17:37","","4","2814","<p>I am currently involved in the implementation/design of an existing application for a large scale customer. The application has a similar model as e.g. vCenter Server whereby a number of components store information in and extract information and workflows form a central database. The environment is managed from a console application which uses a windows service to connect to the database.</p>

<p>Due to security considerations SQL Authentication is not an option, but the application does support Windows Authentication. However when using windows authentication it passes the credentials of the user who is using the management console application on to the database in stead of using the service account under which the service runs.</p>

<p>This results in the situation where the security roles as they are defined within the application (AD users/groups mapped to certain permissions) requires these AD objects to also have a SQL Server login and certain permissions on the database (db-writer for certain tables, depending on the specific permissions in the app).</p>

<p>Apart from the additional administration, this also creates a security risk IMO because the whole point of the application security roles in this specific application is to allow users access to only a part of a certain table (e.g. a subset of the objects). But since they now have a SQL login and db_writer on that entire table they could bypass the app and with a direct connection to the database they could read/alter records they would not be allowed to view/manipulate through the application.</p>

<p>This risk could then (partly) be mitigated by restricting access to the database on a network level, or possibly use triggers to check the calling hostname and program name, but as far as I know that is not completely safe.</p>

<p>The only benefit as is presented to me is there is now a full audit trail available in SQL server on exactly who did what. But this is already implemented in the application as well so it seems kind of moot to me.</p>

<p>I have been frantically searching for any info on this and what would be the best practice. I can only find ASP / Web based stuff but nothing regarding this type of application.</p>

<p>Is it really the best way to go with passing through authentication to SQL server or should the app handle authorization and send all database requests using the service account?</p>

<p>P.S.: This is my first question on stackexchange, if I posted on the wrong sub-site or you find my question inappropriate, please just let me know.</p>
","102485","","226181","","2016-07-14 12:36:04","2016-07-14 12:36:04","Best practice in application design / SQL authentication","<security><sql><roles>","2","2","","","","CC BY-SA 3.0"
"14584","1","","","2010-10-25 20:45:44","","9","796","<p>When you're coding, do you actively think about your code might be exploited in ways it wasn't originally meant to do and thus gain access to protected information, run commands or something else you wouldn't want your users to do?</p>
","2210","","","","","2010-12-07 15:53:32","Do you actively think about security when coding?","<security>","11","2","","","","CC BY-SA 2.5"
"332737","1","332741","","2016-10-04 10:41:31","","5","625","<p>On websites like Facebook and Twitter, you've got a function to log off on all devices. How does it work?</p>

<p>Does it work with IP addresses or something? What happens when you login on a device and use that function?</p>

<p><strong>P.S.:</strong> Facebook and Twitter are just examples in this question. It was just easier to explain what I mean.</p>
","183049","","40857","","2016-10-04 18:58:36","2016-10-04 18:58:36","Log off system on all devices","<programming-practices><security><login>","1","2","","","","CC BY-SA 3.0"
"332981","1","","","2016-10-06 13:00:15","","0","64","<p>I am currently sketching out a project I am doing at my job, where I will have a self hosted WebAPI, connected to a serial device, where the app I am creating will configure that device. No, it is not a Raspberry PI :)</p>

<p>So instead of having a database as a data source for the API, I would make
calls to the serial device. I think that it is a pretty neat idea, and I can use
the usual methodology for developing APIs.</p>

<hr>

<p>So, I have one or two questions that I could use some help with.</p>

<p>Question 1: My company has a limited amount of these serial devices for testing purposes, so I can not rely on having a device every time I want to test my newly written code. So is it a good idea to have a flag in the http-request that specifies whether the api should get the data from the serial device or get testdata from say a document? I was thinking about a OWin middleware that can route the call to the correct service.</p>

<p>Question 2: Security. Since the selfhost API would be installed on the users local computer, and the webapp would only call localhost, is there any need to think about security and authentication and the like? The websuite that is present in my company has a authentication solution already, so is that enough? I always struggle when it comes to security concerns, so I have no confidence in my reasoning ability on that subject :)</p>
","248848","","","","","2017-01-07 04:43:09","security in selfhost web api","<.net><testing><security><api-design>","1","0","","","","CC BY-SA 3.0"
"15350","1","15355","","2010-10-28 14:24:03","","13","6301","<p>Registering on an insurance company's website right now, and my password is 16 characters long, using a nice variety of letters, numbers, special characters, etc. However, here's their list of restrictions:</p>

<blockquote>
  <p>Note your password:</p>
  
  <ul>
  <li>must be between 6 and 12 characters</li>
  <li>must not contain spaces, special/international characters</li>
  <li>must not contain your user name, first name or last name</li>
  <li>is case-sensitive</li>
  <li>should contain at least 1 number and 1 letter</li>
  </ul>
</blockquote>

<p>I can understand minimum 6 characters, not allowing parts of your name, being case-sensitive, and needing at least 1 number and letter. The part I don't get is restricting your choice of characters you can use, and having an upper bound.</p>

<p>Why do websites do this? The only thing I can think of it they don't know the basics of hashing a password, which would secure it better than anything, and get rid of any security concerns.</p>

<p>If I choose to type <code>DELETE FROM users WHERE 1=1</code> as my password, I should be allowed to. PHP's MD5 hash of it becomes <code>fe5d54132b51b7d65ab89b739b600b4b</code> which I don't think will harm anything.</p>
","2416","","","","","2010-12-04 13:39:12","Why do websites restrict the number & choice of characters in a password?","<security><passwords>","6","4","","2015-03-03 19:25:25","","CC BY-SA 2.5"
"15360","1","15363","","2010-10-28 15:03:20","","18","6888","<p>I read <a href=""https://softwareengineering.stackexchange.com/questions/15350/why-do-websites-restrict-the-number-choice-of-characters-in-a-password/15351#15351"">this answer</a> and found a comment insisting not to send password by email:</p>

<blockquote>
  <p>passwords should not be able to be retrieved by email, I hate that. It means my password is stored in plain text somewhere. it should be reset only.</p>
</blockquote>

<p>This raises me the question of handling Forgot Password option?</p>

<p>At any cost the raw password must be displayed in any UI so that user will be able to read it. So what would be the way to handle ""Forgot Password""</p>
","156","","-1","","2017-04-12 07:31:37","2016-12-31 13:43:16","""Forgot Password"" - How to handle this?","<programming-practices><security><email><passwords>","5","4","","","","CC BY-SA 3.0"
"212971","1","","","2013-09-30 18:12:28","","2","252","<p>I'm developing an application where I'd like to use credentials from external websites. This will be used to login with the website API and get information for the user. </p>

<p>Example: I want to use the user Reddit's account to warn him if more than X people reply to one of his comment. </p>

<p>How would I go about storing the user's Reddit credentials on my end securely so I only ask once and can automate this process. Or is that even possible?</p>
","103634","","","","","2015-05-22 19:52:28","How to securely store user credentials from external website","<architecture><security><web-services>","1","2","","","","CC BY-SA 3.0"
"333533","1","","","2016-10-13 17:34:07","","2","1528","<p>I am developing a mobile application back-end service using Laravel 5.3. I am following REST API. 
Application having payment gateway integration and it needs more security.</p>

<p>I followed JWT auth by using the <code>tymon/jwt-auth</code> library for laravel.</p>

<p>I have few concerns: my token getting expired after 1 hour, after that server returning token expired error; and how can the app developer handle this situation? Asking user to log in again and again, is not possible. </p>

<p>How can app developer handle it?</p>

<p>What is the best and more secure approach?</p>
","80500","","222996","","2017-09-09 16:28:42","2017-09-09 16:28:42","How to handle JWT expiry in Laravel 5.3?","<rest><api><security><laravel><jwt>","1","0","","","","CC BY-SA 3.0"
"213085","1","213086","","2013-10-01 22:49:37","","-1","387","<p>I understand that ssh keys are a cryptographically secured way of authenticating yourself to a service or to another person, but beyond that I'm frankly at a bit of a loss.</p>

<p>What confuses me is that I see many developers mention their public key on their site, but how does one have just one key? I have a few for different things. And if my computer crashed, I would have to generate new ones. I obviously can't remember the key.</p>

<p>Do people just save it somewhere, the sequence of numbers/letters, like in their email? And then use that one key for everything? How does someone get a <em>personal</em> key?</p>

<p>I just feel like I'm missing something about this whole theater of operations.</p>

<p>I mean, we walked through RSA in university; I understand the principle, but I never used it in practice until I signed up for github and heroku and few months ago and they forced me to generate some keys, something I didn't even realize I could do before then.</p>
","56275","","","","","2013-10-01 23:51:25","How to manage your personal ssh keys?","<security>","2","5","","2013-10-03 21:07:56","","CC BY-SA 3.0"
"213173","1","","","2013-10-02 15:40:13","","5","124","<p>I've been self employed for a long time now and have recently decided that PHP development within a company is the route I'd like to go down.</p>

<p>I had an initial interview/meeting yesterday with a potential employer and It seems like a great place to work... so I wake up today and start to do a bit more research on the company and try to find out how their website functions and what software and or framework's they're using. In the process of looking for something that will give me a little advantage in the next stage of interviews, I've found a big vulnerability in the system.</p>

<p>I can get access to the database, or a large part of it at least, which has some address, sort-code, banking provider type information in it judging by the table structure.</p>

<p>Now I'm a little stuck as to what I should do next... I'd have thought it would be a plus that I've found the vulnerability, and not someone with malicious intent, but will the company see it that way too?</p>

<p>It's a fairly large UK company and what I've accessed so far is still an Illegal activity I'd have thought.</p>

<p>Should I tell them as soon as i can, hint at there being a vulnerability but not say I've actually gained access, or do i need to get some kind of NDA sorted so i don't end up at the bad end of the deal?</p>

<p>Just to clarify, I know the database structures, and i know the databases aren't empty, so I'm fairly certain there will be confidential information there. I could access that data easily, but haven't.</p>
","88456","","","","","2013-10-02 15:40:13","What To Do If I've Found a Vulnerability In a Possible Future Employers Site?","<security><ethics><vulnerabilities>","0","2","0","2013-10-02 16:49:29","","CC BY-SA 3.0"
"333752","1","333757","","2016-10-16 10:14:08","","0","56","<p>I am developing a product that uses custom hardware with accompanying software.  It requires additional components which are sold separately to make the overall application work.   </p>

<p>Using these additional components makes it similar to a razor-blade style business model (see <a href=""http://www.investopedia.com/terms/r/razor-razorblademodel.asp"" rel=""nofollow"">http://www.investopedia.com/terms/r/razor-razorblademodel.asp</a>).  The intention is to secure the product so that only the allowed add-on components can be used with the main product.  </p>

<p>The technology to do this in the application is with RFID and embedding information inside the RFID tags.  </p>

<p>To prevent easy workarounds, an approach using symmetric encryption would work however, I'm concerned with an approach that uses the same private key in every case.  </p>

<p>Therefore I'm interested in any approaches or tips with key management for this type of application.</p>
","250120","","","","","2016-10-16 12:45:02","Managing encryption keys in an application with add-on components","<security><encryption>","1","1","","","","CC BY-SA 3.0"
"333836","1","333844","","2016-10-17 14:34:51","","0","70","<p><a href=""https://softwareengineering.stackexchange.com/questions/218958/windows-console-app-vs-service#new-answer?newreg=6c6bc46f14544103bd2a90079d79b179"" title=""Windows Console App vs Service"">Windows Console App vs Service</a></p>

<p>I would like to extend the question at the above post, as the previous answers did a great job of helping me understand the difference between a service and not a service.</p>

<p>The question I have now, is with applications that require to be up 24/7, what security concerns there are with a user that is logged in, vs the service not requiring a user to be logged into the machine.  Obviously, if a user walks away without locking, that's an issue (and with redundancy, that's more than one vector of attack), but what other concerns should I be looking at to help my team understand that we're better off using a service for stuff that needs to be up 24/7?</p>

<p>Additional info, the core is on an SS7 network, with some functions migrating to IP (VoIP and mobile, for instance), so the focus of our security concerns are getting wider.</p>
","250261","","-1","","2017-04-12 07:32:04","2016-10-17 15:56:16","Windows Console App vs Service, Part II","<security><windows><operating-systems><services>","1","1","","","","CC BY-SA 3.0"
"213385","1","213387","","2013-10-04 12:46:23","","2","741","<p>I have developed a web application using zend framework, mysql, and other client side technologies like javascript, jquery ajax, kendo grid, and so on. </p>

<p>I have completed development and have done several rounds of testing to make sure the functional part is correct.</p>

<p>Now I would like to check for the vulnerabilities in my application - vulnerabilities such as</p>

<pre><code>           * sql injection 
           * ajax vulnerabilities
           * others 
</code></pre>

<p>which I don't know of. I would like to ask you guys how to check this and make the application secure.  What methods should I use to secure my application?</p>
","77051","","77051","","2013-10-08 12:53:35","2022-09-05 15:19:53","How to check for vulnerabilities in web application","<web-applications><security><ajax><vulnerabilities><sql-injection>","1","0","","2013-10-08 11:40:27","","CC BY-SA 3.0"
"334156","1","","","2016-10-20 13:49:39","","4","1618","<p>we have started with microservices recently, but we have some problems with implementing the Security layer.</p>

<p>The idea is that the request comes to Gateway, the Gateway looks to authorization header, it validates user, create JWT token and then sends request with info about user to another microservice internally. The microservice is reachable only internally, therefore it trust the JWT token.</p>

<p>In last project, we put basic info about users into gateway - it was able to register, login, reset password etc.</p>

<p>But problem is, that the core microservices was handling users too - i.e. it had some fields to validate, which is not neccesary known for gateway. The registration process need first validate at the microservice and if it was ok, it was registered on both - the gateway (password, email) and microservice (phone number, name, ...)</p>

<p>Problem is when it fails on one of the microservice but the other one does not know about it. Then it is registered on i.e. gateway, but not on microservice. It basically means you have to care about ""transactions between microservices"", which is something you dont want to (stateless microservices are best to use).</p>

<p>Also some requests - especially registration - must be handled very specifically, which increase code-base and complexity of gateway.</p>

<hr>

<p>We are thinking about another solutions:</p>

<p>1)The users logic will be put into gateway - it is similar to current situation, but there will be no validation on core microservice, which makes it stateless. The core microservice will load new users lazily - when it opens JWT token and does not find it, it will create it.</p>

<p>2)We would have two microservices, one for registering and users itself, other for the other functionality, if authorization bearer is found, gateway would ask user service microservice for detail, if it is ok, it will pack info into JWT token and send next. Registration would be just passed into user service. Core microservice would be also lazily loaded.</p>

<p>3)We put user service functionality into core microservice itself, which would make ""more monolithic"" approach, but the core microservice is heavily dependent on users. (they register into groups, buy products etc.). The gateway would work similar as in case 2), it would ask core microservice about the user info and then pack JWT token and send it next.</p>

<hr>

<p>Also take in note that we are developing small or medium projects. The whole projects usually use 1000-4000 manhours from scratch to production, the backend itself takes 500-1500 manhours (we are developing mostly mobile apps including the servers they are communicating with).</p>
","234577","","","","","2017-05-07 05:57:54","API Gateway security (for microservice architecture)","<architecture><security><microservices><development>","1","1","","","","CC BY-SA 3.0"
"17310","1","","","2010-11-06 14:19:03","","6","2652","<p>sometimes a programmer comes up with a brilliant idea to protect his/her webservice created with Windows Communication Foundation.</p>

<p>I would like to hear from you guys, which techniques do you use to protect your WCF service and avoid unauthorized users to consume it?</p>

<p>For example, you would:</p>

<ul>
<li>avoid Impersonate, use it only if necessary </li>
<li>publish metadata information to prevent tampering</li>
<li>avoid memory consuption enforcing a maximum size quota </li>
<li>create a security context token to control number of sessions</li>
</ul>
","5934","","101","","2010-11-07 13:02:23","2021-01-25 06:50:28","How do you protect your WCF service?","<security><services><wcf>","1","3","","","","CC BY-SA 2.5"
"334474","1","","","2016-10-24 13:59:49","","0","108","<p>Shared Access Signature is a delegated access mechanism available for Azure resources and account. Based on the documentation here - <a href=""https://azure.microsoft.com/en-in/documentation/articles/storage-dotnet-shared-access-signature-part-1/"" rel=""nofollow"">https://azure.microsoft.com/en-in/documentation/articles/storage-dotnet-shared-access-signature-part-1/</a>, it is clear SAS is never linked to a user principal. Thus making it <strong>vulnerable to repudiation</strong> and defeating the very meaning of <strong>access</strong>. </p>

<p>Please help me in understanding the rationale of using SAS the way it is implemented Azure.</p>
","122500","","122500","","2016-10-24 14:07:42","2017-06-21 21:17:41","How could Azure's implementation of SAS be called Delegated Access Mechanism?","<security><azure>","1","0","","","","CC BY-SA 3.0"
"104830","1","104832","","2011-08-16 19:34:35","","5","261","<p>I'm interested in expanding my knowledge of security issues: things like buffer overflows, format string vulnerabilities, etc. I'd like to be able to go through a language and understand its security implications and pitfalls to get a better understanding of secure coding practices in general.</p>

<p>Are there certain languages that are more conducive to a learning experiment like this? Are there languages, due to abstractions or complexity, I should avoid? Where should I start?</p>
","14872","Atul Goyal","","user8","2011-08-31 08:52:40","2011-08-31 09:19:12","Are there languages that make it easier to understand secure coding principles?","<security><secure-coding>","4","2","0","","","CC BY-SA 3.0"
"334650","1","359579","","2016-10-26 10:57:01","","2","1147","<p>How do you keep track of maven dependency versions?</p>

<p>Let's say you are using version <code>1.0.5</code> of an library.</p>

<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;groupIdName&lt;/groupId&gt;
    &lt;artifactId&gt;artecfact-id&lt;/artifactId&gt;
    &lt;version&gt;1.0.5&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>

<p>But some people find a very bad security bug in version <code>1.0.5</code> and they release version <code>1.0.6</code> with a bugfix for this security vulnerability.</p>

<p>How do you manage in your project to <strong>know</strong> that there is a new <strong>important</strong> version, where it's very important to update?  </p>

<p>I'm sure, no one is looking every week: Is there a new update to all the projects?<br>
Even with watching the github projects, it will end up in a mess, because there are too many dependencies to watch in big projects.</p>

<p>We are using <code>Gitlab</code> and <code>Jenkins</code> in our environment, so if there are good plugins for that tools, or something else like <code>Sonar</code> can help here, let me know.</p>

<p>Looking forward for this discussion!<br>
(I hope the softwareengineering on stackexchange is the right place for this discussion)</p>
","57901","","","","","2017-10-23 20:23:38","How to keep track of maven dependency updates in projects?","<security><dependency-management><maven><jenkins><gitlab>","2","2","","","","CC BY-SA 3.0"
"104967","1","","","2011-08-31 12:52:15","","5","481","<p>I am looking for the current, state of the art, coding standards for web development (mostly PHP). Since I do not want to reinvent the wheel I would like to reuse libraries written by people much clever than I am.</p>

<p>I know about OWASP which is a wonderful source of best practices and brilliant information. Their web site is however quite unorganized when it comes to libraries.</p>

<ul>
<li>On the one hand there is OWASP ESAPI with pointers to libraries.</li>
<li>On the other hand there is OWASP AntiSamy, which also has libraries. It in turn points to HTMLPurifier or the MS Anti-XSS library.</li>
</ul>

<p>I did not find any links between these different solutions.</p>

<p>Is there currently a consensus on the most recommendable libraries to use in order to mitigate the major security risks? </p>

<p>Thank you</p>
","35682","","","","","2012-01-23 11:27:52","Web application development security best practices","<security><secure-coding>","2","0","","2014-12-19 20:09:49","","CC BY-SA 3.0"
"214351","1","","","2013-10-14 06:50:54","","3","1656","<p>We are considering using the <a href=""https://gist.github.com/esp0/6971694"" rel=""nofollow"">Dynamic.CS linq-sample</a> included in the ""Samples"" directory of visual studio 2008 for our WebAPI project to allow clients to query our data. </p>

<p>The interface would be something like this (In addition to the normal GET-methods):</p>

<pre><code>public HttpResponseMessage List(string filter = null);
</code></pre>

<p>The plan is to use the dynamic library to parse the ""filter""-variable and then execute the query agains the DB. Any thoughts if this is a good idea? Is it a security problem?</p>
","13115","","","","","2013-10-24 07:50:13","Using Dynamic LINQ to get a filter for my Web API","<.net><security><api-design><linq>","1","1","","","","CC BY-SA 3.0"
"214839","1","224165","","2013-10-18 13:45:23","","3","144","<p>I have some web sites programmed, I know to do it with python and PHP basically. Normally they are simple web sites, but now I want to provide REST web services but only for allowed users (allowed by me).</p>

<p>I saw that a lot of services uses the ""KEY"" and ""SECRET_KEY"" concepts, which seems to be what I need (if I understand it right).</p>

<p>My suppositions are:</p>

<ol>
<li>If I only do a GET service to retrieve, e.g., all my clients, without anymore, anyone can retrieve my clients without limitations.</li>
<li>I will need some KEY generator to provide keys for my allowed users, so they can use my webservices.</li>
<li>Only with a KEY is not enough: someone can steal a KEY and supplant my user (and this is the reason because exists a SECRET_KEY, right?).</li>
</ol>

<p>If all this is right, how can I make/use a system like that in my web services? Some open source example?</p>

<p>Or maybe there are another easy solutions I'm not considering?</p>

<p>My objective is to allow some users to use my web services.</p>
","105370","","31260","","2013-10-18 14:26:23","2014-01-14 19:59:43","Some hint to program a webservice ""by subscription""","<security><web-services>","1","4","","","","CC BY-SA 3.0"
"214870","1","","","2013-10-18 17:10:01","","2","671","<p>It seems like there's a new major security hole patched in Java every other week, and I would assume the same goes for other development platforms.  After years of frustration trying to get customers to install and configure a compatible JRE on their systems, we started bundling one with our software.  (By bundling, I mean we extract a copy of the JRE in our installation directory--we don't install the JRE and configure it as the system default.)</p>

<p>The problem is, it's a hassle having to keep that JRE up-to-date because first we have to retest everything to make sure the update didn't break anything (it has broken some of our third-party dependencies in the past).</p>

<p>How seriously, if at all, are we putting our customers at risk if we don't update our SDK/JDK and the runtime/JRE that we bundle with our product every time there's a security update?  Is it reasonable to just update on a periodic schedule--say, once every 6 months or so?</p>
","44874","","62539","","2013-10-18 17:28:02","2013-10-18 17:41:27","What am I risking if I don't update my SDK/JDK and bundled runtime/JRE every time there's a security update?","<security><software-updates><runtime><sdk>","1","12","","","","CC BY-SA 3.0"
"214968","1","215605","","2013-10-19 20:46:33","","2","244","<p>There is a growing industry now with more than 30 companies playing in the Backend-As-A-Service (BaaS) market.</p>

<p>The principle is simple: give companies a secure way of exposing data housed on premises and behind the firewall publicly.</p>

<p>This can include database data, as well as Legacy PC data through established connectors; SAP for example provides a connector for transacting with their legacy systems.</p>

<p>Early attempts were fixed providers for specific systems like SAP, IBM or Oracle, but the new breed is extensible, allowing Channel Partners and Consultants to build robust integration applications that can consume whatever data sources the client wants to expose.</p>

<p>I just happen to be close to finishing a Cloud Based HTML5 application platform that provides robust integration services, and I would like to break ground on an extensible data proxy to complete the system.</p>

<p>From what I can gather, I need to provide either an installable web service of some kind, or a Cloud service which the client can configure with VPN for interactions.</p>

<p>Then I can build in connectors, which can be activated with a service account, and expose those transactions via web services of some kind (JSON, SOAP, etc).</p>

<p>I can also provide a framework that allows people to build in their own connectors, and use some kind of schema to hook those connectors into the proxy.</p>

<p>The end result is some kind of public facing web service that could securely be consumed by applications to show data through HTML5 on any device.</p>

<p>My gut is, this isn't as hard as it sounds. Almost all of the 30+ companies (With more popping up almost weekly) have all come into existence in the last 18 months or so, which tells me either the root technology, or the skillset to create the technology is in abundance right now.</p>

<p>Where should I start on this? Are there some open source projects I can leverage? A specific group of developers I can hire? I'm confident someone here can set me on the right path and save me some time.</p>

<p>You don't see this many companies spring up this rapidly if they are all starting from scratch with proprietary technology.</p>

<p><a href=""http://www.theregister.co.uk/2013/08/17/firebase_baas_ga/"" rel=""nofollow"" title=""The Register: WTF is Baas"">The Register: WTF is BaaS</a></p>

<p><a href=""http://www.kony.com/products/development/integration"" rel=""nofollow"">One Minute Video from Kony on their BaaS </a></p>
","62802","","","","","2013-10-26 05:15:58","Principles of an extensible data proxy","<architecture><security><enterprise-architecture><extensibility>","2","0","","","","CC BY-SA 3.0"
"335742","1","335743","","2016-11-10 00:53:29","","2","386","<p>I'm having a difficult time conceptualizing the purpose of a multi-claims-based authorization system. For example, ASP.NET MVC Identity allows for key-value pairs called claims that you can store on a given user. However, each user already comes with a unique ID (if you use the default setup). So say I wanted to authorize a user by a custom claim like ""group number."" What benefit would putting this information into the token as a claim give my application when I could just use the user's ID number and compare that with a DB table which associates the user with their group number?</p>

<p>Also, is the user ID number itself a claim? I've had a difficult time finding a concise explanation of how this works. Thank you.</p>
","237893","","","","","2016-11-10 01:27:38","What is the purpose of a multi-claims-based authorization system?","<security><authentication><authorization>","1","0","","","","CC BY-SA 3.0"
"106714","1","106716","","2011-09-08 16:17:18","","3","664","<p>Recently my university updated their password storage procedure, and they have several criteria such as that the password must contain a number, symbol, and uppercase character, and has a length requirement. Realistically, when a brute force / dictionary attack is being performed, doesn't this just make it easier for the person to crack one that works? I understand that this is to prevent people from doing things like ""password,"" but what about one such as ""youwillneverguessmypassword"" ?   </p>
","33737","","","","","2011-09-08 18:17:41","Does forcing a user to add numbers or uppercase letters really make a password stronger?","<security><user-experience>","3","8","0","2011-09-08 19:18:21","","CC BY-SA 3.0"
"215943","1","","","2013-10-19 10:13:04","","2","410","<p>So I have been searching everywhere and havn't been able to find anything with the sufficient information I need.. so Im a bit stumped on this one at the moment</p>

<p>What I am trying to do is create a public/private key pair (like PGP) upon a users account creation, based on their passphrase and a random seed. The public key would be saved on the server, and ideally the private key would never be seen by the server whatsoever. The user could then sign in, and send a message to another user. Before the message is sent, the senders key pair would be re-generated on the fly based on their credentials (and maybe a password prompt) and used to encrypt the message. The receiver would then use their own re-generated private key to decrypt said message.</p>

<p>The server itself should never see any plaintext passwords, private keys or readable messages. </p>

<p>Bit unsure how on how I could go about implementing this. Iv been looking into PGP, specifically openPGP.js. The main trouble I am having is being able to regenerate the key-pair based off a specific seed. PGP seems to have a random output even if the inputs are the same. Storing the private key in a cookie or in HTML5 storage or something also isnt really an option, too unreliable.</p>

<p>Can anyone point me in the right direction?</p>
","","SlickTheNick","","","","2013-10-29 23:15:26","Creating deterministic key pairs in javascript for use in encrypting/decrypting/signing messages","<javascript><security>","1","2","","","","CC BY-SA 3.0"
"336110","1","","","2016-11-15 16:38:04","","4","323","<p>Our customer (a bank) needs to publish a web-service API for use by 3rd party applications. The security is going to involve OAuth2 and JWT (JSON Web Token).
The problem is that the customer is afraid of misuse of the published APIs by the 3rd parties to whom they don't trust completely (please, don't comment on this). A basic scenario is like this:</p>

<p>The public API contains an operation IsOurCustomer() that returns true/false if the person has a product in the bank. The subsequent operation is CreateNewCustomer(), and is called when IsOurCustomer() returns false.</p>

<p>The bank is afraid that a 3rd party could scan their customer-base by checking who is/isn't their customer via calling IsOurCustomer() sequentially for all people taken from another source (say from a public state registry). (I can't tell whether the presumed damage is real, or whether it's a paranoia only.)</p>

<p><strong>Is there a way how to prevent the possibility of data-scanning?</strong></p>

<p>There are some partial solutions we came with, but none of them mitigates the problem completely:</p>

<ol>
<li><em>Throttling</em> - It's hard to set the right limit which wouldn't restrict the legal work of the 3rd party company, but would prevent them to misuse the API at the same time. Especially, when the 3rd party has many employees and enough time. The 3rd party could issue thousands of (justified) customer-checks per day, which could allow them to scan 1 million of people per year.</li>
<li><em>Legal threats</em> - when API misuse is detected (which needs logging, monitoring).</li>
<li><em>Payments per API call</em> - above an agreed limit</li>
<li><em>Heuristics</em> - e.g. signal an alert when the ratio of calls to IsOurCustomer() and CreateNewCustomer() is too high.</li>
<li>""Data Leak Prevention system"" - I don't know of any usable DLP for our purpose.</li>
</ol>
","253747","","","","","2016-11-15 22:07:10","How to prevent data-scanning via public API?","<security><web-services><api-design>","4","6","","","","CC BY-SA 3.0"
"336168","1","","","2016-11-16 12:53:11","","2","128","<p>The scenario:</p>

<ul>
<li>Our customer creates physical devices used in infrastructure across the globe</li>
<li>Their new devices have IoT capabilities and can communicate their status and other sensor data to the cloud</li>
<li>We are building a web portal that displays information about these devices</li>
<li>This web portal provides access to customers and to their staff</li>
</ul>

<p>The need:</p>

<p>We need to build a secure customer registration process that ensures the person who registers an account with the portal is their actual customer, and gains access to the data emitted from the device they own.</p>

<p>The current process, as outlined so far:</p>

<p>When a device is sold their ERP system will inform the customer portal, via a secure connection (API), that a device has been sold.  It will include device details (serial number, etc.) and some customer information (note: the customer information at this point may belong to a wholesaler and not be the end customer we are interested in).</p>

<p>The devices will include some kind of label with a QR code/URL/key that can be used to register the device.</p>

<p>The problem: it is difficult to make this secure, because, for example, it would be possible for someone to photograph the QR code while the device is in transit.  Someone with the photograph could then register the device inappropriately.</p>

<p>Ideas:</p>

<ul>
<li>Create a tamper-proof label, such as something that you can scratch the surface of (like a lottery ticket) to reveal a secret key used for registration.  Include a big warning that, if you are the end user and this label has been tampered with, you need to inform the company immediately.</li>
<li>Try to develop some kind of two-factor authentication, whereby on registration with the portal, the portal informs the ERP of registration, and the ERP sends an email to the customer to verify the registration.  Problem with this approach is the wholesaler situation I mentioned previously.</li>
<li>Request that the customer enter some kind of information that only they, and the origin company know, such as order ID.  Problem with this is that it's not terribly secure, the order ID may appear on bills of sale, shipping forms, etc.</li>
</ul>

<p>Can anyone suggest a secure method of doing this?  Is there an existing solution or pattern we can adopt?  Thoughts welcome - thanks!</p>
","253879","","61852","","2016-11-16 18:16:10","2016-11-16 18:41:09","Designing a secure system that verifies the person registering a product is the end-user/customer","<design-patterns><architecture><security>","1","4","","","","CC BY-SA 3.0"
"336175","1","336185","","2016-11-16 15:06:43","","4","3332","<p>So I will be creating a feature to a php application that does the following:</p>

<ul>
<li>Create a session that expires after 30 minutes.</li>
<li>After 30 minutes, if there is no user activity in the application (including typing to a textbox, moving a mouse throughout the page), the session will be destroyed and the system will redirect itself to a logout page (logout.php). What I mean by keyboard/mouse is only specific to the system, if the system is open while I am doing other things outside of the system, the system should consider it idol.</li>
<li>If the session has moments left to live (E.G. 15 seconds) and there is user activity, the session's life would be extended to another 30 minutes. The reason for this is if a user is inputting a critical information, it would be highly inconvenient to log him/her out just before submitting the form. This is why keyboard and mouse movements should be detected by the system.</li>
</ul>

<p>I have come up with two possible solutions, but I am not satisfied with them.</p>

<h2>First solution</h2>

<p>I will almost use javascript for everything.</p>

<ul>
<li>Manage the session or cookie (I am not really sure if javascript recognizes server side sessions)</li>
<li>Detect keyboard/mouse activity</li>
<li>Extend the life of the session/cookie</li>
<li>Redirect to logout.php to destroy the session</li>
</ul>

<p>I believe this solution is extremely bad. I believe there are ways to manipulate javascript code to change it (to prevent the redirection to logout.php, for example). That is, I am doing a process that should be done in the server.</p>

<h2>Second solution</h2>

<ul>
<li>use javascript to detect keyboard/mouse activity as before.</li>
<li>15 seconds before 30 minutes, I will have to send an ajax request to a php page. The ajax request contains the information whether there is user activity during this time.</li>
<li>Now this particular php page manages the information sent by ajax. If user activity is detected, php just extends the session's life. Otherwise it has to redirect to logout.php either through ajax's .done function or through other means.</li>
</ul>

<p>I don't think the processes I described above are good solutions. Specifically the heavy use of javascript to do server side things. My problem is I cannot find a way to detect keyboard/mouse movements using php. Everything I found regarding how to do this is by using javascript (understandably since user actions are done in the browser and not in the server).</p>

<p>How should I proceed? What would be the best and most secure solution?</p>
","144461","","144461","","2016-11-16 16:18:43","2016-11-17 19:07:37","Managing session timeouts with regards to user activity in the page","<php><javascript><security><ajax><session>","2","6","","","","CC BY-SA 3.0"
"336195","1","336233","","2016-11-16 18:06:36","","3","426","<p>For example, web application monitoring services like New Relic RUM or Bucky use JavaScript to collect data on a user's session and eventually send that data back to an endpoint. For New Relic, the data is sent to an endpoint like ""<a href=""http://bam.nr-data.net"" rel=""nofollow noreferrer"">http://bam.nr-data.net</a>"" with a great deal of parameters. With Bucky a similar payload is sent to an endpoint of your choosing.</p>

<p>How do these services prevent malicious users from abusing those endpoints? Couldn't a user easily mess with the JavaScript to send junk data? And, with a little more work, might they be able to send many payloads of that junk data, polluting the data these services are meant to collect?</p>

<p>I'm not a front-end developer myself (in DevOps), but from what I understand it is <a href=""https://softwareengineering.stackexchange.com/questions/251707/client-side-coding-how-to-prevent-malicious-use"">essentially impossible</a> to completely prevent abuse of anything accessible in client-side code. Other <a href=""https://softwareengineering.stackexchange.com/questions/317174/prevent-abuse-to-rest-api-endpoint"">answers here on SE</a> and elsewhere suggest the same.</p>

<p>Are these services simply biting the bullet and hoping nobody abuses them? Do they rely on obscurity/obfuscation to minimize the chances? Or have they figured out a way to mitigate the implications of the client-accessible nature?</p>
","253908","","-1","","2017-04-13 12:45:55","2016-11-17 08:23:18","How do services that rely on client-side access to an API or data consumption endpoint prevent abuse?","<javascript><web-development><rest><security><client-side>","2","5","","","","CC BY-SA 3.0"
"20663","1","20668","","2010-11-22 17:48:02","","6","8033","<p>I'm working on a decentralized transaction processing system that needs both authentication and general encryption, and I have a design decision to make: should I use PGP or X.509 certificates?</p>

<p>While the world tends to use X.509 for authentication (especially in browsers), they are based on the principle of having a <em>central</em> authority vouch for each certificate, meaning the system would need a CA and anyone who wants to participate in the system would need to have their keys signed by that CA.</p>

<p>PGP, on the other hand, is based on a ""Web of Trust"", where parties who want to communicate merely need to have <em>any</em> trusted party in common who will sign both keys. A CA isn't necessary in this case.</p>

<p>My overall design goals prefer the Web-of-Trust model, to keep the system decentralized, but I may also have customers who prefer a centralized model, and I don't want to prohibit that possibility. Is there anything stopping the Web-of-Trust principle from working with X.509? Likewise, is it easy and straightforward to mimic CAs in the PGP cryptosystem? Are they interchangeable in practice?</p>

<p>(For some reason, this is making me think of the false dichtomy: ""I'm trying to bang in a nail, should I use a beer bottle or the heel of a shoe?"")</p>
","4788","","4788","","2010-11-22 22:20:32","2010-11-22 22:20:32","Are PGP keys as good for certificates as X.509 keys?","<security><encryption>","1","0","","","","CC BY-SA 2.5"
"21339","1","21344","","2010-11-25 00:50:42","","23","11094","<p>I have been using the <a href=""http://www.projecthoneypot.org"" rel=""noreferrer"">http:BL</a> to block bad IP's from accessing my site.</p>

<p>If a malicious IP (comment spammer) trys to hit the site I just <code>exit</code> the web script which implicitly returns a <code>200 OK</code> response. </p>

<p>Other responses I could return:</p>

<p>404 - Not found?</p>

<p>If I return a 404 maybe the robots will think ""this is a waste of time, lets move on to attack another site"" which would reduce the load on the site (I currently get about 2 spam-hits per second).</p>

<p>However</p>

<ul>
<li>I'm reluctant to return 404's on urls that, under normal circumstances, <em>can</em> be found. </li>
<li>I'm not sure if spam robots can 'waste time'. i.e Why would a bot writer be bothered to code for 404's when they just blitz the web anyway?</li>
</ul>

<p>401 Unauthorized?</p>

<p>Blocking a bad IP is not quite the same as ""resource requires user authentication 1) which has not yet been provided or 2) which has been provided but failed authorization tests""</p>

<hr>

<p>In general I feel that 'responding to the bad-bots according to proper http protocol' gives the bad guys the upper hand. In the sense that I play by the rules while they do not. On some days I feel like I should do something clever to divert these bot's away. On other days I just think that I should not take it personally and just ignore them. Accepting it as par for the course of running a web site. </p>

<p>I dunno - what are your thoughts? How do you respond when you know its a bad IP?</p>
","6720","","261535","","2020-05-13 12:20:48","2020-05-13 21:19:43","Which http response do you return to a hit from a blacklisted ip?","<security>","4","4","","","","CC BY-SA 4.0"
"216605","1","216607","","2013-11-05 18:20:56","","30","11236","<p>I'm diving deeper into developing RESTful APIs and have so far worked with a few different frameworks to achieve this. Of course I've run into the same-origin policy, and now I'm wondering how web servers (rather than web browsers) enforce it. From what I understand, some enforcing seems to happen in the browser's end (e.g., honoring an Access-Control-Allow-Origin header received from a server). But what about the server?</p>

<p>For example, let's say a web server is hosting a Javascript web app that accesses an API, also hosted on that server. I assume that the server would enforce the same-origin policy --- so that only the javascript that is hosted on that server would be allowed to access the API. This would prevent someone else from writing a javascript client for that API and hosting it on another site, right? So how would a web server be able to stop a malicious client that would try to make AJAX requests to its API endpoints while claiming to be running javascript that originated from that same web server? What's the way most popular servers (Apache, nginx) protect against this kind of attack? Or is my understanding of this somehow off the mark?</p>

<p>Or is the cross-origin policy only enforced on the client end?</p>
","103795","","31260","","2013-11-11 13:49:59","2013-11-12 10:29:24","How do web servers enforce the same-origin policy?","<web-development><security><ajax><http><xmlhttprequest>","5","1","","","","CC BY-SA 3.0"
"216617","1","216618","","2013-11-05 20:16:57","","1","4167","<p>I'm writing a Server/Client application where clients will connect to the server. What I want to do, is make sure that the client connecting to the server is actually using my protocol and I can ""trust"" the data being sent from the client to the server. </p>

<p>What I thought about doing is creating a sort of hash on the client's machine that follows a particular algorithm. What I did in a previous version was took their IP address, the client version, and a few other attributes of the client and sent it as a calculated hash to the server, who then took their IP, and the version of the protocol the client claimed to be using, and calculated that number to see if they matched. This works ok until you get clients that connect from within a router environment where their internal IP is different from their external IP. My fix for this was to pass the client's internal IP used to calculate this hash with the authentication protocol. My fear is this approach is not secure enough. Since I'm passing the data used to create the ""auth hash"".</p>

<p>Here's an example of what I'm talking about:</p>

<pre><code>Client IP: 192.168.1.10, Version: 2.4.5.2
hash = 2*4*5*1 * (1+9+2) * (1+6+8) * (1) * (1+0)
Client Connects to Server
client sends: auth hash ip version
Server calculates that info, and accepts or denies the hash.
</code></pre>

<p>Before I go and come up with another algorithm to prove a client can provide data a server (or use this existing algorithm), I was wondering if there are any existing, proven, and secure systems out there for generating a hash that both sides can generate with general knowledge. The server won't know about the client until the very first connection is established.</p>

<p>The protocol's intent is to manage a network of clients who will be contributing data to the server periodically. </p>

<p>New clients will be added simply by connecting the client to the server and ""registering"" with the server. So a client connects to the server for the first time, and registers their info (mac address or some other kind of unique computer identifier), then when they connect again, the server will recognize that client as a previous person and associate them with their data in the database.</p>

<p>Edit:
The approach I ended up going was this:</p>

<p>I ended up using an approach similar to what OpenSSH does, but reverse. Since when a client connects, I'm not sure I can trust the client.</p>

<p>If it is the first time a client is connecting, it will provide me with a public key and a unique identifier (In this case, I will be using a computer's service tag since the computers I'm going to be dealing with are all Dells). The server stores the id and public key in the database then sends the client a secret question encrypted using the public key. The client will then need to respond with the decrypted answer. Before a client can be accepted by the server, I may end up doing a unique id registration on the server manually before connecting the client for the first time, this way not any sly person can just generate public keys and emulate what a client does with a ""new unique id"". </p>

<p>Thanks for the help! I hope this helps someone down the line. Feel free to tear apart the security flaws of this approach :)</p>
","106973","","106973","","2013-11-07 00:13:01","2017-07-10 08:21:53","Approach to Authenticate Clients to TCP Server","<algorithms><security><authentication>","1","4","","","","CC BY-SA 3.0"
"216700","1","","","2013-11-06 16:24:49","","2","1336","<p>Would like to hear from those working in a PCI compliance environment and is practicing agile development and devops methodology, how you maintain compliance with PCI requirements.</p>

<p>Specifically, what do you do to address:</p>

<ul>
<li>separation of duties between development/test and production</li>
<li>alignment of continuous integration / deployment and change control</li>
<li>alignment of agile stories to requirement documentation</li>
</ul>
","107049","","","","","2013-11-06 16:50:09","Making Agile and DevOps methodology compatible with PCI requirements","<agile><development-process><security><legal>","1","0","","2013-11-07 22:46:45","","CC BY-SA 3.0"
"216909","1","216912","","2013-11-08 14:35:03","","1","96","<p>I'm using a CRON on AppEngine and the cron calls my web app at a specific app.</p>

<p>I only want to execute functionality when called by my AppEngine app.</p>

<p>What's is/are recommended approach to confirming that the caller is legitimate? I don't wish to rely on no one else knowing the specific URL.</p>
","107242","","","","","2013-11-08 15:10:54","Recommended secure approach to confirming an URL is called by a legitimate caller","<security>","2","2","","","","CC BY-SA 3.0"
"336748","1","","","2016-11-24 09:42:02","","-2","263","<p>Following the recent incident on reddit (viz <a href=""https://www.reddit.com/r/The_Donald/comments/5ekdy9/the_admins_are_suffering_from_low_energy_have/dad5sf1/"" rel=""nofollow noreferrer"">https://www.reddit.com/r/The_Donald/comments/5ekdy9/the_admins_are_suffering_from_low_energy_have/dad5sf1/</a>) where the CEO of Reddit changed content of certain posts without any notification to anyone.</p>

<p>Is there any way to secure a forum database so it's tamperproof even when accessed by root? It doesn't have to be tamperproof in the sense that root couldn't change it, but it should leave a clear mark.</p>

<p>I'm thinking something along the lines of cryptographic signature of the posts by the poster where (maybe) his password could be used to sign the post while the hash on server could be used to validate that the content is unchanged. However, it would be prefarable to not request the user password every time he wants to post something.</p>

<p><strong>UPDATE:</strong> It should remain centralized, so blockchain doesn't really work here.</p>

<p>Also, why the downvotes?</p>
","149353","","149353","","2016-11-24 21:20:25","2016-11-24 21:20:25","Is there any way to build a tamperproof forum like Reddit?","<database><security>","3","0","","2016-11-28 14:04:18","","CC BY-SA 3.0"
"216998","1","217001","","2013-11-09 17:15:22","","35","6971","<p>You maintain an existing application with an established user base. Over time it is decided that the current password hashing technique is outdated and needs to be upgraded. Furthermore, for UX reasons, you don't want existing users to be forced to update their password. The whole password hashing update needs to happen behind the screen.</p>

<p>Assume a 'simplistic' database model for users that contains:</p>

<ol>
<li>ID</li>
<li>Email</li>
<li>Password</li>
</ol>

<p>How does one go around to solving such a requirement?</p>

<hr>

<p>My current thoughts are:</p>

<ul>
<li>create a new hashing method in the appropriate class</li>
<li>update the user table in the database to hold an additional password
field</li>
<li>Once a user successfully logs in using the outdated password hash, fill the second password field with the updated hash</li>
</ul>

<p>This leaves me with the problem that I cannot reasonable differentiate between users who have and those who have not updated their password hash and thus will be forced to check both. This seems horribly flawed.</p>

<p>Furthermore this basically means that the old hashing technique could be forced to stay indefinitely until every single user has updated their password. Only at that moment could I start removing the old hashing check and remove the superfluous database field.</p>

<p>I'm mainly looking for some design tips here, since my current 'solution' is dirty, incomplete and what not, but if actual code is required to describe a possible solution, feel free to use any language.</p>
","33514","","","","","2018-06-20 08:35:34","Updating password hashing without forcing a new password for existing users","<security><language-agnostic><passwords>","6","6","","","","CC BY-SA 3.0"
"336966","1","","","2016-11-27 17:36:07","","0","163","<p>What data structures and algorithms are suitable for event stream correlation? Specifically, I am looking at these two use cases:</p>

<ol>
<li>X occurrences within t seconds grouped by some variables (v1,v2). For example, 5 failed login attempts within a minute grouped by service such as SSH or FTP and IP address.</li>
<li>Event A is followed by events B and C grouped by some variables (v1,v2) within a time-frame t.</li>
</ol>

<p>In terms of actual implementation, I have found the <a href=""https://simple-evcorr.github.io/"" rel=""nofollow noreferrer"" title=""Simple Event Correlator"">Simple event Correlator</a>
to be approximately what I am looking for, but it's a big blob of perl...</p>
","255013","","","","","2016-11-27 20:48:09","Data structures and algorithms for event correlation","<algorithms><security><data-structures>","1","0","","","","CC BY-SA 3.0"
"218306","1","218419","","2013-11-13 06:49:30","","73","31905","<p>In my education I have been told that it is a flawed idea to expose actual primary keys (not only DB keys, but all primary accessors) to the user.</p>

<p>I always thought it to be a security problem (because an attacker could attempt to read stuff not their own).</p>

<p>Now I have to check if the user is allowed to access anyway, so is there a different reason behind it?</p>

<p>Also, as my users have to access the data anyway I will need to have a public key for the outside world somewhere in between. Now that public key has the same problems as the primary key, doesn't it?</p>

<hr>

<p>There has been the request of an example on why do that anyway, so here is one.
Keep in mind that the question is meant to be about the principle itself not only if it applies in this example. Answers addressing other situations are explicitly welcome.</p>

<p>Application (Web, Mobile) that handles activity, has multiple UIs and at least one automated API for intersystem communication (e.G. the accounting department wants to know how much to charge the customer based on what has been done).
The Application has multiple customers so separation of their data (logically, the data is stored in the same DB) is a must have of the system. Each request will be checked for validity no matter what.</p>

<p>Activity is very fine granular so it is together in some container object, lets call it ""Task"".</p>

<p>Three usecases:</p>

<ol>
<li>User A wants to send User B to some Task so he sends him a link (HTTP) to get some Activity done there.</li>
<li>User B has to go outside the building so he opens the Task on his mobile device.</li>
<li>Accounting wants to charge the customer for the Task, but uses a third party accounting system that automatically loads the Task / Activity by some code that refers to the REST - API of the Application</li>
</ol>

<p>Each of the usecases requires (or gets easier if) the agent to have some addressable identifier for the Task and the Activity.</p>
","36528","","247375","","2017-08-28 18:49:22","2017-08-28 18:49:22","Why not expose a primary key","<design><security><theory>","9","7","","","","CC BY-SA 3.0"
"23146","1","23147","","2010-12-02 15:40:12","","21","824","<p>I am having a disagreement with a client about the user authentication process for a system. The nub of it is that they want <em>each user to have a globally unique password</em> (i.e. no two users can have the same password).</p>
<p>I have wheeled out all the obvious arguments against this:</p>
<ul>
<li>It's a security vulnerability.</li>
<li>It confuses identification with authentication.</li>
<li>It's pointless.</li>
<li>etc.</li>
</ul>
<p>Still they are insisting that there is nothing wrong with this approach.</p>
<p>I have done various Google searches looking for authoritative (or semi-authoritative , or even just independent) opinions on this, but can't find any (mainly it's just such an obvious faux pas that it doesn't seem worth warning against, as far as I can tell).  Can anybody point me towards any such independent opinion, please?</p>
<hr />
<p><strong>EDIT</strong>: Thanks for all your answers, but I already understand the problems with this proposed approach/requirement, and can even explain them to the client, but the client won't accept them, hence my request for independent and/or authoritative sources.</p>
<p>I'd also found the Daily WTF article, but it suffers from the problem that Jon Hopkins has pointed out - that this is such a self-evident WTF that it doesn't seem worth explaining <strong>why</strong>.</p>
<p>And yes, the passwords are going to be salted and hashed. In which case global uniqueness might well be difficult to ensure, but that doesn't solve my problem - it just means that I have a requirement that the client won't budge on, that's not only ill-advised, but is also difficult to implement. And if I was in a position to say &quot;I'm not budging on salting and hashing&quot;, then I'd be in a position to say &quot;I'm not implementing globally unique passwords&quot;.</p>
<p>Any pointers to independent and/or authoritative sources for why this is a <strong>bad</strong> idea still gratefully received...</p>
","2180","","223418","","2023-07-15 21:36:18","2023-07-16 11:50:34","Citations for inadvisability of globally unique password","<security><passwords>","9","9","","","","CC BY-SA 4.0"
"219019","1","","","2013-11-20 16:26:21","","3","437","<p>As I understand in most security breach where the list of hashed password are compromised, attackers do use brute-force to try to find weak password and, invariably, they always find quite some (like in the recent Github breach).</p>

<p>If I'm not mistaken in most cases when a user creates an account, the password is sent, encrypted (due to TLS / SSL), to the website which then adds some salt and stores the hash + salt.</p>

<p>Even in most sophisticated cases (like when bcrypt is used), upon account creation there's one point in time at which the server does have the password in cleartext.</p>

<p>My question is: couldn't you use, at that very moment when you have the password in the clear that the user is trying to use for his new account, a gigantic rainbow-table on the server side to check for billions and billions of weak passwords in a split-nanosecond?</p>

<p>Then if you detect that a weak password is used, you'd simply tell to the user that his password is too simple and that, no, using ""edcrfvtgb1"" isn't smart.</p>

<p>I mean: if attackers manage to brute-force weak-password <em>even though they have to deal with the problem of the salt</em>, couldn't servers benefit from the fact that, when the users creates a new account, they do know the password in the clear to simply look it up in a big rainbow table when the user creates his account?</p>

<p>This doesn't seem hard to implement and seen harddisk sizes these days, it's probably not problematic to store a big rainbow table on the server side.</p>

<p>Am I missing something obvious or would this help catch a <em>lot</em> of weak passwords and, hence, mitigate the endless accounts compromise we keep seeing on a nearly daily basis?</p>
","39479","","","","","2013-11-21 15:58:45","Would using rainbow tables to detect weak user passwords feasible?","<security><passwords><hashing>","2","5","","","","CC BY-SA 3.0"
"219028","1","","","2013-11-20 17:43:21","","115","81089","<p>How do I make sure my REST API only responds to requests generated by trusted clients, in my case my own mobile applications? I want to prevent unwanted requests coming from other sources. I don't want users to fill in a serial key or whatever, it should happen behind the scenes, upon installation, and without any user interaction required.</p>

<p>As far as I know, HTTPS is only to validate the server you are communicating with is who it says it is. I'm ofcourse going to be using HTTPS to encrypt the data. </p>

<p>Is there a way to accomplish this? </p>

<p><strong>Update:</strong>
The user can perform read-only actions, which do not require the user to be logged in, but they can also perform write actions, which do require the user to be logged in (Authentication by Access Token). In both cases I want the API to respond to requests coming only from trusted mobile applications.</p>

<p>The API will also be used for registering a new account through the mobile application.</p>

<p><strong>Update 2:</strong> It seems like there are multiple answers to this, but I honestly don't know which one to flag as the answer. Some say it can be done, some say it can't. </p>
","106175","","106175","","2013-11-21 10:48:38","2021-12-13 06:37:41","How to safeguard a REST API for only trusted mobile applications","<security><rest><mobile>","9","4","","","","CC BY-SA 3.0"
"219198","1","219199","","2013-11-22 08:56:59","","11","1500","<p>I was signing up for a website last night, and once again was greeted with the fact that my username cannot contain certain characters (including spaces), and neither could my password.</p>

<p>Is there a historic reason for this, or is there no particular reason?  Passwords that are phrases have higher entropy and are harder to crack than simple letter/number substitution (see image below):</p>

<p><img src=""https://i.stack.imgur.com/JnmyB.png"" alt=""enter image description here""></p>

<p>And on the username front, no spaces?  Really?  It's just a string.  I could understand historic concerns against SQL Injection attacks but modern websites are passed that now (I hope!)</p>
","7693","","7693","","2013-11-22 09:09:07","2013-11-22 19:13:21","Why do modern websites still insist on archaic username/password requirements?","<security><websites><passwords><login>","7","6","","2013-11-26 14:41:13","","CC BY-SA 3.0"
"219675","1","","","2013-11-27 16:16:24","","1","450","<p>I'm exploring using HMAC style secret-key authentication with timestamp expiry, but am struggling to get my head around how you validate the timestamp portion.</p>

<p>On the client side you would do:</p>

<pre><code>my_hmac = hmac(my_secret, my_values)
</code></pre>

<p>Where you would have a <code>timestamp</code> field in <code>my_values</code>.  </p>

<p>On the server (where you also know <code>my_secret</code>) you would attempt to rebuild the HMACd string with the request parameters:</p>

<pre><code>my_hmac_to_compare = hmac(my_secret, my_values_from_http_request)
</code></pre>

<p>Is it simply a case of embedding the timestamp as a parameter so it's hashed in to the HMAC string and then ensuring the timestamp is within N minutes of when we process the request?</p>

<p>I have odd visions of having to iterate over 5 minutes worth of timestamps, rebuilding the HMAC string on the server attempting to find the needle-in-the-haystack that will generate the correct HMAC string.</p>

<p><strong>Bonus question:</strong> Is there a consensus on how you would initially transfer the secret key to a client from a server?  It obviously becomes ""dirty"" after it goes over the wire, but in a user facing application you can't have someone pasting in an extensive secret key, especially if it's a mobile client.</p>
","109929","","","","","2013-11-27 16:16:24","Validating time-limited HMACs","<security><authentication><hmac>","0","3","","","","CC BY-SA 3.0"
"219870","1","","","2013-11-29 14:21:13","","1","1248","<p>In many articles about Rest API's best practices, it is recommended to not depend upon sessions on server side since it leads to a stateful mechanism.</p>

<p>I currently use Play 2.2 framework, with a mechanism that store the data about logged in user in the Play cache (temporary persistent so).</p>

<p>When the user wants to authenticate, it calls a dedicated API that grabs its credentials and if valid, server generates a cookie that will be sent to him. This cookie contains a reference id of the user's data in the Play's cache.</p>

<p>Then, each time a user calls an API requiring user authentication, server grabs the user cookie (if any), asks for the cache and checks in there whether user is well already authenticated regarding the validation duration. </p>

<p>Here a little sample:</p>

<pre><code>def myApi = userAuthenticatorRequest.securedAction {    //user has to be already logged in
    implicit request =&gt;
      //do something
  }
</code></pre>

<p>Should I leave from this solution in order to be compliant with best practices, or should I keep it?
Is it really considered as a stateful mechanism?
If I understand, this is stateful since a call to a secured API required actually two calls:</p>

<ul>
<li>authentication api</li>
<li>secured api</li>
</ul>

<p>while a stateless would authenticate user directly in the secured api, and thus would be totally independent of any context. Of course, user would have to sent each time its credentials (or API key)</p>
","43961","","43961","","2013-11-29 14:32:00","2013-11-29 16:01:26","Is it an implementation of a stateful mechanism for Rest API authentication?","<architecture><security><rest><authentication><playframework>","1","0","","","","CC BY-SA 3.0"
"338121","1","338138","","2016-12-14 11:24:19","","4","1332","<p>I am building a simple Q&amp;A app with PHP, HTML and JS. I have three tables: <code>users</code>,<code>question</code> and <code>answers</code>, each table has it's own primary key and <code>questions</code> and <code>answers</code> both have foreign key constraints. <code>questions</code> store <code>users.uID</code> to look up author, and <code>answers</code> store <code>question.qID</code>to identify which question they belong to, and also author that wrote the answer, so <code>users.uID</code> is also foreign key.</p>

<p>And here is my main concern: how to properly implement submit button for answer, that passes the author ID and also question ID that is supposed to be inserted in <code>answers</code> table via ajax request, so it has to get that ID from somewhere. The main concern is not XSRF, but the fact that authorised user could tamper with it, by changing a part of html code if the ID is stored visibly (or invisibly) somewhere.</p>

<p>User ID is easy, that can be stored in session once retrieved from DB and user logs in and will be reused elsewhere too so no big deal in term of performance costs, and can be accessed by all scripts while hidden from user. But also storing the question ID in session, each time user visits a question, and then replacing that with another question ID when he visits another question seems to me like it is asking for causing heavy load on server at some point. </p>

<p>Adding hash to the submit button, that is then validated by script that processes the ajax call data looks cumbersome to me too, since you have to store that hash in session too. And using hidden field is not safe either, since user can see that field in source code and can tamper with it.</p>

<p>So where to efficiently store that question ID, so it is ready when the submit button is pressed and also that user cannot tamper with it, and send ajax call with other ID? Is the session really only option?</p>
","197872","","","","","2016-12-14 15:04:01","How to validate ajax request comes from correct page and is not tampered with?","<php><javascript><security><html><ajax>","2","6","","","","CC BY-SA 3.0"
"109931","1","109933","","2011-09-21 19:09:07","","4","262","<p>I've heard that you shouldn't let search engines index your development server.  The reasons given were:</p>

<ul>
<li>Duplicate content penalties</li>
<li>Customers making purchases from an unsecured domain (if eCommerce)</li>
</ul>

<p>These issues may seem relatively minor and I'm not sure it would be enough to convince someone to put in the effort to lock down the server.  Aren't there broader security concerns?  What should be secured and why?</p>
","1785","","9771","","2011-09-21 19:52:35","2011-09-21 19:52:41","Why should you prevent a search engine from indexing your development server?","<web-development><security>","2","9","","","","CC BY-SA 3.0"
"83037","1","111815","","2011-06-10 14:34:05","","6","3317","<p>When creating a Security Token Service (STS) for a claims based security model, it seems appropriate that tokens are generated in such a way that they expire after some duration, as suggested <a href=""http://blogs.objectsharp.com/cs/blogs/steve/archive/2010/10/18/what-makes-claims-based-authentication-secure.aspx"" rel=""noreferrer"">here</a>.
Around this concept, I have a few specific questions, but am looking for any feedback regarding best practices in this area.</p>

<ul>
<li>What are recommended values for the timeout length and/or what should be taken into consideration when determining this?</li>
<li>If a user is active for longer than the typical expiration period, how should this be handled such that the user is no required to re-authenticate in the middle of their session?</li>
<li>Is there an elegant way to design a service to perform batch actions ""on behalf of"" another user by utilizing the token?  i.e. Utilizing the token at a later time may have caused it to expire.</li>
</ul>
","25720","","","","","2011-10-01 06:57:20","Best practices for expiration of tokens in a Security Token Service (STS)","<security>","1","1","","","","CC BY-SA 3.0"
"270362","1","270367","","2015-01-16 23:50:52","","3","226","<p>After reading Heroku articles, Stack Overflow questions, and the Stripe payments integration guides, the general advice is that I should should purchase an SSL certificate for my custom domain that points to my Heroku app.</p>

<p>Can anyone offer an explanation or other resource to help me understand <strong><em>why</em></strong> I need an SSL certificate?</p>

<p>I understand that SSL encrypts transmitted data, but if Heroku provides SSL, then where am I lacking encryption?</p>

<p>Would a simple explanation be that <a href=""http://example.com"" rel=""nofollow"">http://example.com</a> forwards all transmitted data to <a href=""https://myapp.herokuapp.com"" rel=""nofollow"">https://myapp.herokuapp.com</a>, therefore someone could intercept that data on that ""leg"" of the DNS routing chain?</p>
","164783","","","","","2015-01-17 19:07:14","Why should I purchase an SSL certificate for custom domain?","<security><ssl><heroku>","3","0","","","","CC BY-SA 3.0"
"83476","1","","","2011-06-13 08:01:33","","0","342","<p>I am creating a soap service where users will be able to interact with each other.
They will have a contact list where people can be added.
One of the security measures(others are in place, too) is to have a local ID assigned to a contact.</p>

<p>To make the process clear, imagine the following scenario:</p>

<p>$UserA prompts $UserB to be added to $UserA's contact list.
$UserB accepts and $UserA receives a local ID to use as UserID referring to the contact.
The database contains a table called USER_MAP(LocalID,UserID).</p>

<p>Two questions:</p>

<p>1) Do you think this is a valid approach when dealing with user ids security? If not, why?
2) If you deem it valid, can you suggest a formula to generate said IDs?</p>

<p>At the moment, the idea for the formula is: 
($UserA_ID+$UserB_ID)*($UserA_RegDate+$UserB_RegDate)</p>

<p>Consider RegDates as being in ""number of days since the 0 date value"".</p>

<p>Each user might have 1..N local ids depending on how many users are willing to add.
A local ID is local to the user but global in the user space, i.e. for every interaction between users the same local id is used.
To make it clearer: if $UserA requests to see $UserB profile, he will be passing the local user id which will be mapped at the server level to the correct id.</p>

<p>Just to make it clear: future does not mean ""in a long time from now, maybe, who knows"", rather means : ""it is planned, I want to do it, I want to make sure I have my pieces ready and THEN I will do it"" :) Thus, it's not a ""maybe"" rather just a matter of WHEN.</p>

<p>Apparently someone has issues understanding the logic behind the approach of a local id.
A couple ideas that can help you understand why it's a good idea(in my opinion):</p>

<ul>
<li><p>If your ID is local instead of global, you have <em>only</em> access to your own resources/contacts. Useful for instance to avoid programmatically getting access to a profile you wouldn't be allowed to see. This with third parties <em>may</em> be a problem, especially in case of unfair uses</p></li>
<li><p>If your ID is local, you can use it as a shortcut for local data instead of having to go to the original account. The contact list could, for instance, hold some of the original data which isn't going to change.</p></li>
<li><p>If you have a local id it's much easier to ""cut the wire"", because all you have to do is deleting one or two records. Say that a user wants to delete a contact. All I will have to do is to remove <em>at best</em> two records, all the other data stays there untouched and
simply filtered out by the queries.</p></li>
</ul>

<p>Better now?</p>

<p>Thank you for your time!</p>
","26908","","26908","","2011-06-13 13:24:18","2011-06-13 16:11:00","Assigning a local id to a user","<database><security><users>","2","2","","","","CC BY-SA 3.0"
"375365","1","","","2018-07-17 19:48:19","","0","97","<p>Firstly this is not about how to store password for access to the application itself. That is handled using .Net Identity. Authentication is handled using JWT. So it is a web application.</p>

<p>The problem is to be able to store and retrieve passwords as safely as possible for the users of the system.</p>

<p>One user (a company with several employees) may have a number of clients for whom they have access to report, say taxes or VAT using different services. That requires credentials for those services. And it requires that those credentials are stored as safely as at all possible.</p>

<p>Users could do this themselves in password managers, but there is a big risk that either they mess up by not synchronizing changes between employees or they forget to delete credentials when a client is no longer with them.</p>

<p>Further there may be levels of access usually meaning several password manager storage files. Which will increase the mess the user's employees can get themselves into.</p>

<p>I can think of the following requirements</p>

<ul>
<li>Passwords are encrypted with public/private key pair</li>
<li>Passwords are stored in the database as encrypted</li>
<li>Passwords are never shown in clear text, only copied to clipboard and expires in short time</li>
<li>Only employees having access to correct private key can decrypt</li>
<li>When client is deleted all passwords for that client are deleted</li>
<li>public/private key pair is not stored in database, security handled by access to client machines</li>
</ul>

<p>Is there anything that I have overlooked or something that could be done in a better way?</p>
","174505","","","","","2018-07-17 21:05:05","Password manager inside application","<security><passwords>","1","3","","","","CC BY-SA 4.0"
"270616","1","","","2015-01-20 14:43:43","","4","1495","<p>One of my team members committed a huge mistake; a clear SQL injection-vulnerability. It obviously didn't pass my peer review and I made very clear that this is unacceptable. I never saw this programmer make this mistake before and I'm unaware of any other security holes this particular programmer committed. The problem is fixed and my explanation is understood.</p>

<p>My considerations:</p>

<ol>
<li>The programmer is now aware of this mistake and probably won't do it again.</li>
<li>The problem however was huge and could have had major consequences when brought to production.</li>
<li>It's not a junior programmer (> 5 years experience).</li>
</ol>

<p>Should I tell the manager?</p>
","117321","","117321","","2015-01-20 15:20:46","2015-01-20 15:20:46","One of my team members committed SQL injection-vulnerable code; should I report it to the manager?","<security><sql><team>","2","10","","2015-01-20 17:37:45","","CC BY-SA 3.0"
"83929","1","83968","","2011-06-14 19:34:05","","9","7351","<p>I need to implement flexible AND simple (if such thing exist) and at the same time utilize built-on means if possible</p>

<p>So far I have MembershipProvider and RoleProviders implemented. This is cool but where do I go next? </p>

<p>I feel like I need to add term ""Priviledge"" and than hardcode those inside application. Users will configure roles to add Privilidges to Roles and assign Roles to users.</p>

<p>Does that sound like a good model? Should I think about adding priviledges at User level on top of adding them to Roles? I might but I envision problems with setup (confusing) and following support. </p>

<p>If I don't do that and some specific users will need lesser priviledges - admin will have to create another role, etc.. </p>

<p>Any silver bullet for system like this? And why Microsoft didn't go further then just Membership and Role providers?</p>

<p>Another idea:
Leave Roles as ""priviledge"" holder and hardcode them. Then I can code to those roles inside app using all available markups/attributes, etc - all Microsoft.</p>

<p>Add new entity ""Group"" and create relationship like this</p>

<ul>
<li>Users </li>
<li>UserGroups </li>
<li>Groups </li>
<li>RoleGroups</li>
<li>Roles</li>
</ul>

<p>This way I can collect Roles into groups and assign those groups to Users. Sounds great and matches other software patterns. But then I can't really implement things inside RoleProvider like:</p>

<ul>
<li>AddUsersToRoles</li>
<li>RemoveUsersFromRoles</li>
</ul>

<p>And some things do not really make sense anymore because they will be hard-coded</p>

<ul>
<li>DeleteRole </li>
<li>CreateRole</li>
</ul>
","27781","","","","","2011-06-14 20:36:31","Permissions/right model/pattern for .NET application","<design-patterns><security>","1","0","","","","CC BY-SA 3.0"
"270799","1","270810","","2015-01-22 06:12:10","","29","4660","<p>I was reading <a href=""https://news.ycombinator.com/item?id=8068896"">a Hacker News thread</a> where one user posts a link from 2011 explaining that <a href=""http://www.webperformance.com/load-testing/blog/2011/11/what-is-the-fastest-webserver/"">IIS is much faster</a> than most other (*nix) web servers. Another user replies, explaining that IIS gets that advantage by having a <a href=""http://www.microsoft.com/technet/prodtechnol/WindowsServer2003/Library/IIS/a2a45c42-38bc-464c-a097-d7a202092a54.mspx?mfr=true"">kernel module called HTTP.sys</a>. To my knowledge, most other popular web servers in 2015 do not do this.</p>

<p>I would never want to write a kernel mode web server, because I could never trust myself to make it free of security exploits (which would be less serious running in a lower protection ring).</p>

<p>From the perspective of the software engineer (as opposed to a customer for web servers), is running in kernel mode a smart performance decision? Can security concerns be mitigated in application development to the point of making a kernel mode server a net profit for the consumer?</p>
","165347","","165347","","2015-01-22 07:19:37","2020-10-04 14:18:18","Kernel mode web servers: A clever optimization or a security nightmare?","<security><operating-systems><iis><web-servers><apache2>","3","3","","","","CC BY-SA 3.0"
"84080","1","","","2011-06-15 02:15:42","","2","2219","<p>Like the title says, I would like some advice from knowledgable web developers on figuring out security issues for my e-commerce site.</p>

<p>I am designing the database as well as the code that communicates with the database to make changes, etc. I have a few questions, but in general a good checklist on what to do to make the security pretty tight, seeing as I will be dealing with credit cards. I will not be storing credit card numbers. Links to good places would be helpful.</p>

<p>My main concern is keeping the database secure. I am pretty new to web development, and I am just concerned about thst.</p>

<p>I do have a question about the design of a database used for online transactions. Is there a better way to make the schema than to just put all the user info into one table: ex. </p>

<pre><code>customer(customerid, firstname, lastname, username, password,
         address, city, country, zipcode)
</code></pre>

<p>Would it be better to store user credentials in another table and link them with the customerid? Sorry if I am not getting too specific, but I am new to web development and mainly have experience in offline programming. Again my main concern is security issues. If anyone has a great article on security, that would do just fine as well. Thanks for your time!</p>
","","Andy","","","","2011-06-15 05:41:38","Advice on making sure e-commerce site is secure using PHP and MySQL","<php><mysql><database><security><e-commerce>","4","2","","","","CC BY-SA 3.0"
"84189","1","84201","","2011-06-15 14:06:33","","15","5332","<p>I hope this question isn't too broad. In the future I may need to add some accounting and financial-tracking systems to some applications (mostly web-based applications, but my questions pertains to desktop apps as well). </p>

<p>Now, creating a simple record of financial transactions is theoretically easy. One database table with a few columns could do the job. Even MS Access, Excel, or even just a plain ASCII text file could be used to store transaction dates, account IDs, and dollar amounts. However, I feel that even a frequently backed-up SQL table with transactional integrity might not be robust enough for serious financial tracking.</p>

<p>I hear terms like ""double-entry accounting"", and I get the feeling that most financial tracking apps (for example, Mint.com, or GnuCash) have a much more complicated data structure or process in place to make double-sure that everything adds up perfectly, exactly as it should, and that no data is ever lost or corrupted.</p>

<p>My question is: <b>When designing an app to track financial transactions, what special design considerations should be made?</b> It seems like there could be so many potential issues... issues with rounding precision, parity checks, some kind of audit process, special backups, security/encryption, extra ways to protect data in the case of a crash mid data-entry....  I don't really know what I should be asking specifically, but I get the feeling that the programming industry has a set of best practices I know nothing about. What are they?</p>

<p><b>Edit:</b></p>

<p>It looks like I opened a bigger can of worms than I expected. To clarify, I'm thinking specifically of two types of apps:</p>

<ol><li>""Check registry""-type apps like GnuCash or Quicken that maintain a record of an individuals transactions for their own use.</li>
<li>Apps that track invoicing/credit/or ""points"" for vendors and customers that deal with a company.</li></ol>

<p>I probably will not be doing any direct banking or (AFAIK) anything that has a ton of finance-related government regulations attached to it.</p>
","19700","","19700","","2011-06-15 15:05:59","2014-02-26 16:10:22","What special considerations are needed when designing databases to hold financial records?","<security><database-design><financial><system-reliability>","7","8","","","","CC BY-SA 3.0"
"271026","1","","","2015-01-24 22:14:50","","3","87","<p>I have a ServiceCallContext object that must be passed in as the first parameter of any service call. I would like to put a User object on the context object but I know I can't force the caller to send back the User object they received from the service and I can't prevent them from filling that in with any information they like.</p>

<p>So as I understand it, I would need to use a security token (via something like OAuth) to authenticate them and would always need to look up any User information I need on the service side after authentication rather than putting it on the context object.</p>

<p>However, I know it's common to make a hash for a data file in order to verify that its contents haven't been tampered with. Would it be reasonable to do this for user information I put on a context object so that I don't have to make a call to the persistence layer for every service call? What are the risks of doing it that way?</p>
","108340","","","","","2015-09-22 03:35:07","Securing service calls","<security><web-services>","2","0","","","","CC BY-SA 3.0"
"375773","1","377334","","2018-07-24 08:44:05","","0","113","<p>Let's say I have a web application where my users can log in, and save resources through my API and an ajax call. Now let's say I put my web application behind a Web Application Firewall (like barracuda).</p>

<p>As conscientious a developer I put a safeguard in my API code to check that the user currently trying to save the resource is the actual resource owner. If I detect that the user is not authorized, what should I do?</p>

<ul>
<li>Nothing. Just issue a 403.</li>
<li>Log the hacking attempt in the error log.</li>
<li>Notify the WAF from the application (e.g. add a security alert header in the HTTP response) and let the WAF deal with it (is that even possible?).</li>
<li>Do not rely on the WAF for that sort of thing. Handle the problem in the application, e.g. block the user account for a while, and/or notify the resource owner that someone is trying to modify his resource.</li>
</ul>
","311273","","","","","2018-08-23 14:01:49","Mitigate a hacking attempt when it is detected by an app sitting behind a WAF","<web-applications><security>","2","1","","","","CC BY-SA 4.0"
"155923","1","","","2012-07-07 09:59:20","","0","182","<p>I'm making a simple multiplayer game of Tic Tac Toe in Python using Bridge (its an RPC service built over a message queue - RabbitMQ) and I'd like to structure it so that the client and the server are just one file. When a user runs the game, he is offered a choice to either create a game or join an existing game. So when a user creates a game, the program will create the game and also join him as a player to the game. This is basically a listen server (as opposed to a dedicated server) - a familiar concept in multiplayer games.</p>

<p>I came across a really interesting question while trying to make this - <strong>how can I ensure that the player hosting the game doesn't tamper with it (or atleast make it difficult)</strong>? The player hosting the game has access to the array used to store the board etc., and these must be stored in the process' virtual memory, so it seems like this is impossible. On the other hand, many multiplayer games use this model for LAN games. </p>
","32693","","","","","2012-07-07 10:02:55","Multiplayer Game Listen Servers: Ensuring Integrity","<security><networking><rpc>","1","0","","","","CC BY-SA 3.0"
"84625","1","","","2011-06-16 21:02:00","","2","434","<p>I have been considering using the Amazon cloud (EC2) for a small workflow application. In terms of power and storage, a SQL Server Express database will more than meet my needs. I have been cautioned against paying for just a Windows server instance and installing SQL Server Express due to mainly security issues. </p>

<p>Is it reasonable to think that there is an Amazon Machine Image (preconfigured images that you can load onto your instance) with SQL Server Express installed where most of the server ""hardening"" has been taken care of?</p>

<p>The wise course may be to just pay for the Windows + SQL Server instance so it is already configured for me, but it is quite a cost difference. </p>
","10126","","","","","2011-08-05 22:17:26","Amazon Cloud (EC2) w/SQL Server. Pay for SQL instance, or use an AMI w/SQL Server Express?","<security><sql-server><amazon-ec2>","1","0","","","","CC BY-SA 3.0"
"376069","1","376086","","2018-07-29 12:28:08","","1","71","<p>Assuming I have resources I restrict access to with a username + password login in my web application and in my REST API. Should I keep different sessions for both meaning that a login via the web UI doesn't grant access to resources accessible via REST and vice-versa? The username and password combinations would be the same.</p>

<p>Afaik if I grant access to both with one login I'd still be able to enforce advanced REST authentication methods, like <a href=""https://softwareengineering.stackexchange.com/questions/183665/the-best-way-to-implement-authentication-for-a-rest-api"">HMAC</a>, at least when the login comes through REST.</p>

<p>The concrete application is implemented with Java EE techniques, especially Java Server Faces which separates JSF sessions and REST session intentionally or unintentionally, however, <a href=""https://stackoverflow.com/questions/2684407/accessing-facescontext-from-web-service"">it's possible to overcome the separation easily</a>.</p>
","208566","","","","","2018-07-29 20:21:08","Should I separate the REST sessions from the sessions in the rest of the application?","<rest><security><authentication><login><jsf>","1","0","0","","","CC BY-SA 4.0"
"271376","1","271393","","2015-01-28 09:14:38","","17","7787","<p>It's clear to everyone (<em>I hope</em>) that storing passwords without at least salting/hashing them is a <strong>terrible</strong> idea.</p>

<p>What about emails? Let's say you keep the subscription email address, if you encrypt it properly it may not be usable to send emails to the users. On the other hand, if you don't encrypt it and the database gets stolen, all your users risk a potential spam.</p>

<p>This question is not about law-specific issues (although they may be given, they remain country-dependent) or about encrypting the database itself.</p>
","110080","","7422","","2015-01-28 09:31:34","2015-02-01 07:59:35","Should I keep email addresses as plaintext in database?","<database><security><email>","2","2","","","","CC BY-SA 3.0"
"156537","1","156551","","2012-07-12 11:27:05","","5","921","<p>I have very little knowledge in application security. I have often seen to protect your application from csrf attacks developers use tokens and pass these tokens with request to validate. I want to know if i just validate the request is coming from my server and rejects all requests coming from any other server how can it be unsafe?</p>
","48848","","","","","2013-09-30 03:48:03","CSRF Protection with codeigniter","<php><security><code-security>","1","1","","","","CC BY-SA 3.0"
"156845","1","156892","","2012-07-14 21:21:43","","0","1188","<p>Been building a WP7 app and now I need it to communicate to a WCF service I made to make changes to an SQL database. I am a little concerned about security as the user name and password for accessing the SQL database is in the App.Config. I have read in places that you can encrypt the user name and password in the config file.</p>

<p>As the username and password is never exposed to the clients connected to the WCF service, would security in my situation be much of a problem?</p>

<p>Just in case anyone suggests a method of security, I do not have SSL on my web server.</p>
","51026","","","","","2012-09-13 13:02:32","WCF service and security","<c#><wcf><server-security>","1","0","","","","CC BY-SA 3.0"
"156880","1","","","2012-07-15 08:47:04","","3","206","<p><strong>Edit</strong>: I admit to being unclear when I first wrote the question. I suppose I wasn't sure of the issue myself, the comments and answers provided up to now helped me focus on the issue, thank you to all involved. This edit is a total rewrite of the question.
<strong>End editorial comment</strong></p>

<p>On a dynamic website we have two systems - content management, and user interface (trivial).</p>

<p>We are trying to decide if the two should have separate authentication systems (being two systems, this might increase security [or not - @GlenH7?]), each having its own hierarchy of permissions etc.</p>

<p>Or is it better to have a single system (it's the same database, after all... plus easier maintenance) and only play around with permissions (regular, jumbo, power, super nova, admin, <a href=""http://en.wikipedia.org/wiki/Q_%28Star_Trek%29"" rel=""nofollow"">Q</a>)?</p>
","54893","","54893","","2012-07-16 05:20:22","2012-07-16 15:33:51","Authentication Systems - Separate for Management?","<security><users>","2","3","0","","","CC BY-SA 3.0"
"271988","1","310167","","2015-02-03 16:45:42","","3","124","<p>I am developing a cross platform app that can handle payments, the online payment service   issued a certificate for my use, thus I have a .pem certificate and within it there is 2 actual certificates and my private key. </p>

<p>The problem is that I can't seem t find how to use it safely, as it has to go in the requests to the web service of the online payment service, therefore I have to include it in my mobile app package, but if anybody opens the package he or she will instantly have access to the private key.  </p>

<p>How can I manage this situation? Should I just include it and forget about it as anyway an attacker will have to have valid credit card numbers, or should I create an intermediate web service that can add the certificate?</p>
","166196","","31260","","2016-02-15 13:30:28","2016-02-15 15:59:08","Pem certificate in mobile app","<security><certificate>","2","0","","","","CC BY-SA 3.0"
"376721","1","","","2018-08-11 10:21:33","","1","309","<p>right now application is storing a file data in database and we are considering instead to store a link (http, ftp, etc) to the file and its checksum. We will only provide a service and the service consumer is supposed to provide the URI and its checksum.
As we do not want to store the file, we won't be able to calculate a checksum, checksum is needed because we want to provide some kind of proof that the initial file has not been tampered with. </p>

<p>Is this applicable, if we require client apps to calculate checksum lets say in MD5 or SHA-256 would it give the same result on all environments (linux, windows, macOS, etc.), would it differ by the algorithm calculating the checksum. Or should we receive the file data and calculate its checksum in our app to make sure that a strong and unified checksum calculation method is applied, and provide a tool to calculate it again when user has access to file so they can verify that it is the original file.</p>
","234299","","","","","2018-08-11 10:21:33","Storing File URI and Checksum to check if the file was changed in future","<security><cryptography>","0","6","","","","CC BY-SA 4.0"
"376758","1","376767","","2018-08-12 15:11:12","","0","410","<p>The security of a TLS connection relies on trusting the CA's certificate, which in turn, is usually actually a proof of DNS entry ownership. Even though the server operator may request a certificate on its behalf, when server operator and domain owner distrust each other, domain owner wins.</p>

<p>SSL and TLS are usually associated with the domain name, and the client doesn't care about server's real IP. However the client always asks the server for a certificate. This results in one more RTT, making HTTPS one time slower than HTTP, not taking into account the key exchange which add 1 to 2 RTTs. Keep-Alive header and TLS 1.3 makes the problem less of a headache, but the RTT at first handshake cannot be saved. Why not just let the DNS server return the server IP together with the certificate and key exchange information, saving one RTT?</p>

<p>The only advantage I see here is that multiple servers can use multiple certificates. This allows to revoke one of the certificates without affecting the others. However, if any of these servers is compromised, it doesn't make detecting compromise any easier. With any private key MITM attacks can already be quite transparent, and it's just as difficult to notice the attack.</p>
","312714","","312714","","2018-08-13 16:33:21","2018-08-13 16:33:21","Why not put TLS certificate in DNS responses?","<security><http><https>","1","4","","","","CC BY-SA 4.0"
"157096","1","157100","","2012-07-17 16:32:15","","6","4893","<p>Many web sites ask users to enter their email address twice, sometimes taking the trouble to disable copy-pasting.</p>

<p>What is the logic behind this? Is this e.g. a security measure?</p>
","11732","","","","","2014-08-11 20:06:20","What is the rationale behind entering email twice for registration?","<web-applications><security><ui><online-identity>","5","5","","2014-08-12 14:09:57","","CC BY-SA 3.0"
"157097","1","","","2012-07-17 16:40:45","","3","882","<p>The system I am developing is designed to have multiple organizations, with users and roles for each organization.  Some organizations can interact, some can not, and generally organizations are not allowed to see or modify each others data with some exceptions.  </p>

<p>I have a model class A that manipulates the data storage in a permanent storage container of some kind.  I have a controller class B that validates input (including access rights verification) to objects of class A.</p>

<p>The controller classes are in a separate library from the model classes.</p>

<p>All user interaction is performed from view classes which are again in a separated library (in this case exposed as web services).</p>

<p>However, it seems that there is a possible security risk in keeping access control logic separate from the model, since no security checks will be performed if the model is not accessed by its associated controller and is accessed instead by some other code due to some malicious attacker or programmer error.</p>

<p>Should I place the security logic in the same model classes weaving these concerns together or should I keep the separation as I have now?</p>
","14294","","","","","2013-11-21 03:47:50","Separation of concerns and security","<security><separation-of-concerns>","2","2","","","","CC BY-SA 3.0"
"85841","1","85908","","2011-06-21 14:37:42","","8","789","<p>A random person on the internet told me that a technology was secure(1), safe to use and didn't contain keyloggers because it is open source.  While I can trivially detect the key stroke logger in this <a href=""http://sourceforge.net/apps/mediawiki/pykeylogger/index.php?title=Main_Page"">open source application</a>, what can <em>developers</em>(2) do to protect themselves against rouge committers to open source projects?</p>

<p>Doing a back of the envelope threat analysis, if I were a rogue developer, I'd fork a branch on git and promote it's download since it would have twitter support (and a secret key stroke logger).  If it was an SVN repo, I'd create just create a new project. Even better would be to put the malicious code in the automatic update routines.</p>

<p>(1) I won't mention which because I can only deal with one kind of zealot at a time.</p>

<p>(2) Ordinary users are at the mercy of their virus and malware detection software-- it's absurd to expect grandma to read the source of code of their open source word processor's source code to find the keystroke logger.</p>
","191","","","","","2011-06-21 20:24:28","How do you go about checking your open source libraries for keystroke loggers?","<open-source><security>","4","0","","","","CC BY-SA 3.0"
"157172","1","369467","","2012-07-18 08:28:56","","15","2538","<p>I'm bootstrapping my own project, it has a registration/login area (via devise with RoR, properly hashed and salted of course). As I'm using subdomains and I need to access them with iframes (it's justified, really!) I'd need one of those expensive certificates that cover subdomains.</p>

<p>As I'm doing this out of my own time and money, so I'm hesitant to drop a couple of hundreds on a certificate, plus a couple of hours delving into something I haven't tried before. I'm not storing any sensitive information besides the email address and the password. As far as I understand, the only vulnerability happens when a user logs or signs up from an unencrypted network (such as a coffee shop) and someone is listening the network.</p>

<p>Am I being cheap? Is this something I should tackle before releasing into the wild. I probably should mention I have 25,000 users signed up to be notified when I launch, so I'm nervous about it.</p>
","9667","","","","","2018-04-16 22:03:53","How important is an SSL certificate for a website?","<security><ssl>","11","11","","","","CC BY-SA 3.0"
"157259","1","","","2012-07-18 15:47:12","","0","266","<p>I have always found it more logic to validate input instead of filtering it. How to appropriately filter data depends on the situation, so IMO it should be done in output or when saving to a database.</p>

<p>But I see that some frameworks provide automatic XSS filters for incoming POST and GET data. What is the logic behind this solution? I can't see any advantages in doing this except providing a quick and easy solution to ""lazy"" developers.</p>

<p>Or is there some specific security reason I don't understand?</p>
","55105","","","","","2012-07-18 16:41:51","What is the logic behind filtering/sanitizing input?","<web-development><security><validation>","2","2","","","","CC BY-SA 3.0"
"376930","1","376933","","2018-08-15 21:04:21","","3","589","<p>I have been tasked with designing a class library that I am loathe to actually build. It is basically a huge backdoor to our software security. The idea was that it would only be accessible from one terminal on a closed system. I plan to lock my code with a password, but is there a way to make sure that my library binary files cannot be added to a project without a password (or something to that effect)? </p>

<p>I am not looking for a full explanation, as this is probably not the correct medium for such a thing. I am more looking for what the topics I should be researching are called. My search-fu has not really turned up much yet, so I am looking for more keywords that can lead me in the right direction. A specific book or website would be even better.</p>

<p>Obviously, obfuscating my code as much as possible will also be a security practice I intend to employ. If that is my ""best-case"" practice for securing my code, so be it. I was hoping for something a little more, though.</p>
","312981","","312981","","2018-08-15 21:18:41","2018-08-16 16:57:26","Locking access to a Class Library (C#)","<code-security>","4","7","","","","CC BY-SA 4.0"
"272681","1","","","2015-02-09 22:35:12","","1","21","<p>If some resource on a RESTful api is to be protected, we can do it by using OAuth for example, and then if the there's no token on the headers of the request (i.e. no identity) we return a 401 status code, and if there is we return some representation.</p>

<p>My doubt is the following: considering the identity of who is requesting the resource (specifically I'm thinking about using claims based identity), is it ok to return a resource representation that changes with the identity?</p>

<p>So for example, for a request from someone with a certain set of claims we return one representation containing some set of data and some set of links. If the request is from someone with another set of clains, the set of data changes and so the links. If someone has no identity whatsoever, we return even another representation. So basically we are controlling who can see and can do what with each resource.</p>

<p>Is that something useful to do, or there's some problem with it that I'm not seeing?</p>
","82383","","82383","","2015-02-10 00:10:05","2015-02-10 00:10:05","Resource representation can depend on identity?","<security><rest><identity>","1","0","","","","CC BY-SA 3.0"
"272702","1","272923","","2015-02-10 02:40:50","","6","1853","<p>I'm using Facebook to authenticate users. We also have conventional username/ password login and registration form too. Anyway, when a user chooses to login with Facebook, we use the following procedure:</p>

<ol>
<li>Redirect to Facebook, user is authenticated, returneded from Facebook to the app - email, name, facebook ID etc is provided from FB .. but ofcourse, no password</li>
<li>We look in our system for any existing user by the email address. If a user is found, then that is the currently logged in user; otherwise, create a new user with the user info returned from FB.</li>
</ol>

<p>Email kinda makes sense as we don't want duplicate email addresses (also the database currently won't allow it due to unique index) so if a user has signed up already with that email address, it won't attempt to create a new user for them. Instead it will pull the previously registered user.</p>

<p>Is this the sound approach though? Exploring all possibilities, I was wondering what happens in the event that the user tries to register by our conventional registration form, but as they have already created an account with that email from their initial Facebook login, we wouldn't allow the duplicate email. So having made the decision to use their Facebook to login, they are stuck with that method. Is this a common/ok approach? </p>

<p>Also without intention, if they use the conventional registration form first, and setup their account that way, we have their password, so they could login using our form or login with FB and the user account will just be pulled by email. However, if they choose to login with FB first time, and their account is created that way (we won't obtain the pw), they must always use FB only. I've absolutely no idea whether this could be problematic or not, I kinda want to go with the option of - whatever means you chose to login/register first time round - then that's what you stick with :)</p>

<p>I'm a little new to having users sign up with multiple logins so heads a bit full of ""what ifs"" etc. Would appreciate any advise on this, and common approaches. Thanks</p>

<p>Alternatively, we loose the index on the email field, add a field somewhere to store the facebook ID, and at the application level decide whether to permit duplicate email address and more distinction between users of different login methods (therefor allowing a user to have a conventionally registered user account, and/or a seperate facebook login auth/created user account, both with the same email address - but different methods of login - least if the user deletes their Facebook account, they can create an account with their email through our register form)</p>
","142254","","","","","2015-02-11 20:08:39","Using Facebook to authenticate, how to link to user record in my app? Email?","<security><authentication><facebook>","2","0","","","","CC BY-SA 3.0"
"272704","1","272722","","2015-02-10 03:22:19","","0","97","<p>This is probably a no brainer, but I've not been able to find an answer that is definitive.</p>

<p>I have a Codeigniter site running on Apache with mod_rewrite (to get rid of index.php) and mod_ssl for HTTPS.  My question is.....</p>

<p>If at <a href=""https://example.com/form.php"" rel=""nofollow"">https://example.com/form.php</a> I have a form like this...</p>

<pre><code>&lt;form action=""/process.php""&gt;
.....
&lt;/form&gt;
</code></pre>

<p>Will that form be submitted to HTTPS, or is it going over HTTP?  Do I have to explicitly say HTTPS in the action?</p>
","167491","","167209","","2015-02-10 17:15:27","2015-02-10 17:15:27","Secure Form Submission","<security><websites><codeigniter><https>","1","0","","","","CC BY-SA 3.0"
"157611","1","157614","","2012-07-20 16:48:03","","0","220","<p>I would have this asked on StackOverflow if it had code, but it's more on the idea/concept so I asked here.</p>
<p>I am working on the UI of our inventory system when I found out that when registering a user in the system, the username and password of the user <em>is optional</em>. I asked our supervisor why is this so. He said that in the system, there are &quot;bins of assets&quot; (think of boxes with toys) where we assign through the system employees to handle these bins. Employees must be registered in the system but some of them are not given access to the system, therefore <em>there is no use giving them usernames and passwords</em>.</p>
<p>But I think his argument is wrong, really wrong because every time I hear &quot;no username no password&quot; makes me cringe as it is most synonymous to a no-password, free-to-access account.</p>
<p>And so I ask:</p>
<ul>
<li><p><strong>What would be the correct database design to separate this system-user employee and non-system-user employee that does not use this no username, no password scheme?</strong></p>
<p>Currently, as the description implies, we have a single table with uid, username, hashed password and other fields with additional user data.</p>
</li>
<li><p>To prove to him a point, I would like to know <strong>why storing a blank username and password for an account is totally wrong for non-system-user registered employee</strong>.</p>
</li>
<li><p><strong>What are alternatives to having this system?</strong> I know it's best to keep in one table the registered users but I have never seen this situation where there are registered users that don't have access to a system. It's like you are given a Facebook account, profiles and all but don't have a username and password for it (or in this case, blank)</p>
</li>
</ul>
","56020","","-1","","2020-06-16 10:01:49","2012-07-20 17:08:04","User management data - the need for a username and password","<security><database-design>","3","2","","","","CC BY-SA 3.0"
"272887","1","273003","","2015-02-11 15:56:44","","3","2183","<p>I am adding spam protection to my personal php framework and I think honeypots are a great way to block spam. Unfortunately they weren't invented yesterday and probably most bots do fetch CSS and can figure out whether the field is real or not. For example if I were designing a spam bot it would be highly intuitive for me to make my bot miss fields with <code>display: none</code> in their style attribute or fields that have relatively large style attributes such as <code>width:0; height:0; border:none; background:none; position:absolute; cursor:defualt</code> which is by the way what I'm currently using. Furthermore if all other fields lack a style attribute it's highly possible that the only one that doesn't is a honeypot.</p>

<p>In other words it seems to me that honey pots are not that difficult to spot. Can anyone with practice tell me which is the best way to hide a honeypot?</p>

<p>And JavaScript is not really an option because I'm building this, as I said, as part of a framework, so I can't really hardcode some JS into a php function.</p>

<p>And finally, there's no spam tag so I'm tagging this as security.</p>
","143301","","","","","2015-02-12 11:38:03","How to hide a honeypot ( excluding external CSS and JS )","<php><security>","1","4","","","","CC BY-SA 3.0"
"157703","1","159839","","2012-07-21 19:58:47","","3","646","<p>So In my app (iOS), you have to register in order to use the service (a food service).  But in order to change details about your account (username, password, and email), you have to reenter your password.  Except for if the user logged out, this is the only time you need your password to use the app.  So I was wondering, since the user basically never uses their password, and its likely they would forget it the one time they might need it, is it ok if I store their password to their local device (in <code>NSUserDefaults</code>)?</p>

<p>Since their password would only be on their local device, it doesn't seem like a security risk.  If the app was hacked, the only password they could get would be their own.</p>

<p>Further, I was planning on just storing it as a string (no encryption).  Would it make a difference if I hashed it or encrypted it before saving the password to their defaults?</p>

<p>Thanks in Advance.</p>
","44190","","","","","2012-08-07 11:00:13","Saving Passwords To The Local Device","<security><iphone><ios><user-experience><passwords>","3","0","","","","CC BY-SA 3.0"
"272994","1","273545","","2015-02-12 10:19:57","","1","1090","<p>I'm not sure if this counts as an Information Security or Webmasters question rather than Programmers, however I'll see how we go.</p>

<p>I've been prototyping a help website for a particular browser game, and I've made the layout of the help website compact and concise with the idea that the rest of the page space can be filled with an iframe that will contain the game itself so players can also play while being on my website.</p>

<p>This way, players of the game can play the browser game and have access to all of the tools and information on my help website at the top of the page. The help website doesn't interact with the game inside the iframe of course, and its purpose is to provide useful references and calculators relating to the game.</p>

<p>I've done some research into the security of iframes, and how the website hosting the iframe can't interfere with the iframe due to the Same Origin Policy. The only security flaw I can think of for players is players not being sure that the real official browser game is running in the iframe and not a fake phishing copy.</p>

<p>What other security concerns should I be aware of and how can these be overcome either by me, the developer, or checked by users to ensure their security on my help website when playing the game via my help website? My main concern is players not feeling safe playing the game through an iframe on my website.</p>
","150658","","150658","","2015-02-12 10:25:34","2015-02-17 19:03:06","Browser game played in an iframe - security concerns","<security><browser><games>","1","2","","","","CC BY-SA 3.0"
"273195","1","273377","","2015-02-14 03:36:01","","10","9958","<p>I have created a sealed jar, but I don't see difference compared to using a non-sealed one.</p>

<ul>
<li>What tests I can perform to verify the jar is sealed?  </li>
<li>What reason we could have to prefer using a sealed over non one?  </li>
<li>Will a sealed create any trouble to users of my projects?</li>
</ul>
","112610","","","user40980","2015-02-15 01:07:34","2017-02-22 10:33:23","What are the reasons for sealing a .jar and how would I verify that?","<java><security>","2","2","","","","CC BY-SA 3.0"
"377622","1","377636","","2018-08-29 02:57:37","","3","2633","<p>Setting the debatability of using personal accounts on the workplace aside.</p>

<hr>

<p><strong>Context:</strong></p>

<p>The company I work for is dedicated to creating apps for other companies. Because of this we have many different clients and handle many different projects within our company's Github Enterprise organization.
I'm one of the people in charge of the company's Medium blog. Since we would like to promote the company by showing the kind of people that work here, I consider it essential to be able to post articles using each of our personal accounts. In my opinion, being able to share sample code greatly increases the value of an article. And being able to do it with our own personal Github accounts would also serve as a motivator for people to contribute to the blog. (Especially those who have many personal projects on their personal Github accounts)</p>

<p><strong>Current Situation:</strong></p>

<ul>
<li><p>All engineers at our workplace have Github Enterprise accounts. These accounts allow us to pull and push from the repositories within our organization. Only admins are allowed to create new repositories though.</p></li>
<li><p>Our GHE accounts connect through SSH.</p></li>
<li><p>We are currently not allowed to use personal Github accounts within our work computers, but allowing them is being taken into consideration.</p></li>
</ul>

<p><strong>Issue:</strong></p>

<p>Managers are afraid that if personal Github accounts are allowed on company machines, employees might end up pushing our clients' code to their personal repositories BY MISTAKE, making it a huge risk of unintentional information leak. </p>

<p>Allow me to clarify here that, it is not an issue of policies or trust. </p>

<p><strong>The Question:</strong></p>

<p>Considering the following hypothetical actions taken by an employee:</p>

<ol>
<li>Clones a project from the GHE repository to work on it.</li>
<li>Modifies some code or adds some features to the project (but forgets push the changes)</li>
<li>Changes account and works on some personal project from their personal account.</li>
<li>Remembers that he has to commit changes. So he opens the work project and pushes the changes.</li>
<li>For some reason he misses the message or warning that he is pushing or creating a repository with his personal account.</li>
</ol>

<p>Is there a way to ensure that client code won't be made public by a mistake like this? (either through some kind of configuration)</p>

<p>Is uploading code to their personal accounts by mistake even possible considering the repository was made on GHE? (If my understanding is correct, repositories cloned by my work account are automatically configured to push, merge, and pull from the Github Enterprise using the work account only, so even if i changed the account i'd just get an error, but maybe i'd get a prompt to create a new repository on my account? I'm not really an expert using Github...)</p>
","313992","","1204","","2018-08-29 15:16:00","2018-08-29 15:16:00","How to avoid pushing Github Enterprise code to my personal Github account by mistake if both are configured in my work computer?","<security><github><enterprise-development>","3","0","","","","CC BY-SA 4.0"
"158245","1","158253","","2012-07-25 23:43:41","","9","1876","<p>I'm in the design process for a Java web app that I will probably end up deploying to Google App Engine (GAE). The nice thing about GAE is that I really don't have to worry about fortifying my app from the dreaded DDoS attack - I just specify a ""billing ceiling"", and if my traffic peaks up to this ceiling (DDoS or otherwise), GAE will just shut my app down. In other words, GAE will essentially scale to any amount until you simply can't afford to keep the app running any longer.</p>

<p>So I'm trying to plan a contingency whereby, if I do hit this billing ceiling and GAE shuts my app down, my web app domain DNS settings ""fail over"" to another, non-GAE IP address. Some initial research has shown that certain CDNs like CloudFlare offer services for this exact situation. Basically, I just keep my DNS settings with them, and they provide an API I can hit to automate a failover procedure. Thus, if I detect that I'm at 99% my billing ceiling for my GAE app, I can hit this CloudFlare API, and CloudFlare will dynamically change my DNS settings to point away from the GAE servers to some other IP address.</p>

<p>My initial contingency would be to failover to a ""read-only"" (static content only) version of my web app hosted somewhere else, maybe by GoDaddy or Rackspace.</p>

<p>But then it suddenly dawned on me: <strong>if DDoS attacks target the domain name, what difference does it make if I rollover from my GAE IP address to my (say) GoDaddy IP address?</strong> In essence, the failover wouldn't do anything other than allows the DDoS attackers to bring down my backup/GoDaddy site!</p>

<p>In other words, DDoS attackers coordinate an attack on my web app, hosted by GAE, at <code>www.blah-whatever.com</code>, which is really an IP address of <em>100.2.3.4</em>. They cause my traffic to spike to 98% my billing ceiling, and my custom monitor triggers a CloudFlare failover from <em>100.2.3.4</em> to <em>105.2.3.4</em>. The DDoS attackers don't care! They're still launching an attack against <code>www.blah-whatever.com</code>! The DDoS attack continues!</p>

<p>So I ask: what protection do CDNs like CloudFlare offer so that - when you need to fail over to another DNS - you aren't at risk for the same, continued DDoS attack? If such protection exists, are there any technical restrictions (e.g. read-only, etc.) that are placed on the failover site? If not, what good are they?! Thanks in advance!</p>
","37136","","","","","2012-07-29 08:49:57","How do CDNs protect failover sites from DDoS attacks?","<java><web-applications><security><google-app-engine>","2","1","","","","CC BY-SA 3.0"
"87226","1","87228","","2011-06-27 00:08:30","","5","366","<p>The question <a href=""https://softwareengineering.stackexchange.com/questions/14584/do-you-actively-think-about-security-when-coding"">Do you actively think about security when coding?</a> asks about security mindset while programming.</p>

<p>Obviously, a developer does need to think about security while coding &mdash; SQL injection, password security, etc.</p>

<p>However, as far as the real, fully-formed security, especially the tricky problems that may not be immediately obvious, should I be concerned with tackling these throughout the development process, or should it be a step of its own in later development?</p>

<p>I was listening to a podcast on <a href=""http://www.grc.com/securitynow.htm"" rel=""nofollow noreferrer"">Security Now</a> and they mentioned about how a lot of the of the security problems found in Flash were because when Flash was first developed it wasn't built with security in mind (because it didn't need to) &mdash; therefore Flash has major security flaws at its core.</p>

<p>I know that no one would want to actively disagree with ""think security first"" as a best practice, but many companies do not follow best practices.  <strong>So, what is the correct approach to balance between needing to get the product done and developing it securely?</strong></p>
","16322","","-1","","2017-04-12 07:31:41","2011-06-30 22:55:16","Develop secureness first or as a later step?","<security>","4","2","","","","CC BY-SA 3.0"
"273409","1","","","2015-02-16 13:24:49","","1","333","<p>Let's say that my <code>Rest api</code> is secured using <code>OAuth 2</code>. Let's say my client is a <code>mobile App</code>. Let's say that i have an <code>Api</code> call:</p>

<pre><code>@Post /increasePoints host:https://www.example.com/increasePoints  amout=10
</code></pre>

<p>Now Using this api call, one should have a valid <code>Access Token</code>. from my app i have control when to call this function so there is no problem. but Let's say the authenticated user get a hold of the <code>access token</code>. how can i stop him from posting to this api using his <code>access token</code>?</p>

<p>Few options that i thought of:</p>

<ol>
<li><em>sign each call with a special header.</em> </li>
<li><em>use client_authentication with scope points</em> - i've just read about this type of authentication but the user can get the <code>access token</code> with same ease for what i understand.</li>
</ol>
","88248","","","","","2015-04-08 14:34:53","Secure Rest api from authenticated user","<security><rest><oauth2>","2","8","","","","CC BY-SA 3.0"
"273431","1","","","2015-02-16 20:25:53","","1","264","<p>I'm coming at this from a somewhat beginners viewpoint so if this is an obvious question it's because I didn't know the right terms to search for.  Are there DBMS's that provide an alternative interface (say an API) to the usual query language text prompt, that's less flexible and less powerful for simple operations?  Ideally any task that involved user input would be handled with a combination of simple queries via this API and logic in the programming language.  SQL or another query language would be reserved for either human users or particular nearly-static queries that did not incorporate user input.</p>

<p>Architecturally the lack of a text stream would probably remove simple network transparency, requiring a local ""server"" acting as dispatch to the real server on the network.</p>

<p>As I said I'm currently a beginner at any of this, but this seems such an obvious design decision that I suspect it either already exists (maybe everywhere), or it is actually impossible in practice.  It would be nice to know why.</p>

<p>Added later:
To clarify the intent is to access the database without using reflection somewhere.  Ideally all possible locations of reflection of user input would be ruled out including any use of the system shell.  SQL is just the starting point, but under this logic Shellshock is considered the same type of vulnerability as SQL injection.</p>
","168251","","168251","","2015-02-18 17:44:35","2015-02-18 17:44:35","Is it possible to avoid SQL injection by not using a Query Language for most tasks?","<design><database><security>","2","4","","2015-02-23 23:58:48","","CC BY-SA 3.0"
"377745","1","377905","","2018-08-31 09:59:32","","0","125","<p>I am building a website with the Flask framework. One functionality of the site will be that users can send messages to each other. </p>

<p>I created a prototype of this using <code>Flask WTF</code> forms. The basic implementation is as follows:</p>

<ol>
<li>User lands on messaging page and chooses recipient</li>
<li>Javascript detects which recipient the user has chosen</li>
<li>User sends message via form</li>
<li>Form is handled by endpoint</li>
<li>Message is stored on the backend's database</li>
</ol>

<p>Here are some limitations and considerations I can think of:</p>

<ul>
<li>this system is not ""live"", i.e.: users have to refresh page to see new messages</li>
<li>users can't see if the other user is typing (not a massive deal breaker in my use case)</li>
<li>figuring out the recipient with JS could have security violations (?)</li>
<li>a massive influx of messages can bring down the whole backend since the messaging system is not decoupled from it</li>
<li>notifying users of a new message / marking message as read will have to be done via JS which again could have security implications (?)</li>
</ul>

<p>As you can see, I am mostly worried about using JS to handle some of this, as I am not very familiar with how to do it in such a way that it can't be maliciously manipulated (e.g.: users attempting to access messages not intended for them / sending messages to users they are not allowed to, etc.)</p>

<p>The other concern is that the system is not decoupled.</p>

<p>After building this prototype, I actually began considering paying for a service like Twilio to handle this part of the website, but I would like to see if I can build it myself.</p>

<p>What other problems might I face and how can I address these concerns?</p>
","147328","","147328","","2018-08-31 13:56:18","2018-09-04 14:45:27","Security and performance considerations when creating chat system on a Flask backend","<security><performance><messaging><flask>","1","3","","","","CC BY-SA 4.0"
"273560","1","273563","","2015-02-17 22:50:42","","1","138","<p>I am developing an application which can install extension modules (plugins, if you will) from APT-style repositories hosted elsewhere. The plugins need not be signed (although the downloads are verified), and can be downloaded over basic insecure HTTP. Is it a good idea to require the user's password (in a similar way to <code>sudo</code>) to download packages, or just to install them? Should I require a login at all?</p>

<p><strong>To be more specific:</strong> should I verify that the user installing the packages is authorised to do so client-side?</p>
","168383","","168383","","2015-02-17 23:03:06","2015-02-17 23:39:01","Is it a good idea to require passwords in offline applications?","<java><security><repository><plugins><authorization>","2","1","","","","CC BY-SA 3.0"
"87366","1","","","2011-06-27 15:56:28","","43","4072","<p>I've come across quite a few sites that either limit the length they allow passwords to be and/or disallow certain characters. That's limiting to me as I want to widen and lengthen the search space of my password. It also gives me an uncomfortable sense that they might not be hashing.</p>

<p>Are there <em>good</em> reasons for either setting an upper length or excluding characters in passwords?</p>
","19233","","","","","2020-01-20 04:48:55","Are there any valid reasons for disallowing characters and limiting the length of passwords?","<security><passwords>","11","10","","","","CC BY-SA 3.0"
"87370","1","","","2011-06-27 16:08:04","","4","110","<p>My team makes a product (business management software) that our customers install on their own servers. The product uses a SQL database for data storage and app configuration.</p>

<p>There have been quite a few cases where something strange happened in the customer's database (caused by bugs in our app and also sometimes admins who mess with the database). To figure out what is wrong with the data, we have to send SQL scripts to the customer and tell them how to run them on the database server. Then, once we know how to fix it, we have to send another script to repair the data.</p>

<p>Is there a secure way to add a page in our application that allows an application admin to enter SQL scripts that read and write directly to the database? Our support team could use that to help customers run these scripts, without needing direct access to the SQL server.</p>

<p>My big concerns are that someone might abuse this power to get data they shouldn't have and maybe to erase or modify data that they shouldn't be able to modify. I'm not worried about system admins, because they could find another way to do the same thing. But what if someone else got access to the form? Is there any way to do this kind of thing securely?</p>
","13647","","","","","2011-06-27 17:24:01","Is there a secure way to add a database troubleshooting page to an application?","<database><security><support>","2","3","","","","CC BY-SA 3.0"
"158447","1","158459","","2012-07-27 11:34:34","","4","2963","<p>The secure attention key is designed to make login spoofing impossible, as the kernel will suspend any program, including those masquerading as the computer's login process, before starting a trustable login operation.</p>

<p>Why cannot other programs simulate <kbd>control</kbd>+<kbd>alt</kbd>+<kbd>del</kbd>?  </p>

<p>What is the reason behind this?</p>
","50201","","183832","","2015-11-24 20:11:18","2022-09-05 08:15:42","why control + alt + delete couldn't be intercepted by any application","<security><login>","4","3","","","","CC BY-SA 3.0"
"158532","1","","","2012-07-27 22:35:05","","0","3564","<p>What's a commonly accepted way of implementing SSO using a third party OAuth provider?</p>

<p>I have a server with user resources associated with server's user ID, the user ID also has a Facebook user ID associated. Would it be a good approach to authenticate a client to the server if the login was redirected to, say, Facebook where it would return an OAuth token and the token is then shared with the client?</p>

<p>Suppose SSL is implemented, the OAuth token would then act in the same way as a session cookie that gives permission to user resources on the server. </p>

<p>The same user an different client can then reauthenticate with Facebook which would return the same Facebook ID, which gives access to the same user's resources and a different OAuth token which expires independently and removing the app on Facebook can callback the server with a deauthenticate request to keep things synchronised. </p>

<p>Is this a good policy to use? Is it safe against attacks like session sidejacking, cross site reference etc?</p>
","15460","","","","","2013-03-18 20:43:40","Should OAuth token be shared to implement SSO?","<security><ssl><oauth>","1","0","","","","CC BY-SA 3.0"
"158602","1","","","2012-07-28 18:24:20","","-2","345","<p>I'm primarily an ASP.NET developer but this question really applies regardless of language.  So obviously it is a good idea to prevent external attacks that arise from session hijacking and csrf attacks as well.  But what about internal attacks when the data involved is temporary, needed for the entire session but also sensitive and worth stealing?  There is the naturally just only hire trustworthy people route, but lets say that doesn't apply.</p>

<p>Say it is a given you already have code reviews and strict production data access permissions to prevent theft by developers.  The application encrypts sensitive data before storing to prevent theft by dbas.</p>

<p>How do you protect your temporary sensitive data against web server admins?  It seems that they could retrieve information by inspecting web server logs, traffic sniffing and inspection of process memory contents.  Naturally I would say production web server admins do not have access to the raw source code.</p>
","14294","","","","","2013-02-22 10:23:51","How to handle security of temporary data on web server?","<web-development><security>","3","7","","","","CC BY-SA 3.0"
"273614","1","","","2015-02-18 12:37:20","","7","10533","<p><strong>Note</strong>: Yes, I know that storing functions in databases should be punishable by law.</p>

<p>We are developing a financial web application using PostgreSQL, Sinatra and AngularJS. As you may have guessed, a financial application may need some calculations.</p>

<p>There is a certain database model (called 'Hypothesis') that has a certain function that needs to be executed overnight. The problem is that this function is different for each instance of the model. That being said, whenever a new hypothesis is added a corresponding function also needs to be added.</p>

<p>Because of the nature of financial applications, the function can either do simple arithmetic operations or integrate over an area. This leaves us with the following options:</p>

<ol>
<li><p><strong>Implement a DSL (domain-specific language)</strong>:
This would be ideal, but adding branching and looping logic to a DSL seems more like creating a new programming language.</p></li>
<li><p><strong>STDIO pipe</strong>: Simply allow the execution of a program in a sandbox on a server. This is most flexible, but the gods of software security would not be merciful. Docker I guess?</p></li>
<li><p><strong>Pure sandboxed ruby code</strong>: Create a sandbox that allows only functionally pure Ruby code to be executed in it. Then simply evaluate the function inside the sandbox whenever required. This would be a security flaw as well, but not half as much as options 2. For now this option seems to be implementable using <a href=""https://github.com/vaharoni/trusted-sandbox"" rel=""noreferrer"">trusted-sandbox</a> and <a href=""https://github.com/quix/pure"" rel=""noreferrer"">pure</a>.</p></li>
<li><p><strong>Use the octave-ruby gem</strong>: Beautiful idea. But it seems that nobody cares much about the project and we will probably need to fork it and work on it. This seem like the best option, since writing complex math expression is trivial in Octave.</p></li>
<li><p>???</p></li>
<li><p>Profit</p></li>
</ol>

<p>Another concern would be implementing the ability to test the functions with mock data in the admin panel, but this is not mandatory.</p>

<p>Can somebody suggest a better/more flexible/more secure option? Or at least one that doesn't store a function string in the database? I hope that I have explained the problem well enough.</p>
","108356","","108356","","2015-02-18 14:41:52","2015-09-04 17:52:13","What is the ""correct"" way to store functions in a database?","<security><sql><ruby><math><postgres>","4","5","","","","CC BY-SA 3.0"
"273642","1","274396","","2015-02-18 16:03:38","","1","86","<p>I work on a <a href=""http://en.wikipedia.org/wiki/Representational_State_Transfer"" rel=""nofollow"">REST</a> API that mixes two types of security:</p>

<p>First you have standard role-based security - so we have multiple roles such as administrator, read-only user, super user user, etc.</p>

<p>Then we also have most of those users belonging to certain customers, so we need to secure specific resources (and child resources) based on user customer / owner.</p>

<p>Is there a well-accepted name for this second type of security? The reason I am asking is that I want to find what patterns exist out there to working with the mix of the two - and it is hard to search for it if you do not know proper term for it.</p>
","78866","","31267","user40980","2016-05-25 15:32:48","2016-05-25 15:32:48","What's the proper name for the type of security where we secure resources by ownerrship?","<security><rest><resources><roles>","1","0","","","","CC BY-SA 3.0"
"273657","1","273681","","2015-02-18 17:38:18","","21","17925","<p>I am using JWT tokens in HTTP headers to authenticate requests to a resource server.  The resource server and auth server are two separate worker roles on Azure.</p>

<p>I cannot makeup my mind as to whether I should store the claims in the token or attach them to the request/response some other way.  The Claims list affects rendering of client-side UI elements as well as access to data on the server.  For this reason I want to make sure that claims received by the server are authentic and validated before the request is processed.</p>

<p>Examples of claims are:  CanEditProductList, CanEditShopDescription, CanReadUserDetails.</p>

<p><strong>The reasons I want to use the JWT token for them are:</strong></p>

<ul>
<li>Better protection against client-side editing of claims (i.e. hacking claims list). </li>
<li>No need to look up the claims on every request.</li>
</ul>

<p><strong>The reasons I don't want to use the JWT token:</strong></p>

<ul>
<li>The auth server then has to know the app-centric claims list. </li>
<li>The token becomes a single point of hack-entry.</li>
<li>I've read a few things saying that JWT tokens aren't intended for app-level data.</li>
</ul>

<p>It seems to me that both have drawbacks, but I am leaning towards the inclusion of these claims into the token and just want to run this by people who have dealt with this before.</p>

<p>NOTE: I'll be using HTTPS for all API requests, so it seems to me that the token will be safe 'enough'.  I'm using AngularJS, C#, Web API 2 and MVC5.</p>
","92352","","","","","2021-04-01 20:57:38","Should I store my user claims in the JWT token?","<security><http><authentication><authorization>","2","2","","","","CC BY-SA 3.0"
"87948","1","","","2011-06-29 07:02:21","","4","472","<p>I'd like to offer a service where customers can write arbitrary java code, send it to me, and I'll run it for them on Amazon EC2.  My question is: how can I do this without exposing one customer's data to another customer?</p>

<p>Right now I'm thinking that each customer can be sandboxed as their own OS-level user with restricted permissions.  Is that good enough?</p>

<p>I understand that this is a tricky issue, but it seems to be one that many people, such as the designers of multi-user OS's and Amazon themselves are solving, so I am optimistic that there might be a good approach.</p>
","29444","","","","","2011-06-29 12:39:55","How do I let customers run arbitrary code as securely as possible?","<security><amazon-ec2>","4","2","","","","CC BY-SA 3.0"
"159119","1","","","2012-08-02 04:28:18","","10","12083","<p>I've been reading a lot on OAuth2 trying to get my head around it, but I'm still confused about something.</p>

<p>I understand that the client authorises with the OAuth provider (Google for example) and allows the Resource Server to have access to the user's profile data. Then the client can send the access token to the resource server and be given back the resource.</p>

<p>But what does not seem to be covered in any of the documentation is what happens when the client app asks the resource server for a resource and passes it the access token. Everything I have read so far states that the resource server just responds with the requested resource.</p>

<p>But that seems like a huge hole, surely the resource server must somehow validate the access token, otherwise I could just fake up any old request and pass an old, stolen, fake, or randomly generated token and it would just accept it.</p>

<p>Can anyone point me at a simple to follow explanation of OAuth2 because so far the ones I have read feel incomplete.</p>
","6947","","8035","","2016-08-11 10:51:26","2017-02-15 12:57:47","OAuth2 flow - does the server validate with the Auth server?","<security><oauth2>","3","0","","","","CC BY-SA 3.0"
"378374","1","378450","","2018-09-13 09:32:10","","1","228","<p>I am developing the back-end of an e-commerce system, which has customer and administrator type accounts. These two roles do not overlap, administrators are there to do the back office work, while customers do the shopping.</p>

<p>I would like to make the admin panel completely inaccessible to the public. If I were the only developer, I would probably opt for developing two applications mostly bound by the same database. My reasoning is based mostly on the principle of least privilege - if there is no need to make something public, then why would I? Also, this does not mean that I intend to implement weak customer security. I only believe that if I can get some extra safety for this specific scenario, then why not?</p>

<p>However, my colleague, who's doing the UI, is settled on creating a single app with a single login page for all users. I guess it is not really important, and I am not keen of arguments. And yet I still would like to apply the aforementioned principle to make it somewhat impossible to login as an administrator from the public.</p>

<p>I was thinking:</p>

<ol>
<li>Have a main domain <strong>mystore.com</strong> and a subdomain <strong>admin.mystore.com</strong> both pointing to the same backend.</li>
<li>Only allow access to the subdomain via a VPN connection (I guess I would perform the necessary checks in the backend application code).</li>
<li>If the login request is coming from the admin subdomain, I would match the credentials agains the admins table. Otherwise I would check the customers table.</li>
</ol>

<p>In my eyes, an administrator is not a customer, and since they don't really share any details aside from the login credentials and full name, I would keep these two separate.</p>

<p>Questions:</p>

<ol>
<li>Overall, does my reasoning make any sense, how bad is this idea and am I just wasting my time?</li>
<li>If it's feasible, is only allowing access to a subdomian via a VPN possible? Sadly I don't know much about setting VPNs up either.</li>
<li>If not feasible, what would be your advice? Would you have one site, one login page, one common table and exactly the same level of security for both the admins and customers?</li>
</ol>

<hr>

<p><strong>More details</strong></p>

<p>I probably didn't make my limitation very clear.</p>

<p>Let's say that I already have a working UI single-page app, which I won't be able to modify for a number of reasons.</p>

<p>This UI code has a login page, which calls a login endpoint somewhere, which then returns a token. Based on this token the page redirects the user to either the admin or the customer dashboard.</p>

<p>The administrator resources in the back-end are, of course, protected by user roles, so it's not a <em>huge</em> problem. Yet still, in addition to that I want to limit the possibility of logging in as an admin from the public Internet as much as possible.</p>

<p>I have complete freedom over the server and no control over the UI. I was thinking about separating admins and customers into different tables and routing the login request to match against the respective table based on how the endpoint is being accessed. If I can't achieve what I want this way, then <em>it seems</em> like any other change would require an accompanying UI change.</p>
","315196","","315196","","2018-09-14 14:28:57","2018-09-14 14:53:40","Securing e-commerce administrator panel with a VPN","<web-development><security><e-commerce><backend>","2","2","","","","CC BY-SA 4.0"
"159260","1","","","2012-08-02 20:07:17","","3","640","<p>I've been thinking about how to architect an infrastructure for one of our business applications with the following requirement:</p>

<ul>
<li><strong>Data written by some user can only be read by that user and his superior and a 3rd person yet to be defined</strong></li>
</ul>

<p>I'm thinking in using some sort of asymmetric algorithm, such as RSA for data encryption.</p>

<p>We can generate a public-private key pair for each user and store the public key of each one openly on a database, but how should we handle the private key ?</p>

<p>If we just let the users manage their private key one day we will have a big headache if one of them loses his key.</p>

<p>If the private key becomes public somehow then the data would become public too, rendering the architecture invalid.</p>

<p>Our infrastructure is heavily Microsoft-oriented: All applications are ASP.Net MVC3, our dabatase is SQL Server 2005 and we use Active Directory for user authentication and basic data, such as e-mail/phone number.</p>

<p>How would you guys architect a solution to solve this problem ?</p>

<p>Bottom-line: This is not a banking or financial application, it's some kind of 360-degree personal feedback system.</p>

<p>EDIT:
Adding more requirements, hoping to make it more clear:</p>

<ul>
<li>This database will be in production environment, where developers don't have access;</li>
<li>When the database is restored, developers should not be able to recover the data;</li>
<li>The DBA should not be able to view the data by SELECT'ing the rows on the tables;</li>
</ul>

<p>EDIT 2: Bounty info.
Bounty went to the answer with more upvotes, although my personal feel is that none of the answers provided addressed the question correctly. For this reason, I'm granting the bounty but not marking the answer as correct.</p>
","9506","","9506","","2012-08-14 21:13:11","2012-08-14 21:13:11","Public-private key pair handling on a Windows ecosystem","<architecture><security><windows><encryption><cryptography>","4","2","","","","CC BY-SA 3.0"
"274265","1","","","2015-02-24 09:29:01","","1","124","<p>I just discovered that we store sensitive information on our SharePoint. Since it's accessible by a password alone (and we all know that <strong>others</strong> click for the password/user name to be automatically pre-filled, even at an outside computer), I feel that we're not managing it securely enough.</p>

<p>The problem is that before I can make some waves regarding it, I need to suggest a better solution. This far, I suggested that we e-mail it to each other (since that requires at the very least login to Exchange, something that needs to be provided at each synchronization).</p>

<p>It's <strong>faaar</strong> form perfect, of course.</p>

<p>I've googled for the issue and I get a lot of general hints and generic suggestions. I'd like to add to them the info on actual software that can be used or a pattern that's practically declared.</p>

<p>We're sitting on SharePoint, Windows 7/8, Exchange Server and use windows authentication via AD when accessing our computers.</p>

<p>Often, we're working at the office (65%) or at home (25%) but some portion is done in a coffee shop or such (10%). The information to be stored is just a text file (or a set of text files) and needs not necessarily to be compartmentalized inside our organization (we trust all the employees). The information needs to be centrally available (as it can change on occasion) but there's no need to encrypt it.</p>

<p>Thoughts?</p>
","81367","","165490","","2015-02-24 09:45:34","2015-02-24 10:38:21","How to store sensitive information (e.g. clients' credentials) accessibly for everybody inside?","<security><passwords>","1","0","","","","CC BY-SA 3.0"
"159385","1","","","2012-08-03 16:30:37","","0","4728","<p>I'm working on an application which requires user credentials and so on. So a database is required on the backend.</p>

<p>What is the best practice to connect to a database without hardcoding your password into it? The program could be reverse engineered and one might get the password which is something we obviously don't want.</p>
","54602","","31260","","2012-08-18 07:57:47","2012-08-20 15:34:13","Application connecting to database server","<c#><database><security>","4","1","","","","CC BY-SA 3.0"
"378569","1","","","2018-09-17 14:28:18","","3","264","<p>Goal: Prevent unauthorized 'clone' apps from using REST API-based solutions <strong>where the customers manage their own servers and services instead of the vendor doing so</strong> (database, resource, and identity). In other words: on-premise servers instead of a cloud-based solution. </p>

<p>My company wants to be able to authorize only some third-parties to be able to create apps that can use our APIs, but not just anybody, in addition to our own apps. So we will likely have some process where third parties will submit their apps to us for signing and adding to some kind of 'white-list' (whatever form that ends up taking.. hence the question.)</p>

<p>(Why no cloud? Some countries and industries are subject to stricter regulations where cloud or off-site servers is not an option for some classes of sensitive operational data. If that is not good enough of a reason, then please consider this a thought experiment). </p>

<p>This question is a variation on <a href=""https://softwareengineering.stackexchange.com/questions/219028/how-to-safeguard-a-rest-api-for-only-trusted-mobile-applications"">this near identical question</a>, but with the additional constraint that the software vendor doesn't own or manage the servers.</p>

<p>I have zero affiliation with CodeBlue, the makers of Approov, but they did publish a decent explanation of the typical process for securing REST APIs for both web apps and mobile apps. Here is a link to part 2 of 3 which covers some of the critical points such as the mediation server and the attestation process for authorizing the client and techniques for keeping shared secrets out of public clients (i.e.: mobile apps).</p>

<p><a href=""https://www.approov.io/blog/mobile-api-security-techniques-part-2.html"" rel=""nofollow noreferrer"">https://www.approov.io/blog/mobile-api-security-techniques-part-2.html</a></p>

<p>The solution described by the above article from CodeBlue sounds dandy for a cloud-based or vendor-controlled environment. However, I have been struggling to find a way to protect against clone apps when the customer has physical access to not only the clients, but to the servers. Configuration alone could probably enable unauthorized apps, and if that doesn't work the app itself could be modified.</p>

<p>Of course there is a legal safety net here (license agreement, terms of service), but is there anything code-wise that can be done to harden against this, if not prevent it outright?</p>

<p>I am aware of - and pursuing - various techniques for obfuscating solutions (like spreading the secrets around, and protecting against reverse engineering) and for client attestation, but in all of my models so far there exists the possibility that a malicious customer (or agent) can trick the REST API into believing that requests are made by an authorized client. I know I'm in some kind of arms race here - so I'm reaching out to the community for thoughts on this because all of the methods I have researched over the past week rely on the vendor owning the server.</p>
","203749","","203749","","2018-09-17 15:47:58","2018-09-21 09:15:28","How to safeguard a COTS REST API with on-premise servers for approved client apps only?","<rest><security><web-api><authorization>","2","9","","","","CC BY-SA 4.0"
"274362","1","","","2015-02-25 02:31:39","","0","121","<p>Obviously, when you store a password, you should use something similar to bcrypt before you store it in in the database.</p>

<p>But I have a client who wants to add the ability to add a ""secret code"" to each database entry that a user will have to enter before gaining access to that entry.</p>

<p>The ""secret key"" isn't exactly as critical as a password, so should I bcrypt this secret code, or does it even need it?</p>
","79640","","79640","","2015-02-25 02:42:19","2015-02-25 07:38:40","Should a ""secret access code"" use the same security as a normal password?","<design><security><authentication>","2","4","","2015-02-25 12:36:52","","CC BY-SA 3.0"
"274473","1","274475","","2015-02-25 19:42:02","","28","8716","<p>In one of the projects I'm working on the following pattern is seen on a fairly regular basis:</p>

<pre><code>var guid = Guid.NewGuid().ToString();
while (guid == Guid.Empty.ToString())
{
    guid = Guid.NewGuid().ToString();
}
</code></pre>

<p>While I understand that a a GUID is not <a href=""https://stackoverflow.com/questions/39771"">guaranteed</a> to be unique and as per the MSDN documentation a <a href=""https://msdn.microsoft.com/en-us/library/system.guid.newguid.aspx"" rel=""noreferrer"">generated GUID may be zero</a>, is this a practical consideration actually worth sending cycles testing for both in the computational sense and in terms of developer time thinking about it?</p>
","2471","","-1","","2017-05-23 11:33:35","2023-10-05 06:01:42","Is it worth even checking to see if Guid.NewGuid() is Guid.Empty?","<.net><security>","6","10","","","","CC BY-SA 3.0"
"379054","1","379177","","2018-09-26 15:35:33","","0","315","<p>I'm working in a scenario where I have a backend (let's call it the server) and a frontend client app (let's call it the client).</p>

<p>The client is entirely headless, and can connect to any instance of the backend installed on a server (supply the URL).</p>

<p>Over time, we can expect the backend to grow and branch into new API versions. We cannot assume the client will maintain parity with the backend, so the client may connect to an instance of the backend with an API version that it cannot support.</p>

<p>The client needs to know the API version of the connected backend so it can take action/adjust its functionality accordingly.</p>

<p>My question is: <strong>How can the client securely know the API version of the backend?</strong></p>

<p>The glaringly obvious answer is: <em>The backend advertises its API version in a header.</em></p>

<p>This, however, is uncomfortable for a variety of reasons --- as a rule, advertising software versions to all and sundry <a href=""https://www.troyhunt.com/shhh-dont-let-your-response-headers/"" rel=""nofollow noreferrer"">is a bad idea</a>.</p>

<p>Only the client application needs to know the API version.</p>

<p>One approach is to implement an API key system, where the backend can issue keys which should be supplied by the client to unlock sensitive API endpoints.</p>

<p>However, the scenario I'm working with is user-facing â€“ one instance of the client, supporting many API versions, may be used to connect to many instances of the backend.</p>

<p>The specific scenario is a headless CMS, with a management app that needs to support remote installs of the backend with an initially unknown API version. The login screen currently has fields for server URL, username and password, and adding a fourth for ""API Key"" becomes a bit cumbersome.</p>

<p>So is there another approach I've failed to hit upon yet? The API Key seems to be the most feasible so far, but I don't necessarily want end users to supply keys upon login.</p>
","","user192491","1204","","2018-10-01 15:23:38","2018-10-01 15:23:38","How can a headless client securely know the API version of a multi-instance backend?","<api><security><client-server>","3","2","","","","CC BY-SA 4.0"
"379267","1","379268","","2018-10-01 08:40:49","","0","64","<p>I'm struggling with X-Script attacks. I think I understand what they are but it's unclear if they only affect public facing web pages (which I will define better).</p>

<p>The example I often see is where the attack is 'attached' to something public (such as a forum) where the user does not need to be logged in (and hence, a public facing web page). This means, as the page loads, the javascript loads and the attack can be performed. </p>

<p>My question is, can X-Script attacks still be dangerous if only the user who set's it can have access to it (if it's hidden behind a login)?</p>

<p>I am excluding SQL injection for this question please.</p>

<p>For example, consider a simple website that allows a user to login and see a list of comments they've made. They can't share their comments with anyone and only the logged in user can see the comments. The user can add any code they like here. As such, any malicious code they add will only affect that logged in user! </p>

<p>Do I still need to be concerned about X-script attacks on this type of website?</p>
","119594","","","","","2018-10-01 09:09:12","Is X-Script an issue only for public web pages?","<security>","1","0","","","","CC BY-SA 4.0"
"379343","1","379346","","2018-10-02 18:05:23","","0","1097","<p>When I created a c# desktop application and move the exe file to another computer that has anti virus security, the security program shows an alert as unknown exe. I want to create a desktop application and a windows installer. How can I solve this problem? The virus programs should not alert an unknown exe.</p>
","160523","","1204","","2018-10-02 19:50:49","2018-10-03 11:11:26","How to create secure desktop installer that doesn't trigger a virus alert for unknown exe?","<c#><.net><security><installer>","2","0","","","","CC BY-SA 4.0"
"275569","1","275596","","2015-03-07 18:25:52","","17","10681","<p>I'm sure that many of the middle to high level languages can be reverse engineered. But if a C program can be reverse-engineered, and turned back into editable source code, how do I discourage such a thing?</p>
","170520","","","user53019","2015-03-08 00:26:06","2015-05-05 15:49:48","Can you ""stop"" a C program from being reverse engineered?","<c><security>","9","14","","2015-03-08 21:31:05","","CC BY-SA 3.0"
"275606","1","275612","","2015-03-08 07:20:48","","-2","447","<p>For example, say I have a string and it has the letters:</p>

<p>RDNAL</p>

<p>This is not an actual English word or it doesn't start an actual english word, so the program would skip this string and would avoid it.</p>

<p>But say the string was:</p>

<p>MICRO</p>

<p>This is the first 5 letters of an actual word, like microwave or microprocessor, etc. And it actually is a word</p>

<p>I want to write a program in Java that will be able to see if a given string contains any block of strings that belong to a potential word.</p>

<p>I'm playing a game where I have to decypher a secret language, so I set numbers equal to each ""character"", and now I want to run each number and put an English letter to each number and see if it possibly spells out a word. </p>

<p>Is this possible or is this just way too massive to do? I'm asking here because I'm not sure if it's impossible or possible based on the number of combinations or some kind of program to reference to check words against. </p>

<p>I think I can write the program to add a letter to each number then rotate through and spit out a string, but I am not sure about comparing the string to an English word. </p>
","170552","","31260","","2015-06-06 16:10:31","2015-06-06 16:10:31","Program to look at the first say 5 characters of a word and return a string if that string is actually the first 5 characters of a word?","<java><design-patterns><algorithms><open-source><security>","1","1","","","","CC BY-SA 3.0"
"275623","1","275634","","2015-03-08 13:59:10","","5","4861","<p>I realized that in Rails there is a built in <code>permanent</code> method for its persistent login cookies (aka. ""remember me"" cookies) method to give the client a cookie that expires in 20 years:</p>

<p><code>cookies.permanent[:remember_token] = remember_token</code></p>

<p>However it seems that in a lot of websites the cookies are set to expire in a far shorter time period, say 3 months or 2 weeks, after which the client will have to log in again.</p>

<p>Is it really a markedly bad practice to set a persistent login cookie to be stored permanently? Why or why not? If it's bad, why does it seem that a considerable number of developers are doing so, such that Rails has provided a built-in method to support the practice.</p>
","106675","","","user53019","2015-03-09 13:54:47","2015-03-09 13:55:33","Is setting ""permanent"" persistent login cookies a bad practice?","<programming-practices><security><ruby-on-rails><cookies>","2","2","","","","CC BY-SA 3.0"
"379583","1","379934","","2018-10-08 00:45:21","","-2","76","<p>I have security question that i am not sure if this approach is safe and secure way to download a file and present to a web user ? </p>

<p>We have customers invoice files stored in a server location (publicly inaccessible location), then we do read them via the PHP code in a file (in public accessible location) like below, </p>

<p>I just wonder, if this way of </p>

<ol>
<li>presenting files to the enduser is secure enough ? </li>
<li>that end user will not have any knowledge at all, of where the files are stored in the server ?</li>
<li><p>any other recommendation on how to handle similar situation ?</p>

<pre><code>$i = $invoice-&gt;get();
$filename = sprintf(INV_PDF_FILENAME,$i['customerid'],date('Ymd',$i['dateIssued']));
$x = sprintf('/tmp/invoices/%s',$filename);
header('Content-type: application/pdf');
header('Content-Disposition: attachment; filename=""'.$filename.'""');
header('Expires: 0');
header('Pragma: cache');
header('Cache-Control: private');
readfile($x);
</code></pre></li>
</ol>
","59309","","","","","2018-11-11 21:01:55","Web Security (PHP) - Is it Secure to do downloading files & presenting with Headers to the End User ?","<php><security><code-security><server-security>","1","0","","","","CC BY-SA 4.0"
"90211","1","90216","","2011-07-06 19:36:59","","3","423","<p>If I have an application that is using a less secure method for storing passwords, such as SHA-1, how would I go about converting to SHA-256 or SHA-512?</p>
","23632","","6605","","2011-07-06 19:45:07","2011-07-07 00:04:47","How would I go about changing encryption methods on existing passwords?","<security><encryption>","3","1","","","","CC BY-SA 3.0"
"90689","1","90885","","2011-07-07 16:47:18","","4","316","<p>After being hacked companies often give numbers and details on how much of their data was compromised e.g ""13K user and passwords"".</p>

<p>After a possible intrusion how do you know what the hacker did in your server?</p>
","18523","","","","","2011-07-08 11:05:52","Possible hack aftermath","<security><hacking><server-side>","3","4","0","2014-08-12 02:45:55","","CC BY-SA 3.0"
"276031","1","276032","","2015-03-11 23:51:26","","11","3121","<p>I don't have lot of expierence with desktop applications, but if I had to create a client server desktop app, the data access would be done through a webservice. I believe data access through a webservice provides security - I don't need to pass in the db server user name and password etc. </p>

<p>Before webservices, how did database applications do this? Was all the important db information passed into the installlation of the desktop app? If so how did programmers manage the security aspect? Or did programmers use something similar to webservices?</p>
","170706","","119814","","2015-03-12 06:42:22","2015-03-12 06:56:52","How did desktop applications communicate with remote server before webservices?","<programming-practices><security>","3","2","","","","CC BY-SA 3.0"
"276051","1","276059","","2015-03-12 05:14:03","","3","86","<p>(Is this the best forum for this type of question?)</p>

<p>I'm writing a web application which allows approved users to login, and perform various tasks, depending on the security role(s) they have been assigned.</p>

<p>I'm guessing that to prevent users from performing tasks that their roles don't permit, this should probably entail 2 main phases:</p>

<ol>
<li>Present web pages which contain <em>only</em> the options (menus, pages, buttons, fields, etc) that the user should be able to access, on the web pages.  (This is basically working, already.)</li>
<li>In case a user tries some hacking (e.g. posting fields/values which their webpage doesn't allow them to post), double check all actions before processing them.  (This sounds pretty complex in some areas, to me.)</li>
</ol>

<p>Does this strategy sound appropriate/normal/necessary?  Any tips or links to pages which discuss this, before I possibly spend a lot of time going down the wrong track?</p>

<p>I'm using Perl/MySQL on Linux, though the principles might be generic.</p>

<p>Thanks.</p>
","170980","","170980","","2015-03-12 07:11:40","2015-03-12 07:12:42","Web application security: Need a 2 phase check?","<web-development><security>","1","1","","","","CC BY-SA 3.0"
"276435","1","","","2015-03-16 14:35:08","","0","174","<p>I am using custom security scheme to verify communication between client and server.</p>

<p>Both client and server have same secret <strong>hash phrase</strong>.</p>

<ol>
<li>Client builds a <strong>message</strong>, combines it with <strong>hash phrase</strong> and calculates
SHA512 <strong>hash</strong>, and sends both <strong>message</strong> and <strong>hash</strong> to server</li>
<li>Server receives a <strong>message</strong>, combines it with <strong>hash phrase</strong> and
calculates SHA512 <strong>hash</strong>, and then verifies that <strong>hash</strong> is the same as
the one sent by client</li>
</ol>

<p>This scheme works fine, but allows man in the middle to sniff the message and send it again, again and again to server.</p>

<p>Now, I know how to solve this, for example, by assigning <strong>unique id</strong> to each message and rejecting duplicates - but these <strong>unique id</strong>s must be stored somewhere (database, session, ...)</p>

<p>Is there some more stateless approach that can solve this problem?</p>
","56628","","56628","","2015-03-16 14:42:24","2015-03-17 01:08:06","Security scheme that prevents duplicate message attacks","<c#><security><communication>","2","9","","","","CC BY-SA 3.0"
"276575","1","276592","","2015-03-17 21:00:07","","1","180","<p>In order to sign data with personal digital signature in a web application, server side languages like PHP can do the whole job, but that would require that the user uploads his private key, lets say stored in PFX file, which would also require that he submit the (personal) password to unlock the PFX. Other alternative is to upload the already unlocked information in PEM format, which doesn't require the password, but the private key is much or more exposed as in the previous case.</p>

<p>What remains is to sign the data in the client machine, and submit the signed data together with the public key to the server.</p>

<p>As it is a web application i assume that would be done with JavaScript.</p>

<p>What would be the  the most global (crossbrowser/""official"") JavaScript solution?</p>

<p>If you think this is misleading I appreciate correction and guidance.</p>

<p>Thank you</p>
","161954","","","","","2015-03-18 00:27:48","Personal Digital Signatures in Web Applications","<javascript><security><authentication><cryptography>","1","1","","2015-03-19 20:13:28","","CC BY-SA 3.0"
"380528","1","","","2018-10-24 16:42:00","","1","352","<p>I have been working on a project that integrates spring-cloud-based microservices and MVC applications with SSO. currently, I use spring-session for the session repository service. My current applications login component contains an authentication server to create a session in the backend, and a frontend client calling such a login service, it works fine. But when I logout from other applications, my current strategy is to redirect to the logout page of this login component and then send an ajax call to the backend service to set the session stored in the session repository to expire. This approach works only if the user is successfully redirected to the login component to logout.</p>

<p>I thought about calling the logout service directly from the other applications instead of redirecting all logout requests to the login component, but the downside would be for all my other applications, I need to implement the logout service. </p>

<p>What would be the general strategies to use to guarantee user session is logged out in an SSO environment that could minimize creating duplicated logout service for each application?</p>
","246673","","","","","2018-10-25 03:46:01","Single Sign On Logout Strategy","<security><microservices><sso>","1","0","","","","CC BY-SA 4.0"
"277068","1","","","2015-03-23 01:16:37","","3","119","<p>In my program, I have an encrypted database on the file system with a password. It is decrypted in RAM, and the sensitive data get spread out too much in RAM for mistake to be auditable easily enough. (Which rule out zeroing memory manually and using SecureString all over the place)</p>

<p>So what I think about doing is spawning a new process in a new windows desktop, asking the user to enter his password here, then decrypting the database, doing my stuff, then closing the child process immediately.</p>

<p>This make the whole thing very easy to audit. The sensitive data never leave out the child process, and the timespan where sensitive data is in RAM is limited to some milli seconds.</p>

<p>The question is : My solution works great only if Windows is effectively zeroing the memory after the process is closed. Is it a safe thing to assume ? (I know that the OS free the memory, but freeing and zeroing is not the same thing)</p>

<p>Do you see a better solution ? (easy to audit)</p>
","172142","","","","","2015-05-04 19:07:38","Are Secure Desktop and separate process enough for hiding sensitive information in RAM?","<security><windows>","1","4","","","","CC BY-SA 3.0"
"380710","1","380712","","2018-10-29 04:09:22","","-1","625","<p>I have created a login form for my website, but the issue is how to process the data provided in the form by the uses.
You see, I can't just write a basic function like this one -</p>

<pre><code>myfunction(){
if(usename==='xyz' &amp;&amp; password==='pqr');
return true;
else{
return false;
}
}
</code></pre>

<p>'Cause it will be clearly visible to all in the inspection. What should I do?</p>

<p>Also, I should mention that I am not really good at developing, I only got some basic knowledge of HTML, CSS, and JavaScript</p>
","318899","","","","","2018-10-30 08:59:01","How to process a login form data?","<javascript><web-development><security><login>","2","0","","","","CC BY-SA 4.0"
"161418","1","161422","","2012-08-18 08:39:46","","6","369","<p>As a freelance developer, I sometimes have to access the administration panels of hosting providers of my customers. It is an astonishingly frightening experience. Below are some points I noticed when accessing recently a not-so-unpopular hosting provider based in UK which has the word ""secure"" mentioned in large on the home page:</p>

<ul>
<li><p>The default administrative account is created with a <strong>terrible password: five lowercase and digits only characters</strong>, no uppercase, no symbols.</p></li>
<li><p>The password is displayed in several locations in the administration panel, which is a good sign that it's <strong>saved in plain text</strong> in the database.</p></li>
<li><p>This administrative account is used to access <em>everything</em>: FTP, MySQL and the administration panel itself (including personal information, invoices, etc.).</p></li>
<li><p>It is impossible to create additional accounts, which forces the customer to <strong>give the same administrative password to any freelancers who work on the project</strong> (giving them unlimited access to everything).</p></li>
<li><p>The <strong>MySQL database can be accessed from anywhere</strong>, not just locally. This behavior cannot be changed.</p></li>
<li><p>There is <strong>no audit</strong>.</p></li>
<li><p>Nothing helps or invites the customer to do <strong>regular backups</strong>.</p></li>
<li><p>The hosting uses <strong>PHP 5.2.4, a version released on August 30<sup>th</sup>, 2007</strong> and cannot be upgraded to a more recent version. For those who are unfamiliar with PHP, the language has frequent updates due to lots of security issues discovered regularly, and running a website in 2012 even with the version released in 2011 is a very bad idea.</p></li>
</ul>

<p>My experience with other well-known hosting companies in UK, USA and France is similar. Some are slightly better, security-wise, but too many are doing everything they can to enforce worst practices. Then, they claim being secure and easy to use, which gives the feeling that the customer can rely on the hosting provider for everything related to security.</p>

<hr>

<p>What should be the professional response from a developer to the customer regarding such hosting companies?</p>

<p>As a developer who have a duty to inform the less technologically knowledgeable customers about the risks they encounter, what should I do?</p>

<ul>
<li><p>Saying shortly that the hosting provider sucks because it's not secure is not a solution: if the hosting provider is not unpopular, the customer will trust the large hosting company, rather than some freelance developer.</p></li>
<li><p>Explaining in details every aspect of security and risk management wouldn't help neither, since it would be too long and boring for the customers to read. Spending hours reconfiguring stuff would be frightening for them too.</p></li>
</ul>
","6605","","","","","2012-08-18 10:03:36","How to explain to my customer that the hosting provider is terrible, security-wise?","<security><customer-relations><hosting><professionalism>","3","2","","","","CC BY-SA 3.0"
"161436","1","161460","","2012-08-18 12:21:49","","6","2884","<p>Continuing from my previous question: <a href=""https://softwareengineering.stackexchange.com/q/161373/61497"">Javascript simple code to understand prototype-based OOP basics</a>
Let's say we run into console this two separate objects(even if they are called child and parent there is no inheritance between them):</p>

<pre><code>var parent = {
    name: ""parent"",
    print: function(){
       console.log(""Hello, ""+this.name);
    }
};

var child = {
    name: ""child"",
    print: function(){
       console.log(""Hi, ""+this.name);
    }
};

parent.print()
// This will print: Hello, parent
child.print()
// This will print: Hi, child

temp =parent;
parent = child;
child = temp;


parent.print()
// This will now print: Hi, child
child.print() 
// This will now print: Hello, parent
</code></pre>

<p>Now suppose that parent is a library, as a HTML5 application in a browser this cannot do much harm because is practically running sandboxed, but now with the advent of the ChromeOS, FirefoxOS and other [Browser] OS they will also be linked to a native API, that would be a head out of the â€žsandboxâ€. Now if someone changes the namespace it would be harder for a code reviewer (either automated or not ) to spot an incorrect use if the namespaces changes.</p>

<p>My question would be: Are there many ways in which the above situation can be done and what can be done to protect this namespaces? (Either in the javascript itself or by some static code analysis tool)</p>
","61497","","-1","","2017-04-12 07:31:31","2014-06-03 12:43:18","How can we protect the namespace of an object in Javascript?","<javascript><object-oriented><security><code-security>","1","0","","","","CC BY-SA 3.0"
"277152","1","277155","","2015-03-23 16:12:45","","-1","6046","<p>Im finding it difficult to understand reverse look up tables and how it works, and the concept of hash chains. This is apart of a computer security model i am taking.
So i understand that brute force, dictionary attack and look up table take up a lot of time, and store all options and then search through all the database. however reverse look up tables addresses this problem, and sacrifices time for storage. But how this happens i am getting confused. 
Many thanks</p>
","172210","","172210","","2015-03-23 16:25:31","2015-03-23 16:51:10","Can someone please explain reverse look up tables?","<security><hashing><passwords><lookup>","1","4","","2015-03-24 21:56:37","","CC BY-SA 3.0"
"277340","1","","","2015-03-25 12:26:47","","1","331","<p>Webhooks can be a very powerful thing when you try to automate or integrate software, however, handling their deployment in a controlled environment can suck in terms of security and deployment alone.</p>

<p>I need a way of allowing anybody in the company â€”anybody that can be trusted with API access, that isâ€” to be able to create, deploy, use (and perhaps even share) webhooks without requiring access to a server.</p>

<p>I have thought that a way of doing this is to create a small application that can store, route and run scripts. The best way I can think to implement such a thing is by taking code stored in a database and creating a temporary file to then run a system command for the given language.</p>

<p>However, I think there would be nothing that would prevent that code from, say, shutting down the machine, downloading and executing external dangerous code, etc.</p>

<p>Then I thought about Linux containers, but I would preferably want a portable solution. I looked for an equivalent in Windows and apparently the technology does not exist yet:</p>

<p><a href=""http://www.theregister.co.uk/2014/10/16/windows_containers_deep_dive/"" rel=""nofollow"">http://www.theregister.co.uk/2014/10/16/windows_containers_deep_dive/</a>
<a href=""http://www.theregister.co.uk/2014/11/18/windows_docker_client/"" rel=""nofollow"">http://www.theregister.co.uk/2014/11/18/windows_docker_client/</a></p>

<p>Is there a simpler approach that can still be regarded as secure?, I would want to at least be able to execute php, python, ssj and shell scripts.</p>

<p>P.S.: Free downvotes for whoever suggests PHP eval</p>
","10869","","10869","","2015-03-26 00:20:06","2015-05-25 01:33:33","What is a simple, correct and secure way of executing code stored in database?, that is also sandboxed","<security><web-services><scripting><code-security>","1","3","","","","CC BY-SA 3.0"
"380856","1","","","2018-11-01 05:48:13","","2","656","<p>I'm trying to implement authentication and session management for a microservice. In order to do the process RESTfully, I understand that I'll need to use some kind of token-based authentication to avoid tracking client session data on the server. The following quote from <a href=""https://security.stackexchange.com/questions/81756/session-authentication-vs-token-authentication"">this answer</a> on the Information Security Stack Exchange nicely sums up my understanding of the implementation:</p>

<blockquote>
  <p>In Token-based Authentication no session is persisted server-side (stateless). The initial steps are the same. Credentials are exchanged against a token which is then attached to every subsequent request (It can also be stored in a cookie). However for the purpose of decreasing memory usage, easy scale-ability and total flexibility a string with all the necessary information is issued (the token) which is checked after each request made by the client to the server.</p>
</blockquote>

<p>From this, I understand how stateless session maintenance is advantageous for scalability, and flexibility as explained. But it seems to me that this leaves the application exposed to some serious problems:</p>

<ol>
<li>If a hacker somehow intercepts the credential exchange HTTP REST call, they could execute <a href=""https://en.wikipedia.org/wiki/Replay_attack"" rel=""nofollow noreferrer"">replay attacks</a> on the server get all the information they want.</li>
<li>In fact, since the session token is stored on the client side, couldn't a hacker just retrieve the requisite information from LocalStorage/SessionStorage by debugging the app? Or by monitoring the incoming and outgoing HTTP calls using dev tools? If they get the required token information (even encrypted token information), they could simply start faking REST calls to the server from another window and get all the data they want!</li>
</ol>

<p><a href=""https://i.stack.imgur.com/Fr629.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Fr629.png"" alt=""Replay Attack Wikipedia image""></a></p>

<ol start=""3"">
<li>Finally, even if you do give the client a session token, wouldn't the server still have to authenticate <em>that</em> token? In effect, the server would have to maintain session tokens to user mappings...but doesn't that defeat the purpose of a stateless REST-based architecture?</li>
</ol>

<p>Maybe I am seeing these problems because there is a gap in my understanding. If that's the case, I'd like some clarity of the basic concepts. If not, I'd like to know if there are any techniques to address these specific problems.</p>
","319138","","","","","2018-11-02 09:49:40","Security Issues with RESTful Authentication & Session Management","<rest><security><microservices><authentication><session>","2","0","","","","CC BY-SA 4.0"
"277601","1","","","2015-03-28 01:12:14","","0","81","<p>This is more of a conceptual question because the way that I am doing it would be secure enough for my purposes (educational). I created a simple admin panel that displays a stock picks database as inputs:</p>

<pre><code>{% for pick in picks %}
        &lt;tr data-post-id=""{{i.id}}""&gt;
            &lt;td class=""symbol""&gt;&lt;input type=""text"" value=""{{pick.symbol}}""&gt;&lt;/td&gt;
            &lt;td class=""buy_date""&gt;&lt;input type=""text"" value=""{{pick.buy_datetime}}""&gt;&lt;/td&gt;
            &lt;td class=""buy_price""&gt;&lt;input type=""text"" value=""{{pick.buy_price}}""&gt;&lt;/td&gt;
            &lt;td class=""sell_price""&gt;&lt;input type=""text"" value=""{{pick.sell_price}}""&gt;&lt;/td&gt;
            &lt;td class=""quantity""&gt;&lt;input type=""text"" value=""{{pick.buy_quantity}}""&gt;&lt;/td&gt;
            &lt;td class=""current_price""&gt;&lt;input type=""text"" value=""{{pick.current_price}}"" disabled&gt;&lt;/td&gt;
            &lt;td class=""save""&gt;&lt;button&gt;save&lt;/button&gt;&lt;/td&gt;
        &lt;/tr&gt;
{%endfor%}
</code></pre>

<p>In the panel, you can edit the individual row and save it to the database through an ajax request based on the data-post-id. Then it dawned on me, if a malicious user was able to bypass the login system, could they edit any row in the table by changing the data-post-id in their browser? If so, what else can I do to limit what can be edited and make sure that only what is intended to be edited is edited?</p>
","","anon","","anon","2015-03-28 01:20:22","2015-03-28 18:04:04","How Do I Securely Edit a Database Entry Based On ID in an Admin System?","<web-development><security><django>","1","0","","","","CC BY-SA 3.0"
"162007","1","162013","","2012-08-23 14:22:08","","56","23568","<p>I've got a bit of an argument at my workplace and I'm trying to figure out who is right, and what is the right thing to do.</p>
<p>Context: An intranet web application that our customers use for accounting and other ERP stuff.</p>
<p>I'm of the opinion that an error message presented to the user (when things crash) should include as much information as possible, including the stack trace. Of course, it has to start with a nice &quot;An Error has occurred, please submit the below information to the developers&quot; in large, friendly letters.</p>
<p>My reasoning is that a screenshot of the crashed application will often be the only easily available source of information. Sure, you can try to get a hold of the client's systems administrator(s), attempt to explain where your log files are etc., but that will probably be slow and painful (talking to the client representatives mostly is).</p>
<p>Also, having an immediate and full information is extremely useful in development where you don't have to go hunting through the log files to find what you need on every exception. But that could be solved with a configuration switch.</p>
<p>Unfortunately there has been some kind of &quot;Security audit&quot; (no idea how they did that without the sources), and they complained about the full exception messages citing them as a security threat. Naturally, the clients (at least one that I know of) has taken this at face value and now demands that the messages be cleaned.</p>
<p>I fail to see how a potential attacker could use a stack trace to figure anything out he couldn't have figured out before. Are there any examples, any documented proof of anyone ever doing that? I think that we should fight this foolish idea, but perhaps I'm the fool here, so...</p>
<p>Who's right?</p>
","7279","","74729","","2022-09-05 15:18:07","2022-09-05 19:38:39","Should a stack trace be in the error message presented to the user?","<security><error-handling><usability>","8","10","","","","CC BY-SA 4.0"
"277711","1","277729","","2015-03-30 07:03:38","","4","407","<p>I normally avoid sProcs as much as possible. I dont like the language be it TSQL or PL/SQL; they seem archaic against Java/Dot-Net which I use. I go for them when a routine needs to fetch a lot of data, crunch it and generate a small set of output. Sitting inside the DB makes the fetching process a lot fast, no network hit. But that is all.</p>

<p>I recently came across a DAL design where absolutely all of the CURD operations were implemented in Stored Procedures. Actually one giant sProc to be precise. Here is the skeleton:</p>

<pre><code>PROCEDURE myGenericProc(int QueryNo, varchar genericParam1, ..., varchar genericParamN)
BEGIN
    SWITCH queryNo
    CASE 1
        SELECT * FROM table1 INNER JOIN table 2 ON ...

    CASE 2
        DELETE FROM table 3 WHERE ...
    ...

    CASE n
        UPDATE table4 SET a=b WHERE ...
END
</code></pre>

<p>The designer's logic behind this is: if I do these things in code, then the database-connection needs to have full rights on all the tables. The connection credentials are generally in connection string, which is on the application server. If the application server is compromised, inevitably the entire DB is also compromised.</p>

<p>As an alternative, have all the queries in the sProc, then grant that sProc full rights. Call only that sProc. This way, even if the application server is compromised, only the sProc interface can be attacked. No one can do <code>DROP users_master</code>. </p>

<p>While I agree with the principle, I hate the implementation. Unfortunately, some security paranoid clients (banks) want us to do exactly that. Also, the DBAs hate tuning access privileges on 200+ sProcs, they want as-few-as-possible items to audit.</p>

<h2>Question:</h2>

<p>Is there any other implementation that provides same level of security, but is more <em>cleaner</em> ?</p>
","106083","","","","","2015-03-30 13:37:11","Secure DAL Design using Stored Procedures","<security><database-design><stored-procedures>","3","8","","","","CC BY-SA 3.0"
"277770","1","","","2015-03-30 17:18:09","","5","730","<p>I'm working on an add-in that will integrate git into the VBA IDE. I'm using the <a href=""https://github.com/libgit2/libgit2sharp"" rel=""nofollow noreferrer"">LibGit2Sharp</a> library under the hood, which supports <a href=""https://github.com/libgit2/libgit2sharp/wiki/git-fetch"" rel=""nofollow noreferrer"">User name and password credentials</a>, but not <a href=""https://developer.github.com/guides/managing-deploy-keys/#deploy-keys"" rel=""nofollow noreferrer"">SSH Keys</a>. I would use GitHub's SSH Keys if the library supported them, but it doesn't.</p>

<p>So, I can easily enough ask the user for their credentials prior to trying to interact with the remote repository, but I can feel the ""bug"" reports coming in already. </p>

<blockquote>
  <p>Why do I have to provide my password every time I try to push to my repo?</p>
</blockquote>

<p>So...</p>

<p><strong>Question 1:</strong></p>

<p>Is it safe and acceptable to keep the password in memory after the user has entered it the first time? If there are caveats to that being safe or unsafe, what are they?</p>

<p><strong>Question 2:</strong></p>

<p>I can also see users not wanting to keep entering their password even on the <em>first</em> time they push during a session. Would it be safe enough to <em>encrypt</em> (not hash) the user name and password and store them along with the add-in's other configuration settings?</p>

<p>I mean, Visual Studio doesn't ask me for my GitHub credentials each time I start up the IDE, so it must be possible to do this relatively safely. But <strong><em>how</em></strong>?</p>

<hr>

<p>I have read through <a href=""https://softwareengineering.stackexchange.com/search?page=3&amp;tab=relevance&amp;q=store%20a%20password%20is%3aq"">many related questions</a>, but feel no closer to knowing how to go about safely using my users' credentials in my add-in. Most of the existing questions relate to websites and databases, where the right answer is ""don't store the password in a recoverable way, salt and hash it and store the hash only"", but in this instance, it's not a password to <strong>my</strong> service. I need to secure it the best I can, but in a recoverable way. Otherwise, there's no way my program can ""log into"" their repository on their behalf.</p>
","142319","","-1","","2017-04-12 07:31:39","2015-04-06 19:46:58","Safest way to use and store User's third party credentials","<security><github>","1","5","","","","CC BY-SA 3.0"
"381772","1","","","2018-11-20 19:08:45","","2","126","<p>I am making a websocket server that can communicate with clients.</p>

<p>This server is going to be on a private vLAN channel on a public place, AKA only the staff have access to the network which the server is on.</p>

<p>When this is the case, do i need to implement SSL or any other form of security, if the ""hackers"" cant get access without being connected to the vLAN?</p>
","320271","","","","","2019-08-17 23:01:40","Do i need to implement Security for my webpage, if it is only connected to a LAN","<web-applications><security><websites><server-security>","1","4","","","","CC BY-SA 4.0"
"162848","1","162851","","2012-08-29 16:29:16","","1","1760","<p>In ""<a href=""http://youtu.be/wEhu57pih5w"" rel=""nofollow"">The Clean Code Talks -- Unit Testing</a>"", MiÅ¡ko Hevery mentions that ""as little work as possible should be done in constructors [to make classes more easily testable]'. It got me thinking about the way I have implemented my user authentication mechanism.</p>

<p>Having delved into MVC development through CodeIgniter, I designed my first web application to perform user authentication for protected resources <em>in controllers' constructors</em> in cases where <em>every</em> public function in that controller requires the user to be authenticated.</p>

<p>For controllers with public methods having mixed authentication requirements, I would naturally move the authentication from the constructor to each method requiring authentication (though I don't currently have a need for this).</p>

<p>I made this choice primarily </p>

<ol>
<li>to keep the controller tight, and</li>
<li>to ensure that all resources in the controller are always covered.</li>
</ol>

<p>As for code longevity and maintainability: given the application structure, I can't foresee a situation in which one of the affected controllers would need a public method that didn't require user authentication, but I can see this as a potential drawback <em>in general</em> with this implementation (i.e., requiring future refactoring).</p>

<p>Is this a good idea?</p>
","9492","","9492","","2016-01-12 14:52:31","2016-01-12 14:52:31","Performing user authentication in a CodeIgniter controller constructor?","<security><mvc><codeigniter>","1","0","","","","CC BY-SA 3.0"
"382113","1","","","2018-11-27 17:43:56","","1","87","<p>The problem I am trying to solve today is DDoS. I am working on a game project which is hosted on a TCP port (7777). The game is known to have a community full of idiots (pardon the language) that do not like competition among communities, so they just like to DDoS servers to... kill the competition instead. Depending on the attack, it could cause the game server to crash, or even overload the bandwidth of the entire machine.</p>

<p>My theoretical solution to this problem is creating a dynamic firewall containing the IPs of registered users. Only allowed IPs would be granted the access to the 7777 port. In this way, botnets would be prevented to even reach the server and cause damage. Practically speaking though, I have no idea on how to reach this solution.</p>

<p>I am using Amazon Web Services and their firewalls are Security Groups. The problem is that they have a limit of 50 entries in the IP address inbound list, which is not an acceptable an amount since all users would need to be inside that table.</p>

<p>How can I solve this?</p>

<p>Notes:</p>

<ul>
<li>Assume all the other ports, SSH excluded, will be blocked.</li>
</ul>

<p>(not sure if this is the right site, feel free to move to ServerFault if it'd feel like a better place)</p>
","109956","","","","","2019-08-25 01:03:00","Allowing a dynamic list of IP addresses to access a specific port in an AWS EC2 Instance","<security><amazon-ec2>","1","3","","","","CC BY-SA 4.0"
"278782","1","","","2015-04-10 21:38:22","","1","208","<p>We currently have a web app (.net MVC 5), user's login using their username and password and then we store an encrypted value in a cookie to authenticate them on future requests.</p>

<p>We are now in the process of designing an API for that will be mainly used by our mobile app (will be built once the API is ready). </p>

<p>What I/we are trying to understand is the best way to secure requests made to the API. Our current plan is to have a simple API method that accepts a username and password, which will then validate these details and on success return a token that is unique to that user. This token will then be used on each subsequent request to authenticate. </p>

<p>The issue here is that if that token is stolen then someone could impersonate that user quite easily. So should we be sending back some kind of token secret that we can use to sign each request (using something like HMAC) then this can be checked on the server before allowing the request to continue?</p>
","43458","","","","","2015-04-10 21:41:35","Securing a Web Api for individual Users","<security><web-api><asp.net-mvc-web-api>","1","0","","","","CC BY-SA 3.0"
"382587","1","382588","","2018-12-06 17:56:17","","10","2148","<p>I inherited some projects in which secrets were in source control in App.config and similar files. Fortunately it's not a public repository so the risk isn't as serious as it could have been. I'm looking into better ways to manage this, such as Azure KeyVault. (But I don't intend this question to be specific to that solution.)</p>

<p>In general, aren't we just moving the problem? For example, with Azure KeyVault, the app ID and app secret become the things that you need to keep out of source control. Here's an unfortunately <a href=""https://github.com/rahulpnath/Blog/blob/master/AzureKeyVault/AzureKeyVault/Program.cs"" rel=""noreferrer"">typical example</a> of how this tends to go wrong. Other approaches end up being similar, with API keys or keystore files that you have to protect.</p>

<p>It seems to me that products like Azure KeyVault are no better, and pointlessly more complicated, than keeping your secrets in a <a href=""https://stackoverflow.com/questions/480538/use-xml-includes-or-config-references-in-app-config-to-include-other-config-file"">separate config file</a> and making sure it's in your .gitignore or equivalent. This file would have to be shared as needed via a side channel. Of course, people will probably insecurely email it to each other...</p>

<p>Is there a way to manage secrets that doesn't just move the problem? I believe this question has a single clearly defined answer. By analogy, if I were to ask how HTTPS doesn't just move the problem, the answer would be that CA keys are distributed with your OS, and we trust them because we trust the distribution method of the OS. (Whether we should is a separate question...)</p>
","293020","","293020","","2018-12-06 18:08:10","2018-12-06 23:25:29","Keeping secrets out of source control - are we just moving the problem?","<version-control><code-security>","3","0","","","","CC BY-SA 4.0"
"279474","1","279758","","2015-04-17 23:09:15","","6","574","<p>I'm working on a development tool that requires knowing one or more api passwords for a user to operate. Currently it works on Mac, and uses keychain to store the credentials for later re-use.</p>

<p>Are there any similar password store options that are cross-platform and have the following properties?</p>

<ul>
<li>Store the credentials securely</li>
<li>Ability to authorize applications to access the credentials repeatedly without re-authenticating?</li>
<li>Credentials are accessible via an API (provided the user has authorized one-time or indefinite access)?</li>
<li>(Nice-to-have) Ability to authorize applications for a specific time period (i.e. a week or a month), after which the user is required to re-authorize the application.</li>
<li>(Nice-to-have) Support for multi-factor authentication during authorization</li>
</ul>

<p>Keychain works great in this sense, since it allows me to let them be responsible for the security of the credentials, and allows the credentials to be used by other applications (provided a structured credential key) with authorization that can be one-time or indefinite.</p>

<p>I've attempted to the scour the web (probably poorly), but I'm having trouble with the fact I only get password managers, which are geared towards a user requesting the credentials, rather than an application, or I get instructions for how to properly store using bcrypt, which is great for verifying passwords, but not if I need to retreive it later. For instance, I have a proof of concept for storing the credentials in LastPass, but it requires enter a master password each time the credentials are requested unless I store the master password somewhere accessible, which kind of defeats the purpose of the password manager in the first place.</p>
","32468","","32468","","2015-04-18 15:54:11","2015-04-24 15:39:06","Multi platform password storage with retrieval for applications with authorization?","<security><authentication><cross-platform><passwords><authorization>","3","6","","","","CC BY-SA 3.0"
"382821","1","","","2018-12-11 04:11:07","","0","241","<p>I have this web API project which handle all database access via entity framework.</p>

<p>I have another web client reside in DMZ to call those APIs (via ajax or c#) in the web API project.</p>

<p>When I make API call via c#, models passing between web client and web API are the same. </p>

<p>For web API, the model is generate by entity framework (database first). </p>

<p>For web client, I create a model class.</p>

<p>Now when I change\update the table in database, I can easily update the model in web API via entity framework but I have to manually update the model class in web client.</p>

<p>It's easy when I only have a few models to maintain, not when I have a lot of models.</p>

<p>Should i separate them just for the sake of separation or I can just ask web client to reference web API and just use those models generate by entity framework?</p>

<p>Are there any security concern if I ask web client to reference web API project?</p>

<p>How should I manage models between web client and web API in this situation?</p>
","176465","","176465","","2018-12-11 04:16:39","2018-12-11 06:35:23","How to manage model(s) between web client (DMZ) and web API?","<security><model><asp.net-mvc-web-api><industry-standard>","1","1","0","","","CC BY-SA 4.0"
"279704","1","","","2015-04-20 22:04:01","","0","110","<p>I need to add a paywall to my site. According to <a href=""http://ui-patterns.com/patterns/Paywall"" rel=""nofollow"">this article</a>, I want to implement a taxometer system. The easiest and least secure way would be tracking the number of viewed articles using secure cookies. But, what if the user deletes the cookie?</p>

<p>I tried to store the data in the backend but I need some sort of connection between my backend the the user's browser. I can't think of anything other than cookies. I know there is a way to do that because NYTimes has improved its paywall system and it works.</p>

<p>I deleted the cookies, session storage and local storage and it still works. I wanna know how they manage to keep track of the browser.</p>

<p>BTW, my backend is python if it helps.</p>

<p>EDIT:</p>

<p>Looks like <a href=""https://nakedsecurity.sophos.com/2014/12/01/browser-fingerprints-the-invisible-cookies-you-cant-delete/"" rel=""nofollow"">browser fingerprinting</a> is the best way to do it so far. The issue with it is that its javascript based and could be disabled easily.</p>
","30448","","30448","","2015-04-20 23:05:56","2015-04-20 23:05:56","Implement taxometer paywall","<security><web>","0","4","","","","CC BY-SA 3.0"
"163671","1","163673","","2012-09-04 19:22:55","","-1","188","<p>I'm making a 'PokÃ©mon Storage System' with a Client/Server model and as part of that I was thinking of storing an inventory file on the users computer which I do not wish to be edited except by my program. An alternative to this would be to instead to store the inventory file on the server and control it's editing by sending commands to the server but I was wondering if there are any situations which require files to be stored on a users computer where editing would be undesirable and if so how do you protect the files? I was thinking AES with some sort of checksum?</p>
","51851","","","","","2012-09-04 19:57:20","Situations that require protecting files against tampering when stored on a users computer","<security>","3","1","","","","CC BY-SA 3.0"
"163952","1","163955","","2012-09-06 18:31:04","","1","5801","<p>Email messages are sent in plain text which means that the messages I send to Derpina are visible to anyone who somehow gets access to them while they are in transit. </p>

<p>To overcome this, various encryption mechanisms were developed: PEM and PGP are two of them. </p>

<p>PEM canonically converts, adds digital signature, encrypts, and sends; PGP does exactly the same.</p>

<p>So how do they differ? Is it that PGP (being a program) is used to generate a PEM message?</p>
","62898","","","user8","2012-09-22 02:33:37","2012-09-22 02:33:37","How do PGP and PEM differ?","<security><email><encryption><privacy>","1","0","0","","","CC BY-SA 3.0"
"280257","1","280311","","2015-04-27 04:44:01","","34","15530","<p>I can't understand the reasoning for making the claims/payload of a JWT publicly visible after base64 decoding it.</p>

<p>Why?</p>

<p>It seems like it'd be much more useful to have it encrypted with the secret.</p>

<p>Can someone explain why, or in what situation, keeping this data public is useful?</p>
","176022","","222996","","2017-09-05 07:43:05","2021-03-09 11:16:18","JSON Web Token - why is the payload public?","<security><json><authentication><jwt>","3","1","","","","CC BY-SA 3.0"
"384867","1","384871","","2019-01-03 01:13:16","","0","189","<p>I was hired to program a basic, plain text site for a local business that amongst other things, provides basic pricing quotes through a Javascript Applet. For obvious reasons, it seemed unnecessary to me to in anyway encrypt the traffic to and from the site. However, the person who hired me strongly requested that I set up HTTPS on the site ""for security reasons"". Assuming I provide minimal upkeep, is there any further risk associated with setting up the SSL certification? </p>
","324824","","","","","2019-01-03 17:49:51","Is there any risk in creating a SSL certified site?","<security><ssl>","3","3","","","","CC BY-SA 4.0"
"280727","1","280731","","2015-05-01 19:45:30","","10","52764","<p>We run a cloud-based medical software, and a very important part of the program is bridging to an imaging software straight from our website, passing information through command line arguments.  We pass a patient's name and ID through a Java applet, and it will open the imaging program that is installed locally on the user's computer.  There are many different imaging software vendors that we bridge to, so it isn't possible to make our own imaging software in the browser.</p>

<p>I was wondering what the best way is to pass in these arguments and open the program, without using the Java applet that we have.  As you all may know, Google is dropping NPAPI support in Chrome, and has just recently pushed update 42 which disables Java applets by default.  It is still possible to use them for now, but support will be dropped completely by September.  So, what would be the best thing to replace our Java applet with?</p>
","176600","","","","","2018-09-14 15:48:48","How to open a desktop application through browser without a Java applet?","<java><security><browser><chrome>","3","3","","","","CC BY-SA 3.0"
"164635","1","164640","","2012-09-12 13:20:13","","2","282","<h3>I'm not talking about MySQL, I'm talking about Microsoft SQL Server</h3>
<p>I've been aware of PDO for quite some time now, standard mysql functions are dangerous and should be avoided.</p>
<p><a href=""http://php.net/manual/en/function.mysql-connect.php"" rel=""nofollow noreferrer"">http://php.net/manual/en/function.mysql-connect.php</a></p>
<p>But what about the MSSQL function in PHP?  They are, for most purposes, identical sets of functions, but the PHP page describing mssql_* carries no warning of deprecation.</p>
<p><a href=""http://us.php.net/manual/en/function.mssql-connect.php"" rel=""nofollow noreferrer"">http://us.php.net/manual/en/function.mssql-connect.php</a></p>
<p>There are PDO drivers available for MSSQL, but they aren't quite as readily available or used as the MySQL drivers.</p>
<p>Ideally, it looks to me like I should get them working and move from mssql_* to PDO like I have with MySQL, but is it as big of a priority?</p>
<p>Is there some hidden safety to MSSQL that means it's exempt from all of the mysql_* hatred as of late?  Or is its obscurity as a backend the only reason there hasn't been more PDO encouragement?</p>
","59198","","-1","","2020-06-16 10:01:49","2012-09-12 15:42:39","Does the deprecation of mysql_* functions in PHP carry over to other Databases(MSSQL)?","<php><security><sql-server>","1","2","","","","CC BY-SA 3.0"
"281998","1","","","2015-05-05 14:48:09","","2","2291","<p>I am trying to figure out where or how i should store application secrets and keys inside a desktop application. 
For example a facebook app key or dropbox key and secret.</p>

<p>So I've read that i should hash, salt, encrypt etc etc these values. This is to prevent someone from reverse engineering my code and seeing the keys. </p>

<p>The is all good and well, but with all these methods, i'm just storing a salt or hash value somewhere instead of the key itself, in the end. Surely if a hacker can get to the salt/hash and possibly the source code, they will be able to decrypt the encrypted key and get my password/key/secret anyway? </p>

<p>One option I've read about that seems the most secure is to not store this value in the desktop app at all, but to call a web service to obtain the key (probably encrypted). But my question is, even in this case, a decent hacker will surely just do a memory dump or something to see what the value returned from the web service is, and then we're back at square 1.</p>

<p>The next best alternative seems to be obscurity.</p>

<p>Am I missing something completely?</p>

<p>On a side note, what use will a facebook/twitter/dropbox/etc key/secret be to a hacker anyway? Surely they would still need a user's credentials or access token to be able to use it anyway?</p>

<p>Any advice or suggestions will be appreciated.</p>
","177950","","","","","2015-05-05 20:20:56","Where to store hashes, salts, keys in Desktop Applications","<security><encryption>","3","2","","","","CC BY-SA 3.0"
"385183","1","","","2019-01-09 12:38:30","","-2","402","<p>I have been trying to figure out an ACL solution for my application which should manage API endpoint's access rights dynamically. Some said that I have an option of Spring Security ACL. I checked it but lack of documentation frightened me a bit. So that I started to design my own ACL implementation; since I did not start implementation can not provide code example but at least I can provide the flow and components planned to be used.</p>

<ol>
<li>A security configuration service. Which will interact with required services to provide dao services between application and database (ofc this will have ref to DAO class as well)</li>
<li>A new annotation to be used with aspect to tag/label all endpoints and to catch through aspect. </li>
<li>An aspect service to intercept requests and check authorization.</li>
</ol>

<p>So this a highly overall idea above definitions with their required helpers.</p>

<p>I will trigger aspect per end point access request. Since I know the label for the endpoint (written in the annotation) I can simply cross-check the access rule and user's roles ( I will access it through the Authentication object of Spring).</p>

<p>Any suggestion or a flaw I am missing here ?</p>
","325349","","353068","","2020-02-10 10:56:50","2022-03-01 15:04:25","Custom ACL Implementation","<java><design><security>","1","2","","","","CC BY-SA 4.0"
"385244","1","385292","","2019-01-10 08:55:10","","0","3835","<p>I know that @RolesAllowd annotation can be used to provide role-based access control to REST endpoints and I am currently using that with RestEASY. </p>

<p>I need to know how it is working behind the scenes. Can anybody please explain to me how Java validates the roles mentioned in the annotation. </p>

<p>So far I managed to figure out that the roles are stored in the UserPrincipal of the HttpServletRequest.</p>
","78509","","","","","2019-01-10 20:02:06","How @RolesAllowed annotation is workin in Java","<rest><security><java-ee>","1","0","","2019-01-10 20:58:34","","CC BY-SA 4.0"
"164916","1","","","2012-09-14 17:03:54","","6","181","<p>There are cases where you have the opportunity, as a developer, to enforce stricter security features and protections on a software, though they could very well be managed at an environmental level (ie, the operating system would take care of it).</p>

<p>Where would you say you draw the line, and what elements do you factor in your decision?</p>

<h2>Concrete Examples</h2>

<h3>User Management is the OS's responsibility</h3>

<p>Not exactly meant as a security feature, but in a similar case Google Chrome used to not allow separate profiles. The invoked reason (though it now supports multiple profiles for a same OS user) used to be that user management was the operating system's responsibility.</p>

<h3>Disabling Web-Form Fields</h3>

<p>A recurrent request I see addressed online is to have auto-completion be disabled on form fields. Auto-completion didn't exist in old browsers, and was a welcome feature at the time it was introduced for people who needed to fill in forms often. But it also brought in some security concerns, and so some browsers started to implement, on top of the (obviously needed) setting in their own preference/customization panel, an <code>autocomplete</code> attribute for <code>form</code> or <code>input</code> fields. And this has now been introduced into the upcoming HTML5 standard. For browsers that do not listen to this attribute, strange hacks<sup>*</sup> are offered, like generating unique IDs and names for fields to avoid them from being suggested in future forms (which comes with another herd of issues, like polluting your local auto-fill cache and not preventing a password from being stored in it, but instead probably duplicating its occurences).</p>

<p>In this particular case, and others, I'd argue that this is a <strong>user setting</strong> and that it's the <strong>user's desire</strong> and the <strong>user's responsibility</strong> to enable or disable auto-fill (by disabling the feature altogether). And if it is based on an internal policy and security requirement in a corporate environment, then substitute the user for the administrator in the above.</p>

<p>I assume it could be counter-argued that the user may want to access non-critical applications (or sites) with this handy feature enabled, and critical applications with this feature disabled. But then I'd think that's what security zones are for (in some browsers), or the sign that you need a more secure (and dedicated) environment / account to use these applications.</p>

<p><sup>* I obviously don't deny the ingeniosity of the people who were <strong>forced</strong> to find workarounds, just the necessity of said workarounds.</sup></p>

<hr>

<h2>Questions</h2>

<p>That was a tad long-winded, so I guess my questions are:</p>

<ul>
<li>Would you in general consider it to be the application's (hence, the developer's) responsiblity?</li>
<li>Where do you draw the line, if not in the ""general"" case?</li>
</ul>
","3631","","3631","","2012-09-16 07:37:37","2012-09-16 07:37:37","Development-led security vs administration-led security in a software product?","<security><auto-completion>","1","1","0","","","CC BY-SA 3.0"
"165164","1","165172","","2012-09-17 16:27:41","","5","1361","<p>I asked something kind of similar on stackoverflow with a particular piece of code however I want to try to ask this in a broader sense.</p>

<p>So I have this web application that I have started to write in backbone using a Single Page Architecture (SPA) however I am starting to second guess myself because of security.  Now we are not storing and sending credit card information or anything like that through this web application but we are storing sensitive information that people are uploading to us and will have the ability to re-download too.</p>

<p>The obviously security concern that I have with JavaScript is that you can't trust anything that comes from JavaScript however in a Backbone SPA application, everything is being sent through JavaScript. There are two security features that I will have to build in JavaScript; permissions and authentication.</p>

<p>The authentication piece is just me override the Backbone.Router.prototype.navigate method to check the fragment it is trying to load and if the JavaScript application.session.loggedIn is not set to true (and they are not viewing a none authenticated page), they are redirected to the login page automatically.  The user could easily modify application.session.loggedIn to equal true (or modify Backbone.Router.prototype.navigate method) but then they would also have to not so easily dynamically embedded a link into the page (or modify a current one) that has the proper classes, data-* attributes, and href values to then load a page that should only be loaded when they user has logged in (and has the permissions).</p>

<p>So I have an acl object that deals with the permissions stuff.  All someone would have to do to view pages or parts of pages they should not be able to is to call acl.addPermission(resource, permission) with the proper permissions or modify the acl.hasPermission() to always return true and then navigate away and then back to the page.</p>

<p>Now certain things is EMCAScript 5 like Object.seal() or Object.freeze() would help with some of this however we have to support IE 8 which does not support those pieces of functionality.</p>

<p>Now the REST API also performs security checks on every request so technically even if they are able to see parts of the interface that they should not be able to, they still should not be able to actually affect any data.</p>

<p>The main benefits for me in developing a JavaScript SPA application is that the application is a lot more responsive since it is only transferring the minimum amount of JSON data for the requested action and performing the minimum amount of work too.  There are also other things that I think are beneficial like you are going to have to develop an API for the data (which is good if you want expand your application to different platforms/technologies) or their is more of a separation between front-end and back-end however if security is a concern, it is really wise to go down the road of a JavaScript SPA application for the front-end?</p>
","20237","","14766","","2012-09-17 16:39:36","2012-10-18 19:38:46","Should I be using a JavaScript SPA designed when security is important","<javascript><architecture><security>","2","1","","","","CC BY-SA 3.0"
"283483","1","","","2015-05-11 09:03:36","","3","624","<p>Is there any point to having a dedicated development database server(s) that all developers can use, i.e. they don't have a local copy of the db in their machines. Quite clearly, this will slow down development but I'm curious whether anyone actually does this in the enterprise level. I know I should trust the devs we hire and I'm guessing this will mostly be the kind of answers that I will be getting but if anyone actually does this I would want to know if it's even worth doing.</p>

<p>UPDATE:</p>

<p>Great answers. My question arises from this question from quora regarding source code protection: <a href=""http://www.quora.com/How-does-Facebook-protect-their-source-code"" rel=""nofollow"">http://www.quora.com/How-does-Facebook-protect-their-source-code</a></p>

<p>Here's the pertinent answer that got me thinking:</p>

<p><code>
Facebook (and Google and probably many others) don't have employees check out code on their laptops. Code is checked out on developer servers or workstations and employees connect to these to work. These are only accessible on the corporate network, and connecting  from outside the network requires VPN, which itself requires multi-factor authentication.
</code></p>

<p>Now that I think about this, if developer have terminal access to the development servers then they must have access to mostly whatever is in there which most likely includes the db. </p>
","156469","","156469","","2015-05-11 10:03:13","2015-05-11 12:20:23","Is there any point in preventing developers from having a local copy of the database in their machine?","<database-development><code-security>","2","7","","","","CC BY-SA 3.0"
"385669","1","","","2019-01-17 01:30:37","","10","1414","<p>If passwords are stored hashed, how would a computer know that your password is similar to the last one if you try resetting your password? Wouldn't the two passwords be totally different since one is hashed, and unable to be reversed?</p>
","326041","","","","","2019-01-22 19:35:32","If passwords are stored hashed, how would a computer know that your password is similar to the last one if you try resetting your password?","<database><security><hashing><passwords>","5","3","0","","","CC BY-SA 4.0"
"283569","1","","","2015-05-12 00:35:08","","0","152","<p>I am building a web app that will <strong>first validate a promotion code via AJAX call</strong> and then <strong>if it is valid, allow the user to fill out the rest of the form</strong>, I use KnockoutJS to reveal and hide the elements.</p>

<p>My issue is, what is stopping a sneaky user from building a code generator and pumping the codes into my ajax endpoint until he gets a valid code? What is the recommended way of stopping this abuse?</p>

<p>PS: In the final step of the form I also validate the promotion code server-side just in case. </p>
","179630","","","","","2015-05-12 05:08:16","How to protect controller endpoint from abuse?","<javascript><security><ajax>","2","2","","","","CC BY-SA 3.0"
"385843","1","385847","","2019-01-20 17:18:47","","3","138","<p>My project relies on a specialized component which is stuck (by its configuration) to an older version of the framework my project is using. This makes updating to the latest version of the framework impossible. </p>

<p>What are the best practices when dealing with this type of issue?</p>
","326335","","278015","","2019-01-21 09:19:43","2019-01-21 09:19:43","Critical dependency is preventing me from updating my app to latest framework version","<security><dependency-management>","2","1","","","","CC BY-SA 4.0"
"165460","1","165466","","2012-09-20 01:48:07","","5","2133","<p>First things first: I have absolutely no interest in learning how to crack systems for personal enrichment, hurting other people or doing anything remotely malicious.</p>

<p>I understand the basis of many exploits (XSS, SQL injection, use after free etc.), though I've never performed any myself. I even have some idea about how to guard web applications from common exploits (like the aforementioned XSS and SQL injection)</p>

<p><a href=""https://security.stackexchange.com/questions/20371/from-a-technical-standpoint-how-does-the-zero-day-internet-explorer-vulnerabili"">Reading this question</a> about the Internet Explorer zero-day vulnerability from the Security SE piqued my curiosity and made me wonder: how did someone even find out about this exploit? What tools did they use? How did they know what to look for?</p>

<p>I'm wary about visiting hacker dens online for fear of getting my own system infected (the Defcon stories make me paranoid). So what's a good, safe place to start learning?</p>
","50454","","-1","","2017-03-17 10:46:00","2012-09-20 10:46:28","Learning about security and finding exploits","<learning><security>","3","1","","2012-09-24 16:59:40","","CC BY-SA 3.0"
"165529","1","","","2012-09-20 15:04:28","","2","308","<p>Recently, iOS 6 was <a href=""http://www.engadget.com/2012/09/20/ios-6-jailbreak-a4-devices/"" rel=""nofollow"">""jailbroken""</a> but only on the Apple A4 CPU. </p>

<p>Why is the ""jailbreaking"" process specific to a CPU?</p>

<p>From <a href=""http://en.wikipedia.org/wiki/IOS_jailbreaking"" rel=""nofollow"">Wikipedia</a>:</p>

<blockquote>
  <p>... ""iOS jailbreaking is the process of removing the limitations imposed by
  Apple on devices running the iOS operating system through the use of
  hardware/software exploits â€“ such devices include the iPhone, iPod
  touch, iPad, and second generation Apple TV. Jailbreaking allows iOS
  users to gain root access to the operating system"""""" ...</p>
</blockquote>
","37859","","23724","","2012-09-20 18:22:37","2012-09-23 04:03:38","Why is iOS ""jailbreaking"" CPU specific?","<security><ios><hacking>","1","3","","","","CC BY-SA 3.0"
"165552","1","165555","","2012-09-20 16:57:45","","9","2659","<p>We are developing a web application with a fairly standard registration process which requires a client/user to verify their email address before they are allowed to use the site.  The site also allows users to change their email address after verification (with a re-type email field, as well).</p>

<p>What are the pros and cons of having the user re-verify their email.  Is this even needed?</p>

<p><strong>EDIT:</strong></p>

<p><em>Summary of answers and comments below:</em></p>

<ul>
<li>""Over-verification"" annoys people, so don't use it unless critical</li>
<li>Consider a ""re-type email"" field to prevent typos, but users can still copy/paste, rendering it moot.</li>
<li>Beware of overwriting known good data with potentially good data</li>
<li>Send email to old for notification; to new for verification</li>
<li>Don't assume that the user still has access to the old email</li>
<li>Identify impact of incorrect email if account is compromised</li>
</ul>
","56860","","56860","","2012-09-21 06:51:36","2013-02-28 14:51:45","What is the best policy for allowing clients to change email?","<security><email><authentication>","3","0","","","","CC BY-SA 3.0"
"165589","1","165642","","2012-09-20 22:20:20","","8","295","<p>I am working on a website that requires a bit of marketing; let me explain.</p>

<p>This website is offering a <em>single</em>, say, iTunes 50$ voucher to a lucky winner.</p>

<p>To be entered in the draw, you need to invite (and has to join) at least one friend to the website. Pretty straightforward.</p>

<p>Now, of course it would be easy for anyone to just create a fake account and invite that account so, I was thinking of some other way to somehow find out of possible cheating.</p>

<p>I was thinking of an IP check on the newly subscribed (invited) user, and if there is the same IP logged in the last 24 hours, and if that's the case, investigate more about it. </p>

<p>But I was thinking that maybe there is a more clever way around this issue. Has anyone ever though about this? What other solutions did you try?</p>

<p>Thanks in advance.</p>
","65728","","","","","2012-09-21 12:32:55","Avoiding ""double"" subscriptions","<security>","4","3","","","","CC BY-SA 3.0"
"385921","1","385922","","2019-01-22 09:35:54","","3","1761","<p>I'm rather new at programming so I'm still getting a grip on things.</p>

<p>I'm creating an offline login system in C# that will have the ability add/remove users. The computer will not be connected to the internet.</p>

<p>This was the approach that I was going to take:</p>

<p>Have the username and a salted + hashed password in an XML file. The XML file will be encrypted with a unique key that is worn around the user's neck (something like an ID card).</p>

<p>So the process should goes like this:</p>

<ol>
<li>User scans their ID card and enters their username.</li>
<li>Application finds user's encrypted XML file and decrypts it.</li>
<li>User enters their password in. </li>
<li>Application checks it and grants/denies access.</li>
</ol>

<p>EDIT: To everyone reading, don't do this - It's a bad idea. The assembly can be reverse engineered. </p>
","","user326468","","user326468","2019-01-23 06:38:44","2019-01-23 06:38:44","Best approach to creating a secure offline login system in C#?","<c#><security><encryption><login><offline>","3","3","","","","CC BY-SA 4.0"
"386148","1","","","2019-01-26 05:32:51","","1","537","<p>Recently I have been working on a rather large system with Vue.js for a single page app (SPA) and an API for the backend. The customer is concerned with the security, performance and maintainability. </p>

<p>So, I'm thinking along having API broken into 3 separate pieces:</p>

<ol>
<li>the security api which authenticates/authorizes, issues/revokes token with user roles/permissions and accounts. It would have a separate db</li>
<li>the business API that has the business functionality, accessible only thru the token issued by the security api. It would have a separate db</li>
<li>notification api that sends real time notifications and email or text alerts. Again a separate db. </li>
</ol>

<p>On the front there would be separate apps: 
one for security api for managing roles user accounts, monitor logs etc
and another one, the business app, for the complex business functionality.</p>

<p>I would like to know:  </p>

<ol>
<li><p>what are the advantages and inconveniences of this architecture (2 frontend apps and 3 webapi) compared to a single frontend and a single web api ?</p></li>
<li><p>which one would be the recommended one, in view of the triple constraint of security, performance and maintainability ?  </p></li>
</ol>
","67385","","209774","","2019-01-26 11:07:42","2019-01-26 11:47:39","Breaking 3-tier architecture into multi-tier architecture","<architecture><api><security><web-api><n-tier>","1","1","","","","CC BY-SA 4.0"
"165967","1","","","2012-09-24 06:06:58","","6","403","<p>Let me start by saying that I am a computer security researcher. Part of my job is to create malware to deploy on a controlled environment in order to study or evaluate several aspects of computer security.</p>

<p>Now, I am starting to think that using an online code hosting service (such as <a href=""http://bitbucket.org"" rel=""nofollow"">BitBucket</a>, <a href=""http://www.github.com"" rel=""nofollow"">Github</a>, etc...) to have all my code in 1 place, would allow me to work on my projects more efficiently.</p>

<p>My question is: <strong>Are there any issues with this?</strong> I have studied those companies' privacy policies, and they state that they allow usage of their services for lawful usage. Since I am not distributing malware, but I am only using it on my machines and machines that I am authorized to use, aren't I allowed to use the service? For the usage that I am doing, malware is the same as any other software.</p>

<p><strong>I recognise that I should be extremely careful with code hosting</strong>, as any mistake from my part could hold me liable for damages and leave me open against legal action. As such I am recognizing that I should use private repositories, so the code is not available to the public. <strong>But how private is a private repository?</strong> How can I trust that companies like them will not leak or sell a potential (electronic) viral weaponry that I may have created in the future?</p>
","57656","","25936","","2012-09-24 07:07:06","2012-09-24 07:07:06","Would I be able to use code hosting services to host malware code?","<security><project-hosting>","2","3","","","","CC BY-SA 3.0"
"284365","1","","","2015-05-19 22:08:38","","4","3383","<p>I was looking <a href=""http://docs.oracle.com/cd/E17904_01/web.1111/e13702/maven_deployer.htm"" rel=""nofollow"">at the Oracle documentation for the weblogic maven plugin.</a></p>

<p>In it, they store the weblogic user name and password for accessing in the pom.xml.</p>

<p>Just wondering, isn't this a terrible idea? How should one handle this? </p>

<pre><code> &lt;plugin&gt; 
      &lt;groupId&gt;com.oracle.weblogic&lt;/groupId&gt; 
      &lt;artifactId&gt;weblogic-maven-plugin&lt;/artifactId&gt; 
      &lt;version&gt;10.3.4&lt;/version&gt; 
      &lt;configuration&gt; 
          &lt;adminurl&gt;t3://localhost:7001&lt;/adminurl&gt;
          &lt;user&gt;weblogic&lt;/user&gt; 
          &lt;password&gt;weblogic123&lt;/password&gt; 
          &lt;upload&gt;true&lt;/upload&gt; 
          &lt;action&gt;deploy&lt;/action&gt; 
          &lt;remote&gt;false&lt;/remote&gt; 
          &lt;verbose&gt;true&lt;/verbose&gt; 
&lt;source&gt;${project.build.directory}/${project.build.finalName}.${project.packaging}&lt;/source&gt; 
         &lt;name&gt;${project.build.finalName}&lt;/name&gt; 
      &lt;/configuration&gt; 

      &lt;executions&gt; 
         &lt;execution&gt; 
            &lt;phase&gt;install&lt;/phase&gt; 
              &lt;goals&gt; 
                &lt;goal&gt;deploy&lt;/goal&gt; 
              &lt;/goals&gt; 
         &lt;/execution&gt; 
       &lt;/executions&gt; 

  &lt;/plugin&gt; 
</code></pre>
","109776","","","","","2015-05-20 07:46:09","What's the best practise for storing web server credentials for your web app deployment?","<web-applications><security><passwords>","1","0","","","","CC BY-SA 3.0"
"166268","1","166676","","2012-09-26 09:12:48","","4","425","<p>Should I be concerned with security when installing Node packages globally? Why or why not?</p>
","5508","","65760","","2012-10-10 12:07:33","2012-10-10 12:07:33","How secure (or insecure) is it to install Node packages globally?","<javascript><security><node.js>","1","0","","","","CC BY-SA 3.0"
"284592","1","","","2015-05-21 18:00:16","","1","93","<p>A typical API authentication usually rely on a pair of API ID + SECRET, my question is: if the API ID is unique and randomly generated and is considered strong enough (e.g. SHA512), why a SECRET is even needed?</p>

<p>What if, I created an API only need a API ID for authentication, what would be the drawback, especially in term of security?</p>

<p>Some people might say, it is easy to revoke the SECRET without changing API ID, <strong>but this does not sound since if you need to update the SECRET, you need to modify the config/source code</strong> as well. </p>

<p>Internally the API program can still have some unique ID to identify the client, <strong>but this information does not need to expose to the client code</strong>, just use a single ID is enough, right?</p>

<p>Actually I would considered using a single API ID is more secure - since when you change , it is more hard to identify the client (as there is no constant API ID)</p>

<p>Any conveats?</p>
","3415","","","","","2015-05-21 20:00:10","API authentication with a single ID","<security><rest><api><api-design><web-api>","1","0","","","","CC BY-SA 3.0"
"284654","1","284657","","2015-05-22 10:51:46","","0","201","<p>When a user forgets their password, is it better practice to reset the password and email that to the user or just to email the current password to the user's email address.</p>
","181044","","110531","","2015-05-22 11:43:33","2017-07-26 06:27:37","Resetting vs. re-sending forgotten passwords","<security><passwords>","2","10","","","","CC BY-SA 3.0"
"284700","1","284703","","2015-05-22 19:37:31","","1","168","<p>I keep coming across questions and articles on the internet suggesting that it's not a good practice to have the IDs of your database records visible to the public. Yet I've never taken it seriously myself nor have (in my professional career) come across an application that actively attempted to hide IDs. I've recently been working on an MVC application and have my public URLs in the following format:</p>

<pre><code>/Book/55/title-of-book
</code></pre>

<p>Should I make efforts to change the <code>Id</code> part of the URL (55) into a hash of some sort? For example here's how Reddit has its URLs:</p>

<pre><code>/r/subreddit/comments/36v4kb/title_of_article/
</code></pre>

<p>If I were to keep the IDs hidden in my URLs I'd also have to strip them from all places where they publicly appear in my code and do changes in my database. That's not an easy task but I have no problem doing it if it's considered good practice.</p>

<p>What are the benefits of keeping IDs hidden and what are the best ways of going about hiding them?</p>
","154465","","80833","","2015-05-22 20:14:02","2015-05-22 20:14:02","How much should I concern myself with hiding the IDs of my database in URLs?","<web-development><security>","2","1","","","","CC BY-SA 3.0"
"386778","1","386779","","2019-02-06 19:32:44","","1","202","<p>This is a basic question, but I don't have any sense of what other developers do in this scenario.</p>
<h3>The Situation</h3>
<p>I am creating an interface to allow end users to insert and update data in a table stored in an Oracle database. The interface will ask for an Excel worksheet and then generate a MERGE script with SQL to insert the data into the database table. I want the users to have to log into the database before they can perform these types of transactions.</p>
<p>I can think of a few ways to accomplish this:</p>
<ol>
<li><p>Ask my DBA to create a new schema in the database, store this table there, and give all end users permission to edit tables in this schema.</p>
</li>
<li><p>Ask my DBA to create a new schema (aka &quot;user&quot; in the case of Oracle) and have end users all use this one userId and password. So maybe the userID is named &quot;Accounting&quot; and the password is &quot;hunter2&quot; and everyone in Accounting is given this user ID and password. Then I store the table in the &quot;Accounting&quot; schema.</p>
</li>
</ol>
<p>Number 1 seems like a better option than number 2, but I'm not confident that either of these are good ideas.</p>
<h3>My questions</h3>
<p>Could anyone recommend a general strategy or some best practices on how to deal with this type of situation? Perhaps I'm thinking about this all the wrong way?</p>
","316187","","-1","","2020-06-16 10:01:49","2019-02-16 05:47:02","How to safely allow different end users to insert data into a table stored in an Oracle database?","<database><security><user-interface><schema><oracle>","1","0","","","","CC BY-SA 4.0"
"284905","1","","","2015-05-25 12:57:34","","0","556","<p>Can you tell me the value of using PHP encoder (ioncube, phpshield) with currently present service like decry.pt (<a href=""http://www.decry.pt/"" rel=""nofollow"">http://www.decry.pt/</a>) that can easily decode source codes.</p>

<p>I have tried decry.pt's free demo. Just drag &amp; drop an encoded source and it will return the decoded one. It is so easy.</p>

<p>It seems the value of encoder can be easily be canceled.</p>
","181322","","","","","2015-05-27 04:05:19","What is the value of encoders with decoders currently present","<php><security>","2","0","","","","CC BY-SA 3.0"
"166959","1","","","2012-10-01 18:36:36","","3","401","<p>I'm building an Android app and associated set of web services for uploading/downloading data. I need a basic (no frills) solution for account management (register, login, logout, verify credentials/token).</p>

<p>What open source / third party solutions exist for this scenario?</p>

<p>I need:</p>

<ul>
<li>create a new account db based on a salt</li>
<li>simple web service to create a new account</li>
<li>simple web service to authenticate supplied credentials and return some sort of token</li>
</ul>

<p>That's it, I can get by without 'fancy' email activation or  password reset for the time being.</p>

<p>And then moving beyond simple account management, I will need some sort of 'token' based authentication for a web service.</p>

<p>Are there off-the-shelf components for this? Should I just use a 'blank' django or rails app to get this done? Seems crazy for everyone to be doing CREATE TABLE user_accounts ...</p>

<p>Thoughts?</p>

<p>Thank you.</p>
","65631","","65631","","2012-10-01 23:21:37","2012-10-03 04:33:55","Drop in service for account management, authentication, identity?","<web-applications><security><web-services>","2","1","","","","CC BY-SA 3.0"
"387044","1","","","2019-02-12 09:11:42","","1","93","<p>Consider a token issuer/validator. Every token is PKI signed. </p>

<p>Is it more secure to use a new key-pair (performance could be ignored for now) per request or is it no difference to have only one key-pair for all?</p>

<p>It's a theoretical question, an implementation could be for example to generate a key-pair with expiration usage time etc.</p>

<p>The question looks obvious, but I, as a newbie in security, have concerns about it.</p>
","328194","","","","","2019-03-14 14:01:10","Is it more secure to use more PKI keys?","<security>","1","1","","","","CC BY-SA 4.0"
"387350","1","387364","","2019-02-18 10:38:16","","2","171","<p>This is basically an extension to <a href=""https://softwareengineering.stackexchange.com/questions/382022/what-is-the-best-practice-s-for-managing-many-certificates"">my previous question</a>. That time our internal discussions didn't end up anywhere and the whole issue was forgotten for the time being.</p>

<p>Now we've touched upon it again, this time with username/password credentials for external systems. So, a more generic/slightly different version of the same question:</p>

<p>When your system interfaces with multiple 3rd party external systems, there are some sort of endpoint configurations involved. Typically there will be a URL and either a username/password combo, an API key, or a client certificate. More often than not there will even be two sets of these - one for a testing/development environment, another for production.</p>

<p>So, after these have been communicated, what is the best practice what to do with them?</p>

<ul>
<li>My opinion is that they should be documented somewhere. If you want them to be secure, you can encrypt then somehow (KeePass, ZIP file with a password, whatever). But there should be a logical place where they should be kept against future need. Perhaps it can be in the project documentation. Perhaps there's a central storage for these. Whatever. Just - somewhere else where people can quickly find them when needed.</li>
<li>My colleague's opinion is that they should NOT be documented anywhere. Well, OK, the test credentials can be documented, but the production credentials should only exist in a config file on the production server(s) and nowhere else. His reasoning is that nobody should need to access these credentials outside that server and storing them elsewhere compromises security. If the production server suffers a crash - that's what backups are for and those backups include the config files too. And if the whole system is so broken that even the backups are corrupted - then you have a bigger problem anyway.</li>
</ul>
","7279","","","","","2019-02-18 12:44:39","Should usernames and passwords to external systems be documented?","<security><configuration-management><passwords>","1","0","","","","CC BY-SA 4.0"
"285377","1","","","2015-05-30 19:40:51","","6","373","<p>Same Origin Policy does not prevent origin <code>foo.bar</code> from creating a form with action attribute set to another origin <code>baz.duh</code> and even allows to programmatically submit this form without the user knowing through untrusted events originating via JavaScript just by loading the page. To solve this issue, programmers are forced to use CSRF tokens.</p>

<p>If AJAX requests originating from <code>XMLHttpRequest</code> and <code>canvas</code> objects are subject to Same Origin Policy and not allowed to access the response, why aren't form submissions/XHR requests simply disallowed? What is the reasoning behind this allowance?</p>

<p>I know endpoints accepting the <code>GET</code> request method can be exploited by images as well, but this question is about <code>POST</code> and similar method forms only. Wouldn't the need of CSRF tokens vanish if SOP didn't permit cross-origin form submission? What purpose does cross-origin form submission serve?</p>
","179490","","158187","","2015-07-08 15:43:48","2022-12-09 10:12:29","Why does SOP permit cross-origin form submissions?","<security><web><http>","1","0","","","","CC BY-SA 3.0"
"167482","1","","","2012-10-04 19:21:59","","-1","1142","<p>It's been a while I have been thinking on what could be the best scenario for creating a secure login in a client-server application running on internet or any other networks ! So I became with the idea to ask this question on programmers and I hope that this question will make awareness of new aspects of threads and security here by some kind of brain storming , I am really interested in good and new anseawres . Thanks in advance for your participation .</p>
","61284","","21094","","2012-10-04 20:05:39","2012-10-04 20:28:52","What is the Best Practice for creating a secure login in a client - server appllication?","<.net><security><login>","3","3","","","","CC BY-SA 3.0"
"387833","1","","","2019-02-28 14:32:49","","3","141","<p>I'm currently working on a protocol which passes automated instructions between separate organisations.  I'm looking for a way to delegate authentication of devices to which ever organisation a device belongs to.  This doesn't affect authorisation models, only authentication.</p>

<p>So to put this in terms of DNS domains:</p>

<ul>
<li>organisation <code>foomy.tld</code> should be able to authenticate (eg: sign the certificate for?) <code>new_deive.foomy.tld</code>.</li>
<li>organisation <code>acme.tld</code> could choose to trust <code>foomy.tld</code>:

<ul>
<li>It should then be able to trust <code>new_device.foomy.tld</code> is what it says it is on the authority of <code>foomy.tld</code></li>
<li>BUT organisation <code>acme.tld</code> should NEVER trust <code>foomy.tld</code> to authenticate any device outside the domain of <code>foomy.tld</code>.</li>
</ul></li>
</ul>

<h3>Considering using x509 and SSL</h3>

<p>In the case of x509 CA certificates, the CA role is usually performed by a third party CA.  But that isn't appropriate for this purpose:</p>

<ul>
<li>The creation / destruction of device IDs (services) is too rapid to consider a traditional CA (too expensive, too slow).</li>
<li>This mechanism needs to authenticate clients and servers.  Devices / services do not always have public IP addresses so CA solutions such as LetsEncrypt aren't an option.  </li>
<li>Creating a dedicated CA for this single purpose is not cost effective and likely to damage adoption.</li>
</ul>

<p>So this leads to the idea of an organisation acting as their own CA for this purpose.  But as it turns out, x509 really doesn't support this well, because once you accept a CA as being trustworthy you cannot limit the scope of that trust enough.  IE: <a href=""https://security.stackexchange.com/questions/31376/can-i-restrict-a-certification-authority-to-signing-certain-domains-only"">You cannot trust it to only sign certificates for it's own domain</a>.</p>

<h3>Considering re-purposing single sign on mechanisms</h3>

<p>The single sign-on mechanisms I've looked at appear to be built around the concept of authenticating users.  Background automated services don't appear to be well supported.</p>

<p>Maybe I missed something here.</p>

<h3>Question - Keeping it as narrow as possible.</h3>

<p>Is there another approach allowing this type of cross organisation authentication which I can use for my problem ?</p>
","51266","","9113","","2019-03-06 06:40:33","2019-03-08 19:41:37","How to authenticate devices across organisation boundaries without a third party CA","<security><authentication>","1","21","","","","CC BY-SA 4.0"
"286177","1","292136","","2015-06-08 18:36:29","","2","168","<p>It seems to me that it would be pretty useful to be able to indicate an expected crypto hash value in file downloads especially since so many application and data downloads rely on mirrored hosting. This could be done as an attribute to an 'a' tag (I'm not sure if there is a better way). In this scenario the browser would of course check the hash and probably remove the file with a warning if the hash didn't match what was downloaded. As far as I know there is no way to achieve something like this today. Is that correct? If that's true is there a good reason that something like that shouldn't be proposed as an addition to the HTML5 spec. And finally, if it is a reasonable thing to suggest, what is the best way to make such a suggestion?</p>
","32942","","","","","2015-08-07 20:22:14","Crypto hash in 'a href'?","<security><html5><specifications>","2","4","","","","CC BY-SA 3.0"
"286396","1","","","2015-06-10 14:30:10","","8","3784","<p>I'm a junior programmer, am working on a WPF application that will deploy to ~50 users. </p>

<p>We basically are streamlining all of his charting/tracking of client data. Each user will probably make about 25 read/writes a day. </p>

<p>I have everything working in Azure but my issue/fear/question is I'm directly calling stored procedures in the Azure SQL db for all CRUD/Loading operations... is this wise/correct? Should I be leveraging another technique like a web service? Never worked with web services or web apis or web workers.. etc.. I'm basically just doing what it takes to make it WORK.</p>

<p>Again... I'm a junior dev...&amp; I know just enough to be dangerous.</p>

<p>My concerns are that it is less secure and I'm afraid of higher costs from Azure because I'm doing something a bad or terrible way.</p>
","173797","","","","","2019-11-27 15:42:36","Directly query database vs. Using web service","<security><web-services><azure><stored-procedures>","3","7","","","","CC BY-SA 3.0"
"388285","1","","","2019-03-08 15:46:01","","0","378","<p>My company works with different developers from different studios, always sharing the code to everyone aboard.  At the moment, we need to protect a part of the code, not from theft but from some random developer in the studio maybe changing something important by mistake.  Is there a way to protect a critical part of the code from this happening?</p>
","330495","","90149","","2019-03-11 17:31:55","2019-04-04 22:26:37","Protect Part of the Code","<version-control><source-code><code-security>","3","7","","","","CC BY-SA 4.0"
"286499","1","286503","","2015-06-11 16:29:03","","1","1199","<p>I have generated a .exe of a Python script. I wish to give this software as a demo version to few of clients. </p>

<p>For the same I want to bind the software to a particular PC. i.e. If I install the software one a particular PC, the client should not be able to copy the .exe from his PC to some other PC and use the software. </p>

<p>What are the ways in which I can ensure this. I have heard that binding the MAC address of the PC with software is one of the options. Please correct me if I am wrong or suggest other methodologies of achieving the desired task.</p>
","183289","","31260","","2016-12-20 12:44:36","2016-12-20 12:44:36","Binding software to one PC","<security>","2","4","","2015-06-16 21:35:11","","CC BY-SA 3.0"
"388392","1","388523","","2019-03-11 09:58:45","","3","792","<p>I've made a simple login form. It's made very generic to be used for any project. Now I wonder if the security is good enough and if my approach is safe.</p>

<p><strong>On success</strong></p>

<p>When successfully logged in I do two things. I set a cookie with <code>username</code> and <code>hash</code> (sha256). I also write a temp file to the server with the <code>username</code> and <code>hash</code> (sha256). Both username and hash now matches the cookie.</p>

<p><strong>Can be logged in the day after</strong></p>

<p>The reason for this approach is that I can still be logged in a day later. It does not need to check password, just match the hashes for that username.</p>

<p><strong>Can it be easily hacked?</strong></p>

<p>Is this a good approach? If not, what are the pitfalls? Can it be easily hacked? If so give alternatives.</p>

<p>If you need more information about the project, the full form is here <a href=""https://github.com/jenstornell/wall"" rel=""nofollow noreferrer"">https://github.com/jenstornell/wall</a> and only the login part is here: <a href=""https://github.com/jenstornell/knock"" rel=""nofollow noreferrer"">https://github.com/jenstornell/knock</a></p>
","174677","","252416","","2019-03-13 07:24:58","2019-03-13 09:38:16","Is a cookie hash that matches with file hash safe?","<php><security><authentication><cookies>","4","9","","","","CC BY-SA 4.0"
"168390","1","","","2012-10-10 20:31:14","","4","269","<p>I stumbled upon this news article on BBC,</p>

<ul>
<li><a href=""http://www.bbc.co.uk/news/technology-19896353"" rel=""nofollow"">RSA splits passwords in two to foil hackers' attacks</a></li>
</ul>

<p><strong>tl;dr</strong> - a (randomized) password is split in half and is stored across two separate servers, to foil hackers that gained access to either server upon a security breach.</p>

<p>Now the main question is, how would this kind of system would be made... <em>codespeaking</em>, for PHP which I commonly develop on my web applications, the database password is normally stored in a configuration file, i.e. config.php with the username and password, in that case it is understandable that the passwords can be stolen if the security was compromised.</p>

<p>However when splitting and sending the other half to the other server, how would this go on when making a communication to the other server (keeping in mind with PHP) since the other server password would be stored in a configuration file, wouldn't it? In terms of security is to keep the other server password away from the main one, just exactly how would the main server communicate, without exposing any other password, apart from the first server.</p>

<p>This certainly makes me think...</p>
","2090","","","","","2012-10-10 21:30:12","System that splits passwords across two servers","<database><security><server><passwords>","4","3","0","","","CC BY-SA 3.0"
"388552","1","","","2019-03-13 17:21:41","","0","60","<p>I'm just getting into OAuth2 and I'm a tad confused (you've probably heard that before)!</p>

<p>I am writing a small independent service which will expose a basic REST API enabling client applications to upload and download files. Please don't ask why I'm not using S3 or some other cloud provider service - suffice to say that the decision is out of my hands! </p>

<p>The service will just lump files into a flat storage space and leave it up to the client applications to structure the information if required. The service will therefore handle 'clients' with many 'files'.</p>

<p>Initially, this service will only be used by an old monolithic legacy web app - a classic 3 tier client-server architecture using J2EE and Apache Wicket for the front end (so server generated UI). There are dedicated instances of this web application running within third-party data centres as well as a few instances running in our own data centre. All of these will access the new service so not all communication will be within the same data center (all over HTTPS though).</p>

<p>Some instances of the legacy web-app are multi-tenant so within one such instance, not all tenants will have access to the new service. </p>

<p>At some point, there will also be a dedicated administration interface (in order to create new clients and assign storage quotas etc.) which will be a JS-SPA and will call admin REST endpoints.</p>

<p>So I'm having trouble figuring out which OAuth flow to implement. Implicit Flow seems appropriate for the JS Administration interface but as for the legacy app (and any future services/applications) I'm not really sure.</p>
","330888","","1204","","2019-03-13 18:24:19","2019-03-13 18:24:19","Which OAuth2 Flow?","<security><microservices><soa><oauth2>","0","2","","","","CC BY-SA 4.0"
"388559","1","","","2019-03-13 18:55:28","","8","1025","<p>I've been working on a personal project in C# whose purpose is more or less to allow the user to execute scripts written by other users and restrict the permissions of that script. My program compiles the scripts using a third-party library, sandboxes them using the .NET Code Access Security mechanisms and makes sure that they have only those permissions that the user wants to give them.</p>

<p>Broadly speaking, my security requirements are:</p>

<ul>
<li>the user should be able to restrict the untrusted script's access to only certain parts of the filesystem, including forbidding all filesystem access</li>
<li>the user should be able to restrict the untrusted script's network connections to only certain IP addresses or hostnames, including forbidding all network connections</li>
<li>it is okay if the user script manages to hang or terminate the host application, but the user script must not be able to circumvent the permission restrictions (i.e. denial of service is okay, breach isn't)</li>
</ul>

<p>I'm contemplating trying to do something similar in C++, as a sort of a personal exercise. Obviously, things are more complicated when running native code directly, even if the user scripts are written in a scripting language like Lua.</p>

<p>The first approach I can think of is to insert my own hooks in the scripting environments standard library functions. For example, if the scripting language is Lua, instead of exposing io.open normally, I would have to expose a wrapper that checked the arguments against the script's permissions before passing them to the original implementation.</p>

<p>My concern with this approach is that it drastically increases the amount of my own code that is in charge of security and, therefore, a potential security vulnerability that I wrote myself. In other words, when working with .NET CAS, I can trust that Microsoft did its job well in the sandboxing code, as opposed to having to trust my own sandboxing code.</p>

<p>Are there any alternatives I'm unaware of?</p>
","92451","","92451","","2019-03-14 14:08:10","2019-06-09 10:03:36","Securely sandboxing user scripts in a C++ program","<c++><security>","1","11","","","","CC BY-SA 4.0"
"388934","1","388936","","2019-03-20 15:12:55","","3","217","<p>We're developing an Angular application that consumes a web method exposing some information that is not sensitive, just bus seat promotions; the user enters where he wants to go and when and he will be presented with the available offers (if any). The site does not require any kind of authentication for this information is publicly available and it is just trying to offer an easy way to gather this information for the public.</p>

<p>There's been an argument about whether it is convenient to implement OAUTH on the service itself, creating a service account for the angular application so we know that no one else is trying to access this information. The way I see it, I don't think it is necessary, this is publicly available info and if they want to access it they can parse the information on the site or even figure out the credentials that the Angular app is using. Is there any benefit that I'm missing here?</p>
","225184","","225184","","2019-03-20 15:33:16","2019-03-21 19:35:10","Does it make sense to authenticate a method that exposes non-sensitive data","<architecture><security><web-services>","1","11","0","","","CC BY-SA 4.0"
"287397","1","287445","","2015-06-20 17:44:49","","2","2206","<p>I am building an API for minecraft called the <a href=""http://www.minecraftforum.net/forums/mapping-and-modding/minecraft-mods/wip-mods/2344753-the-quantum-api-a-better-alternative-to-forge-and"" rel=""nofollow"">Quantum API</a>. We all know that reflection can be used to do some nasty stuff to classes, and even cause undefined behavior if used without care.</p>

<p>Is there a way to make classes and objects immune to reflection? Perhaps with a security manager? Or vice versa, restrict a certain list of classes/objects from using reflection?</p>

<p>My use would be to prevent other mods that are loaded with this API from using reflection to change a RuntimePermission in a SecurityManager, and to prevent modification of minecraft's base classes (and objects) at runtime, as well as the API's own classes (and objects).</p>
","116419","","","","","2015-06-21 12:57:47","How can I make an object/class inaccessible to Reflection","<java><reflection><code-security>","1","8","","","","CC BY-SA 3.0"
"169941","1","169970","","2012-10-15 13:36:29","","10","474","<p>At my local university, there is a small student computing club of about 20 students.  The club has several small teams with specific areas of focus, such as mobile development, robotics, game development, and hacking / security.</p>

<p>I am introducing some basic agile development concepts to a couple of the teams, such as user stories, estimating complexity of tasks, and continuous integration for version control and automated builds/testing.</p>

<p>I am familiar with some basic development life-cycles, such as waterfall, spiral, RUP, agile, etc., but I am wondering if there is such a thing as a software development life-cycle for hacking / breaching security.  Surely, hackers are writing computer code, but what is the life-cycle of that code?  I don't think that they would be too concerned with maintenance, as once the breach has been found and patched, the code that exploited that breach is useless.</p>

<p>I imagine the life-cycle would be something like:</p>

<ol>
<li>Find gap in security</li>
<li>Exploit gap in security</li>
<li>Procure payload</li>
<li>Utilize payload</li>
</ol>

<p><strong>What kind of differences (if any) are there for the development life-cycle of software when the purpose of the product is to breach security?</strong></p>
","58568","","12436","","2012-10-16 15:44:50","2012-10-16 15:44:50","What are unique aspects of a software Lifecycle of an attack/tool on a software vulnerability?","<development-process><security><hacking><sdlc>","5","8","","","","CC BY-SA 3.0"
"389226","1","","","2019-03-26 15:41:43","","0","63","<p><strong>So I am developing an employee management application on behalf of a company and am concerned about the extent of rights and capabilities that are to be bestowed upon registered administrator accounts.</strong> </p>

<p>Here's the question under a <strong>philosophical light</strong>:
<em>""What is to be done when the one with power is corrupt?""</em></p>

<p>Here's the question under a more <strong>practical example</strong>:
<em>""What is to be done when the one in charge of a bank is corrupt?""</em></p>

<p>Now I'm not even suggesting that the company is corrupt, but I am wondering if there are some, perhaps light-hearted, <strong>measures</strong> that can be put in place to avoid the <strong>potential of fraud</strong> that may be accessible to those with administrator powers. </p>

<p>It's not easy to find any information online in regards to this. How do people deal with this concerning issue? Surely it isn't to simply be dismissed; banks have authorities and standards they must adhere to, <strong>but what arbiter of justice resides in the land of software?</strong></p>

<ul>
<li>Do I just trust the company that their appointed Administrators who
deal with HR and registration of employees are reliable?</li>
<li>Do I include analytical components that act as a light but
unnoticeable deterrence e.g. if an administrator downloads a passport
at a certain time, should this be backlogged in a database? If so, what should be done with it and who is it accessible by?</li>
</ul>
","331900","","","","","2019-04-01 09:20:53","Extent of Administrator Capabilities: HR and Design Logistics?","<design><programming-practices><database-design><security><management>","4","0","0","","","CC BY-SA 4.0"
"287600","1","294481","","2015-06-23 09:15:10","","6","3117","<h1>Background</h1>

<p>I have a Web API 2 project, without any extension of ASP.NET MVC or ASP.NET projects. The API will only be used to communicate between the server and Windows 8, Windows Phone 8.1 and iOS applications. No website will consume the API. The API makes it possible for a user to manage products in a warehouse. A user can add, remove, and check products Ã­n the database. </p>

<pre><code>public class User
{
    public int Id { get; set; }
    [Required]
    public string UserName { get; set; }
    [Required]
    public string DisplayName{ get; set; }
    [Required]
    public bool IsEnabled {get; set;}
}
</code></pre>

<p>Nothing fancy - just a model for Entitiy Framework. Of course a model for the product also exists. Notice, I don't require any password from my users, since this is not important for the data security. The users of the API will never know each others UserName - only each others DisplayName.</p>

<h1>The problems</h1>

<p>The problem is regarding security in Web API. I do not want to expose my API to the whole world - just the applications. So i have done a lot research, and from the research I have the following to scenario:</p>

<h2>Scenario #1</h2>

<p>The best way to ensure a high level of security in my API is to:</p>

<ul>
<li>Use SSL</li>
<li>Use token-based authentication of the clients</li>
<li>use a token with a very short expiration time</li>
<li>not to use the ASP.NET Identity</li>
<li>to use Message Handlers instead of Action Filters</li>
<li>Add a UserToken field to User model and generate a token for each user</li>
</ul>

<h2>Scenario #2</h2>

<p>The best way to ensure a high level of security in my API is to:</p>

<ul>
<li>use SSL</li>
<li>use ASP.NET Identity to do username and password approach</li>
<li>use a token-based approach based on the authentication of ASP.NET Identity</li>
</ul>

<h1>The Questions</h1>

<ul>
<li>What is the best approach? Scenario #1 or #2?</li>
<li>In general, what is the best way to secure an API? </li>
<li>Is the best way one of my scenarios?</li>
</ul>

<p>Please feel free to add/remove items from the two scenarios, but also to add new and more secure scenarios.  </p>
","184527","","184527","","2015-06-23 09:27:16","2015-08-24 19:09:07","Token or ASP.NET Identity based security in ASP.NET Web API 2","<c#><security><web-api><asp.net-mvc-web-api>","1","0","","","","CC BY-SA 3.0"
"287606","1","","","2015-06-23 11:27:41","","41","8717","<p>Suppose I'm reviewing code that job applicants send to prove their skills. Clearly I don't want to run executables they send. Not so clearly I'd rather not run the result of compilation of their code (just for example, <a href=""https://stackoverflow.com/questions/30727515/why-is-executing-java-code-in-comments-with-certain-unicode-characters-allowed"">Java allows to hide runnable code in comments</a>).</p>

<p>What about compiling their code? I want compiler warnings if any but what if their code contains some clever character sequences which exploit my compiler and my compiler compromises my machine?</p>

<p>When I Google for ""compiler vulnerabilities"" the hits I get are all about compiler optimizations and code emission and whether emitted code is as secure as original source code was intended to be.</p>

<p>Are compilers typically validated to ensure they won't compromise the user machine when compiling some clever piece of code? How safe is it to compile a piece of code from a stranger?</p>
","587","","-1","","2017-05-23 12:40:26","2015-06-24 10:51:03","How safe is it to compile a piece of source code from a random stranger?","<security><source-code><compiler><vulnerabilities>","13","22","","2015-06-24 10:55:55","","CC BY-SA 3.0"
"389493","1","389551","","2019-03-30 17:58:17","","0","81","<p>Custom code written for the Salesforce platform is incapable of making a PATCH request to an external server (PUT and POST are okay though), and I need to make a PATCH request to an external service (Microsoft Graph).</p>

<p>While authentication can be handled with a POST request directly from SF to MSG, obtaining the access token, I can't make the second callout, which is a PATCH. So for that, I wrote a simple Heroku-based Flask application that receives a POST request and then uses the Requests library to make the PATCH request to MSG.</p>

<p>From a practical point of view, this works as intended. However, from a security point of view, I would like to confirm if it is safe to assume that this approach is safe as well.</p>

<p>The Heroku dyno receives a POST containing the token, the endpoint to call and a ""payload"" which is the exact JSON I'd send to MSG directly. Of course, the connection to the dyno is secured through HTTPS, and the SF administrator has access to the URL (but not the dyno's code or repository). This way, the Flask app knows who to call, which token to use, and what is the JSON data to send.</p>

<p>Given that the dyno doesn't store anything, and simply forwards the callouts, could this be considered a safe approach?</p>
","183415","","","","","2019-04-01 07:52:24","Is it a bad thing to delegate a callout to an external system, given that my current one can't do it?","<rest><security>","1","1","","","","CC BY-SA 4.0"
"389508","1","","","2019-03-31 08:38:22","","0","75","<p>I created one webapi application which includes few modules like account, user etc and overall includes 10 or more endpoints.</p>

<p>I deployed this in EC2 instances and configured in application load balancer with domain in cloud front. The authentication used is oauth2 (bearer token)</p>

<p>All working fine and can access using domain address and load balancer address. As this can access from anywhere and can register to the application using register API. So how can I restrict this.</p>

<p>How can I restrict this public access? Which is the standard practice for this deployment?</p>
","144324","","","","","2019-03-31 08:38:22","How to restrict API endpoints which are deployed in AWS Application Load Balancer?","<security><deployment><aws><load-balancing>","0","4","","","","CC BY-SA 4.0"
"287978","1","","","2015-06-26 16:47:58","","0","134","<p>In general, I write a debug log whenever one of my functions is entered, including the parameters.</p>

<p>For instance:</p>

<pre><code>    function execute_query($query, $conn_string)
    {
        $this-&gt;log-&gt;debug(sprintf('Entering execute_query(query=%s, conn_string=%s)', $query, $conn_string));
        //Do Stuff
    }
</code></pre>

<p>The potential problem that I see is that the parameter could contains private data (e.g. connection string could contain a username and password) and it will be written to the log. </p>

<p>That being said, when developing the application I have the logger set to include the debug level, and I would actually find this helpful. When deploying to production I would expect the level to be set to info or error, and so the username/password would never be written to the log. </p>

<p>Is there a best practice around this?</p>
","184908","","","","","2015-07-29 08:06:47","Logging private data","<programming-practices><security><logging>","1","2","","","","CC BY-SA 3.0"
"288012","1","288014","","2015-06-27 03:38:51","","0","1777","<p>I've seen a few useful plugins for Eclipse such as <a href=""http://github.eclipsesource.com/jshint-eclipse/"" rel=""nofollow"">jshint-eclipse</a>. However, I'm a bit leery of installing third-party code.</p>

<p>Is it generally safe to install Eclipse plugins without worrying about my local system being compromised?</p>
","133064","","","","","2015-06-27 04:23:33","Eclipse plugins - safe to install?","<security><eclipse><plugins>","1","1","","2015-11-29 15:55:54","","CC BY-SA 3.0"
"170656","1","170658","","2012-10-19 23:10:31","","2","10126","<p>Looking at the code of Joomla I see that in the first line of the index, it defines the base path of installation with <code>dirname(__FILE__)</code>.</p>

<p>Is this a possible risk for the site? If a non controlled error message show the internal path of the Joomla directory, because of, for example a failed include, can it be used to perform some kind of attack to the site? If yes, is it convenient to use this function?</p>
","69424","","25936","","2012-10-19 23:25:37","2019-05-02 07:12:33","Is using dirname(__FILE__) a good practice?","<php><security>","3","1","","","","CC BY-SA 3.0"
"170877","1","170887","","2012-10-22 13:43:02","","2","711","<p>I'm storing some phone numbers in the database which should kept totally secret (they're supposed to access via web). BTW, because of the position of these people, I need to prevent any chance for leak of their numbers. So, the only solution I could thinking of is Encryption.</p>

<p>As the database could contains bunch of data, I won't encrypt the database entirely. Also, I actually prefer to use different key for each person to encrypt their phone numbers, so in the case of leaking one key, the other phone numbers should be safe at least. The problem is that other people also need to send SMS messages via the application through a web-interface and also some more privileged persons need to see these numbers, so I also need to make these numbers visible to the other privileged persons by the way.</p>

<p>I'm wondering of something like a public-key/private-key structure, but it's too much for just encrypting a phone number per person, and also there would be a problem for new users, because the previous numbers didn't encrypted with their public-keys.</p>

<p>So, is there any solution you might recommend to me? maybe I should to revise or update the structure of how I'm trying to do that, huh?</p>
","67077","","7422","","2012-10-22 14:02:58","2012-10-22 14:44:34","help for choosing an encryption method for a database column","<database><security><encryption>","2","6","","","","CC BY-SA 3.0"
"288429","1","305299","","2015-07-01 17:54:31","","5","7901","<p>Is it safe to only use intval to sanitize the user input for a database select, as in the following example?</p>

<pre><code>$id = intval($_GET['id']);

$query = ""SELECT * FROM table WHERE id='$id'"";
</code></pre>
","185636","","","","","2018-03-20 11:19:27","Is it safe to only use intval to sanitize user input for a database select?","<php><mysql><code-security>","5","3","","","","CC BY-SA 3.0"
"389797","1","","","2019-04-04 13:18:17","","1","168","<p>In one of the existing batch process codebase, I can see a practice of JDBC Connection String is getting logged and also persisted. Logging or Persisting a JDBC Connection String <em>alone</em> may not be a security issue. Though, it's a little discomforting to make this information available to naked eyes. But is it a best practice to do so? If not, is there any other reason? OR Is there any usefulness to this practice? </p>
","291901","","","","","2019-04-04 13:39:08","JDBC Connection Url Logging - Security Risk","<design><security><application-design><jdbc>","2","7","","","","CC BY-SA 4.0"
"390000","1","390003","","2019-04-08 18:03:03","","2","111","<p>I know very little about encryption, so I figured I'd ask the internet if it's possible to do the following (and if so, what kind of algorithm should I be looking at):</p>

<p>Write some code that saves data to and loads data from a file, however the file is usable only once. What I mean is that the data is loaded in from it, and the file is overwritten with new data by the software which is now the file that can be loaded. If the user however made a copy of the previous version and replaces the new file with it, that same file should no longer work.</p>

<p>The conditions under which I'd like to achieve this are the following:</p>

<ul>
<li>Windows environment.</li>
<li>The software is offline, on the user's machine.</li>
<li>The user is smart enough to be able to locate any files the software creates and make copies (meaning keeping some sort of validation code in a separate file would be insufficient as a solution). They are smart, tenacious and motivated in finding a method to load data from old files, but they don't know much about computer science, so they wouldn't decompile the software or crack any encryption that might be involved in the solution.</li>
</ul>
","333128","","5099","","2019-04-09 07:17:39","2019-04-09 07:17:39","Is it possible to create once loadable files?","<security><data><encryption>","1","0","","","","CC BY-SA 4.0"
"390060","1","","","2019-04-09 11:21:32","","3","276","<p>We currently have a customer that wants us to implement push notifications to our app. The problem is that for this customer, security is really, really important...
I am not able to find any <strong>official</strong> documents, that state that the only way to send push a notification to an Android or iOS device via internet is the use of FCM / APNS.
Sadly, I don't think that I can convince the decision makers to open ports to a Google / Apple service, if I can't show them that this is a real necessity.</p>

<p>I know how push notifications work etc. and I myself know that it is necessary, but as I said, I need to convince some decision makers, so it would be really helpful if I could show them something official...</p>
","333214","","173647","","2019-04-09 12:16:08","2019-04-09 12:16:08","Why are cloud services needed for push notifications?","<android><ios><push><notifications><server-security>","1","1","","","","CC BY-SA 4.0"
"288897","1","288916","","2015-07-07 02:51:13","","1","338","<p>I have recently joined a team working on an application with an integrated chat system. It is a standard chat system that allows clients to communicate, with messages routed through a central server.</p>

<p>Usually when dealing with user-input text, it is recommended to 'escape-on-output' instead of 'escape-on-input'. There are numerous examples (<a href=""http://lukeplant.me.uk/blog/posts/why-escape-on-input-is-a-bad-idea/"" rel=""nofollow noreferrer"">1</a>, <a href=""https://security.stackexchange.com/questions/9415/filter-user-input-before-the-database-or-upon-display"">2</a>, <a href=""https://security.stackexchange.com/questions/42498/which-is-the-best-way-to-sanitize-user-input-in-php"">3</a>) as to why this is better, but it basically boils down to: you need to sanitize the text depending on the context in which it is used. If inserting a user chat message into a database, you should escape for SQL and use prepared statements. If display the chat message to a web browser, you should escape for HTML. Etc.</p>

<p>Unfortunately, none of the above security concerns were recognized until recently. (Yes, really).</p>

<p>The quick 'hack' solution was to filter user chat messages when received by the server, and <em>strip out any possibly nefarious-looking character</em> (&lt;,>,"",',{,},\, etc). This led to a lot of user complaints, since their punctuation would now magically disappear when displaying in the chat channel.</p>

<p>I want to believe that we can do better than this current 'hack', and allow users to type any text they want in a secure environment.</p>

<p>The problem is that I am working with seemingly impossible constraints. We have numerous versions of the client, spread over many devices, thousands of users, and slow adoption rate of new versions. There's lots of fragmentation, and we can't force clients to update.</p>

<p>Management doesn't care too much about user experience, and has basically told me:</p>

<blockquote>
  <p>Implement a solution to protect against every possible type of
  malicious user-input without having to touch the clients. Oh, and also
  protect against any future 'careless' developer who doesn't know what
  they are doing and might accidentally try to <code>eval()</code> the user chat
  message.</p>
</blockquote>

<p>(Yes, I was actually told that last part).</p>

<p>Is there any better solution to this problem that would provide a slightly better user experience?</p>

<p>Thanks for reading.</p>
","135994","","-1","","2017-03-17 10:46:00","2015-07-07 13:42:00","Security and sanitizing user-input with limited control over 'output' targets","<web-development><security>","2","1","","","","CC BY-SA 3.0"
"390226","1","","","2019-04-11 21:46:39","","0","727","<p>We have a web app in which we allow users to log into the app using any Open ID provider(e.g. Okta, Google, Facebook etc.). We want to implement the correct Open ID Connect prescribed methodology/workflow to keep the user logged into the site.</p>

<p>The existing implementation, looks at the expiry of the Access Token then if it's close to expiry uses a Refresh Token to get a new Access Token to keep the user logged in. I feel like this is wrong. When a user logs in to the web app, the Identity Token is used to Authenticate the identity of the user using the Authorization Code workflow. The Access Token and Refresh Token are stored on the server side. Periodically, the Refresh Token is used to get new Access Tokens to keep the user logged into the site. I believe this is a security risk because -</p>

<p>Imagine if a user is logged onto his OP account in a browser. He opens up Sky and is directly logged into MP because heâ€™s already logged into MP. He then in a separate tab, logs out of his OP account. He will continue to be logged into MP for days on the basis of this Refresh Token/Access Token mechanism! Isnâ€™t this a security risk?</p>

<p>If feel like the correct way to go about this is to use Session Management using iframes as prescribed here on OIDC - <a href=""https://openid.net/specs/openid-connect-session-1_0.html"" rel=""nofollow noreferrer"">https://openid.net/specs/openid-connect-session-1_0.html</a></p>

<p>For more context, when a user logs into our WebApp we pull data from the OP's UserInfo endpoint to create a profile within our WebApp and set permissions/roles within our app based on data sent over from the OP's UserInfo endpoint. We continue doing this periodically. For this purpose, I feel like using the Access Token(and using the Refresh Token to get new Access Token) to access the UserInfo API is correct because it conforms to the OAuth 2.0 concept of protecting/authorizing API/Resource endpoints using Access Tokens.</p>

<p>I want to know if this is indeed the correct way to manage how a user should be logged in when supporting Open ID Connect.</p>
","331578","","","","","2023-06-30 06:07:35","Open ID Connect Session Management Access/Refresh Token vs Session iFrame","<web-applications><security><oauth2><openid>","3","0","","","","CC BY-SA 4.0"
"390398","1","390399","","2019-04-15 15:08:34","","0","57","<p>I am developing a website where customers can register products they bought in order to receive a benefit in the form of e.g. a cashback, a discount or promotional goods. In the future, we also plan on developing more of these websites in the future.</p>

<p>The website includes the following several registration steps:</p>

<ul>
<li>One of the steps gathers customer details, including what we need to
provide the benefit (e.g. Address or IBAN number).</li>
<li>One of the steps gathers a proof of purchase, often in the form of a product code or receipt.</li>
</ul>

<p>For each of these steps, validation is done to ensure that the data is legitimate input before continuing. At the end of the registration, there is a 'register now' kind of button to officially register.</p>

<p>I want to split the implementation between an API and a frontend.
Now I want to make sure that the customer doesn't bypass registration steps in the frontend (that include validation) and calls the final API call by itself to get the benefit without having bought the product.</p>

<p>I imagine this may be doable with some kind of session, or by keeping all data around and re-submit it in the final request and then validating it again in the backend. However, I am unsure which would be better, and if there is some option that I am missing which would be better than both.</p>

<p>For this question I want to focus on the web design aspect, so defending against forged purchase proofs is out of scope of this question.</p>
","332776","","","","","2019-04-15 15:21:49","Designing anonymous registration website","<security><web-api><front-end>","1","0","","","","CC BY-SA 4.0"
"289186","1","","","2015-07-09 07:37:55","","-1","270","<p>Is it a security hole to name each session with the username of the user currently logged in?</p>

<p>example:</p>

<pre><code>//Alice has login
sessions_name('Alice'); sessions_start(); //Alice has login
//When Bob Logs in
sessions_name('Bob'); sessions_start(); //code follows for Bob
</code></pre>

<p>etc....</p>
","182568","","","","","2015-07-09 14:03:09","Cookie name security","<php><security><session><cookies>","1","3","","","","CC BY-SA 3.0"
"289252","1","","","2015-07-09 16:37:11","","0","282","<p>I have a functional sign up page for a blog that updates a database with a users name, email, profile picture and a short bio. The General information page and the profile picture upload/bio page are two separate pages and I have a problem with users being able to go back into their profile pic page and re-entering their information again for their bio and user which then screws the entire database up. While incorporating php $_SESSION, I want to be able to track a users progress with the form and if attempting to update the same form page, have the user sent to their current page that has yet to be completed. I'm in search of an algorithm suitable for this and yet have not been able to implement one that works properly. The first page of my form looks to see if step01(general info form) has been completed.</p>

<pre><code>    session_start();
if(!isset($_SESSION['step01']))
{
    if($_SESSION['step01']=='complete')
    {
        echo ""&lt;script&gt;window.location.assign('localhost:8888/knoxville_programmers/blog-signup-propic.php');&lt;/script&gt;"";
    }
    else
    {
        $_SESSION['step01'] ='incomplete';
    }
}
</code></pre>

<p>Upon completion of the first form the second form for uploading a user picture and bio checks if 1.) the first form is completed and 2.) that the current form hasn't already been completed. If it has then the user is redirected to their user page. </p>

<pre><code>    session_start();
if(!$_SESSION['step01']=='complete')
{
    echo ""&lt;script&gt;window.location.assign('localhost:8888/knoxville_programmers/blog-signup.php');&lt;/script&gt;"";
    #echo ""&lt;script&gt;window.location.assign('localhost/knoxville_programmers/blog-signup.php');&lt;/script&gt;"";
}
elseif($_SESSION['step01']=='complete')
{
    if(!isset($_SESSION['step02']))
    {
        $_SESSION['step02']='incomplete';
    }
    elseif (isset($_SESSION['step02'])) 
    {
        if($_SESSION['step02']=='complete')
        {
            echo ""&lt;script&gt;window.location.assign('localhost:8888/knoxville_programmers/user-page.php');&lt;/script&gt;"";
            #echo ""&lt;script&gt;window.location.assign('localhost/knoxville_programmers/user-page.php');&lt;/script&gt;"";
        }
        else
        {
            $_SESSION['step02']='incomplete';
        }
    }

}
</code></pre>

<p>My method of approach is error prone and i have not been able to have it work properly for a minute and am in need of a more suitable idea.</p>
","186679","","186679","","2015-07-09 16:46:35","2015-10-07 19:19:34","Algorithm to maintain a blog sign up page","<php><database><security><mysql><tracking>","1","0","","","","CC BY-SA 3.0"
"390489","1","","","2019-04-17 07:34:24","","-1","132","<p>I'm learning angular and have been reading about various backend solutions like direct db access, REST, and graphql. One thing I haven't seen addressed anywhere yet is how do you protect privileged information from being leaked to an unprivileged user.</p>

<p>Say I have a list of users with the properties id, displayname, loginname and passwordhash. And say my app shows a list of all users. How do I prevent the password hashes from being sent to every client requesting this view?</p>
","218476","","","","","2021-09-06 00:15:30","How to prevent angular 2 client from accessing privileged fields","<security><node.js><angular2>","1","0","","","","CC BY-SA 4.0"
"390602","1","390611","","2019-04-18 17:50:01","","0","147","<p>I've heard that companies store their private keys offline ""in a safe that will never be opened"" and stuff like that (the context for this is a console developer like Microsoft keeping the Xbox private keys offline in a safe).</p>

<p>How would they still sign code with their private keys if they're fully locked away? Does someone go and physically get the keys to sign the code? Is this a figure of speech that I don't understand?</p>
","334134","","","","","2019-04-18 23:16:57","How do companies store private keys offline but still sign code with them?","<security><keys>","2","1","","","","CC BY-SA 4.0"
"173117","1","","","2012-10-31 21:38:08","","4","244","<p>My predicament:</p>

<p>I designed an app, written in Python, to read my mail and check for messages that contain a certain digital signature. It opens these and looks for keywords. If the message contains these keywords, certain related functions area executed on the computer. It is a way I can control my computer from my cell phone without being there. I am still in the beginning stages and it can only currently remotely open and close applications/processes.</p>

<p>The obvious issue is security risks. I hoped to spearhead that by requiring and checking for that digital signature. However, my issue comes when I'd like to make this program usable by multiple users. The idea is that the user will send keywords: username and password, for instance, to log into their personal email account and send messages to it to be parsed.</p>

<p>Please ignore the security implications of sending non-encoded passwords through email. (Though if you could help me on that part I'd much appreciate it as well, but currently, that is not the scope of my question.)</p>

<p>My issue is designing an intermediary process that will take an email/password to read an email and scan for those keywords. The issue is, that the program has to be accessing an email to read the email for the username/password! I have got myself into a loop and cannot figure out how to have this required intermediary program. I could just create an arbitrary email account and have that check for login-creds, but is there a better way of doing this than that?</p>

<p>Also, is there a better way of communicating with a computer remotely than this? Especially if the computer is not a server and is behind a router with only a subnet ip?</p>

<p>If I am asking this question in the wrong place, I deeply apologize. Any help would be much appreciated!</p>
","68933","","","user28988","2012-10-31 22:47:28","2012-11-01 11:37:24","How to go about designing an intermediate routing filter program to accept input and forward accordingly?","<python><security><email><routing>","1","0","","","","CC BY-SA 3.0"
"289819","1","","","2015-07-15 14:11:12","","0","565","<p>Assuming we are talking physical tiers, my understanding is that in order to pass data from say the data tier to the business logic tier the JSON format is used (or XML), so say I have an ORM (Hibernate) as part of my data access logic, I then serialize the resulting Object (pointed to by a REST call from BLL) to JSON and pass it into the business layer. Finally I run any business logic required on this object in the BLL and serialize it to JSON and send it to the client.</p>

<p>My question is this, with all this (potentailly personal) JSON data being passed over from network to network, does it need any form of security, for example some kind of encryption on the JSON messages?</p>
","144682","","","","","2017-04-25 10:12:36","Passing Data Between Tiers in 3-Tier Architecture","<architecture><security><json><n-tier>","0","4","","","","CC BY-SA 3.0"
"390968","1","","","2019-04-26 06:01:40","","2","1160","<p>I 've a pair of private and public ssh keys, which I'm using in encrypting and decrypting my JWT.</p>

<p>So I'm creating and signing my JWT with my private key and shared the public key with the client who then use it to decode the JWT.</p>

<p>Now, I'll be frequently using the private key to do this, so, how/where do I store my private key?</p>

<p>My application spans across multiple server instances. So do I store the private key file (.pem file) in my application code, so that whenever it's deployed to a new instance, it can be used easily or do I store it in db? Or is neither of these correct?</p>

<p>Can someone please help me with this?</p>
","330718","","","","","2019-04-26 06:46:53","How to store private ssh keys for my application?","<security><cryptography><keys>","1","0","","","","CC BY-SA 4.0"
"173334","1","173338","","2012-11-02 10:08:53","","2","353","<p>I would like to set up an app that allows users to send their code and execute it on my server. The thought of running untrusted code makes me cringe, so I am trying to set up an exhaustive list of security threats that should be addressed.</p>

<p>I am assuming I should strip down certain features of the language executed, like file access or (maybe) networking. I also come across terms like <code>sandboxing</code> or <code>chroot</code>. I know what they mean, but how should I actually use them?</p>

<p>In short: What security threats should I address before allowing users to run their code on my machine, and how do I do it?</p>
","37542","","","","","2012-11-02 10:34:55","What are the security implications of running untrusted code on my server?","<security>","1","4","","","","CC BY-SA 3.0"
"289872","1","","","2015-07-15 21:56:57","","1","1414","<p>I have a security method I would like to be able to sprinkle into other classes throughout my program. It is currently an abstract class but I feel it would be more appropriate as an interface. Can someone help me convert it? I wasn't able to call PrincipalIdentity() the same way I could with it being abstract.</p>

<pre><code>public abstract class SecurityBase {

        public GenericPrincipal PrincipalIdentity() {

            WindowsIdentity windowsIdentity = WindowsIdentity.GetCurrent();

            string authenticationType = windowsIdentity.AuthenticationType;
            string userName = windowsIdentity.Name.Split('\\')[1];;

            GenericIdentity authenticatedGenericIdentity = new GenericIdentity(userName, authenticationType);

            string[] Roles = //generate array;    
            GenericPrincipal pr = new GenericPrincipal(authenticatedGenericIdentity, Roles);

            return pr;
        }
    }
</code></pre>
","173797","","","","","2015-07-16 04:04:13","Convert this abstract class to an interface","<c#><security><interfaces><abstract-class>","2","4","","","","CC BY-SA 3.0"
"289873","1","","","2015-07-15 22:17:12","","1","7357","<p>I want to create hash based on random id, That hash has to be valid for only 15 minutes. Is there a way to do that?</p>

<p>I'm using this for form submission. If some unknown submitted form or some one submitted after 15 mins I should be able to figure out when it was created?</p>

<p>I am storing random id in session and when user submits form I want to decrypt the value and match with original id. If it matches and it is with in 15 mins or created time then I will add that value to database, after doing some validations.</p>
","186203","","","user40980","2015-07-15 22:22:58","2016-11-07 20:31:00","How to generate Generate Hash incorporating time stamp so it can be unhashed to get the timestamp when it was generated?","<algorithms><security><hashing>","2","3","","","","CC BY-SA 3.0"
"391380","1","","","2019-05-03 17:32:11","","1","143","<p>I was tasked with writing software for my company. As I am now writing a third  program (with many more coming), what's the best way to control the distribution/usage of our software? </p>

<p>The software I'm writing should only be used on our network and shouldn't run elsewhere. We are a small company and don't have the infrastructure set up to see files that have been copied. </p>

<p>Is serial keys the answer? That seems like it would be a pain for the other employees who use the software. Or is there a better, more secure way? </p>

<p>I'm interested to know what ways I can mitigate/prevent usage of our software outside of our company network. </p>
","335389","","1204","","2019-05-03 17:43:25","2019-05-03 17:43:25","What's the best way to control distribution/usage of proprietary, internal software?","<c#><licensing><security><distribution><proprietary>","0","3","0","","","CC BY-SA 4.0"
"290439","1","290443","","2015-07-22 08:28:25","","0","409","<p>I'm developing a web app for internal file sharing and one of the requirements is to have PIN code protected folders. </p>

<p>What I came up now is a folder like structure with the following:</p>

<ul>
<li><strong>Folder without PIN code entry</strong> - only <strong>Open</strong> button which directly forwards to the folder</li>
<li><strong>Folder with PIN code entry</strong> - text field with <strong>Verify</strong> button which forwards only when the PIN is correct</li>
</ul>

<p>What I'm not sure is what would be the best practice in the case of the folder with PIN code in terms of PIN verification and forwarding user to the folder. At the moment I have a web service to which I forward PIN, folder ID and user ID, all in cleartext format and I'm waiting for the service response which can either be true or false. </p>

<p>I'm assuming that this isn't the best practice as the <em>smart but naughty</em> user could loop through all the possible combinations of the PIN code and wait which one will give him <strong>true</strong> as a response. I have to add that only authenticated users can access folders so in worst case I'd know with whose user the breach was made.</p>

<p>What should I do to improve security and is there something I could do better?</p>
","173775","","","","","2015-07-22 10:01:06","File sharing web application - folder PIN code entry best practice","<security><web-services><asp.net-mvc><directory-structure>","1","3","","","","CC BY-SA 3.0"
"290544","1","","","2015-07-23 01:39:48","","0","40","<p>Various online resources offer proxy lists claiming that they offer various levels of anonymity. I'm trying to find out how this can be programmatically tested. I suspect the answer lies in headers. Would testing a proxy's security by running a sender/receiver and seeing what headers come through the proxy on the receiving end be a good approach?</p>

<p><strong>EDIT:</strong> One good resource I found so far mentioning proxy headers: <a href=""http://meatballwiki.org/wiki/AnonymousProxy"" rel=""nofollow"">http://meatballwiki.org/wiki/AnonymousProxy</a></p>
","10910","","10910","","2015-07-23 01:55:44","2015-07-23 01:55:44","Detecting web proxy security","<security><networking>","0","2","","","","CC BY-SA 3.0"
"175082","1","175093","","2012-11-08 10:40:36","","1","189","<p>I need to implement something similar to a license server. This will have to be installed off site at the customers' location and needs to communicate with other applications at the customers' site (the applications that use the licenses) and an application running in our hosting center (for reporting and getting license information).</p>

<p>My question is how to set this up in a way I can trust that:</p>

<ol>
<li>The license server is really our application and not something that just simulates it; and</li>
<li>There is no ""man in the middle"" (i.e. a proxy or something that alters the traffic).</li>
</ol>

<p>The first thing I thought of was to use with client certificates and that would solve at least 2. However, what I'm worried about is that someone just decompiles (this is build in .NET) the license server, alters some logic and recompiles it. This would be hard to detect from both connecting applications.</p>

<p>This doesn't have to be absolutely secure since we have a limited number of customers whom we have a trust relationship with. However, I do want to make it more difficult than a simple decompile/recompile of the license server. I primarily want to protect against an employee or nephew of the boss trying to be smart.</p>
","5769","","47","","2012-11-08 10:53:09","2012-11-08 17:51:23","How do I trust an off site application","<.net><security>","3","0","","","","CC BY-SA 3.0"
"391902","1","","","2019-05-15 05:13:47","","1","135","<p>My users will be businesses with a small number of accounts each: e.g. Business #1 with 3 users, Business #2 with 5 users, etc.</p>

<p>I am trying to determine the best way to organise the relation (on Postgresql, hosted on AWS) for each business client: for e.g. each business will have their own sets of <code>customers</code>, <code>logs</code>, <code>products</code>, <code>config</code> relations.</p>

<p>I want to create a scaleable database across all client businesses.</p>

<ul>
<li>Do I create a <em>single</em> relation, e.g. of <code>customers</code>, for <em>all</em> my clients? E.g. each business client is given a unique ID, and during onboarding of the business user, the user's account is tied to the specific business UID. Examples in 2 images below.</li>
</ul>

<p><a href=""https://i.stack.imgur.com/OIPbL.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/OIPbL.png"" alt=""enter image description here""></a></p>

<hr>

<p><a href=""https://i.stack.imgur.com/tzXSc.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/tzXSc.png"" alt=""enter image description here""></a></p>

<p>This seems like a huge security risk given that all business information is stored in a single table/DB.</p>

<ul>
<li><strong>OR</strong>, do I create individual databases hosted separately in AWS for each business? This seems safe, but also practically not scaleable and expensive!</li>
</ul>

<p>I'm pretty sure there's a middle path where all B2B apps tread which my inexperience simply makes me oblivious to. </p>

<p>I've read <a href=""https://softwareengineering.stackexchange.com/questions/260798/500-databases-or-1-database-with-500-tables-or-just-1-table-with-all-the-records?rq=1"">this</a> and <a href=""https://softwareengineering.stackexchange.com/questions/141261/multi-tenancy-single-database-vs-multiple-database"">this</a>. My question is more directed to the <em>implementation</em> of the table if I were to go with a shared DB and shared schema.</p>
","336351","","336351","","2019-05-15 05:33:48","2019-05-15 18:14:42","How to store relational data belonging to different client customers?","<design><design-patterns><database><database-design><security>","0","5","","","","CC BY-SA 4.0"
"291473","1","","","2015-07-31 19:32:19","","3","885","<p>I have an app that uses an API server and I do not want to have anything other than it to be able to use that API. I know this isn't totally possible, but I want to do what I can.</p>

<p>I don't think my current method of achieving this is the greatest and I'd like to scrap it and start over fresh. Here's how it works:</p>

<ol>
<li>The app picks a string from a set that I'll call the ""entropy"".</li>
<li>Using that string it makes a hash of the current UTC date using the entropy as the salt</li>
<li>It sends that hash to the API server which then creates the hash using every possible entropy from the set until it finds a match</li>
<li>If it finds a match, a API key is generated for the app and sent back.</li>
</ol>

<p>The server stores the entropy string, the API key, as well as the <a href=""https://developer.apple.com/library/ios/documentation/UIKit/Reference/UIDevice_Class/#//apple_ref/occ/instp/UIDevice/identifierForVendor"" rel=""nofollow"">IDFV</a> in a database. </p>

<p>When the app makes a request, it sends their API key, the IDFV, and a bearer token. The bearer token is a hash of the URL with the entropy string as the salt.</p>

<p>When the server recieves a request it:</p>

<ol>
<li>Selects the entropy string from the database using the API Key and the IDFV as search parameters.</li>
<li>Generate it's own bearer using the URL it's responding to, and the entryopy from the above select.</li>
<li>Verify that the entropy strings match</li>
</ol>

<p>If the select query returns nothing, or if the bearers don't match the server will return a 403 and not proceed.</p>

<p>The problems I'm worried about are:</p>

<ul>
<li>If the user has an incorrect date on their device the registration will fail.  Likewise,</li>
<li>If the server has an incorrect date the registration will fail</li>
<li>If the app starts registration at 23:59:59 and there's a 1s delay time to the server (which over 3G is totally plausible), the registration will fail</li>
<li>With a hard-coded list of entropy strings can the app be decompiled and the strings extracted</li>
<li>With only a limited number of entropy strings it's possible to find all of them with enough time.</li>
</ul>

<p>Some of the things I have took into consideration:</p>

<ul>
<li>All requests and responses are served over HTTPS</li>
<li>The API server rate-limits requests to hamper brute force attempts</li>
<li>The API server is behind CloudFlare to also do some basic attack prevention.</li>
</ul>

<p>What I want to know is what would be a better way of going about this that doesn't require any extra user interaction?  The iOS app is built using Objective-C and the API server is built using Ruby.</p>
","143416","","","","","2018-08-25 18:36:03","Securing a private API used by an iOS App","<security><ruby><api-design><objective-c>","1","2","","","","CC BY-SA 3.0"
"291488","1","291527","","2015-07-31 22:17:19","","1","1904","<p>I have a C# program (could be any programming language) that saves data to a file on a memory (hard disk, USB drive, etc.). The program uses this data for monitoring its operation time, but it could be any purpose.<br>
When the program is started, it reads the data from the file so it knows how long it has been operating before. It updates the data in the file every minute, so there is a failure of maximum 1 minute if the program is not shut down properly.  </p>

<p>My problem is a quite general question: <strong>How can I prevent the user from manipulating the file?</strong>  </p>

<p>I want to avoid that someone edits the operation time while the program is not running, or at least I want to be able to detect manipulation.  </p>

<ul>
<li>I though of a checksum first, but I also need to prevent that from manipulation.  </li>
<li>The user can replace the current files by backups every time, thus the files themselves are not save if he knows where to look.</li>
<li>Therefore I need to store data at a location that is not easily editable. On a windows system, this could be the registry. Alternatively I could create a hidden system file in a special directory. However, I think the only chance is to hide the file or any information about the data from the user.</li>
<li>The user could replace the whole operating system including all data by an image. Therefore also a hidden location is not safe, but a) I cannot avoid this risk, and b) the user would need special equipment and knowledge, so the system is safe to most users.  </li>
</ul>

<p>Any other ideas how to secure data on a typical computer?</p>
","189433","","149904","","2015-08-01 06:09:46","2015-08-26 20:33:12","Avoid data manipulation by user","<security><data><file-systems><users>","2","10","","","","CC BY-SA 3.0"
"291494","1","","","2015-07-31 23:24:29","","1","1537","<p>I am having difficulty with the answer provided <a href=""https://softwareengineering.stackexchange.com/questions/49326/is-an-if-password-xxxxxxx-enough-for-minimum-security"">here</a>, but I couldn't understand how to implement it. My code is pretty much identical:</p>

<pre><code>&lt;script language=""javascript""&gt;
  function check(form) {
    if(form.userName.value == ""User"" &amp;&amp; form.userPass.value == ""averyobviouspassword"") {
      window.open('testok/menu.html')
    }
    else {
      alert(""Wrong Password Or Username"")
    }
  }
&lt;/script&gt;
</code></pre>

<p>The problem with this is, if you were to Inspect Element on the page, you can plainly see the password. I'm not looking for other solutions like a SQL database, because this is just a test website. The solution I thought might work was this:</p>

<pre><code>if(hash(enteredPassword) == storedHash)
</code></pre>

<p>I just don't know how to implement it.</p>
","189440","","-1","user40980","2017-04-12 07:31:41","2015-12-06 11:12:14","Javascript Password Security","<javascript><web-development><security><html>","3","1","","2015-12-07 15:52:40","","CC BY-SA 3.0"
"291506","1","","","2015-08-01 04:39:35","","1","581","<p>Passwords are recommended to be stored in char[] instead of String, as Strings are stored in StringPool.
<a href=""https://stackoverflow.com/questions/8881291/why-is-char-preferred-over-string-for-passwords/8889285#8889285"">Read more here</a></p>

<p>As per <a href=""https://stackoverflow.com/questions/24053587/how-to-check-string-pool-contents"">this question</a> Strings in StringPool are not available directly.
To obtain Strings in Stringpool, we would need a password-dictionary to check them in StringPool. If we have a password-dictionary, we don't need to worry about StringPool, we can anyhow try directly on password fields.</p>

<p>To prevent <a href=""https://en.wikipedia.org/wiki/Brute-force_attack"" rel=""nofollow noreferrer"">Brute-force attack</a>  we are limiting number of re-tries for passwords and checking for any suspicious activities.</p>

<p>If all that is in place still should we not use ""String"" as a datatype for passwords?</p>

<p>The answer obtained from similar questions is: We can have access to memory dump and get access to Strings in stringpool.</p>

<p>Follow up questions:</p>

<ul>
<li>How can one access the memory dump?</li>
<li>Can the access be prevented? </li>
<li>If access to memory dump is prevented, Is it safe to use String as a type for passwords?</li>
</ul>
","89049","","-1","","2017-05-23 12:40:20","2015-09-09 02:08:22","Why are Strings in StringPool considered insecure?","<java><security><strings><passwords><server-security>","2","1","","","","CC BY-SA 3.0"
"392611","1","403482","","2019-05-30 10:08:39","","0","49","<p>I've seen a few similar questions but nothing to address this exact issue... I'd like to have a mobile app that allows users to input username/password once and then be automatically logged in with said credentials on different websites (Moodle, Outlook, MSDNAA and some others that use the same data) whenever they want to access them.</p>

<p>What would be a good, safe way to store this information for use in this manner? Or do I have to try to use a different authentication method for each and every individual website?</p>
","337548","","","","","2020-01-07 21:48:56","Save user credentials for use with multiple third-party websites","<security><passwords>","1","0","","","","CC BY-SA 4.0"
"176095","1","176099","","2012-11-16 15:30:27","","1","8037","<p>I am currently using the Google-Gson library to convert Java objects into JSON inside a web service.</p>

<p>Once the object has been converted to JSON, it is returned to the client to be converted into a JSON object using the JavaScript eval() function. Is the character escaping provided by the Gson library enough to ensure that nothing nasty will happen when I run the eval() function on the JSON payload?</p>

<p>Do I need to HTML Encode the Strings in the Java Objects before passing them to the Gson library? Are there any other security concerns that I should be aware of?</p>
","72804","","31260","","2012-11-16 16:59:50","2012-11-16 16:59:50","Is the escaping provided by the Google-Gson library enough to ensure a safe JSON payload?","<java><javascript><security><json>","1","2","","","","CC BY-SA 3.0"
"176130","1","176132","","2012-11-16 20:01:46","","3","3306","<p>I'm tasked with developing an SSO system, and was guided towards using the SAML spec. After some research I think understand the interaction between a Service Provider and an ID Provider and how a user's identity is confirmed. But what happens when I redirect the user to <strong>another</strong> Service Provider? How do I ascertain the user's identity there? Do I send his SAML assertion tokens along with the redirect request? Or does the second Service Provider need to contact the ID Provider all over again?</p>
","17485","","","","","2018-09-30 20:20:20","Moving between sites using SAML","<security><sso><saml>","3","0","","","","CC BY-SA 3.0"
"393214","1","393222","","2019-06-12 09:29:31","","4","169","<p>I'm currently creating a mobile app and have the following issue.
I am required to only allow the user to login from a device that is registered to the users account. A user can have up to X number of devices registered at any one time.</p>

<p>So when the user registers and they first sign-in. I would need to register the device. Then on each request to the backend webapi, the webapi would need to verify the request came from the registered device.</p>

<p>How would you identify the device? Would you generate some kind of secret locally on the device and share it with the webapi?</p>

<p>Any ideas on how to architect this? </p>

<p>I'm planning to use dotnet core with identity framework for the backend and either xamarin or flutter for the front.</p>
","338482","","","","","2019-06-12 11:18:23","Architecture to lock account to mobile device","<c#><security><.net-core><identity><xamarin>","1","4","","","","CC BY-SA 4.0"
"393248","1","","","2019-06-12 18:33:21","","1","108","<h2>Situation:</h2>

<ul>
<li>A Client is requesting a resource from a Host multiple times, usually with minutes or hours between requests.  </li>
<li>The Client has a signed, verifiable token, which we'll call a <strong>Receipt</strong>, that asserts that they should be allowed to access the resource. (The Receipt will eventually expire, say at the end of the month.)</li>
<li>The Host has no way of knowing (and <em>should</em> have no way of knowing) who the Client is beyond the fact that a given receipt is being reused.</li>
<li>EDIT: The Receipts come from a third party, the Notary. The Notary <em>does</em> have a meaningful idea of who a user is (in the sense that they can charge them money), but <em>does not</em> know which user owns which receipts. (Receipts are validated using a <a href=""https://github.com/ShapeOfMatter/RSA-Blind-Signature"" rel=""nofollow noreferrer"">blind signature scheme</a>.)</li>
</ul>

<h2>Problem:</h2>

<p>Receipts cost money. (We're building a micro-transaction service; so they cost ~0.10USD) We don't want users (Clients) posting their Receipts online for public use, or otherwise sharing Receipts.<br>
(<strong>EDIT: The goal isn't to prevent anyone from ever sharing a Receipt; individual Receipts just aren't worth that much. The goal is to prevent (or make sure we can combat) anyone making a <em>system</em> for sharing Receipts on a large scale.</strong>)</p>

<p>Note that in this model a ""user"" may have multiple ""Clients"" running on different machines, and will share Receipts among <em>their</em> Clients.<br>
<sub>(EDIT: How they do this isn't set-in-stone yet; suppose there's a SaaS party offering encrypted private cloud storage, similar to a password manager.)</sub></p>

<h2>Proposed Solutions:</h2>

<ol>
<li><strong>Have the Client create a public/private key pair</strong> for each receipt (or however often the Client wants to). The public key will be submitted with the Receipt, and whenever the Host sees a given Receipt for the first time they'll store the accompanying public key so they can verify that future submissions came from the same person (even though they don't know who that is).  

<ul>
<li><strong>cons:</strong> This just moves the ""secret that shouldn't be shared"" from the Receipt to the private key.</li>
<li><strong>pros:</strong> A private key really is easier to keep secret, in particular because, while the Receipt is sent to the Host, the private key never leaves the Client's control.</li>
</ul></li>
<li><strong>Have the Host give the Client a single-use Token</strong> (as part of their normal response) to be included with their next submission of a given Receipt. These Tokens can be quite small. Re-submission of a Receipt (even once) without the expected Token is <em>evidence</em> that the receipt has been shared.

<ul>
<li><strong>cons:</strong> This will make both systems (Client and Host) harder to implement. It's convoluted and error-prone. Because Clients owned by a single user <em>will</em> share Receipts, some ""false positives"" are inevitable. Furthermore, sharing Receipts <em>inappropriately</em> is still possible using a system not too different from how well-behaving users will share Receipts among their devices. In this sense this solution relies on incompetent members of they hypothetical sharing pool accidentally violating the Token chain.</li>
<li><strong>pros:</strong> Building a sharing pool would be relatively <em>difficult</em>, and as a pool scaled up in members and usage it would become increasingly non-performant (because of locking) or increasingly likely to break Receipts (because they'd been noticed as shared). Additionally, a ""good samaritan"" in the sharing pool would be able to break the shared Receipts by <em>intentionally</em> violating the Token chains.</li>
</ul></li>
<li><strong>Give ""good samaritans"" a specific function for invalidating receipts</strong>. 

<ul>
<li><strong>cons:</strong> Does nothing to directly prevent sharing, it relies entirely on the idea that any hypothetical sharing pool would either <em>not scale</em>, or <em>eventually</em> be infiltrated by some kind of defector. </li>
<li><strong>pros:</strong> It's much easier to implement. Additionally, if <em>combined</em> with #1, then the Host would have a signed invalidation request they could present if their decision to reject subsequent submissions of that Receipt were ever challenged. </li>
</ul></li>
<li><strong>EDIT: Rate-limit per-Receipt submissions</strong>. For example specify that receipts can't be used more than five times in an hour, or 10 times in the Receipt's lifetime. Thank-you <a href=""https://softwareengineering.stackexchange.com/users/319783/kain0-0"">@Kain0_0</a> for the suggestion.

<ul>
<li><strong>cons:</strong> Does nothing to directly <em>prevent</em> sharing. May limit usage of otherwise compliant users (for better or worse).</li>
<li><strong>pros:</strong> Places a hard limit on <em>how much</em> a given receipt could be shared in practice. </li>
</ul></li>
</ol>

<p><strong>Originally I was planing on doing #1 and #2</strong>,<br>
but having thought about it for a couple days I'm thinking #1 and #3 (or <em>maybe</em> just #3) would be easier and <em>good enough</em>.</p>

<h3>Do people have suggestions for any (combination) of the above solutions, or other solutions I haven't listed?</h3>

<h3>Are there important angles I've overlooked?</h3>

<p><sub>EDIT: Additional context: <a href=""https://www.402receipts.info/"" rel=""nofollow noreferrer"">This is the protocol I'm working on</a>, in case people want to learn more or get more deeply involved.</sub></p>
","327280","","327280","","2019-06-14 12:58:09","2019-06-14 12:58:09","Prevent token sharing: chained single-use tokens VS a designated invalidation feature","<security><authorization><privacy>","0","9","","","","CC BY-SA 4.0"
"293435","1","","","2015-08-11 15:42:46","","22","3697","<p>SQL injection is a very serious security issue, in large part because it's so easy to get it wrong: the obvious, intuitive way to build a query incorporating user input leaves you vulnerable, and the Right Way to mitigate it requires you to know about parameterized queries and SQL injection first.</p>

<p>Seems to me that the obvious way to fix this would be to shut down the obvious (but wrong) option: fix the database engine so that any query received that uses hard-coded values in its WHERE clause instead of parameters returns a nice, descriptive error message instructing you to use parameters instead.  This would obviously need to have an opt-out option so that stuff like ad-hoc queries from administrative tools will still run easily, but it should be enabled by default.</p>

<p>Having this would shut down SQL injection cold, almost overnight, but as far as I know, no RDBMS actually does this.  Is there any good reason why not?</p>
","935","","","","","2015-08-20 18:57:44","Why not just make non-parameterized queries return an error?","<security><sql><rdbms>","4","17","0","","","CC BY-SA 3.0"
"393600","1","","","2019-06-20 12:11:14","","0","59","<p>I'd like to build a rest service that will accept objects that has digital signature. This service has to support both <code>xml</code> and <code>json</code> data serialization formats. I'd like to use <code>.Net core</code> framework to build this service.</p>

<p>Controller has to check that digital signature is valid and dto properties were not modified.</p>

<p>This signature has to be stored (in the database) and used (if required) to verify that message was not changed while processing.</p>

<p>Sending flow is like below</p>

<ul>
<li>client fills object with data</li>
<li>client calculates hash and sign it</li>
<li>client sends object and signature to the service</li>
<li>service calculate hash from object properties and verify signature</li>
<li>object and signature is stored in the db  </li>
</ul>

<p>The question is how to define and share hash calculation logic between service and client? Please note that client can be implemented using different framework or programming language.</p>

<p>UPD: Or, probably there is an alternative way to check data integrity that are sent by the client. Like <a href=""https://docs.aws.amazon.com/AmazonS3/latest/dev/RESTAuthentication.html"" rel=""nofollow noreferrer"">Amazon has implemented</a>.</p>

<p>I've thought that dto can have <code>string GetHashData()</code> method that will concatenate valuable dto properties to the string. Then hash can be calculated for this and is used to sign or to check the signature.</p>

<p>However having method in the dto object does not look good. </p>

<p>I can implement some helper class and use it in the rest service that to calculate hash for each object type. But this logic has to be implemented on the client side as well. It can make usage of the service a little bit tricky.</p>

<p>I know that both xml and json has digital signature, like XMLDSIG and JWS. But it makes digital signature to be dependent from the format that was used by the client to talk with service. I can not use JWS or XMLDSIG if object was deserialized and passed as parameter to the REST controller.</p>
","283731","","283731","","2019-06-20 13:27:47","2019-06-20 13:27:47","rest service with digitally signed parameters","<rest><security>","1","0","","","","CC BY-SA 4.0"
"293707","1","","","2015-08-14 11:30:32","","1","122","<p>Is returning sensitive data like a password from a function safe, and what attack vectors exist?
(Personally, it is regarding PHP, but is a general question.)</p>

<pre><code>function returnDBPass(){
    $pass=""mydbpass"";
    return $pass;
}
</code></pre>
","142856","","","","","2015-08-14 14:32:54","How safe is returning a password from a function?","<php><security>","0","4","","2015-08-14 14:52:09","","CC BY-SA 3.0"
"177030","1","177032","","2012-11-24 09:59:48","","10","5947","<p>I'm developing a big community/forum website and I'd like to upload my code to <a href=""https://github.com/"">GitHub</a> to have at least some sort of version control over it (because I have nothing other than a .rar file as a backup, not even SVN), to let others contribute to the project, and also perhaps using it to let my potential future employers see some of my code as some sort of curriculum.</p>

<p>But what I'm wondering now, and I'm suprised I haven't seen anyone mention it before is the security aspect of it. Isn't publishing the code of a website a <strong><em>HUGE</em></strong> security hole? Is like giving a potential hacker or anyone who would like to find any potential exploit possible, even considering that the critical files aren't uploaded (database passwords, authentication scripts, etc.).</p>

<p>Of course that there are millions of projects uploaded to GitHub and no one will find mine just 'by chance'. But if they look for it, it would indeed be there.</p>

<p>Bottomline: my problem is not about copyright or licenses, but others finding exploits in my website.</p>

<p>I'm I missing something here?</p>
","73532","","","","","2012-11-24 17:25:51","Security issue about making my code public in GitHub","<open-source><security><github>","5","5","","","","CC BY-SA 3.0"
"177092","1","177093","","2012-11-25 06:30:37","","1","646","<p>I mean, say you were writing professional grade software that would involve sensitive client information. (Take this in the context of me being an amateur programmer.)</p>

<p>Would you use hlib and hmac? Are they good enough to secure data? Or would you write something fancier by hand?</p>

<p>Edit: In context of those libraries containing more or less the best hashing algorithms in the world, I guess it's silly to ask if you'd ""write something fancier.""</p>

<p>What I'm really asking here is whether it's enough on its own.</p>
","56275","","","","","2012-11-25 06:36:10","Are python's cryptographic modules good enough?","<python><security><encryption><cryptography><hmac>","1","3","","","","CC BY-SA 3.0"
"293845","1","293846","","2015-08-16 20:29:24","","1","155","<p>This probably a rather naive question given my limited knowledge in the code I've been looking at, but I want to get my head around it before I start diving into writing actual code myself.</p>

<p>I'm writing a common set of tools for PHP and most of my inspiration has come from the .NET framework.  The ironic thing is that I have never used the .NET framework, but I do understand C# and can therefore port the concepts I ""do"" understand from Mono.</p>

<p>But I have run into a bit of a wall, <code>System.Security</code>.  As I browse over the API docs, and the Mono security implementations on Github, I quickly feel like none of features could ever be applied to PHP.  My current confusion is as follows:</p>

<pre><code>PermissionSet ps1 = new PermissionSet(PermissionState.None);
ps1.AddPermission(new FileDialogPermission(FileDialogPermissionAccess.Open));
Console.WriteLine(ps1.ToXml().ToString());
</code></pre>

<p>So here is a basic example.  What I want to do in PHP is create an application partially governed by permissions on the ""environment"" level.  That is to say, one machine shouldn't be able to perform certain actions that another might.  For instance, machine A, shouldn't be allowed to TCP to machine B.</p>

<p>But when I look at the code in the example, I don't really understand why it makes any difference.  My current understanding is that this is not ""setting"" the permissions, but ""checking"" them.  And the permission itself is predefined somewhere else, I.E. in the machine.</p>

<p>I have looked over Java's implementation of the same feature, and side by side .NET looks a lot more in-depth.  I would like to incorporate this concept into my own PHP code, but right now I don't know how I would do it.  </p>

<p>Are the permissions entirely arbitary? does .NET ""impose"" restrictions? or simply provide security diagnostics to the application?  If the last one is true, then porting to PHP is not only possible, but may actually be quite useful.  However I know that in PHP, the second one is impossible.</p>

<p>Could someone please clear up what the Java and .NET security namespaces do, and give me an idea of how feasible it is to port to other languages.</p>
","154688","","","","","2015-08-16 21:25:32","Porting security from Java/.NET to PHP","<java><.net><security><porting>","1","0","","","","CC BY-SA 3.0"
"177105","1","177123","","2012-11-25 12:05:14","","3","3575","<p>I'm attempting to design a single sign on system for use in a distributed architecture. Specifically, I must provide a way for a client website (that is, a website on a different domain/server/network) to allow users to register accounts on my central system.</p>

<p>So, when the user takes an action on a client website, and that action is deemed to require an account, the client will produce a page (on their site/domain) where the user can register for a new account by providing an email and password.</p>

<p>The client must then send this information to a web service, which will register the account and return some session token type value.</p>

<p>The client will need to hash the password before sending it across the wire, and the webservice will require https, but this doesn't feel like it's safe enough and I need some advice on how I can implement this in the most secure way possible. </p>

<p>A few other bits of relevant information:</p>

<ul>
<li>Ideally we'd prefer not to share any code with the client</li>
<li>We've considered just redirecting the user to a secure page on the same server as the webservice, but this is likely to be rejected for non-technical reasons.</li>
<li>We almost certainaly need to salt the password before hashing and passing it over, but that requires the client to either a) generate the salt and communicate it to us, or b) come and ask us for the salt - both feel dirty.</li>
</ul>

<p>Any help or advice is most appreciated.</p>
","72544","","","","","2012-11-25 16:37:11","Securing credentials passed to web service","<architecture><security><passwords><sso>","3","3","","","","CC BY-SA 3.0"
"294042","1","294045","","2015-08-19 09:17:20","","2","890","<p>I'm currently designing a REST-API with the following properties:</p>

<ol>
<li>Backend for a single page application (Later Apps) </li>
<li>Integrated user database for each instance </li>
<li>HTTPS/TLS only </li>
<li>Authentication with a username / password combination</li>
</ol>

<p>My current approach for the authentication process is the following:</p>

<ul>
<li>(Client) POST Username&amp;Password to <code>/api/users/action/auth</code></li>
<li>(Server) Authenticate User, Generate token, Send token to client</li>
<li>(Client) Use Authorization-Header with token for subsequent request</li>
<li>(Client) DELETE <code>/api/users/action/auth</code> to invalidate the token</li>
</ul>

<p>The token will expire after some idle time.</p>

<p>I've chosen this design because I don't like the idea of storing the plain authentication data on the clients device.</p>

<p>Reading a lot of other questions and articles on this topics I don't think this approach is the best. The following questions arose:</p>

<ul>
<li>Does the token generation and usage for subsequent requests violate the stateless-principle of REST?</li>
<li>Is this procedure secure? (XSRF?)</li>
<li>Is there a better design approach? I thought OAuth may be an overkill</li>
</ul>

<p>EDIT:</p>

<p>Regarding 'secure':</p>

<p>The application will contain a lot of sensitive information so security is quite important. Assuming the secure usage of HTTPS (only TLS, strong DH-Group, No export mods etc.) are there any easy to exploit security flaws in this approach?</p>

<p>Regarding 'better':</p>

<p>I choose this model because it's easy to implement on both sides. I put a thought into using <code>HMAC(token, 'POST' || '/api/resource' ||Â timeInterval)</code> as token for each request, my conclusion was that this would add unnecessary complexity without improving security. (Already using TLS) </p>
","192433","","192433","","2015-08-20 09:36:42","2015-08-20 09:36:42","Restful User/Password Authentication","<security><rest><api-design><authentication><go>","2","1","","","","CC BY-SA 3.0"
"177342","1","177349","","2012-11-27 15:19:16","","24","8545","<p>Passwords shouldn't be stored in plain text for obvious security reasons: you have to store hashes, and you should also generate the hash carefully to avoid rainbow table attacks.</p>

<p>However, usually you have the requirement to store the last <em>n</em> passwords and to enforce minimal complexity and minimal change between the different passwords (to prevent the user from using a sequence like Password_1, Password_2, ..., Password_<em>n</em>). This would be trivial with plain text passwords, but how can you do that by storing only hashes?</p>

<p>In other words: how it is possible to implement a safe password history mechanism?</p>
","11","","","","","2012-11-28 19:46:37","How to implement a safe password history","<security><passwords>","5","12","","","","CC BY-SA 3.0"
"177424","1","177426","","2012-11-27 23:04:56","","0","937","<p>I recently came across a website that generates a random adjective, surrounded by a prefix and suffix entered by the user. For example, if the user enters ""123"" for prefix, and ""789"" for suffix, it might generate ""123Productive789"". I've been screwing around with it, and I thought I might try something out. I entered this into the prefix field:</p>

<pre><code>&lt;a href=""javascript:window.close();""&gt;Click&lt;/a&gt;&lt;hr /&gt;
</code></pre>

<p>And, sure enough, I was given the link, then an <code>&lt;hr&gt;</code>, then a random adjective. What I'm wondering is, could this be dangerous? There must be many more websites out there that have this issue, are all of them vulnerable to some sort of php injection?</p>
","55060","","55060","","2012-11-27 23:28:58","2012-11-27 23:28:58","Can HTML injection be a security issue?","<security>","1","7","","","","CC BY-SA 3.0"
"394050","1","","","2019-06-30 17:35:29","","-1","1320","<p>What is the difference between buffer overflows and out-of-bounds writes? Are buffer overflows a kind of out-of-bounds writes?</p>
","339885","","","","","2019-06-30 18:47:52","Buffer Overflows and Out-of-bounds Writes","<security>","1","2","","2019-07-01 17:22:44","","CC BY-SA 4.0"
"177589","1","177591","","2012-11-28 23:42:08","","3","189","<p>I've built an application that requires users to authenticate with one or more social media accounts from either Facebook, Twitter, or LinkedIn. </p>

<p><strong>Edit</strong>
Once the user has signed in, an 'identity' for them is maintained in the system, to which all content they create is associated. A user can associate one account from each of the supported providers with this identity.</p>

<p>I'm concerned about how to protect potential users from connecting the wrong account to their identity in our application.</p>

<p><strong>/Edit</strong></p>

<p>There are two main scenarios that could happen:</p>

<ul>
<li><p>User has multiple accounts on one of the three providers, and is not logged into the one s/he desires.</p></li>
<li><p>User comes to a public or shared computer, in which the previous user left themselves logged into one of the three providers.</p></li>
</ul>

<p>While I haven't encountered many examples of this myself, I'm considering requiring users to password authenticate with Facebook, Twitter, and LinkedIn whenever they are signing into our application.</p>

<p>Is that a reasonable approach, or are there reasons why many other sites and applications don't challenge users to provide a user name and password when authorizing applications to access their social media accounts?</p>

<p>Thanks in advance!</p>

<p><strong>Edit</strong></p>

<p>A clarification, I'm not intending to store anyone's user name and password. Rather, when a user clicks the button to sign in, with Facebook as an example, I'm considering showing an ""Is this you?"" type window.</p>

<p>The idea is that a user would respond to the challenge by either signing into Facebook on the account fetched from the oauth hash, or would sign into the correct account and the oauth callback would run with the new oauth hash data.</p>
","26179","","26179","","2012-11-29 00:19:07","2012-11-29 02:17:46","Is it reasonable to require passwords when users sign into my application through social media accounts?","<security><social-networks>","5","2","","","","CC BY-SA 3.0"
"177605","1","177608","","2012-11-29 01:45:13","","2","569","<p>I've been setting up debug tags for automated testing of a GWT-based web application. This involves turning on custom debug id tags/attributes for elements in the source of the app. It's a non-trivial task, particularly for larger, more complex web applications. Recently there's been some discussion of whether enabling such debug ids is a good idea to do across the board. </p>

<p>Currently the debug ids are only turned on in development and testing servers, not in production. There have been points raised that enabling debug ids does cause performance to take a hit, and that debug ids in production may lead to security issues.</p>

<p>What are benefits of doing this? Are there any significant risks for turning on debug tags in production code? </p>
","36853","","36853","","2012-11-29 04:07:36","2012-12-17 07:40:23","What are the downsides of leaving automation tags in production code?","<web-development><security><automation><gwt>","4","2","","","","CC BY-SA 3.0"
"394329","1","394349","","2019-07-06 21:39:12","","-2","131","<p>I am working on a product that will not be able to be updated once released.  Furthermore, if the product malfunctions, the results may include death, serious bodily harm, or major financial setbacks.  Therefore, my code <em>must</em> be correct the first time, as I will not get a second chance.</p>

<p>What techniques are available for this?  I already plan on extensive testing, but I know that testing can only demonstrate the presence of bugs, not prove their absence.</p>
","102240","","","","","2019-07-07 16:45:14","How do I ensure my product is correct the first time?","<security><formal-methods><system-reliability>","2","3","","2019-07-07 18:56:22","","CC BY-SA 4.0"
"177936","1","","","2012-11-30 21:21:14","","3","1385","<p>I've heard that PHP is somewhat secure because Apache won't allow the download of raw PHP. Is this reliable, though? For example, if you wanted to password protect something, but didn't want to create a database, would something like <code>$pass = ""123454321"";</code> be safe?</p>

<p>Bottom line, is it safe to assume that nobody has access to the actual .php file?</p>
","55060","","25936","","2012-11-30 21:38:22","2012-12-01 00:14:17","Is having sensitive data in a PHP script secure?","<php><security>","2","3","0","","","CC BY-SA 3.0"
"394482","1","","","2019-07-10 12:46:41","","2","151","<p>I need an advice on securing interaction between an application App and a microservice RecordApp. </p>

<p>App is the main application, where all users are registered and do some activity. RecordApp is a utility application where App users can store records that publicly visible in the App (like sub-twitter). RecordApp knows nothing about users, but each record (""tweet"") needs to have an author. I need to provide ability to use the RecordApp from the frontend and don't use the App like a proxy. I have some options to do this:  </p>

<p>The first is: User passes authentication on the App server and receives JWT token (that was signed using App public key) that tells that the user has name ""User1"" and can create public records. Then user sends this to RecordApp, it validates it (using RecordApp secret key) and sees that this user can create a record and then creates it. But if some hacker steals the User cookie, then the hacker can post malicious records by the name of ""User1"". I could solve this by setting httpOnly flag for the cookie, but App and RecordApp have different domains, so that wouldn't work.<br>
What do I do to secure such microservice?</p>

<p>The second option is as user passes authentication on the App server, send to the user a public_key that will be used to sign jwt with the record contents. If the hacker will be able to steal it from the-middle, then they just can post this message unchanged. But what do I do to protect the public key then?</p>

<p>Thanks in advance!</p>
","340654","","340654","","2019-07-10 12:56:48","2021-07-02 11:01:25","Securing a microservice that will be accessible from frontend","<api><security><microservices><jwt>","1","2","0","","","CC BY-SA 4.0"
"294790","1","294801","","2015-08-28 09:55:11","","4","2385","<p>The established procedure regarding releasing code out in the open is to accompany it with a license. Out of the many flavors that exist (BSD, MIT, GPL, LGPL, Boost ...) there are some that <strong>prohibit using the code in proprietary software</strong>, unless you pay an agreed fee ofcourse. </p>

<p>I have two questions on this : </p>

<ul>
<li>How is such a violation detectable ? The question stems from the fact that comercial products almost never show their code so you can't know what they use. </li>
</ul>

<p>I am NOT asking about the legal ramifications - that's off-topic - I'm asking about the technical approach to detect such usage.
- Are there any known cases where such a violation has been reported and persecuted?  If so, how was it detected? </p>
","120443","","68823","","2015-08-28 11:02:45","2015-08-28 12:11:13","How to *detect* if open source software is used in a commercial product?","<open-source><security>","1","21","","2015-08-29 01:45:51","","CC BY-SA 3.0"
"395045","1","","","2019-07-22 19:32:26","","1","75","<p>I have a vanilla <code>php</code> <code>api</code>(on a vds) and I want to make data coming from that api available to a few clients that are using a <code>python</code> app that's also written by me. That python app is running on my client/s pc. But now i'm facing a problem: that app can be ""pirated"".</p>

<p>How do I make sure that the access is limited to only my paid subscribers?</p>

<p>I know that ""DRM"" or copy protection won't work therefore I was thinking about using tokens that are only available 1 day. And each call will send an Authorization header and based on that the api can decide what to do.</p>

<pre><code>private function check_authorization(){
    if(Server::exists('HTTP_AUTHORIZATION')){
        $credentials = preg_split('/[\s:]/', trim(Server::get('HTTP_AUTHORIZATION')));

        //try to authenticate the user using those credentials

        return true;
    }
    return false;
} 
</code></pre>

<p>Now I was thinking about binding those tokens to 1 IP/day but then there's the dynamic ip and the spoofing problem.</p>

<p>Also I was thinking about using something like <code>Steam</code> way to authenticate new devices for a user: new device? just send a 6 digits code trough email and ask the user to send it over to the api for confirmation. But if i can't identify the device, other than its ip it'll be pretty painful for those clients who happen to be less fortunate and have a dynamic ip.</p>

<p>Should i go as far as checking the operating system, maybe even get the mac and bind my tokens to those macs? Is that even possible?</p>

<p>Thank you!</p>
","341590","","341590","","2019-07-22 19:38:33","2019-07-22 19:42:43","Api limit access to subscribers only","<php><api><security><authentication><python-3.x>","1","0","","","","CC BY-SA 4.0"
"395128","1","","","2019-07-24 12:05:33","","7","11488","<p>I have worked with public API's in only one small project, but I recently learned that if one were to distribute a project with API keys inside this is a security risk.</p>

<p>So I have two questions:</p>

<ul>
<li>What does an API key contain that would pose a security risk?</li>
<li>How does one create an application that makes use of public API's and
distribute that application without posing a security risk?</li>
</ul>

<p>Surely if someone can reverse engineer the application, they could extract any API keys that are present.</p>
","341724","","326536","","2019-08-03 18:00:30","2019-08-03 18:00:30","Why must API keys be kept private?","<api><security><risk>","4","3","","","","CC BY-SA 4.0"
"395387","1","","","2019-07-30 19:27:36","","2","1747","<p>I am planning on creating a wrapper class in c# which will call cryptographic functions provided by .Net Framework, just to make sure I am clear, I am not writing any cryptographic algorithm, just writing a wrapper to facilitate requests coming from other modules of Applications.  </p>

<p>I have seen a lot of examples in which the wrapper class is made static, one of the reasons I could understand is that static class are sealed so they can not be inherited, and I think it would make sense to but I read somewhere that 
<code>Static classes are loaded automatically by the .NET Framework common language runtime (CLR) when the program or namespace containing the class is loaded.</code></p>

<p>Is that going to be a problem since the class is loaded automatically way before it is used, security wise, should I make my wrapper class static?</p>
","303014","","","","","2019-12-29 23:19:58","Wrapper Class Should be made static?","<c#><design-patterns><security>","3","7","","","","CC BY-SA 4.0"
"297066","1","297101","","2015-09-12 03:22:58","","5","102","<p>I just read <a href=""http://tutorials.jenkov.com/oauth2/index.html"">this excellent tutorial on OAuthv2</a> but am still missing some important concepts regarding authorization grants.</p>

<p>I'm fundamentally not understanding the necessity for the two request/response cycles between client app and authorization server, where:</p>

<ul>
<li>First the user is redirected to the auth server during an <strong>Authorization Request</strong>, whereby (on successful authentication), they receive an <strong>auth code</strong>; and then</li>
<li>Next, the client app makes a second <strong>Token Request</strong> to the auth server, whereby the auth server validates the client's ID, secret and auth code, and sends back an <strong>access token</strong> for it to use</li>
</ul>

<hr>

<h3>Auth codes vs. access tokens</h3>

<p>What is the difference between this ""auth code"" and this ""access token""? Why do I need to first generate an auth code so that I can, subsequently, obtain an access token?!? <strong>Why not just do all this in 1 roundtrip and get an access token upon successful authentication?</strong></p>

<h3>Access tokens and resource servers</h3>

<p>I assume that the main point of the access token is to act as a hall pass for future requests, so that client apps aren't re-authenticating each subsequent request. Ergo I assume that, with a valid access token, client apps can now ""speak directly"" with resource servers. And I assume that, upon receiving each request, the resource servers probably validate access tokens with their respective auth servers. <strong>Am I on track here or way off base?</strong></p>

<h3>Access tokens and SSO?</h3>

<p><strong>Can access tokens be used in an SSO scenario where you have multiple resource servers all using the same auth server?</strong> Meaning, once I authenticate with an auth server and receive my access token from it when I'm inside 1 SSO app, can I then migrate to another SSO app, and apply the same access token (assuming it hasn't expired yet) and be ""signed in"" to that second app, without having to re-authenticate?</p>
","154753","","","","","2015-09-12 18:17:52","OAuthv2 authorization grants","<security><oauth2><sso>","1","1","","","","CC BY-SA 3.0"
"179311","1","","","2012-12-13 18:43:14","","0","229","<p>I would like to redistribute my app (PHP) in a way that the user gets the front end (presentation) layer which is using the API on my server through a web service. 
I want the user to be able to alter his part of the app but at the same time exclude such altered app from the normal support and offer support on pay by the hour basis. </p>

<p>Is there a way to check if the source code was altered?
Only solution I can think of would be to get check sums of all the files then send it through my API and compare them with the original app. Is there any more secure way to do it so it would be harder for the user to break such protection? </p>
","72594","","57164","","2012-12-13 19:05:28","2012-12-13 20:25:28","Is there a way to check if redistributed code has been altered?","<php><licensing><web-applications><code-security>","4","0","","","","CC BY-SA 3.0"
"395829","1","","","2019-08-09 06:59:26","","0","74","<p>I am developing a mobile application that will have both free and paid versions. </p>

<p>The way I see how I could differentiate between what is a paid and free user is to set a property <code>isPaid</code> on their respective documents. </p>

<p>What I want to understand is how to set the <code>isPaid</code> property on <code>user</code>'s document securely. </p>

<p>One option that I see is after successful payment directly access the document that belongs to the user and change the <code>isPaid</code> property. All of that would be done on the mobile application side.</p>

<p>Another option could be to use the Firebase Functions and trigger one to set the correct value on the <code>isPaid</code> property for the given user.</p>

<p>But what could prevent a malicious user from setting these properties directly OR how to ensure that there actually is a pending subscription from Google or Apple and the user really is a paying one.</p>

<p>Currently my Firestore structure looks like this:</p>

<pre class=""lang-js prettyprint-override""><code>{
  ""users"": [
    { 
        ""uid"": ""123123123123123"",
        ""name"":""Bob"",
        ""isPaid"": false,
        ""messages"": [
            {
                ""messageText"":""hello""
            }
        ]
    },
    { 
        ""uid"": ""456456456456456"",
        ""name"":""Alice"",
        ""isPaid"": true,
        ""messages"": [
            {
                ""messageText"":""hey""
            }
        ]
    }, 
    ...
}
</code></pre>

<p>Thanks!</p>
","342994","","","","","2019-08-09 06:59:26","What is the correct way of setting and then differentiating between paid and free user in Firebase / Firestore?","<design-patterns><database><data-structures><security><nosql>","0","4","","","","CC BY-SA 4.0"
"297417","1","297612","","2015-09-16 13:26:32","","20","15574","<p>I just <a href=""http://www.thebuzzmedia.com/designing-a-secure-rest-api-without-oauth-authentication/"">read this article</a> that is a few years old but describes a clever way of securing your REST APIs. Essentially:</p>

<ul>
<li>Each client has a unique public/private key pair</li>
<li>Only the client and the server know the private key; it is never sent over the wire</li>
<li>With each request, the client takes several inputs (the entire request itself, the current timestamp, and the private key) and runs them through an HMAC function to produce a hash of the request</li>
<li>The client then sends the normal request (which contains the public key) and the hash to the server</li>
<li>The server looks up the client's private key (based on the provided public key) and does some timestamp check (that admittedly I don't understand) that verifies the request is not a victim of a <a href=""https://en.wikipedia.org/wiki/Replay_attack"">replay attack</a></li>
<li>If all is well, then the server uses the private key and the same HMAC function to generate its own hash of the request</li>
<li>The server then compares both hashes (the one sent by the client as well as the one it generated); if they match, the request is authenticated and allowed to proceed</li>
</ul>

<p>I then stumbled across <a href=""http://jwt.io"">JWT</a>, which sounds very similar. However the first article does not mention JWT at all, and so I am wondering if JWT is different than the above auth solution, and if so, how.</p>
","154753","","","","","2023-02-22 12:26:55","REST API security: HMAC/key hashing vs JWT","<security><rest><authentication><keys><hmac>","2","2","","","","CC BY-SA 3.0"
"396087","1","396088","","2019-08-16 14:47:44","","0","208","<p>tldr: In building a platform where users can create private groups, and invite other people to those private groups, how is it be to secure those groups?</p>

<p>I'm building a platform around private groups and communities. I'm not really sure on what is the most suitable pattern/mechanism to secure groups so only those invited can read/write. </p>

<p>Technology is Okta and Spring Security. </p>

<p>Should I be creating groups and using the role claim in a oauth token, so when I user creates a new group I'd need to create that group on the auth server and add that group to each user who is invited. This would work I believe but with how Spring Security works would require users to log out and back in, in order to gain the new group. </p>

<p>Is scopes instead another alternative? or would I make use of claims and each new group created would need the user to ""authenticate"" with the group? </p>

<p>Do I just limit/control access based on what groups the user profile has assigned to it? Seems simple but also doesn't seem the most secure.</p>

<p>I'm sure there is a pretty standard way to handle this I'm just not sure what approach to take.  </p>
","289163","","","","","2019-08-16 14:56:47","How to dynamically create and assign user permissions for a group based service","<security><permissions><oauth2>","1","0","","","","CC BY-SA 4.0"
"180012","1","180014","","2012-12-19 14:34:31","","66","22190","<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""https://softwareengineering.stackexchange.com/questions/86461/writing-web-server-less-applications"">Writing Web â€œserver lessâ€ applications</a>  </p>
</blockquote>



<p>So, let's say I'm going to build a Stack Exchange clone and I decide to use something like CouchDB as my backend store. If I use their built-in authentication and database-level authorization, is there any reason not to allow the client-side Javascript to write directly to the publicly available CouchDB server? Since this is basically a CRUD application and the business logic consists of ""Only the author can edit their post"" I don't see much of a need to have a layer between the client-side stuff and the database. I would simply use validation on the CouchDB side to make sure someone isn't putting in garbage data and make sure that permissions are set properly so that users can only read their own _user data. The rendering would be done client-side by something like AngularJS. In essence you could just have a CouchDB server and a bunch of ""static"" pages and you're good to go. You wouldn't need any kind of server-side processing, just something that could serve up the HTML pages.</p>

<p>Opening my database up to the world seems wrong, but in this scenario I can't think of why as long as permissions are set properly. It goes against my instinct as a web developer, but I can't think of a good reason. So, why is this a bad idea?</p>

<p>EDIT: Looks like there is a similar discussion here: <a href=""https://softwareengineering.stackexchange.com/questions/86461/writing-web-server-less-applications"">Writing Web &quot;server less&quot; applications</a></p>

<p>EDIT: Awesome discussion so far, and I appreciate everyone's feedback! I feel like I should add a few generic assumptions instead of calling out CouchDB and AngularJS specifically. So let's assume that:</p>

<ul>
<li>The database can authenticate users directly from its hidden store</li>
<li>All database communication would happen over SSL</li>
<li>Data validation <em>can</em> (but maybe shouldn't?) be handled by the database</li>
<li>The only authorization we care about other than admin functions is someone only being allowed to edit their own post</li>
<li>We're perfectly fine with everyone being able to read all data (EXCEPT user records which may contain password hashes)</li>
<li>Administrative functions would be restricted by database authorization</li>
<li>No one can add themselves to an administrator role</li>
<li>The database is relatively easy to scale</li>
<li>There is little to no true business logic; this is a basic CRUD app</li>
</ul>
","75474","","-1","","2017-04-12 07:31:31","2018-08-30 02:40:01","Is there any reason not to go directly from client-side Javascript to a database?","<javascript><architecture><database><security><couchdb>","14","11","","","","CC BY-SA 3.0"
"396478","1","396480","","2019-08-26 00:41:36","","2","801","<p>Suppose one plans to implement authentication for their web app. There have been cases, like with Instagram, where passwords were accidentally stored in plain text due to logs.</p>
<p>While we'd hope to never make this mistake, we're thinking it might be best to do an unsalted SHA512 hash on the client-side, and use that as the effective password to hash again with bcrypt on the server-side?</p>
<p>This way, if a similar mistake were to be made, at the very least the user's original plain text password would never leave their machine. As a result, it can't be stored in our systems.</p>
<p>This assumes that on server-side, we still use bcrypt to salt and hash the password, and store the effective password securely.</p>
<p>The motivation is that in the scenario that a misconfiguration occurs, an unsalted SHA512 string is stored instead of the user's original plain text password. This is still bad, but in theory, less so?</p>
<p>Is this a viable setup, and are the examples of services doing this?</p>
","342576","","342576","","2023-04-24 11:22:10","2023-04-24 11:22:10","Client Side Hashing + Server Side Hashing","<security><hashing><passwords>","1","0","","","","CC BY-SA 4.0"
"298101","1","298107","","2015-09-24 02:55:15","","4","657","<p>We currently have a platform with a SOA architecture in which the user's identity is propagated from the web application via middle tier services (REST and SOAP) until we actually query our data storage layer.</p>

<p>We use the user's identity to apply access control at the entity layer. The user's identity is communicated between services by attaching security tokens to the service invocations (SAML/JWT).</p>

<p>One of our customers wants to use an <a href=""https://en.wikipedia.org/wiki/Event-driven_architecture"" rel=""nofollow"">Event Driven Architecture</a> to build a product on our platform instead of the more traditional request/response pattern. They want to use the <a href=""https://azure.microsoft.com/en-us/documentation/articles/service-bus-fundamentals-hybrid-solutions/"" rel=""nofollow"">Azure Service Bus</a> Queues and Topics to achieve a higher scalability.</p>

<p>I was wondering how in this architecture we could propagate the user's identity to the consumers of the messages/events stored on the service bus.</p>

<p>FOR EXAMPLE:</p>

<p>Suppose the user creates a new task in the front-end web application. Instead of calling the Task service (sending along the user's identity) and waiting for the response, the application stores the task creation event in the queue and delegates the actual creation of the task to a background worker subscribed to this type of message. </p>

<p>However, in order to determine if the user who initiated the task creation is allowed to create a task, the task service (a background worker) needs to call the entity layer in the context of the user. </p>

<p>I could store the security token together with the task creation payload, but given the temporal decoupling of the producer and consumer, this token may have expired by the time it is used to call into the entity layer.</p>

<p>Are there any well-established patterns to solve this problem? I realize that I can move the access control into the web-application, but as we've built a platform for others to build applications on, I do not necessarily want to trust those application to enforce the security requirements. That is the key reason why we've build the access control into the entity layer.</p>

<p>Are all consumers of service bus events always part of a trusted subsystem, or are there ways of solving this elegantly?</p>
","76757","","","","","2015-09-24 04:47:26","Identity propagation using Azure service bus","<architecture><security><event-programming><identity><service-bus>","1","0","","","","CC BY-SA 3.0"
"180272","1","","","2012-12-21 09:19:39","","13","1077","<p>Most security threats that I've heard of have arisen due to a bug in the software (e.g. all input is not properly sanity checked, stack overflows, etc.). So if we exclude all social hacking, are all security threats due to bugs? In other words, if there were no bugs, would there be no security threats (again, excluding the faults of humans such as disclosing passwords and such)? Or can systems be exploited in ways not caused by bugs?</p>
","2210","","","","","2012-12-21 11:43:18","Are all security threats triggered by software bugs?","<security><bug><hacking>","7","6","","","","CC BY-SA 3.0"
"298423","1","298427","","2015-09-28 00:07:41","","-1","806","<p>I am trying to create an authentication client and server for my project, and I am trying to think of ways on how a potential hacker could modify my code and use it to hack the servers. Do people actually do this often and if so, how do programmers try to get around it in open source projects?</p>
","198083","","","","","2015-09-28 00:55:08","Do people modify open source code to hack?","<open-source><security>","2","0","","2015-09-28 02:26:50","","CC BY-SA 3.0"
"298582","1","","","2015-09-29 20:20:42","","-4","406","<p>I'm a Java Developer, I created a Desktop Application , that is Free, and now I'm about to finish the payed version. my question is when I create a startup and other developers work on my code. How can I prevent them from copying the source code and take it home or leak it?? and is there is a software for that, what there names are?? and I need the name of some kind of software that keep track of every activity the user make (keyboard keys pressed, website visited even if history is deleted, software installed ...). I will be using Windows. Thanks a lot</p>
","198329","","","","","2015-09-29 20:27:22","How to protect source code from being copied or leaked by employes","<project-management><code-security>","1","7","0","2015-09-29 20:50:10","","CC BY-SA 3.0"
"298623","1","","","2015-09-30 11:43:41","","1","154","<p>I'm looking to secure an API based on a shared key and a given username and datetime. The API gives access to trusted third parties and does not require the input from a user in order to access their account (i.e. no OAuth user interaction flow). The third party does not know, nor should require, the user's password.</p>

<pre><code>/// &lt;summary&gt;
/// Generate a Time/String based Hash from the given DateTimeStamp, Authentication Details 
/// and (Pre-Shared) API Key.
/// &lt;/summary&gt;
/// &lt;param name=""datetimeStamp""&gt;The DateTimeStamp that is to be used to generate the Hash&lt;/param&gt;
/// &lt;param name=""userName""&gt;The UserName that is to be used to generate the Hash&lt;/param&gt;
/// &lt;returns&gt;A string based Hash generated from the DateTimeStamp, Username and 
/// Pre-Agreed API Hash Key&lt;/returns&gt;
public string GenerateHash(DateTimeOffset dateTimeStamp, string userName)
{
    string hash = string.Empty;
    DateTimeOffset DateStamp = dateTimeStamp.ToUniversalTime();
    string input = string.Format(""{0}{1}{2}"", DateStamp, userName, PreSharedKey);
    var sha1 = System.Security.Cryptography.SHA1.Create();
    byte[] inputBytes = System.Text.Encoding.ASCII.GetBytes(input);
    byte[] hashArray = sha1.ComputeHash(inputBytes);
    var hashOutput = new StringBuilder();
    for (int i = 0; i &lt; hashArray.Length; i++)
        hash += hashArray[i].ToString(""X2"");
    return hash;
}
</code></pre>

<p>A POST is made to an authentication API like so:</p>

<pre><code>{ 
  Hash : ""9B970DD40DB803EDB301C5B1CC23DF7B2C5B5FF5"", 
  DateTimeStamp : ""yyyyMMddHHmmss"", 
  UserName : ""admin""
}
</code></pre>

<p>The Hash is made up of the following: SHA1(datetime + username + presharedkey).</p>

<p>An authentication token is then generated and returned to the third party (session token that has an expiry date).</p>

<p>Are there any obvious problems with such an approach? Is there a better way to do such authentication when the third party is semi-trusted, and the user shouldn't be required to authorise access to their account?</p>
","21585","","21585","","2015-09-30 12:06:25","2015-09-30 12:06:25","'HMAC style' design example for a shared secret","<security><authentication><hmac>","0","7","","","","CC BY-SA 3.0"
"180957","1","180973","","2012-12-29 19:41:37","","3","1093","<p>I have an open source project for <code>mydomain.com</code> which requires connections to a database (...as is tradition). What is the standard practice for allowing others to work on the site, without giving them full access to the database's credentials?</p>

<p>For example: If I have a <code>connect.php</code> page that connects to the database. I don't want someone to be able to read that file, or simply write <code>&lt;?php include(""http://mydomain.com/connect.php"")</code> because then they will have full access to the database. If I put the file in my <code>.gitignore</code> file, sure the file won't be in the repo, but it'll still be visible in the source code.</p>

<p>Do I just make a read-only user and give them access to that, and then put the full read-write connection file and follow the guidelines of this answer?: <a href=""https://softwareengineering.stackexchange.com/questions/137970/making-sure-database-connection-information-is-secured"">Making sure database connection information is secured</a></p>

<p>What is standard practice here? or what can I research to learn more about this?</p>
","76237","","-1","","2017-04-12 07:31:33","2012-12-30 15:07:06","typical way to share database connection for open-source project, without revealing too much","<open-source><database><security>","2","1","","","","CC BY-SA 3.0"
"298885","1","","","2015-10-03 06:34:33","","3","102","<p>Imagine that you have an object code file from an untrusted source. You want to run this code to know the result of its computation, and you want the code to perform fast, so setting up a whole virtual machine is a last resort. You also want nothing to happen to your system after the code is run.</p>

<p>Having that in mind, as far as I understand, that code would not be able to do any harm if you restrict the number of interrupts for it or disable interrupts whatsoever. One way to ensure there are no interrupts in code is to scan it instruction-wise and refuse to run if there is at least one <code>int</code>Â instruction in it. That will solve the problem, but this approach will as well disallow any system calls, and the code with no system calls is scarcely useful. If the running side decides to allow that code which only invokes some whitelisted interrupts, then the running side needs to be sure that the running code does not change itself in run time. If it does change, then each instruction to run needs to be re-scanned, what would impact performance.</p>

<p>It would be nice to have some kind of gateway between host and guest interrupts, which could translate guest interrupts to possibly different host interrupts or refuse to do so. Are there any solutions or researches available for this topic?</p>
","198893","","","","","2015-12-30 17:02:02","How to be sure that a certain code does not call interrupts?","<security><assembly><verification>","1","7","","","","CC BY-SA 3.0"
"298973","1","308443","","2015-10-04 19:22:16","","127","69018","<p>I am still trying to find the best security solution for protecting REST API, because the amount of mobile applications and API is increasing every day. </p>

<p>I have tried different ways of authentication, but still has some misunderstandings, so I need advice of someone more experienced.    </p>

<p>Let me tell, how I understand all this stuff. If I understand something incorrectly, please let me know.    </p>

<p>As far as REST API is stateless as well as WEB in general, we need to send some auth data in each request(cookies, token....). I know three widely used mechanisms to authenticate user </p>

<ol>
<li><p>Token with HTTPS. I have used this approach a lot of times it is good enough with HTTPS. If user provides correct password and login, he will receive token in response, and will use it for the further requests. Token is generated by the server and stored, for instance in the table separate or the same where user info is stored. So for each request server checks if user has token and it is the same as in the database. Everything is pretty straightforward.   </p></li>
<li><p>JWT Token. This token is self-descriptive, it contains all necessary information about the token itself, user cannot change for example expiration date or any other claim, because this token is generated (signed) by the server with secret keyword. This is also clear. But one big problem, personally for me, how to invalidate token. </p></li>
<li><p>OAuth 2. I don't understand why this approach should be used when communication is established directly between server and client. As far as I understand, OAuth server is used to issue token with restricted scope to allow other applications access user information without storing password and login. This is great solution for the social networks, when user wants to sign up on some page, server can request permissions to get user info, for instance from twitter or facebook, and fill registration fields with user data and so on.    </p></li>
</ol>

<p>Consider mobile client for online store.</p>

<p>First question should I prefer JWT over first type token ? As far as I need login/logout user on mobile client, I need to store somewhere token or in case of JWT, token should be invalidated on logout. Different approaches are used to invalidate token one of the is to create invalid token list (black list). Hmm. Table/file will have much bigger size than if token was stored in table and associated with user, and just removed on logout.    </p>

<p>So what are benefits of JWT token ?    </p>

<p>Second question about OAuth , should I use it in case of direct communication with my server?  What is the purpose of one more layer between client and server only to issue token, but communication will be not with oauth server but with the main server. As I understand OAuth server is responsible only for giving third-party apps permissions (tokens) to access user private information. But my mobile client application is not third-party.</p>
","181882","","181882","","2016-11-01 07:16:50","2019-11-04 12:31:12","REST API security Stored token vs JWT vs OAuth","<security><rest><api><oauth><https>","4","1","","","","CC BY-SA 3.0"
"299062","1","","","2015-10-05 18:21:50","","3","1925","<p>I have a webapi project working in production for few months now.  </p>

<p>The entire webapi is server to server.  </p>

<p>There is a need now to have the same functionality in a browser, meaning the customers can invoke via ajax functions directly on the webapi server.</p>

<p>Since the webapi is stateless and session usage is not really recommended, what are my options here?</p>

<p>Today (server to server), every request reaching the server has user and pass, and on every request there is a login check (not that efficient, I know).   </p>

<p>What happens when the same rest webapi needs to go to the browser and have security?</p>
","118517","","64132","","2015-10-05 18:32:36","2015-10-06 00:16:50","Making a security on webapi for browser usage","<c#><security><web-api>","2","0","","2015-10-07 13:57:56","","CC BY-SA 3.0"
"398382","1","398384","","2019-09-14 04:25:41","","-4","228","<p>Its easy to steal internal hdd, which do not generate sound signals to aware the owner while removing and allows Thief to copy the data.</p>

<p>Is there any way by which these thieves acts can be traced.</p>
","346628","","","","","2019-09-14 05:53:50","How to detect that internal hard disk is removed and which files were copied?","<security><data><hardware>","1","0","","2019-09-14 08:08:50","","CC BY-SA 4.0"
"181290","1","","","2013-01-02 21:13:05","","1","284","<p>I am eager to know what information is checked by the online companies to confirm that the card is yours?</p>

<p>If a programmer has to implement this functionality, how can he access information like address of the client which is not written on the debit card? Thanks</p>
","","user4124","","","","2013-01-03 09:23:04","Verifying a debit card online - What information is checked?","<security>","3","3","","","","CC BY-SA 3.0"
"181577","1","181581","","2013-01-04 21:21:00","","29","14346","<p>Theoretically, if I were to build a program that allocated all the unused memory on a system, and continued to request more and more memory as other applications released memory that they no longer need, would it be possible to read recently released memory from another applications? Or is this somehow protected by modern operating system?</p>

<p>I have no practical application for this, I'm just curious. I realize there are some issues with allocating ""all available memory"" in real-life.</p>

<p>Edit: To clarify, I'm asking specifically about ""Released"" memory, not accessing memory that is currently allocated by another application.</p>
","66745","","66745","","2013-01-04 21:43:28","2019-09-05 03:34:41","Is it possible to read memory from another program by allocating all the empty space on a system?","<security><operating-systems><memory>","5","0","","","","CC BY-SA 3.0"
"181626","1","181631","","2013-01-05 14:08:17","","1","112","<p>I need to write a web application that acts as a configuration interface for some system services. Meaning it will probably change some kind of configuration file and has to restart (linux) system services.</p>

<p>I was wondering how to design such a thing in a secure way. It is very similar to router web interfaces and such, so I had a quick look at some of these as well as webmin.</p>

<p>Basically, I could run the web service/CGI-Script/etc. with root privileges, filter the input as good as possible and just write to the system and execute whatever program I'd like.</p>

<p>This does not seem very secure. I would like to achieve some kind of privilege separation.</p>

<p>Maybe having my web app run as unprivileged user and pass the Information to some privileged daemon/service, i.e., having a Python web app writing the infos to a file and notifying the daemon or use unix sockets to communicate with this backend program. </p>

<p>Any ideas or experience you could share regarding this issue?</p>

<p>Thank you very much in advance.</p>
","76741","","","","","2013-01-05 16:02:40","Securely changing system configuration from a web application","<architecture><web-applications><security>","1","2","","","","CC BY-SA 3.0"
"299468","1","299474","","2015-10-09 11:54:19","","24","11109","<p>For a company I used to work for, I had to implement a socket receiver that mostly took data in UDP form over a local connection from some specialized sensor hardware. The data in question was a well-formed UDP packet, but interestingly, the data payload always ended with a CRC16 checksum formed using the rest of the data.</p>

<p>I implemented the check on my end, as per the spec, but I always wondered if this was necessary. After all, doesn't the UDP protocol itself carry a 16-bit CRC? Therefore, although UDP packets can be lost or out-of-order, I was under the impression that they can not be corrupted without being discarded by the network hardware before they reach the OS's processes. Or is there some special use-case I'm missing?</p>

<p>It's worth adding that I was working in the defence industry, which as I'm sure you can imagine, likes to be super-explicit about everything like this, so I'm wondering whether it was just a case of ""security OCD""...</p>
","157461","","157461","","2015-10-11 13:58:04","2023-05-16 20:49:05","Should UDP data payloads include a CRC?","<security><networking><data-integrity>","3","3","","","","CC BY-SA 3.0"
"299729","1","299732","","2015-10-13 08:28:00","","69","34748","<p>I'm trying to understand the inherent tradeoff between roles and permissions when it comes to access control (authorization).</p>

<p>Let's start with a given: in our system, a <em>Permission</em> will be a fine-grained unit of access (""<em>Edit resource X</em>"", ""<em>Access the dashboard page</em>"", etc.). A <em>Role</em> will be a collection of 1+ Permissions. A <em>User</em> can have 1+ Roles. All these relationships (Users, Roles, Permissions) are all stored in a database and can be changed on the fly and as needed.</p>

<p>My concerns:</p>

<blockquote>
  <p>(1) What is so ""bad"" about checking Roles for access control? What benefits are gained by checking for permissions instead? In other words, what's the difference between these two snippets below:</p>
</blockquote>

<pre><code>if(SecurityUtils.hasRole(user)) {
    // Grant them access to a feature
}

// vs.
if(SecurityUtils.hasPermission(user)) {
    // Grant them access to a feature
}
</code></pre>

<p>And:</p>

<blockquote>
  <p>(2) In this scenario what useful value do Roles even provide? Couldn't we just assign 1+ Permissions to Users directly? What <strong>concrete</strong> value of abstraction do Roles offer (can someone give specific examples)?</p>
</blockquote>
","154753","","","","","2020-12-24 23:08:08","Role vs Permission Based Access Control","<security><permissions><authorization><access-control><roles>","3","2","","","","CC BY-SA 3.0"
"181995","1","","","2013-01-09 09:38:04","","2","1428","<p>On my mobile app, I am storing the username of a logged in person, and downloading some data for the given/stored username. When the user checks for updates to his data content on the server, the server dishes out a delta of the content, based on the username. The app then updates its local display accordingly.</p>

<p>The problem is, since I am using localStorage, there is no guarantee that someone will not edit the username stored locally and try to request data meant for someone else.</p>

<p>What would be the best way of getting around this possible security hole? Please comment on this method that I am planning to implement:</p>

<ol>
<li>Each time you login, a random string is generated and stored for future checking in a database, along with your username, and date/time of request.</li>
<li>Whenever a request to download data for a username comes in, it must be accompanied by the string from the previous attempt. Also, each fresh update for the client is accompanied by a new random string, which is stored in the database and the old one is deemed expired.</li>
<li>If the random string is not provided correctly, the user is logged out of the mobile app (as this could potentially be someone tampering with the app).</li>
</ol>

<p>The advantage I see for this method is that I have an audit trail as well for later verification and forensics. What are the flaws?</p>
","31865","","","","","2013-01-09 12:32:17","How to verify data from localStorage on a server","<javascript><security><mobile><client-server><local-storage>","1","8","","","","CC BY-SA 3.0"
"182045","1","","","2013-01-09 14:42:48","","3","302","<p>I am author of growing <a href=""http://agiletoolkit.org/"" rel=""nofollow"">framework, which is focused around User Interface building in PHP</a>. Essential requirements for the up-coming website redesign is ability to <strong>run code examples</strong>. I am willing to extend this option to add-on authors which would mean <strong>other people</strong> will be able to execute code on my server.</p>

<p>Please suggest how to securely set up the environment which would allow me execute 3rd party PHP code built on my framework. I'd like to hear ideas from someone who have had experience with building sandboxed solutions.</p>
","24750","","13156","","2013-01-09 15:59:29","2016-06-21 17:15:22","Building dedicated codepad in PHP","<php><architecture><security><api><server>","1","2","","","","CC BY-SA 3.0"
"399062","1","399065","","2019-09-29 00:44:12","","4","396","<p>How can personal information that needs to be retrieved at a later date be stored securely in a database? For instance when companies store social security numbers and use them for taxation purposes. They have to be stored securely obviously, and retrieved later. It seems using hashes and salt as with password storage isnâ€™t the correct solution. From a high level, how is this done? </p>
","340868","","286826","","2019-10-17 13:34:29","2019-10-17 13:34:29","How can social security numbers be safely stored in databases and retrieved?","<security><encryption>","1","2","","","","CC BY-SA 4.0"
"300028","1","","","2015-10-16 08:00:28","","1","888","<p>Let say I've a fixed length number, e.g. 6 digit: 837493, I want to apply some process (with a salt), and generate a new number of another 6 digits, </p>

<p>e.g.</p>

<pre><code>number = 837493
another = hash(number + salt) // another is also a 6 digit number, e.g. 948375
</code></pre>

<p>Are there such algorithm exists?</p>
","34401","","","","","2015-10-16 08:00:28","Generate a fixed length number hash from a number","<algorithms><security><hashing>","0","5","","","","CC BY-SA 3.0"
"182349","1","182352","","2013-01-11 16:53:34","","5","249","<p>Recently we had an issue on our site where someone attempted SQL injection via a cookie (we'll call it <code>lastID</code>).  NOC was in a frenzy and angry about how the cookie as an attack vector could be ignored.  They had a developer create a class for managing cookies that will sanitize <code>lastID</code> (and eventually other cookies) to check that it is numeric.</p>

<p>However, I think that this is wrong.  The problem wasn't that <code>lastID</code> wasn't numeric, it was that the query that uses it was vulnerable to injection.  I'm in charge of the review of the code changes, and I want to bring up the fact that forcing <code>lastID</code> to be numeric is not particularly useful and perhaps even undesirable.</p>

<p>Is there a term or concept that describes sanitizing at the right time (i.e. sanitizing at query time rather than at cookie retrieval time), or ""over-sanitizing"" (e.g. forcing <code>lastID</code> to be numeric) that I can use to describe what's happening/should happen in my review?  The second part of Postel's Law seems to apply here in my mind:</p>

<blockquote>
  <p>Be ... liberal in what you accept</p>
</blockquote>
","28544","","","","","2013-01-11 18:06:57","Name for sanitizing at the right time?","<terminology><security><validation>","3","6","","","","CC BY-SA 3.0"
"300091","1","","","2015-10-16 22:17:27","","0","48","<p>I have my own home server and port 80/443 is blocked from my ISP provider.  I want to create a Qt gui application that saves my data on my server using REST (using port 8080 or something) using nginx/node.  The user would log in using a username/password.  What would be another alternative to secure the data being exchanged?  Or a good solution for encrypting the data back and forth between the client and the server?</p>
","170953","","","","","2015-10-16 22:17:27","Client application and secure data exchange without ssl/tls","<security><encryption><client-server>","0","2","","","","CC BY-SA 3.0"
"300158","1","","","2015-10-18 08:43:34","","2","75","<p><em>Just to be clear, by authentication I don't mean user-authentication, but I want to make sure that my app is running on the customer's server and in a defined time-span.</em></p>

<p>Some of our customers use our web apps in their Intranet and on their own servers, on the other hand some of them use Hosting services and they don't own any server machine.</p>

<p>With that said, I'm looking for ways to make sure about customer's Identity. I don't want them to be able to xcopy the app, also I'd like to have some kind of time-expiration limit.</p>

<p>In traditional desktop apps we could use USB security tokens, but their not usable with hosting providers.</p>

<p>It seems that we have to make a central authentication server. I'm a little confused about possible options, so any suggestion about where to start is welcome.</p>
","184905","","","","","2015-12-18 03:57:56","Customer Authentication in a website","<web-applications><security><authentication>","2","1","","","","CC BY-SA 3.0"
"183688","1","183692","","2013-01-15 15:32:16","","10","1154","<p>Often what's displayed to a user (e.g. on a web page) will be based partly on security checks.  I usually consider user-level / ACL security to be part of the business logic of a system.  If a view explicitly checks security to conditionally display UI elements, is it violating MVC by containing business logic?</p>
","4251","","4251","","2013-01-16 14:57:59","2013-01-16 14:57:59","Is the use of security conditionals in a view a violation of MVC?","<web-development><design-patterns><security><mvc>","7","2","","","","CC BY-SA 3.0"
"399576","1","","","2019-10-11 08:44:28","","1","87","<p>A potential client is very interested by a VSTO product we developed. However, their IT department is concerned wether they should trust this sofware. Mainly, they are worried it could expose a security breach into their system.</p>

<p>We are a small company, with very little reputation.
Our apps are signed via en EV Code certificate. What are the other steps we could take to help convince these gate keepers? We were thinking of certifying our software, for example we are aware of the <a href=""https://msdn.microsoft.com/en-us/windows/desktop/mt186449"" rel=""nofollow noreferrer"">Windows Application Certification Kit</a>, but as far as we understand it does not apply to VSTOs?</p>

<p>Hope this is the right place for this question.</p>
","329035","","","","","2019-10-11 13:14:13","Application certification for Microsoft Office VSTO solutions","<security>","2","0","","","","CC BY-SA 4.0"
"183880","1","183889","","2013-01-16 21:34:03","","-1","754","<p>I'm trying to educate myself on potential web attacks.  I just found a site (which will rename anonymous) where it shows me what looks to be like the php session id inside the cookies section of the request header. 
My immediate reaction was ""wow, that's bad""... but then i couldn't really come up with a scenario as to how someone could use this to mess up the site. 
But maybe its because I'm a newbie to this stuff. 
But assuming that I got someone else's session id... I'd have to hack the site with their session id before it expires right? </p>

<p>So my question is, how real is this threat? 
And is this common, where web developers store session ids in cookies, thereby making it visible in F12? 
Sorry for the remedial questions.
I read the article: 
<a href=""https://softwareengineering.stackexchange.com/questions/146692/why-popular-websites-store-very-complicated-session-related-data-in-cookies-a"">Why do popular websites store very complicated session-related data in cookies -- and what does it all mean?</a></p>

<p>And i get that sometimes, you want to use cookies to move data off server to client... but I think I need more clarification on how serious a security breach this is.</p>
","78102","","-1","","2017-04-12 07:31:29","2013-01-17 10:34:34","should F12's request headers show session id as cookie?","<security><session><cookies>","2","1","","","","CC BY-SA 3.0"
"400077","1","","","2019-10-24 11:10:41","","24","5760","<p>I work for a publishing company and we are making interactive software that accompanies our books. The problem is that many clients complain that the antivirus keeps deleting parts of the software, especially the .exe files.</p>

<p>Which is the best way to avoid this? By digitally signing the software? (I don't know if that's the correct term, or maybe it's called licensing). Are there companies who provide such a thing?</p>
","349453","","167942","","2019-10-25 06:57:36","2019-10-25 09:17:36","How to protect software from being deleted by antivirus?","<code-security><software-distribution>","3","7","","2019-10-25 14:39:14","","CC BY-SA 4.0"
"400106","1","400109","","2019-10-24 20:39:53","","1","36","<p>In the context of many devices being secured with their own symmetric key (think: thousands of <a href=""https://en.wikipedia.org/wiki/Internet_of_things"" rel=""nofollow noreferrer"">IoT</a> devices), is it reasonable to hold these secret keys in a MySQL database?</p>

<p>The goal is to verify the authenticity of devices; I'd like to hear from people with experience in security what their thoughts are.</p>
","23693","","","","","2019-10-24 21:17:28","Storage of Per-Device Keys in Database?","<database><security><iot>","1","0","","","","CC BY-SA 4.0"
"400155","1","","","2019-10-25 16:52:09","","1","212","<p>I read that Facebook's continuous integration environments are <a href=""https://engineering.fb.com/web/yarn-a-new-package-manager-for-javascript/"" rel=""nofollow noreferrer"">cut off from the internet for security and reliability reasons</a>.</p>

<p>What would these reasons be? Is this a common practice?</p>
","274828","","","","","2019-10-25 18:25:43","Why would you cut off your continuous integration system from the internet?","<security><continuous-integration>","3","3","","","","CC BY-SA 4.0"
"184436","1","184439","","2013-01-22 10:33:02","","3","96","<p>So after one has programmed and integrated a licensing solution into his or her application, how should one deal with licensing errors?</p>

<p>My understanding is:
Show whether a license is valid or invalid - and report if the license server is not reachable. Nothing more, nothing less.</p>

<p>Licenses could be invalid due to a variety of reasons: Invalid Machine-Code, maximum number of activations reached, invalid licensed version...</p>

<p>But should we report them to the user or just tell him ""okay"", ""not okay"" or ""license server not reachable""?</p>

<p>I don't know if this is the right place to ask, maybe security.stackexchange.com is more suitable, but that could be true for ux.stackexchange.com, too... So I'm asking it here.</p>
","69081","","","","","2013-01-22 11:26:20","Reveal detailed license-errors?","<licensing><security><user-experience>","1","0","","","","CC BY-SA 3.0"
"400327","1","400328","","2019-10-30 08:13:16","","2","74","<p>I have my backend endpoint for registering and logging in the users delivered trough RestApi or GraphQL to be more specific. </p>

<p>I want to implement role based system for my users.</p>

<p>The admins and moderators can be created on the admin module for example:</p>

<pre><code>{
  username: peter,
  passowrd: peter123,
  role: 'admin'
}
</code></pre>

<p>But the regular users that can be created on my application will send the same input but instead of the 'admin' the role <code>'user'</code> would be send.</p>

<p>I was thinking about this approach and was wondering if it's secure ? </p>

<p>Can users change the request object and change the role to admin, and then have super user access ?</p>

<p>Is there some best practices about this, or is this completely safe ?</p>
","349863","","","","","2019-10-30 08:37:28","Role based authentication/authorization security","<security><authentication>","1","0","","","","CC BY-SA 4.0"
"184902","1","","","2013-01-26 01:31:55","","0","231","<p><em>I'm asking this here and not on the security related site because this one is a question about ""software architecture"" and ""development methodologies"", which are both covered by the FAQ.</em></p>

<p><strong>EDIT</strong>: I'm talking about purely remote root / admin software exploits.  Not about insider physically breaking into labs / companies / houses / networks / machines.</p>

<p>Everytime there's a blog entry or article about a new security exploit there are lots and lots of people basically writing that: <em>""No software shall ever be secure, every single software out there can be exploited. Give any pirate sufficient time and he'll eventually exploit any high-target software.""</em>  This is a constant. These type of comments always get modded like crazy and most people seems to accept it as a fact.</p>

<p>And it really gets me wondering: can any software architecture and development methodologies be used to ever come up with secure software or is there something technical that prevents us from writing secure systems/programs/OSes/servers?</p>

<p>The more I think about it, the more I don't understand why we couldn't, technically, build 100% secure software.  All the way down from the OS and then up: browsers, plugins...</p>

<p>Note that I'm not interested in a discussion here: I want to know if technically there is something or not that can prevent, say, an OS, to be written in a 100% secure way and why it's that way.</p>

<p>Now if there's nothing technically that prevents us from writing a 100% secure OS and from then writing a 100% secure server, why hasn't it been done?  Does it means our architecture and development methodologies (and tools?) are deeply flawed?</p>
","39479","","39479","","2013-01-26 13:31:39","2013-01-26 14:43:32","Are security exploits a fatality?","<architecture><security><development-methodologies>","4","5","","2013-01-26 17:17:43","","CC BY-SA 3.0"
"185081","1","","","2013-01-28 16:43:29","","6","2406","<p>There are plenty of compilers and REPL services on the web. For example: <a href=""http://ide.fay-lang.org/"" rel=""noreferrer"">Fay ide</a>.</p>

<p>I find that implementing some similar technology would be very interesting. But it seems like a major security hole. Am I wrong in thinking that exposing a compiler would be risky? An interpreter seems even worse.</p>

<p><strong>update:</strong> I can be a bit more specific. The kind service I'm thinking about hosting myself (a thought experiment at this stage) would be kind of close to the case of the Fay ide above. You take input from the user, process it and return it, potentially as runable javascript to the same or other users. Let's look at that example in particular.</p>

<p>The most obvious security concern that I see for this case, as I don't actually evaluate the code server side, would be for the users, as they would run code made by an 'unknown' author. The fact that they are allowed to read the code before running it should be a significant safeguard in this regard.</p>

<p>Although I also wonder if and when translation of code constitute a threat to the server? What kind of exploit vectors could be thought of in this context?</p>

<p><strong>Summary:</strong> </p>

<ol>
<li>Beyond what you can expect from any web server set up, and beyond the most obvious concerns (or perhaps some of those obvious concerns as well), how could one user compromise another?
-. How can the server application be hardened to ensure not being compromised?</li>
<li>What important questions have I neglected? ;)</li>
<li>I would like to try some experiments, and I have nearlyfreespeech in mind as a host. I could imagine that such use might be prohibited by their terms of use? Or perhaps I can trust them to be sure enough that they have sandboxed my account well enough. What should be my ""minimum"" safeguards, for trying stuff out and what safeguards would be possible with such limited hosting environment?</li>
</ol>

<p><strong>update2:</strong> I believe that compiling to javascript for client side evaluation or evaluating limited edsls would cover for most/all use cases I have in mind. I take it that this means that I really don't put the server side to a more prominent risk than <em>usual</em>. And I don't see how the user is being put into more risk than compared to going to a random link on jsFiddle.</p>
","79270","","79270","","2013-01-28 22:38:00","2013-01-28 22:38:00","Online compilers and repls - not one big security hole?","<security><compiler>","1","5","","","","CC BY-SA 3.0"
"400987","1","","","2019-11-12 22:29:34","","1","197","<p>I s it possible to develop a distributed memory pointer in C++ by using operator overload? </p>

<p>The idea would be that you pass ip address and port to the overloaded pointer *, &amp;, and the pointer returns the memory location of remote computer.</p>
","350845","","209774","","2019-11-13 07:49:16","2019-11-13 08:03:25","Develop a distributed pointer in C++","<security><distributed-computing><smart-pointer>","2","2","","","","CC BY-SA 4.0"
"302269","1","302270","","2015-11-10 23:37:27","","1","318","<p>My site allows users to create custom HTML templates for their profiles (very much like Tumblr and the theme system), and I picked the Twig template engine for the site. </p>

<p>However, I'm not sure if it's a good idea to give users the control of being able to access a template engine. </p>

<p>Is this a bad thing? How should I restrict access, or should I just totally rethink the strategy?</p>
","92848","","52929","","2015-11-10 23:51:16","2015-11-10 23:51:16","Is opening a templating engine to users a bad idea?","<security><templates><code-security><server-security>","1","0","","","","CC BY-SA 3.0"
"302307","1","302326","","2015-11-11 09:54:28","","-3","105","<p>I've wrote a standalone java SE software which executes, for example, the features A, B and C.</p>

<p>Now, i want to that, if a lock is enabled (and this lock is a command sent remotely by my backend), the feature C has not to be longer available for execution by the user.</p>

<p>This lock has to be persistent, so, it has to survive to a device reboot, for example.</p>

<p>Another requirement is that has to be secure, so, it cannot to be just a file nor an entry on a local DB nor anything that could be manipulable by an expert user.</p>

<p>What is the best solution for develop something like that?</p>
","203660","","31260","","2015-11-11 09:57:23","2015-11-11 14:45:24","Manage lock of a software feature","<java><programming-practices><security>","1","4","","2015-11-11 15:13:10","","CC BY-SA 3.0"
"401051","1","","","2019-11-13 21:32:31","","-3","71","<p>My question is simple: What steps should you take to protect research from the vast amount of spyware or insecure applications on a given device?</p>

<p><strong>Background:</strong></p>

<p>I do research into developing new models for machine learning applications. Security of this research is of high importance. This is because developing a new model can be a difficult, time consuming task. However once a new model is understood, all of the coding necessary to leverage the research is often trivial. So it can be stolen very easily.</p>

<p>It seems very possible that data mining could be used to identify researchers. After which spyware (which may well already be on a device) can be used to steal research.</p>

<p><strong>My Solution so far:</strong></p>

<p>I've been doing all of my testing on a newly wiped system that is entirely not connected nor ever connected to the internet (network card removed)</p>

<p>Other than that, I have encrypted all of the source as well as the entire hard drive separately using 7zip.</p>

<p>I'm not sure if this is enough. </p>
","350921","","350921","","2019-11-13 22:05:43","2019-11-13 22:40:02","Protecting research source from spyware/data mining","<security><source-code><development-environment><encryption><data-mining>","1","8","","","","CC BY-SA 4.0"
"401444","1","401454","","2019-11-22 09:02:32","","2","1438","<p>We currently have REST API, where you have a set of different resources, like:</p>

<pre><code>GET /cats
GET /cats/{catId}
GET /dogs
</code></pre>

<p>Clients decide whether they can perform an action based on resource permissions. To query those the client calls:</p>

<pre><code>GET /cats/{catId}/permissions
</code></pre>

<p>And gets back a list like ""deleteCat"", ""sellCat"", ""initiateCatMating"" etc., so its more complicated than read, write etc, i.e. calling OPTIONS is not working.</p>

<p>Now when the client gets let's say 100 cats, it has to call the permission endpoint 100 times. Resources are related, so the number of permission calls virtually explodes, to the amount of slowing the UI down when working with big lists.</p>

<p>I was thinking whether it would be a good/acceptable practice to include the permissions in all resources, like:</p>

<pre><code>cat: {
name:string
permissions:[string]
}
</code></pre>

<p>This way the client will always know what it can do with the resource. Unfortunatelly I could not find any guidance on this, so this approach is either wrong or people just implement it as they like and don't care to ask questions. All I found were some ABAC references, which totally make sense, but solve I think only how the server can handle access easier. I want the client to know if it may call POST/cats/{catId}/matingPartner/{cat2Id} by knowing it has e.g. ""initiateCatMating"" permission for both cats, and if it doesn't than the ""Choose mating partner"" button should not appear in the UI.</p>

<p>Any opinions and links are appreciated.</p>
","351542","","","","","2019-11-24 07:33:48","REST API include permissions into resource","<rest><api><security><permissions>","4","6","","","","CC BY-SA 4.0"
"302820","1","302826","","2015-11-17 15:49:15","","2","571","<p>There are these relevant questions questions:</p>

<ul>
<li><a href=""https://softwareengineering.stackexchange.com/q/205606/33"">Strategy for keeping secret info such as API keys out of source control?</a></li>
<li><a href=""https://stackoverflow.com/q/6009/344286"">How do you deal with configuration files in source control?</a></li>
<li><a href=""https://stackoverflow.com/q/1974886/344286"">How to version control config files pragmatically?</a></li>
</ul>

<p>But as far as I can tell, they deal with the opposite side of the problem. So yes, we've designed a good application that has no secrets stored in it or its repository. They either pull them from the environment variables or from files stored on the system. Great, awesome, secure, right?</p>

<p><em>But what about our secrets</em>? Where do they come from? Do we store these in another vcs repository? Do they only exist in an encrypted database?</p>

<p>Obviously we want developers to have their own credential sets - but we're going to need to have credentials for our test/preprod/prod servers.</p>

<p>How do we keep those secure? Of course we want them accessible to the systems that need them...</p>
","33","","-1","","2017-05-23 12:40:22","2015-11-17 16:46:29","Where should you store/how should you control access to application secrets?","<security><configuration>","2","0","","","","CC BY-SA 3.0"
"302889","1","","","2015-11-18 08:26:13","","1","168","<p>What is the optimal architecture for such case:</p>

<ol>
<li>Web application(.Net Web Forms) connects to third party web service via wcf.</li>
<li>Third party web service accepts only digitally signed soap requests</li>
<li>Some typical business processes consist of several soap requests. </li>
<li>User must start business process (send several soap requests) via web application and digitally sign it in the front-end by its certificate (smart-card holding its certificate). Web application doesn't store any user certificates, it only stores user data that must be sent to web service.</li>
</ol>

<p>My current thoughts are to create some proxy web service that would intercept user soap requests without digital signatures and put them into database. Then user would open some web form where he would see all requests that he must digitally sign. User signs requests via some web browser plugin. As the result of that operation web application gets digitally signed requests that it can send to original web service.</p>

<p>There is some problem with this realization though - it doesn't consider any if's logic and it can't use results gained from previous requests. The process of information exchange between web application and web service must be straightforward since user sends requests to fake proxy web service that can't return real data and results. So we would send data as-is hoping that there would be no results that our process of informational exchange would depend on. </p>

<p>Another option is to digitally sign all requests to web service in real-time. But I can't get how to do it in WCF. I can use IClientMessageInspector and intercept message before it would be sent to web service. In theory I can make some callback at this moment to frontend and wait for user to digitally sign request and then replace original request to user's one. But current realization of web application doesn't allow any callbacks to front end in WCF.</p>

<p>Any thoughts would be highly appreciated.</p>
","102175","","","","","2015-11-19 12:41:55","Architecture supporting digitally signing of tons of soap requests","<architecture><security><xml><wcf>","2","10","","2015-11-19 19:32:14","","CC BY-SA 3.0"
"303018","1","303020","","2015-11-19 16:09:15","","33","4733","<p>We have a few givens:  </p>

<ol>
<li>Developers need a replica of the production database on their machines.  </li>
<li>Developers have the password to said database in the App.config files.  </li>
<li>We don't want the data in said database compromised.</li>
</ol>

<p>A few suggested solutions and their drawbacks:  </p>

<ol>
<li>Full-disk-encryption. This solves all problems, but degrades the laptop's performance, and we are a start-up, so don't have money for powerhorses.  </li>
<li>Creating a VM with encrypted hard disk, and store the database on it. It works well, but it doesn't help too much, since there's a password in Web.Config.  </li>
<li>Solution number 2 + requiring the developer to type the database password every time he runs anything. It solves all problems, but it is really cumbersome for developers that sometimes fire up the application multiple times a minute. Also, we have multiple applications that connect to the same database, and implementation of a password screen will have to differ in each.</li>
</ol>

<p>So, my question is, if there's any common solution to such problem, or any suggestions on how to make any of the above solutions workable?</p>
","204707","","31260","","2015-11-21 06:02:06","2015-11-24 22:09:25","What is a good security practice for storing a critical database on developer's laptops?","<database><security>","6","16","","","","CC BY-SA 3.0"
"186136","1","186143","","2013-02-06 17:23:55","","5","141","<p>One of my company's applications still requires a hardware key to run, but we're currently in the process of removing that requirement and replacing it with an online check.  The issue we are having is that we allow our customers to set up test systems with copies of their live databases.  With the hardware keys, that isn't a problem as they get a special key that tells the software it is a test, but we're trying to figure a way to do this with a software only check.  Our only idea so far is to check the hardware against a registered list in the database, but before we implement this, I want to ask how others have solved similar problems?</p>
","8340","","","","","2013-02-06 18:14:20","Hardware key removal on a test system","<security><development-methodologies><hardware>","1","0","","","","CC BY-SA 3.0"
"186427","1","186429","","2013-02-08 19:32:23","","4","472","<p>I am currently working on a project that makes use of the OpenSSL library for secure communications. Since this library is a requirement for building the project, I am considering including it in the project's repository. Here are the pros and cons as I see them:</p>

<p><strong>Pros:</strong></p>

<ul>
<li>Self-contained build - with one exception, everything needed for building the project is contained in the repository. It would be nice if the user didn't need to go through the trouble of installing and configuring the development headers / libraries for OpenSSL.</li>
</ul>

<p><strong>Cons:</strong></p>

<ul>
<li>Security concerns - it goes without saying that the only version of OpenSSL that anyone should be using is always the latest. As soon as a new release is issued, I will need to update the version of OpenSSL in the project's repository.</li>
</ul>

<p>So the question boils down to this:</p>

<blockquote>
  <p>Is it wise to include a security library with the project that we need to <em>always</em> ensure gets updated whenever a new release is issued?</p>
</blockquote>
","231","","60357","","2017-10-26 17:41:44","2017-10-26 17:41:44","Is it wise to include something like OpenSSL or GnuTLS with a project in a repository?","<version-control><security><dependency-management><software-updates><build-system>","1","1","","","","CC BY-SA 3.0"
"186535","1","186572","","2013-02-10 04:53:50","","3","6313","<p>If a server certificate is published to Github, a la:</p>

<pre><code>-----BEGIN CERTIFICATE-----
</code></pre>

<p>is that necessarily a bad thing? Is there ever a legitimate reason to do this?</p>

<p>I ask because of a <a href=""https://github.com/blog/1390-secrets-in-the-code"" rel=""nofollow"">recent wave of attention</a> Github has gotten since allowing users to search for certain things as <code>.ssh/id.rsa</code> and the like in public repositories.</p>

<p>Also, server certificates are involved in the <code>https</code> protocol, but honestly I'm having trouble determining if they are generally regarded as sensitive information.</p>
","40984","","","","","2013-02-10 16:13:33","Committing https certificates to Github...is there ever a good reason for this?","<security><github><certificate><https>","2","0","","","","CC BY-SA 3.0"
"402045","1","","","2019-12-04 12:53:15","","0","68","<p><strong>Hello,</strong></p>

<p>I want to secure access to a POST request so that the user cannot forge it via software such as postman.</p>

<p>Letâ€™s say a player plays a game and gets a score. At the end of the game, the score is sent to the server through an API via a POST request. I want to be sure that this POST request was sent by the application and not by the user otherwise he could quite modify his score by simply making a POST request.</p>

<p>Currently I use JWT Token to authenticate the user.</p>

<p>I can not really stored secret in the application knowing that it is easily possible to get the source code of an apk file.</p>

<p>My stack:</p>

<ul>
<li>API PHP with Lumen</li>
<li>Flutter</li>
</ul>

<p>In your opinion, what is the best solution to secure this exchange?</p>
","352336","","","","","2019-12-05 02:28:52","Check that a POST request is the origin of the application and not of a user","<api-design><security>","1","1","","","","CC BY-SA 4.0"
"402127","1","","","2019-12-05 18:06:19","","0","55","<p>I have a use case like this and I am wondering if this solution is a good practice or not.</p>

<p>Say I have a website called <code>dashboard.com</code> and this is only for <code>US region</code>. When users login here, I am storing their session into <code>USRedis</code> instance. However this dashboard has two buttons named <code>USWebApp</code> and <code>EUWebApp</code>. </p>

<p>Assume that this is the UI for <code>dashboard.com</code> (pardon for text based UI). The doted elements indicate html buttons. So I have two buttons named <code>USWebApp</code> and <code>EUWebApp</code></p>

<pre><code>http://www.dashboard.com

----------    ----------
|USWebApp|    |EUWebApp|
----------    ----------
</code></pre>

<p>Once user is logged into <code>dashboard.com</code> and clicks <code>USWebApp</code>, I pass the session cookie to <code>USWebApp</code> and <code>USWebApp</code> calls <code>USRedis</code> to validate the session. If session is not valid, then we redirect the user back to <code>dashboard.com</code> (and user logs in again by typing credentials). </p>

<p>On the contrary, user can click <code>EUWebApp</code>. Again I am passing <code>dashboard.com</code>'s session cookie to <code>EUWebApp</code>. However <code>EUWebApp</code> checks <code>EURedis</code> to validate this session. However when user logged into <code>dashboard.com</code> I only persisted their session to <code>USRedis</code>. So when <code>EUWebApp</code> tries to validate this session by looking in <code>EURedis</code>, it won't find the session since I never wrote to <code>EURedis</code> when user logged into <code>dashboard.com</code> (main site) in the first place to begin with.</p>

<p>Two solutions that I can think to solve this</p>

<p>1) <code>EUWebApp</code> should talk to <strong>only</strong> <code>USRedis</code>, to validate the session instead of talking to <code>EURedis</code> or</p>

<p>2) when user logs into <code>dashboard.com</code> I should store their session in both <code>USRedis</code> and <code>EURedis</code>. Therefore <code>USWebApp</code> can use <code>USRedis</code> while <code>EUWebApp</code> can use <code>EURedis</code> to validate the user session.</p>

<p>What do you guys think about this? Especially the 2nd approach? Is that a good practice? </p>

<p>Apart from these two approaches, do you know any other solutions for my architecture?</p>

<p><strong>More information in case interested:</strong> (not really needed for this question)
I am building a main site and integrating with a SAML IDP(Identity provider). Think of dashboard.com as your company's main page where you have access to multiple apps like word, splunk, teams, etc. </p>
","352457","","","","","2019-12-05 18:06:19","Is it a good practice to store session in two different places?","<security><spring><session><redis><saml>","0","8","","","","CC BY-SA 4.0"
"186714","1","","","2013-02-11 21:23:38","","0","275","<p>I have a silverlight app that connects to a entity framework over WCF ria service. </p>

<p>These calls have to be secure. What can I do so only valid users can call the ria service, and to make the call secure?</p>

<p>The user has to log in to get to the silverlight app, so maybe that login in some way can be saved for authentication of the ria calls?</p>
","67607","","31260","","2013-03-13 21:46:51","2013-04-12 22:02:04","Ria service security","<security><wcf><silverlight><ria>","1","0","","","","CC BY-SA 3.0"
"402161","1","402162","","2019-12-06 14:28:18","","3","107","<p>Is it possible to have a scenario where there are 3 email addresses. Each on a different mail server.</p>

<ul>
<li>alice@contoso.com</li>
<li>bob@fabrikam.com</li>
<li>charlie@treyresearch.net</li>
</ul>

<p>Charlie writes an email with Alice and Bob listed as recepients. Charlie uses a rogue SMTP server <code>treyresearch.net</code> that only carries out the SMTP transaction with Alice on the <code>contoso.com</code> server while listing Bob as a recepient but does not carry out the SMTP transaction with the SMTP server for <code>fabrikam.com</code>.</p>

<p>Alice belives that Bob is aware of the content in the email whereas he certainly is not.</p>

<hr>

<p>Is this a possible scenario with SMTP and are there any measures to prevent this?</p>
","352517","","","","","2019-12-06 14:53:56","Is it possible to spoof a recipient in a SMTP transaction? If not how does SMTP prevent this from happening?","<security><data-integrity><smtp>","1","0","","","","CC BY-SA 4.0"
"402547","1","","","2019-12-16 08:45:49","","0","131","<p>I came up with an model to reduce DoS and DDoS attacks and would like your input on its effectiveness...
<a href=""https://i.stack.imgur.com/PX6ql.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/PX6ql.png"" alt=""enter image description here""></a></p>

<p>Basically, once a request reaches our servers without having a valid key, we add a key as a query parameter of the url, then return a redirect response to the client with the same url but with a valid key. </p>

<p>Then we can use this key to throttle the requests instead of using an IP Address.</p>

<p>I understand that the attacker might still make millions of new requests to the server, but redirecting the client should be fairly lighter than say downloading a video or large file.</p>

<h3>What do you think?</h3>
","312229","","","","","2019-12-17 00:19:13","How to reduce DoS and DDoS attacks in an authenticated web server","<architecture><web-servers><server-security><rate-limiting>","1","4","","","","CC BY-SA 4.0"
"402720","1","","","2019-12-19 14:34:47","","-1","218","<p>I am creating a Discord Bot in Discord.Net. So first, of course this bot is not a professional project, but I still want it to look as professional as possible. And a huge part is the storage and process of user data. Sure, I won't get data like Credit Card info, private adress or workplace. I just want a user account, where you can personalize the bot for your server. So all the data I may have are a username, a hashed password and an e-mail (I'm still drawing a concept. Not sure if I need a mail, or use Discord for Authentication). But nevertheless, I want to secure that data, like it's really valuable.</p>

<p>So my first idea was to safe the data into an SQLite-Database, which I already use for the Bot itself (Things like Money, or Userlists are stored there). But you cannot properly secure such a database, it's not SQL. Another idea was something like a single encrypted file, where all the data is stored. but that can get messy and eat storage really easily.</p>

<p>Also, even if I would store it into the SQLite-Database, I still could see everything. The password may be encrypted, but username and e-mail won't be.
As I said, it may not be a big thing, but I also write this bot to learn things for future projects, and safe data storage is really important.</p>

<p>How can I save data like username+password or e-mail adress, while making sure that the data is unlikely to be exposed to anyone, including me? And also important, how can I process this data (I'm using C# for the bot), cause that's what data is for.</p>
","353417","","25476","","2019-12-19 17:41:54","2019-12-19 17:41:54","How can I securely store and process user data?","<c#><security><data>","1","3","","","","CC BY-SA 4.0"
"402742","1","","","2019-12-19 22:39:42","","19","7001","<p>When our in-house developed application (C#, ASP.NET) is throwing an exception, it displays a stack trace that contains path information like <code>C:\users\DEVELOPER_FULL_NAME\path\some-module.cs</code>. So it shows the full name of the developer who compiled it. </p>

<p>The developers are telling me, this is unavoidable. I find this hard to believe.  I am no professional C# programmer, but working in IT, I have been programming (from Pascal to Assembler to C), so I think that my understanding should be fair enough. </p>

<p>So, how do you hide developer related personal information from the stack trace? Compile with a anonymous user on a dedicated machine? Is there a possibility to strip this information using a compile time switch or anything like that?</p>
","353444","","33533","","2020-01-02 09:18:05","2021-02-28 11:02:46","How can we avoid showing the literal path in the exception's stack trace?","<c#><.net><compiler><builds><code-security>","5","8","","","","CC BY-SA 4.0"
"187658","1","","","2013-02-20 03:06:37","","4","2448","<p>I work on a open-source web application (<a href=""http://moodle.org"" rel=""nofollow"">Moodle</a>) which connects to a number of external services such as Google Drive, Dropbox etc. to allow users to exchange files with these services. </p>

<p>Primarily we are using OAuth based APIs to connect with these services. One of the <em>user interaction</em> problems we are facing is that our users do not expect that after they login to an external service that they stay logged into it. That sounds silly, but the scenario is this:</p>

<ol>
<li>User wants to get a file from their Google Drive account</li>
<li>Moodle requests an oauth2 token from Google to browse google drive</li>
<li>User is not logged into Google, so needs to login to Google</li>
<li>Moodle gets token and user carries on their business in Moodle</li>
<li>User logs out of Moodle and does not expect they are still logged into Google</li>
</ol>

<p>My <em>programmer viewpoint</em> is that the browser session is completely the responsibility of user and that our application should not get involved. But we hear from our users about this misconception all the time. Its particularly a problem because our application is often used in shared environments.</p>

<p>Is there a good pattern for dealing with this problem which other applications use?</p>
","81960","","","","","2013-02-20 03:06:37","Connecting with OAuth, dealing with logout and browser sessions","<web-development><security><session><oauth>","0","2","","","","CC BY-SA 3.0"
"304829","1","","","2015-12-11 14:33:49","","3","114","<p>I am working with a system that is using NoSQL (Azure Table Storage) primarily to house its data. Unfortunately, the work also involves billing and medical records - meaning the data itself will need to be protected. That's fine, we can provide user access to the system, and encrypt that data over the wire and at rest in the NoSQL.</p>

<p>The problem comes because we want that data to also be <em>searchable</em>. Unecrypted, that's not a problem so much - we make the searchable fields row keys and can do range queries. Encrypted, that won't work. Worse it seems as though any sort of trie or similar structure would need to be stored unencrypted, defeating the purpose. Storing partial strings encrypted would make it easy to break the encryption since we would be leaking information about the cleartext.</p>

<p>So far, the only semi-viable solutions I've run across are 1) stop using NoSQL or 2) read the entire set into memory and do the search there.</p>

<p>Neither are particularly thrilling. Is there any other good approach for this confluence of requirements?</p>
","51654","","209774","","2018-07-19 20:17:21","2018-07-19 20:17:21","PHI, NoSQL, and searching","<security><nosql><search><trie>","1","5","","","","CC BY-SA 3.0"
"402918","1","","","2019-12-25 02:37:35","","3","49","<p>When creating new skills/apps for a voice assistant such as Google Home or Amazon Echo, are there any established patterns for providing an extra level of security for certain actions that go beyond just a PIN or password?</p>

<p>Here's an example: let's say your skill/app allows you to call a cab. So you'd say something like ""Alexa, call me a cab"". Now, if there's no additional security at all, anyone in proximity of your voice assistant could call a cab in your name - not ideal.</p>

<p>A fixed PIN or password can provide some level of security: ""Alexa, call me a cab!"" - ""Sure thing, what's the PIN?"" - ""It's 1234!""</p>

<p>Unfortunately, if you do this frequently, someone will eventually overhear your PIN or password. Could be your malicious neighbor, or simply your mischievous kids. So that's still vulnerable.</p>

<p>What I would imagine to be more secure would be some sort of <a href=""https://en.wikipedia.org/wiki/Challenge%E2%80%93response_authentication"" rel=""nofollow noreferrer"">Challengeâ€“response authentication</a> protocol that's easy enough for humans to implement in their head - something like: ""Alexa, call me a cab!"" - ""Ok, security check: my challenge is 72, what is your response?"" - ""It's 10."" </p>

<p>The tricky part here is that computing the response would have to be very easy- most humans, of course, won't be able to compute a cryptographic hash function in their head. But something straightforward such as ""add 7 to the challenge"" would probably be good enough to prevent your toddler from calling a cab on your behalf. Once they're in elementary school, you'd have to switch to something a little bit more sophisticated like ""add hour of the day and day of the month"".</p>

<p>Are there any established pattern for this?</p>
","76839","","","","","2019-12-25 05:15:44","Securing a voice assistant skill/app - any established patterns?","<security><authentication>","1","0","","","","CC BY-SA 4.0"
"304931","1","304933","","2015-12-12 19:45:35","","-6","44","<p>I have an app and it stores data in shared preferences which can be easily changed using something like root explorer. So, how can I keep settings and be sure that user won't be able to edit them even with root access? </p>
","207451","","31260","","2015-12-12 21:36:50","2015-12-12 21:36:50","Protect settings on rooted device","<security><android>","1","1","","2015-12-13 01:37:19","","CC BY-SA 3.0"
"187947","1","187952","","2013-02-21 21:38:14","","7","4303","<p>I got closed on SO and told to post this here as it's about general application design as opposed to specific code.</p>

<h2>Intro</h2>

<p>I'm currently working on a project which involves the daily extraction of data (pharmacy records) from a VisualFox Pro database, and uploading some of it to a WordPress site, where clients of the pharmacy can securely view it. I would like some advice in terms of the general methodology of my software - I am able to code it, but need to know if I'm going the right way about it. I'm writing both the PC software (in C#/.NET 4.5) and the PHP WordPress plugin. (It doesn't matter much that it's in WordPress, the actual code for this will pretty much run separately).</p>

<h2>Question 1: Encryption</h2>

<p>The current process for encrypting the data server-side I plan to use is based on <a href=""http://i.amniels.com/mysql-database-encryption-using-public-private-keys"" rel=""noreferrer"">this article</a>. Summarised, it advocates encrypting each separate user's data asymmetrically with their own public key, stored on the server. The private key to decrypt this data is then itself encrypted symmetrically using the user's password, and stored. This way, even if the database is stolen, the user's password hash needs to be broken, and even then the process needs to be repeated for every user's data.</p>

<p>The only weakness, pointed out by the author himself, and the main point of my question, is the fact that while the user is logged in, the decrypted key is stored in session storage. The way the article suggests to deal with it is to just limit the time the user is logged in. I thought a better solution would be to store that key in a short-lived secure cookie (of course the whole process is happening over HTTPS). That way, if the attacker has control of the user's computer and can read their cookies, they can probably just keylog their password and log in, no need to steal the database, while even if the attacker gains access to the server, they cannot decrypt the HTTPS traffic (or can they? I'm not sure.)</p>

<p><strong>Should I use secure cookies or session storage to temporarily store the decrypted key?</strong></p>

<h2>Question 2: Storage</h2>

<p>The second thing I still want to work out is how to store the data - this is more of an efficiency problem. Since every user has their own key for encryption, it follows that records for every user must be stored separately. I don't know if I should store a ""block"" of data for every user, containing encrypted JSON with an array of objects representing records, or whether I should store records in a table with the actual data structure, and encrypt each data field separately with the key.</p>

<p>I am leaning towards storing the data as one block - it seems to me to be more efficient to decrypt one big block of data at a time, than perhaps several thousands separate fields. Also, even if I stored the data in its proper structure, I still wouldn't be able to use MySQL's WHERE, ORDERBY etc, since the data would all be BLOBs.</p>

<p><strong>Should I store the data as a big block per user, or separated into the different fields?</strong></p>

<h2>Question 3: Transfer</h2>

<p>I extract the data from the DBF file, and essentially make a ""diff"", whereby I compare the current extracted data from the last day's data, and only upload the blocks of the users that have changed (I can't only upload the records, as I probably will end up storing the users' data in blocks). I also include ""delete"" instructions for users which have been deleted. This is as there are hundreds of thousands records in the database, totalling over 200mb, and the size increases every day.</p>

<p>My current plan is to write all this data to a JSON file, gzip it and upload it to the server. My question is, how do I do that while ensuring the security of the data? Naturally, the upload will happen over HTTPS, and I have an API password in place to only allow authorised uploads, but my main concern is how to protect the data if the server is compromised. I don't want the attacker to just grab the JSON file from the server while it's being processed. One idea I had was to get the server to send me a list of public keys for the users, and perform the encryption in my software, before the upload. It seems to me like that's the only way of protecting that data. I could encrypt the whole JSON file, perhaps with an API key or a special password, but that's moot if the attacker can just access the decrypted file as it's being processed on the server. Is that a good solution?</p>

<p><strong>Should I encrypt the data individually client-side, or is there a way to securely transfer it to the server and encrypt it there?</strong></p>

<p>Thanks in advance for any answers, I'd love to hear from someone who's dealt with problems like this before.</p>

<p>Matt</p>

<p><strong>EDIT: I'm pretty decided on 1 and 2 - thanks @Morons. I'll use secure cookies and store data in blocks. My main question is now question 3, would love to get some input on that.</strong></p>
","82145","","82145","","2013-02-21 22:48:12","2013-02-22 00:31:57","I need advice developing a sensitive data transfer/storage/encryption system","<c#><php><security><mysql><encryption>","2","6","","","","CC BY-SA 3.0"
"188056","1","188058","","2013-02-22 16:13:23","","1","318","<p>It seems like when web site lists requirements as to what characters MUST be in the password they're only providing a password map for someone who wants to hack their system.</p>

<p>For instance, fsd.gov requires:</p>

<pre><code>The password must be 10-14 characters in length.

The password must contain two each of the following:

Upper/lower case letters, numbers, and special characters.

An example of an acceptable password is:  AAbb1234!@
</code></pre>

<p>Congrats!  If I wanted to hack your password, now I know that trying to guess ""aaaaaaaaa"" will be wrong, you've given me clues as to what I can guess and helped narrow it down.</p>

<p>It seems to me like it's more open and more possible combinations if they didn't require special characters.  Then if you included one your account is now more secure.</p>

<p><em>Note - As you've probably guessed, I'm not a pro at security, which is why I posted here.</em></p>
","9348","","","","","2013-02-22 19:33:42","Why do web sites require certain characters in their credentials?","<security><encryption><passwords>","4","4","0","2013-02-22 17:27:40","","CC BY-SA 3.0"
"403228","1","","","2020-01-03 04:03:52","","20","7987","<p>I am making a full-stack web application for a professor. At his request, the passwords and usernames are generated programmatically, and they cannot be changed or reset by the students. (If you forget your password, you ask the professor, who can look it up.) Does this tightly-controlled system eliminate the need to do all of the normal best practices with regard to storing passwords in a database? </p>

<p>In case it's relevant, the app does not contain any association or identifiers between the student's identifying information (name, gender, etc.) and their username and password. </p>

<hr>

<p>EDIT 1: Thank you for the many responses. This is very helpful to me as I didn't take the traditional route to this career and have some holes in my knowledge that probably seem fundamental to you. Here are a few points of clarification:</p>

<ul>
<li>I am a freelancer on my first-ever freelancing project, and the client/customer is a  professor. I am not his student, and this is not an assignment. </li>
<li>My task is to replace an existing application that is very old and for which the source code is lost.</li>
<li>The application is used in a class taught by several professors in different schools in the US. Much of the content is just static, like a textbook. However you can also take some questionnaires/instruments developed by the professors to get insight into the topic of the course relative to a real-world example of your choosing (i.e., the information you supply is not about yourself or other people). </li>
<li>My original goals in having username/passwords was to identify users so that I could enforce expiration of access to the content, and also control permissions. Permissions matter because in addition to students, there is the concept of administrator users (who have a dashboard where they can view lists of username/passwords they have created, and create more) and a super-admin (who in addition to what admins can do, can create other admin users).</li>
<li>The primary reason I started down the path of username and login is because that is what the old app had. But, the old app stored (lots!) of student information. The professor in charge now does not want to go afoul of <a href=""https://www2.ed.gov/policy/gen/guid/fpco/ferpa/index.html"" rel=""nofollow noreferrer"">FERPA</a> laws so he has changed the requirements there.</li>
<li>A professor can create another username/password set and add it to the current class if needed. But they aren't forced to currently. (They can just give out the original password.) This was the professor's decision when I asked him if he wanted a ""reset password"" button on the list.</li>
</ul>
","241967","","241967","","2020-01-06 20:24:30","2020-01-06 20:24:30","Is this scenario an exception to the rule of never storing passwords in plaintext?","<security><authentication><passwords>","9","10","","","","CC BY-SA 4.0"
"403239","1","","","2020-01-03 10:19:36","","0","74","<p>I'm working with a project that uses ASP.NET Core 2.2. The main solution contains different projects, including APIs for a mobile application, APIs to integrate the system with third parties, a web application, etc. </p>

<ol>
<li>Mobile API - For internal application </li>
<li>Public API - To integrate our system with others </li>
<li>Web - Website</li>
</ol>

<p>We're using token-based authentication for mobile API project. However, to expose our Public APIs for third parties, we don't want to use token-based authentication, instead, we decided to use the key - secret. </p>

<p>But the issue is that another project <em>(integration to use our system internally)</em> has its registered users and they don't want to create an account in our system. I suspect that, in this case, key-secret things wouldn't work. We currently use api-key for every project(tenant), and they have to keep api-key for their users. However, this could create security issues if we expose API endpoints publicly.</p>

<p>Along with this, we'd like to track request per user too.</p>

<p>What type of authentication solves this problem? and how can we handle such a scenario?  </p>
","241751","","241751","","2020-01-03 10:28:31","2020-01-03 10:28:31","Which authentication should be used for external users (not registered with the system)","<security><authentication><web-api><asp.net-core>","0","11","","","","CC BY-SA 4.0"
"305200","1","305217","","2015-12-16 05:29:03","","3","316","<p>Currently, I have this hybrid mobile application which talks to my C# web service to do CRUD transactions. As the mobile application is always on the go, and there might not have internet connectivity in all situations.</p>

<p>Therefore, I'm thinking of using SMS transactions in offline mode.</p>

<p>For Login:</p>

<ol>
<li>Using sms, communicate to server to request for access token.</li>
<li>Token generated and sent using SMS to registered user phone number</li>
<li>User then enter the OTP within 5mins of validity</li>
<li>App will then communicate with server with the OTP, once verified, user will go into a special user interface for offline access instead.</li>
</ol>

<p>For Transactions:</p>

<ol>
<li>Phone sends a sms to the 3G Dongle (Unique Session Token, UserID, Type Of Transaction, Transaction Details)</li>
<li>SMS server received sms message</li>
<li>Application which handles sms message, stores message received in a message queue</li>
<li>Application will dequeue message queue and process the oldest message first</li>
</ol>

<p>There are a few questions in which I would love to have some pointers in:</p>

<ol>
<li>How do I maintain a unique session using SMS? (Token?)</li>
<li>How do I maintain security? (As in the text message is of course, unreadable by humans, yet can't be duplicated and workable for that transaction only)</li>
</ol>

<p>I would be doing all of the above by own codes/libraries without using external cloud/web services as it's more for an internal corporation project.</p>

<p>Update:</p>

<p>I'm thinking of using 'counters', where my text message body would have a counter inside it. </p>

<p>For example:
App Counter: 1 Server Counter: 0</p>

<p>1.App sends a transaction request.(App counter: 1)</p>

<p>2.Server decrypts and checks counter. (Since 1 > 0, allow request and increment server counter to 1)</p>

<p>In this case, even there is an duplicate text message sent by user, the message will not process as the counter is now 1. (1 > 1 will return false). </p>

<p><strong>Apart from multiple users accessing the same account and messing up the counters</strong>, what concerns should I take note of?</p>
","207794","","207794","","2015-12-17 01:06:02","2022-03-11 21:13:10","Using SMS as transaction in offline situations","<architecture><security><sms>","1","0","","","","CC BY-SA 3.0"
"305210","1","305213","","2015-12-16 07:52:14","","1","192","<p>I made a login system with access rights (ASP.NET WebForm) and I store the info's in a database table. I don't use the built in feature of asp.net like Forms authentication and webconfig. My question is, am I doing good?</p>

<p>I check from the database table if a certain user has access to a certain web page and if not I redirect him to another page/ error page informing him/her access denied.</p>

<p>Please let me hear your opinion/advise suggestion if I am doing alright or I should use the built in feature of ASP.NET Forms Authentication.</p>
","205099","","31260","","2015-12-16 08:50:13","2015-12-16 08:54:58","Access rights through database table","<c#><security><asp.net><login>","1","0","","","","CC BY-SA 3.0"
"403438","1","403439","","2020-01-06 23:39:20","","1","113","<p>I'm ingesting 150 objects that each require an user capabilities check, the function <code>isUserAdmin</code> tells me whether or not an user is an admin or not. Inside this function, there's a lot of deeper checks and so on. It'd be really, really nice if I could cache this stuff so I don't have to check for 150 objects.</p>

<p>I'd like to, before anything loads, determine who the user is and set up things that in practice, don't change -- <strong>or do they?</strong> Assume a super admin changes the privileges of an admin user mid-request but I've already set his privilege information, so, assume this <code>admin</code> has the capability to delete other users, he's running a request to do that, but during that time, the <code>superadmin</code> says ""nope, can't do that anymore"", but because on that request I already set that user's permissions, this will not take effect and the <code>admin</code> will still be able to delete users.</p>

<p>What's the fix here? Setting information pre-emptively is basically dangerous in an async-by-proxy environment (which everything is) but not doing this makes me perform the same check 150 times in a row.</p>

<p>I feel like this is a chicken &amp; egg problem and every time I'm faced with such issue, I'm not seeing a vital angle. What am I missing?</p>
","353781","","","","","2020-01-11 07:14:55","How can I store an user's capabilities to boost performance while allowing real-time updates of said capabilities?","<security><session><identity>","4","3","","","","CC BY-SA 4.0"
"305422","1","","","2015-12-18 23:56:38","","-2","293","<p>I'm currently in the process of setting up roles where there are regular users, admins, and super admins, each of which have special permissions. I deferred to this <a href=""https://stackoverflow.com/a/19766233/3046413"">post</a> on how to do so. </p>

<p>It basically comes down to either setting up a few tables in addition to the <code>User</code> table: <code>Roles</code> (second table), <code>UserRoles</code> (join table) or creating boolean attributes for the <code>User</code> model: <code>admin</code> and <code>super_admin</code>. While I'm capable of doing both what should I keep in mind in keeping my app secure? Is one better than the other? Explain.</p>

<p>I ask this because as the the second <a href=""https://stackoverflow.com/a/19765918/3046413"">answer</a> of the SO post states:</p>

<blockquote>
  <p>It really depends on what you wish to do with your admin role. The
  first option, I would say is a bit secure as the admin role is a
  unique model in itself.</p>
  
  <p>The second option is straightforward and would help you get going with
  the least effort. However, if your users figure out the boolean
  variable and a way to set it, any user can become an admin and access
  areas you don't want them to.</p>
</blockquote>

<p>Before coming to this conclusion I wanted to get a second opinion on the matter.</p>
","121757","","-1","","2017-05-23 12:40:18","2015-12-19 07:30:05","Tables vs. Booleans: Which of the two are more secure for setting admin roles in an app?","<database><security><ruby-on-rails><permissions><boolean>","2","4","","2015-12-28 22:59:34","","CC BY-SA 3.0"
"305723","1","305725","","2015-12-23 13:49:51","","4","318","<p>When FaceBook or Google give me an API key, are they just storing it in a database? </p>

<p>Unlike a password, where you can hash and salt it before putting it in the database, it seems to me that a key needs to be stored as-is (or else in a reversible form) so that they can provide it to me upon request.</p>

<p>My concern is with storing immediately usable information in my databases.</p>

<p>I understand that the exact method these companies use is only speculation, unless you are a past employee or have unique insider information, but I'm wondering if there is a most commonly accepted best-practice.</p>
","208530","","","","","2015-12-23 13:58:14","How do large corporations store API keys?","<security><mysql><keys>","1","0","","","","CC BY-SA 3.0"
"403745","1","","","2020-01-13 18:33:08","","-1","828","<p>I have seen numerous posts on this subject but none really answered my questions.</p>

<p>I have some user input that is inserted into my DB and displayed back to the user later. Before inserting it into the DB I validate the input. When I need to display it back to the user I have been using two different methods.</p>

<p>The first is using <code>preg_replace()</code>. With this I can do things like remove all non alphanumeric characters. The second method is to use <code>filter_var()</code> with an option like <code>FILTER_SANITIZE_STRING</code>, which will strip tags and encode special characters. </p>

<p>What I havent been able to find is which I <em>should</em> be using and of course, why.</p>
","352360","","","","","2020-12-26 23:05:10","PHP preg_replace() vs filter_var()","<php><security>","2","3","","","","CC BY-SA 4.0"
"404013","1","","","2020-01-20 02:59:54","","-1","67","<p>I'm trying to understand how separation of duties works between various job functions as a security measure. For starters, there are computer (hardware) operations, applications programs, and systems programs.</p>

<p>From what I understand, computer operators are supposed to be confined to hardware and hard data. They are not supposed to have anything to do with systems programming or applications programming, because of potential conflicts of interest. I follow this so far.</p>

<p>Likewise, the access of applications programmers are supposed to be limited to applications programs. They are not supposed to have anything to do with the systems programs that control their programs, or with the hard data or hardware. Again, this seems to follow.</p>

<p>The ""symmetry"" is broken with systems programmers. They are supposed to work with systems, and understandably, are not supposed to have access to applications programs. But my understanding is that they are allowed to have access to the hard data and hardware, when the other two types of personnel aren't allowed outside their areas. Why might this be?</p>

<p>I'm also confused about the roles of two more agents, systems and administrators and systems analysts. Maybe the problem is that I'm getting hung up on the job titles.</p>

<p>Systems administrators are ""keepers of the seal"" such as providing access abd passwords to the systems. Yet, they are not supposed to have access to the systems, only to applications. Is their function actually an ""applications"" function, despite their job titles?</p>

<p>Ditto for systems analysts, who oversee and work with applications programmers, and in this regard, are ""applications"" people who have access to applications. But they're not supposed to have access to systems, despite their job titles.</p>

<p><strong>Clarification:</strong> In answer to a comment, the question can be restated as follows (in two parts). 1) Why are systems programmers allowed to go outside of systems, (to hardware) when applications programmers and hardware people are expected to stick to issues connected with their departments? 2) why do systems administrators and systems analysts appear have the same scope as ""applications"" programmers when the term ""systems"" is in their job titles?</p>
","35693","","35693","","2020-01-20 04:42:21","2020-01-20 12:01:15","How does separation of duties work between the kinds of workers described below?","<security>","1","2","","","","CC BY-SA 4.0"
"189202","1","189205","","2013-03-04 19:26:35","","109","9452","<p>I've been hired by someone to do some small work on a site. It's a site for a large company. It contains very sensitive data, so security is very important. Upon analyzing the code, I've noticed it's filled with security holes - read, lots of PHP files throwing user get/post input directly into mysql requests and system commands. </p>

<p>The problem is, the person who made the site for him is a programmer with family and children who depend on that job. I can't just say: ""your site is a script kiddie amusement park. Let me redo it for you and you'll be fine."" </p>

<p>What would you do in this situation?</p>

<h2>Update:</h2>

<p>I followed some good advice here and politely reported to the developer that I've found some possible security flaws on the site. I pointed out the line and said there could be a possible vulnerability for SQL injection attacks there, and asked if he knew about it. He replied: <em>""sure, but I think that to exploit it the attacker should have information on the structure of the database; I have to understand better""</em>. </p>

<h2>Update 2:</h2>

<p>I said that's not always the case and suggested he follows this Stack Overflow question link in order to deal with it properly: <a href=""https://stackoverflow.com/questions/60174/how-to-prevent-sql-injection-in-php"">How to prevent SQL injection in PHP?</a> He said he would study it and thanked me for telling him before. I guess my part is done, thanks guys.</p>
","54384","","-1","","2017-05-23 12:40:17","2015-05-24 20:39:17","You're hired to fix a small bug for a security-intensive site. Looking at the code, it's filled with security holes. What do you do?","<php><security><sql-injection>","7","14","","2015-05-24 22:16:45","","CC BY-SA 3.0"
"189455","1","189460","","2013-03-06 12:42:41","","86","46134","<p>I have a website e-mail form. I use a custom CAPTCHA to prevent spam from robots. Despite this, I still get spam.  </p>

<p>Why? How do robots beat the CAPTCHA? Do they use some kind of advanced OCR or just get the solution from where it is stored?  </p>

<p>How can I prevent this? Should I change to another type of CAPTCHA?</p>

<hr>

<p><sub>I am sure the e-mails are coming from the form, because it is sent from my email-sender that serves the form messages. Also the letter style is the same. <br><br> For the record, I am using PHP + MySQL, but I'm not searching for a solution to this problem. I was interested in the general situation how the robots beat these technologies. I just told this situation as an example, so you can understand better what I'm asking about.</sub></p>
","58357","","31260","","2013-03-07 13:43:35","2017-06-22 14:15:56","How can robots beat CAPTCHAs?","<security><captcha>","7","24","","","","CC BY-SA 3.0"
"189499","1","189503","","2013-03-06 16:57:36","","4","1873","<p>It has just dawned on me, that a system I am developing exposes a users username in the URI. This is a problem, since some of the users pages are public. Therefore people will know their username.</p>

<p>I thought that this would be a security issue, but then realised that big names like twitter do the same thing. Pretty much every single twitter user has their username on full display.</p>

<p>If a big name like twitter see it as safe, should I also assume the same?</p>
","74944","","","","","2014-11-09 18:57:45","Using a public username as a login username","<web-applications><security><login>","1","1","","","","CC BY-SA 3.0"
"404450","1","404456","","2020-01-30 06:21:04","","4","3140","<p>I'm wondering whether it is bad practice to keep a user's ID in a JWT.</p>

<p>I'm planning on using the email in the <code>sub</code>, since it's already available to them, and I can use it to identify them, all the same. I can let the DB index it so it's easier to retrieve their information using the email rather than the ID.</p>

<p>Isn't it better to avoid giving the user any information regarding how the DB is referencing them, as in the ID? My concern is that I don't know why everyone is fine with using the ID stored in the DB in a JWT, since it can be easily avoided. Isn't there a scenario where it's not a good idea to give them their DB stored ID? The more vague the information, or already available information the user has about themselves, the better, right?</p>
","163998","","","","","2020-01-30 09:46:54","Why is it fine to use a user's ID in their JWT, as opposed to their email/username?","<security><authentication><jwt>","1","1","","","","CC BY-SA 4.0"
"404781","1","405830","","2020-02-06 09:11:37","","2","229","<p>I have an application which uses lambda and fargate (task) containers for compute, EventBridge for communication, S3 and DynamoDB for storage and exposes data out via an API Gateway.  </p>

<p>From my reading I can see that I can use PrivateLink or similar to expose each of these services into a VPC. However, all the documentation seems to suggest this is useful for accessing EC2 and RDS instances which <em>live</em> in the VPC. Is there any advantage to routing the communications for my services (Lambda,S3,DynamoDB etc) through a VPC when none of them really <em>live</em> in the VPC or is it just adding an unnecessary level of complexity to the application?</p>

<p>Thanks</p>
","356817","","","","","2020-02-27 13:21:04","Does putting a serverless application in a VPC make it more secure?","<architecture><security><aws><lambda>","1","0","","","","CC BY-SA 4.0"
"307060","1","307067","","2016-01-11 03:32:21","","2","998","<p>I have a question about storing encrypted passwords in your database to help secure them. I have a class that encrypts the password passed in and returns a string. This string has 3 parts too it, all separated by a colon. The first part is the iteration, the 2nd part of it is the salt, and the third part of it is the encrypted password. Ex: ""1000:{salt}:{encrypted password}"". </p>

<p>My question is how am I suppose to store this? As of right now, I am storing the entire string in my database under the password column. Then when I go to check the passwords for a login, I retrieve that record, and I have a method in my class that parses it and verifies that the two passwords match. Is this a big 'no no?' I've read where some people store the salt in it's own column then pull that down when verifying a login. However, this class that I am using for the encryption will return a string like I showed above. Then it came with a method that I can just pass that entire string into it and it will parse it up and verify the passwords as a login. </p>

<p>I guess what I'm asking is, do I need to re-construct my class to separate the string (""{iteration}:{salt}:{encrypted password}""), or is storing that entire string in the database OK?</p>
","186568","","5099","","2016-01-11 08:19:13","2016-04-05 12:56:15","ASP.NET storing encrypted & salted Password","<security><asp.net><hashing>","2","8","","","","CC BY-SA 3.0"
"190192","1","","","2013-03-11 23:19:56","","3","137","<p>I have an AdWords script that regularly transfers sensitive data to my server using a POST HTTP request. For security I have a predefined 32 character randomized string that is verified by my server before it accepts the data. <strong>Is this secure?</strong></p>

<p>I don't know too much about the HTTP protocol, but I know that the data is being sent unencrypted. Is it probable/possible for somebody to access the data during the request? From what I've understood, the HTTPS protocol is most useful when on an untrusted network where it's easy for anybody to spy on your packets. In my case, data is being sent from Google's servers to my host's servers (DreamHost in this case). Would it be prudent of me to upgrade to HTTPS, or would this be pointless? Are there any other security pitfalls I should be aware of?</p>

<p>I will accept the first answer that clears up my situation.</p>
","23240","","1996","","2013-03-11 23:55:55","2013-03-11 23:55:55","Is a predefined key enough security when performing HTTP requests between two secure servers?","<security><server><http><google-app-engine><https>","3","1","","","","CC BY-SA 3.0"
"307221","1","307337","","2016-01-12 20:39:01","","3","1006","<p>In this very simplistic but realistic scenario, I have <strong>2 combo web/database servers (A)</strong> behind a load balancer and a single IP address. They also permit access only from one IP address -- <strong>the client (B)</strong>. On each database server, we need to store <strong>read-only secret identity information (like email address, username, etc.)</strong>. </p>

<p><strong>I need a solution that prevents a hacker who may have compromised server (A) from being able to do anything with the data unless they also gain access to server (B).</strong></p>

<p>I need a strategy where client server (B) uses a public key from a private/public API key pair to find a match for this identity information (like an email address) on server (A), and then, without server (A) evaluating that result, return the result back to (B) for evaluation using its private key. <em>The theory being that if the hacker gets root level access to server (A), they can't do anything with it to decode the data, not even with brute-force attacks on md5(), sha1(), sha256(), or against any hashing algorithm.</em></p>

<p><strong>Here's a strategy that won't work, as an example.</strong> Imagine you have PHP's libsodium (a common public/private key system). You use it to encrypt the data and store it on (A). Then, when (B) wants to do a lookup, they send in the public key, it gets mated with the private key on (A), a hash is generated, and that hash is checked against a hash in the database. (So, you find if hashed email request matches a hashed email address in the database.) The problem with this strategy is that if server (A) is compromised for root-level access, all the attacker has to do is intercept the web traffic to find the public key from (B), combine it with the private key from (A) in the PHP server scripts, and then use that information to run a powerful brute-force script to break the hash so that the entire database can be decrypted. This brute-force attack has been used to break md5() and sha1(), but can be used to break even someone's sha256 or other hash API. </p>

<p><strong>Right, so that won't work.</strong> <em>It would be better if there was some way that the result of the match can't be interpreted on server (A) and must be sent back to server (B) for final evaluation, which then requires server (B)'s private key to decrypt the result.</em></p>

<p><strong>Using PHP</strong>, can you explain a programmer API key strategy where a compromised data store will yield no useful information to a hacker unless he has the private key of that programmer's public/private key pair?</p>
","25887","","25887","","2016-01-13 07:36:02","2016-01-13 21:55:23","Strategy for Public / Private API, Encrypted (or Hashed) Data, and Server Compromise","<php><security><api-design><hashing><encryption>","1","4","","","","CC BY-SA 3.0"
"307357","1","","","2016-01-14 03:38:58","","1","49","<p><strong>Problem Description</strong></p>

<hr>

<p>I am working on an enterprise data discovery project that is designed to scan databases for sensitive information. The basic search unit is called a classifier and covers things like 'Social Security Number', 'LastName', 'Driver's License', 'Credit Card Number', etc.</p>

<p>Currently, each classifier is an independent item with its own regex pattern, so a search for 'Driver's License' will yield matches for any pattern that matches the format ^[A-Z]\d{3}-\d{4}-\d{4}$. </p>

<p>We want to reduce false positives from this approach by leveraging data from related classifiers. For instance, if both my last name and driver's license number appear in the same record, I should be able to verify that the first letter of my last name matches the first character of the driver's license number instead of only relying on the regex pattern.</p>

<p>Here's another example: suppose I am searching for 'Zip Codes' on a database and a scan marks the following records as matches:</p>

<pre><code>FirstName LastName 123 Fake Street City, Illinois 61234
012345678 01234567 012345678 987654321 1234556 61234
</code></pre>

<p>I'd like to assign a higher confidence rating to the first match, because it is located near related classifiers like 'Street Address' and 'State' while the second match is probably a false positive from a stream of unrelated digits.</p>

<hr>

<p>What kind of problem domain is involved here and what existing algorithms apply? I've looked through articles on record linkage, semantic matching, information extraction, and other things, but I can't seem to find research on the exact idea I'm explaining.</p>
","211024","","161917","","2016-01-14 14:24:41","2016-01-14 14:24:41","Correlating Search Classifiers in a Database Scan for Sensitive Information","<java><database><security><regular-expressions><mainframe>","0","1","","","","CC BY-SA 3.0"
"405039","1","","","2020-02-12 08:49:48","","2","1214","<p>TL;DR How do you build an airtight license control system for your onprem application, which revokes access once subscription ends?</p>

<hr/> 

<p><strong>Premise</strong></p>

<p>I am building this application in Python that needs to be deployed on premise of the client. This application runs constantly like a service spewing out stats. This application is based on a subscription model.</p>

<hr/> 

<p><strong>Considerations</strong></p>

<ol>
<li>Ensuring the IP is intact as the application resides on the client.

<ul>
<li>Achieving this by building a binary using Cython</li>
</ul></li>
<li>When subscription ends the application should not run. 

<ul>
<li>Thinking of using HOTP(HMAC based OTP) so each client will have a seed baked into the executable. HOTP uses a seed and time to generate a symmetric key. So for every time slot say 1 month, a new key should be given to the executable. </li>
</ul></li>
</ol>

<hr/> 

<p><strong>Questions</strong></p>

<ol>
<li>Is there a better way to achieve this?</li>
<li>How can the application keep time in tamper-proof way? (As OS time is not reliable). <br/> <em>Or</em><br/> How do I store the count of time slots in a secure way such that it cannot be hacked?</li>
<li>As this is a service that is always running, how do I enforce a check at the end of a time slot like 1 month? Also as the application is on-prem, it can be shut down.</li>
</ol>

<p>One ugly way is encrypting and storing an timer.txt which is constantly updated by a separate python process. Is there a better way?</p>

<hr/> 

<p><strong>The above is with consideration of no-internet.</strong></p>

<p>But even if internet exists, it does not guarantee a fool-proof solution, because the network can be monitored and calls to an API can be redirected to a local service with the same name. Does this mean there should be two-way SSL here? </p>
","357288","","209774","","2020-02-12 12:50:25","2020-03-13 22:00:45","License control for an on-premise application","<licensing><security><access-control><projects-and-solutions><obfuscation>","1","6","","","","CC BY-SA 4.0"
"405140","1","","","2020-02-13 21:41:44","","1","59","<p>So, I have an API that authenticates with Identity Server OAuth2 and gives our user a JWT token when logging in through a front end application, this is a token that has access to everything.</p>

<p>The API is also external facing so that third parties could access the API using client id + secret via OAuth2, this token is a lot more restricted to scope and limits.</p>

<p>The problem I'm facing is that I can easily grab hold of the token from logging in via the UI and use it to directly access the API, which has no limits.</p>

<hr>

<p>I've done some searching around on best practices and many references to using server side cookies stored as HttpOnly, or encrypting the token with a key only the application knows but I wanted to ask the question in case someone has hit an issue like this before and knew a better solution?</p>
","357440","","","","","2020-02-14 22:02:03","Identity Server 4 Authentication - Security questions around using the same API for internal application and third parties","<api><security><jwt>","1","0","","","","CC BY-SA 4.0"
"405369","1","","","2020-02-17 23:25:44","","0","105","<p>SETUP:
Local Windows 10 machine. It runs a VM (Ubuntu Server, NAT, Virtualbox)</p>

<p>QUESTION:
I want to make a VNC connection from my Local machine to the VM. Since VNC is not a secure protocol, it is recommended to make the connection through an SSH tunnel. However, since the VM is running on the same machine, I wonder if this is still necessary.</p>
","357733","","","","","2020-02-18 02:37:08","VNC security: SSH tunnel from local machine to VM necessary?","<security><virtual-machine>","1","1","","","","CC BY-SA 4.0"
"191003","1","191009","","2013-03-18 11:21:58","","21","63946","<p>I'm creating a piece of software, that will run on windows and will act like launcher for the game, to serve as an auto-updater and file verifier in client side PC.</p>

<p>One thing I don't understand, why my antivirus software (Avast) is considering my exe file as dangerous and won't start it without asking to put it into sandbox, for safe use.</p>

<p>Is there any rules that my software should obey, to be treated as good, or should I pay hundreds of dollars for some sort of digital signing and other stuff?</p>

<p>I'm using C# with MS Visual Studio 2010.</p>

<p><a href=""https://www.virustotal.com/en/file/8a2e38e78156d3d17d3a5162504dcc7029399dd975ab9b584193c0ecf03cb191/analysis/1363606704/"" rel=""noreferrer"">VirusTotal report</a>. No DLL injections, working as remote file downloader, using WebClient() class.</p>

<p>It is not like it warns about virus, but it ""suggests"" to sandbox it. Look at screenshot:<img src=""https://i.stack.imgur.com/Cp85Z.png"" alt=""enter image description here""></p>
","35316","","31260","","2016-12-20 17:25:37","2018-03-31 00:15:16","How to prevent my executable being treated from AV like bad or virus?","<c#><security><visual-studio-2010><software-updates>","2","15","","","","CC BY-SA 3.0"
"405528","1","","","2020-02-21 05:34:23","","4","297","<p>I'm not a low-level programmer, I mainly program in C# which is a managed language. Still, every now and then I read articles, news and patch notes about the most varied software talking about memory unsafety fixes, including a video (if I remember correctly about Rust and it's memory safety) in which the host says that Microsoft loses lots of money just paying people to fix memory unsafeties. It got me thinking what exactly does ""memory safety"" mean, what kind of code generates memory unsafety, how does scientists (or attackers) find them, how and to which extent can they exploit it and how do you fix the part of the code that has it? It would be very informative if someone could answer these questions with minimal code examples (preferably written in C).</p>
","339024","","","","","2020-02-29 03:32:14","How is memory unsafety generated, found, exploited and fixed?","<c><security><memory>","4","1","","","","CC BY-SA 4.0"
"308335","1","","","2016-01-25 20:56:16","","4","1382","<p>I am setting up a PostgreSQL database with a very small number of tables for a simple website.  I am looking at ways to make it as solid and auditable as possible.  Is there any particular reason why I should or should not create a PostgreSQL role for each user account on the website?  The idea is that I could then use row level permissions on tables containing personal or private information and queries would look something like like this:</p>

<pre class=""lang-sql prettyprint-override""><code>-- Service logs in with role mywebsite and runs:
BEGIN
SET LOCAL ROLE charlie; -- A user on the website
INSERT ...              -- DO STUFF
COMMIT;
</code></pre>

<p>Logging code would then know both the system account (mywebsite in the above example) used to log in to the database and also the user on whose behalf changes are being made (charlie).  The two are available in PostgreSQL as session_user (uid) and current_user (euid).</p>

<p>If you know of any precedents or any reasons why this would be a great or terrible idea I'd love to know.</p>
","210442","","","user40980","2016-01-26 13:59:38","2016-01-26 13:59:38","Postgres roles for website users","<web-development><web-applications><security><postgres>","1","3","","","","CC BY-SA 3.0"
"308354","1","","","2016-01-26 02:16:41","","4","165","<p>I have a web API that accepts <code>Authorization</code> headers to allow access. It responds with the requested data in addition to setting a session cookie. Subsequent requests can be made with no auth headers as the cookie is used in its stead.</p>

<p>Originally, no auth was handled on the node server. API requests were all made directly from browser. This made auth simple, as the client entered user/pass was sent directly in headers and received a session cookie in return.</p>

<p>Now, however, we would like to move towards doing initial payload rendering on the server. This will require both the Server and Client to be ""authorized"" with web API. What are some common approaches to doing this?</p>

<p>A couple of possibilities that occurred to me:</p>

<ul>
<li>Client auths with API as before, API sets cookie for future browser requests, client copies cookie to node server (which stores in session) for use in future server requests.</li>
<li>Client sends user/pass to node server, node server auths and stores cookie in session, all subsequent API calls run through node server.</li>
<li>Client sends user/pass to node server, client auths normally, node server auths normally.</li>
</ul>

<p>First option seems ideal (if possible). This is how I would imagine one would use an ""access token"". Is it possible to use cookies like this? Are there cross origin restrictions that pertain to cookies that I am overlooking? For instance, I know that this does not work the other way around (I cannot auth on server, put API cookie in response to browser, and have the client use that cookie for a different path (the web API instead of the node server).</p>

<p>Second option I really want to avoid as it seems like a lot of unnecessary traffic on the node server, a lot of boilerplate routes, and our web API is already very simple to use directly from browser. Performance wise, this also adds one additional stop. Ideally, the node server should be serving page requests and thats it.</p>

<p>Third option just seems kind of silly. It results in the same user being authed in multiple places, which the web API may or may not like (I didn't design it nor do I know its inner working). We are also sending username password over the wire twice (which logically seems less secure than once).</p>

<p>Any other suggestions are welcome!</p>
","212718","","212718","","2016-01-26 02:56:41","2016-01-26 02:56:41","Client Browser, Node Server, Web API auth structure","<security><authentication>","0","0","","","","CC BY-SA 3.0"
"191623","1","191628","","2013-03-22 21:01:46","","36","23136","<p>I have a project where I need to allow users to run arbitrary, untrusted python code (<a href=""http://www.datamech.com/devan/trypython/trypython.py"">a bit like this</a>) against my server. I'm fairly new to python and I'd like to avoid making any mistakes that introduce security holes or other vulnerabilities into the system. Are there any best-practices available, recommended reading, or other pointers you can give me make my service usable but not abusable? </p>

<p>Here's what I've considered so far:</p>

<ul>
<li>Remove <code>__builtins__</code> from the <code>exec</code> context to prohibit use of potentially dangerous packages like <code>os</code>. Users will only be able to use packages I provide to them.</li>
<li>Use threads to enforce a reasonable timeout.</li>
<li>I'd like to limit the total amount of memory that can be allocated within the <code>exec</code> context, but I'm not sure if it's even possible.</li>
</ul>

<p>There are some alternatives to a straight <code>exec</code>, but I'm not sure which of these would be helpful here:</p>

<ul>
<li>Using an <code>ast.NodeVisitor</code> to catch any attempt to access unsafe objects. But what objects should I prohibit?</li>
<li>Searching for any double-underscores in the input. (less graceful than the above option).</li>
<li>Using <code>PyPy</code> or something similar to sandbox the code.</li>
</ul>

<p><em>NOTE:</em> I'm aware that there is <a href=""http://repl.it/"">at least one</a> JavaScript-based interpreter. That will not work in my scenario.</p>
","81884","","81884","","2013-03-22 22:13:31","2017-08-06 11:03:40","Best practices for execution of untrusted code","<python><security><web-services>","4","7","","","","CC BY-SA 3.0"
"308499","1","308505","","2016-01-27 11:41:40","","4","276","<p><strong>Background:</strong> The company I work for uses different systems to hold their insurance data which is customer related. They want to have an app for their customers where they can find their insurance related things in. Some of these systems provide web services to get the necessary information, so proper user authentication and whatsoever is possible. However, some provide direct database access without anything which comes even close to user authentication, because it was not designed to do that.</p>

<p>To solve this issue we are building an adapter-service, which can connect to all the different systems to get the necessary data. However the user-authentication is still an issue for the systems which don't provide that.</p>

<p>Another software engineer suggested (we are the only engineers) we build a general authentication mechanism which provides authentication to all the systems to get the necessary customer information. We both have the same background, we are young, we don't have that much experience in designing such a system or understanding all the security issues for such a system.</p>

<p><strong>Question:</strong> With the background as stated above, I am concerned about all the security concerns which may come up if we would do that. That for the serious kind of information (insurance data) we may lack the experience to set up a system like that, to ensure the best kind of security is possible and not limited by our knowledge (or Google). </p>

<ul>
<li>His opinion on this matter is that a general authentication mechanism should be build for all systems. So with one login on our side they can get all the data from the different systems if it is available there. If we follow up with things such as OAuth that we don't have to fear the security issue that much. And if we (re)search these things on the internet, that it will be OK.</li>
<li>My opinion on this matter is that a general authentication mechanism will be a good thing for all the systems which don't provide the necessarry things for user authentication (which is also possible the only solution). However we should not override systems which provide their own authentication to access their system to get the necessary data from a customer. Perhaps information can be exchanged between all the systems to ensure the same kind of login is  available everywhere (if user exists in a system which provides authentication and with a systems which uses the general authentication). If an password for example is changed. This idea would make sure if our general authentication mechanism is breached somehow, that not all the systems will be exposed to the attacker, and who knows what the consequences might be.    </li>
</ul>

<p><strong><em>Should we just go through with the idea to make a general authentication mechanism or limit it to the systems who need it and possible exchange login-details if the user should exist in the two different kind of systems (system which supports authentication or doesn't). What are good arguments for or against these ideas?</em></strong></p>

<p><strong>Edit:</strong> The general public would be using it, each system would provide the contract(s) with its data (if the customer exists in the different systems). Example: for customer '1' system A (database) and B (web-service) contains both different contracts from him. However, for customer '2' only system A (database) contains a contract. Depending on the customer their kind of contract(s) they are stored in different systems. All of these systems are third party.</p>
","212937","","212937","","2016-01-27 13:39:34","2016-01-27 16:20:39","Having an discussion about security concerns with another software engineer","<design><security>","2","2","","2016-02-02 14:12:59","","CC BY-SA 3.0"
"406020","1","","","2020-03-03 00:10:22","","3","235","<p>Software libraries targetting resource constrained environments like embedded systems use conditional compilation to allow consumers to shave space and thus increase performance by removing unused features from the final binaries distributed in production.</p>

<p>Assume that library developers produced the compiler flags and were a consideration at design and test phases of the library.</p>

<p>As most design decisions, there are tradeoffs, in this case the code complexity and product quality unarguably suffer due to the increased branches to design and test against.</p>

<p>However with regards to security, the net impact is not clear, there are both positive and negative effects from removing features. Initially, removing code reduces the surface of attack. But on the other hand, building a custom binary means that a bug, and thus exploit, might be present in that specific combination.</p>

<p>The implications differ from those of traditional runtime path complexity, not just because of the consideration of 2 different types of branching, but because compiler condition syntax is far unsafer than its runtime counterpart (at least in C).</p>

<p>An interesting phenomenon is that building a custom binary might expose the users to targetted attacks, but using a standard build might expose the users to mass exploits.</p>

<p>The question is, considering there are both positive and negative influences on security, if we were to quantify them, would the net impact be positive or negative? In other, less academic words, if one is concerned with security, should they build a custom binary without the features they need?</p>

<p>The specific example that sparked this question is Busybox heavy use of conditionally compiled feature flags. <a href=""https://git.busybox.net/busybox/tree/networking/httpd.c"" rel=""nofollow noreferrer"">https://git.busybox.net/busybox/tree/networking/httpd.c</a></p>
","249024","","249024","","2020-03-03 00:22:40","2020-03-03 15:29:39","Does removing unused features from libraries through compiler flags increase or reduce security risks?","<security><compiler><optimization><source-code><conditions>","2","5","","","","CC BY-SA 4.0"
"406048","1","","","2020-03-03 13:58:54","","2","511","<p>I'm building a multi-tenant system that consists of one (SPA) client, calling multiple API's, all under my control.</p>

<p>User authentication is done with OpenID Connect, I'm sending an ID and access token to the client, the client uses the access token to call the API's.</p>

<p>At this stage, the API's know they receive a request from an authenticated user, but they still need to know what that user can do, the Authorization part.</p>

<p>I would like to prevent the scenario where all my API's call a store where authorization data is persisted, it feels like a performance bottleneck, and would tightly couple all my API's.</p>

<p>I would like to keep my OpenID Connect server as decoupled from this specific project as possible, processing only the users's identity and API scope claims. Therefore, putting all authorization-related claims inside the access token seems like the wrong move.</p>

<p>I came up with the following solution:</p>

<ul>
<li><p>User navigates to SPA</p></li>
<li><p>SPA calls OpenID Connect server, gets an access token with identity info</p></li>
<li><p>SPA calls a custom API endpoint, specific for this project, lets call it 'user-info-api'</p></li>
<li><p>This API issues a custom JWT token, signed by cert or shared secret</p></li>
<li><p>This custom JWT token is appended on every subsequent API request, it contains all info needed to do user authorization in each API, therefore eliminating round trips to the authorization store. The only thing the API's need to do is to verify it's signature</p></li>
</ul>

<p>I would like a 2nd opinion on this approach for the following reasons:</p>

<ul>
<li>This seems a bit over-engineered</li>
<li>I'm worried about the increased payload this would bring to each http request.</li>
<li>I'm wondering if there are standardized approaches tackling this same issue</li>
</ul>
","358922","","","","","2020-03-04 12:57:38","Delegating authorization across multiple API's","<api-design><security><authentication><authorization><oauth2>","1","4","","","","CC BY-SA 4.0"
"406084","1","","","2020-03-04 10:05:49","","1","172","<p>I'm planning to setup a hybrid encryption procedure in my app. So basically i did encryption for data send from client to server using this method, now i'm confused on how to encrypt data send from server to client. So what i have done so for is that :</p>

<p>I generated a public-private key pair using an asymmetric encryption(RSA), saved the private key in server side and then shipped the public key with my app(client).Now when i need to send data to the server we generate a secret key and then encrypt our data with this secret key. Now we encrypt the secret key using the initially created public key(from asymmetric enc) and send this encrypted secret key and along with the encrypted data to server. Now the server can use its private key to decrypt the secret key and further use the decrypted secret key to decrypt the data</p>

<p>My question is that, how to encrypt the data from server to client using this method? should i create another asymmetric key pair for this, or is there a way to use the existing pair? I'm confused on decrypting part in client side since we can't save the private key in the app</p>
","282748","","","","","2020-03-04 10:05:49","How can i implement two way asymmetric encryption for my app and backend server?","<algorithms><security><encryption>","0","5","","","","CC BY-SA 4.0"
"406108","1","406113","","2020-03-04 17:50:10","","2","657","<p>I'm fairly new to web development and I have a bit of a weird question.</p>

<p>I'm currently working on a personal project that may or may not eventually become a real, commercialized product.</p>

<p>In my database, I have a ""user"" table that stores the user's information, including their username, encrypted password, first name, last, name, email address, etc.</p>

<p>Now, I've decided that the usernames will <em>always</em> be email addresses since the users won't be able to interact with each other (therefore, no sensitive data security issues). The problem is I have both an ""username"" and an ""email"" column. As of now, when the user create their account, they don't type in an username and an email. They type in an email, which gets passed into the two SQL columns.</p>

<p>Later on, they can change their username and email address separately and both could technically be different. I realize now that this might not be ideal and rewriting the parts of the code affected by this, changing the database structure, etc. is going to to take a little bit of work, which I'm 100% willing to do, but not sure yet if it's necessary at all, so that's why I'm asking this question here.</p>

<p>Could this situation be causing issues in the future, either terms of data management, security management or simply user experience?</p>
","359039","","","","","2020-03-04 20:33:41","Is it good or bad practice to use the user email in two separate columns of the user SQL table?","<database-design><security><user-experience>","3","0","","","","CC BY-SA 4.0"
"191910","1","193636","","2013-03-25 18:39:18","","1","122","<p>I am developing an Android application for my final year project which allows the holder of a mobile device to receive a text notification containing potentially sensitive information from a server.</p>

<p>My question is this, if a User downloads the application, what is a suitable way for them to create an account / log in on my server to receive notifications from it?</p>

<p>I was thinking:</p>

<p><strong>Application</strong></p>

<ul>
<li>Open application</li>
<li>Click Register</li>
<li>Fill out fields (Name / Address / ID / Phone no.)</li>
<li>Send to server</li>
<li>Display ""Account Pending""</li>
<li>If approved, send positive message, begin receiving notifications from server.</li>
<li>If denied, send negative message, if User tries to log in with that account, the App will inform them that it was rejected.</li>
</ul>

<p><strong>Server</strong></p>

<ul>
<li>Add received information to a ""Pending Account""</li>
<li>When an Admin comes online, they can review the information (How can they be sure the person is who they say they are?)</li>
<li>If the account is approved, the details are moved to a normal User account, otherwise moved to rejected accounts.</li>
</ul>

<p>I can't think of another solution which would fit this problem. If anybody knows of a patterns or design I appropriate to hear from you.</p>
","76419","","","","","2013-04-02 10:49:26","Creating an account to receive sensitive information on a mobile device","<design-patterns><security><user-interface><user-experience><verification>","1","0","","","","CC BY-SA 3.0"
"406257","1","406280","","2020-03-08 00:16:46","","2","267","<p>I want to build a REST API but I have some holes when it comes to the security part. I would like to get my head around how to authenticate the calls to the API.</p>

<p>Therefore, this is my first draft for how the process should be:</p>

<ol>
<li>User account is created</li>
<li>Token is automatically generated and stored in db, associated to that user</li>
<li>User calls <code>login</code> endpoint </li>
<li>Obtains their token as a response Token</li>
<li>The token is stored in the client side as long as the session lasts </li>
<li>The token is used to make the rest of the calls</li>
</ol>

<p>I have to admit I am not fully convinced about the idea of returning the token when <code>login</code> is called but I need your advice about whether this is a good idea or not. If not, please, give me some advice to approach this situation.</p>
","359059","","","","","2020-03-09 22:00:06","Securing REST API with authenticated user","<rest><api><security><authorization>","3","4","","","","CC BY-SA 4.0"
"406545","1","","","2020-03-14 12:41:32","","1","85","<p>I'm building a multiplayer game where anyone can add its own server but there is only one central server that contains the database where player information, like experience and gold, are stored. To authenticate as a game server and thus have authorization to give gold to a player, you join a JWT, issued by me, to your requests. However, whoever owning the server could use this token and boost up his own characters. My problem is how can I trust a game server request? To me, except by obfuscating the communication between a game server and the central one, there is not much to be done. But this problem reminds me of cryptocurrencies, would a blockchain help me here?
<a href=""https://i.stack.imgur.com/D6zyW.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/D6zyW.png"" alt=""enter image description here""></a></p>
","359644","","359644","","2020-03-14 13:08:09","2020-03-14 13:08:09","How to trust servers in a network where anyone can add its own","<architecture><security><blockchain>","0","6","","","","CC BY-SA 4.0"
"406566","1","406578","","2020-03-15 15:41:22","","-2","211","<p>So I've been an indie apps developer for 2 years (I launched my first Android app at the end of 2017), and I've built few apps since then, but all of them were simple apps. </p>

<p>Currently I'm planning my next project, and in this next app the user will store sensitive data in the app (It'll be a Calendar App), and I'm planning on storing the data outside user's device <em>(I'll probably use one of Firebase's services)</em> for backup purposes, and to sync data between different devices, <strong>so I'll need to encrypt and secure the data</strong>.</p>

<p>So I've been wondering <strong>is it required of an app developer to learn information security <em>(I literally don't have any experience or knowledge about information security)</em> or it'll be enough to use libraries made by other people for encryption purposes?</strong></p>
","359761","","","","","2020-03-17 13:14:45","Is it required for an app developer to know information security?","<security><mobile><self-improvement>","4","3","","","","CC BY-SA 4.0"
"193563","1","193584","","2013-04-01 16:30:48","","33","26288","<p>I am considering using sourceforge, bitbucket or github for managing source control for my business.  I have open projects and I participate in open projects such as gcc.  But I also have a business where I develop closed-source software for my living.</p>

<p>How trustworthy are sourceforge, github or bitbucket in terms of keeping software secure from prying eyes?  How stable is the hosting in terms of data loss prevention?  Has anyone out there based their business logic with such an outfit?  Has anyone out there surveyed several of the hosting solutions?</p>
","29882","","94074","","2015-06-11 17:52:15","2015-06-11 17:52:15","How safe & trustworthy are hosting sites such as sourceforge, github or bitbucket for closed-source projects?","<version-control><github><project-hosting><code-security><bitbucket>","8","2","","2015-06-13 20:24:08","","CC BY-SA 3.0"
"309220","1","","","2016-02-04 04:57:36","","3","109","<p>I want to store store some app specific secret on the phone - this should be available only for the app &amp; no other app.   </p>

<p>I was looking at DPAPI - however, if the user does not have a logon password, then it seems like the master key will be accessible to everyone. Also I am not clear what else to pass as the entropy parameter.</p>
","69796","","","","","2016-02-06 08:41:02","Windows Phone 8.1 & above - is there some equivalent for Apple's keychain","<security><encryption><windows-phone-8.1>","0","0","","","","CC BY-SA 3.0"
"406781","1","406787","","2020-03-20 06:55:38","","1","192","<p>I recall seeing a large email corporation discourage POP client access, suggesting it was insecure.</p>

<p>Assuming this is not FUD meant to encourage adoption of their client, I am wondering whether either of these may be true:</p>

<ol>
<li>This has a basis in truth in that POP is insecure without the proper extensions, but POP can be as secure as any other method by use of the right extensions/protocols.</li>
<li>There is something inherently defective as to security with the POP protocol even if the most secure extensions are used.</li>
</ol>

<p>Might someone be able to offer a high level introduction to what, if any, issues POP may suffer from?</p>
","21948","","","","","2020-03-24 09:24:08","Does POP suffer from any inherent security problems","<security><email>","2","4","","","","CC BY-SA 4.0"
"406810","1","","","2020-03-20 19:06:52","","2","169","<p>I have an Angular SPA and I spun up my own basic form-based authentication using a <code>.net core web API</code> and <code>SQL server</code> to store user accounts / hashed and salted credentials. This is obviously not an ideal way to handle auth and it was only meant to be temporary. I have since gotten a request to integrate Azure AD, SSO for organizations using the software already. Since I wanted to move in this direction anyways, I think this is the perfect opportunity to rethink my auth solution.</p>

<p>I drew up this plan:</p>

<p><a href=""https://i.stack.imgur.com/BufO3.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BufO3.png"" alt=""enter image description here""></a></p>

<p>As detailed, I want all user access to be handled through Microsoft accounts, and do away with my custom solution. Now, I still need a way to make sure that only accounts allowed by me have access to the software; I plan to do this in the orange layer above. Once a user signs into an account via the login.microsoftonline.com portal, I would then validate that the email address is associated with an account in my SQL database already. If not, I would not allow them access to the software / secure route. The SQL database account entries will be added by me manually.</p>

<p>I figured this was a great solution because it removes the need for me to store sensitive password / user information in my database. I would only be storing an some ID's (Email address, etc...) to Microsoft accounts that I allow in.</p>

<p><strong>So a few questions:</strong></p>

<ol>
<li>Is this a proper SSO solution?</li>
<li>Is there any apparent major flaws in handling things this way?</li>
<li>Should I use the email address in my SQL as the user identifier? or some
other ID given by Azure AD?</li>
</ol>
","338194","","338194","","2020-03-21 00:25:17","2020-03-21 00:25:17","Using Azure AD MSAL as only authentication solution for SPA","<security><authentication><azure>","0","0","","","","CC BY-SA 4.0"
"406933","1","","","2020-03-25 00:02:07","","3","379","<p>I am wondering how software with premium modes, such as Spotify, can operate offline. If a user is not connected to the internet, then they cannot authenticate via a remote server, which has e.g. a database of users and when their accounts expire. The only explanation I can think of is that the software locally stores the account's expiration date and encrypts this file when the user is online. But for this to work offline, the decryption key and method must also be stored locally rather than being retrieved from a server. In this case, it seems that authentication is only secured through obfuscation of the encryption method and key in the machine code. </p>

<p>Is the above the typical way that offline authentication is handled, or is there a better way of achieving this?</p>
","360357","","","","","2020-03-25 06:48:19","How does authentication work for offline software?","<security><authentication>","3","0","","","","CC BY-SA 4.0"
"309501","1","309503","","2016-02-07 11:02:47","","0","123","<p>I'm about to add some user account and password functionality to my software, so I'm reading about password hashing.</p>

<p>So my understanding is Hashing is a one way function, and it works like this:</p>

<ol>
<li>User Bob Types in password box: â€œMyPasswordâ€</li>
<li>Request Sent to server for Bobâ€™s Salt, and hash from database:
Hash: 8912ep98as89uasdp
Salt: 89asdjklasdo11jdsa</li>
<li>â€œMyPasswordâ€ + Salt is hashed using same function and compared to retrieved hash</li>
<li>If they match access is granted.</li>
<li>The hash is stored in application memory for future comparisons.</li>
</ol>

<p>Is that accurate? So that above has granted the user the ability to click around the application, but say my application is retrieving data from a server. I want things to be secure, so for each request from the service I pass along the authentication details (stored hash from step 5), and the service checks it against the database hash before returning a set of data.</p>

<p>Isn't knowing the hash kind of just as bad as knowing the password? If you found out the hash, you could use the service for nefarious means because all the password is used for is generating the hash, and the hash is used for all further authentication.</p>

<p><em>Edit,</em> for clarification, this isn't a web app. It's going to be a WPF application, probably using WCF service to talk to a server.</p>
","214367","","214367","","2016-02-07 12:59:16","2016-02-07 12:59:16","Question on password hashing security","<security><hashing>","1","5","","","","CC BY-SA 3.0"
"309512","1","309515","","2016-02-07 14:25:03","","3","11990","<p>Is providing a user login a non functional requirement?</p>

<p>Since this is concerned with security which is a non functional requirement, I feel that providing a user login is also non functional but again I feel that it is functional.</p>
","214451","","31260","","2016-02-07 14:26:44","2020-10-12 21:10:07","Is providing a user login a functional requirement of a system?","<security><requirements><login><functional-requirements>","4","1","","","","CC BY-SA 3.0"
"194045","1","","","2013-04-05 17:15:02","","14","18723","<p>I have this web application that is going to be all client-side technology (HTML, CSS, JavaScript/AngularJS, etc...).  This web application is going to be interacting with REST API in order to access and modify data.  Right now it is undecided on what type of authentication system the REST API is going to use.</p>

<p>From my understanding, any type of API authentication system (API Keys, OAuth 1/2, etc...) is going to have certain data that needs to be kept secret otherwise access can be compromised.  For API Keys, they keys themselves need to be secret, for OAuth 2 the client secret/access tokens/refresh tokens need to be kept secret, I am sure a few of the 4 keys involved in OAuth 1 needs to be kept secret (not too much experience with OAuth 1).  I have been trying to think if there is a way to store this secret stuff in a pure client-side web application without a middle layer of sorts on the server side.</p>

<p>I have been trying to think about this and I can't think of any place to do that.  I mean I can't store it in javascript because anyone can just view the source or open up the console and get the data.  I am not 100% sure how secure localStorage is and if users can access/modify that data.  Even if local storage was secure, the two ways I can think of getting data into it are not.  One way is to just store the data in the javascript source code which is the most insecure thing I can think of.  Now if I was using something like OAuth 2 in which the rest api itself would give me the tokens, that would still not be that secure (better than the first option) because those tokens would be returned as plain text that anyone who can see the requests the computer is making could see.</p>

<p>Is there any way to have an application that is completely running client side be able to store secret pieces of data securely without some sort of middle layer on the server side?</p>
","20237","","","","","2021-01-04 00:01:34","Securely storing secret data in a client-side web application","<web-development><security>","4","3","","","","CC BY-SA 3.0"
"309831","1","","","2016-02-11 09:13:59","","1","150","<p>I read about JWT and how they can provide secure authentication for calling api routes over http. I naively implemented it and here is how it goes :</p>

<ul>
<li>a client posts username and password to a login route</li>
<li>the server checks if the credentials are ok, creates the token and sends it back</li>
<li>the client keeps the token and adds it to any protected api calls</li>
</ul>

<p>Now say I can see all client http in/out calls. As the password is clear in the first call I would just have to see if the response looks like a legit JWT and I would be pretty sure that the credentials are correct. If the password is encrypted on the client any attacker can decrypt it (just look at the source on the client).</p>

<p>What I am missing here ?</p>
","57387","","","","","2016-02-12 10:10:24","Secure authentication using JWT","<security><http><json><authentication>","2","0","","","","CC BY-SA 3.0"
"408226","1","408227","","2020-04-01 13:59:08","","3","107","<p>This is not about storing my user's login details in the app, I already use hash and JWT tokens for that. There is a part of our app where we need to store the login details of the user for another website.</p>

<p>e.g they enter their username and password, it gets stored in my system and then my node server wakes up at night uses their details to login into the other system and pull out the data it needs. What's the best and safest way to store these details in the system as I need the password in text form to log into the website.</p>

<p>We are receiving permission from the user to do this as it is automating an essential part of our data collection for the user. It's just the other website/system doesn't have any other way of providing the data to us unless we want it in paper form in the post.</p>
","361927","","","","","2020-04-01 14:31:57","Storing username and password for another site in Node and MongoDB","<javascript><security><node.js><mongodb><server-side>","1","0","","","","CC BY-SA 4.0"
"408289","1","408294","","2020-04-02 19:16:44","","3","134","<p>Some node.js libraries (just as an example) can pull in literally hundreds of dependencies. Some of these dependencies are small packages that only have one contributor. Often times the contributor doesn't even have any personal information listed other than their username.</p>

<p>How is it possible to trust that nobody in those hundreds of libraries will never act maliciously, get their account hacked, have a change of heart, purposefully introduce a vulnerability, etc?</p>

<p>It seems that all it would take is one point in the chain to get compromised, or have never had good intentions from the beginning, and that could lead to huge security problems or data breaches. A compromised plugin in a build system could steal source code.</p>

<p>It just seems like the wild west and a disaster waiting to happen. Do companies really review the source code of every single package they use, and the changes on every single update? That just sounds unmaintainable.</p>

<p>I could understand trusting a paid library published by a business, but I don't understand projects using these deeply nested dependencies published by internet strangers.</p>

<p>I guess what my question is that I am having trust issues and don't know how to properly include a library without worrying that I could accidentally compromise a customer's business.</p>
","85551","","","","","2020-04-02 20:53:57","How do projects manage security with so many dependencies in open source projects?","<security><dependencies><vulnerabilities><malicious-code>","1","4","","","","CC BY-SA 4.0"
"408328","1","","","2020-04-03 11:41:47","","2","89","<p>I have a few microservices that i would like to combine in form of an api. The main purpose of the api is to be used by our (first party) mobile app. A side note, we don't have a mobile app or web app right now and we want the backend completely decoupled from the frontend. But i can see that soon a few third parties might need access to the same api as well. I have designed the api with the basic endpoint for all the type of resources. My question is regarding the authorization flow of the api and client.  </p>

<p>I am leaning towards using Oauth 2.0. Password flow for our own app (first party) and Authorization flow or Authorization flow with PCKE depending on the kind fo third party client. Is it a secure way to solve it ? How is it typically done ?</p>

<p>So for a third party developer, the flow would be something like this. They signup using our mobile app, create an app (client id and secret) and then can use it for authorization. This leads me to one more question</p>

<p>1) Would it be safe to expose the signup and create an app endpoint to third parties ? Or only our app should be capable of creating apps and signing up new users ?</p>
","362103","","362103","","2020-04-03 11:55:55","2020-04-03 11:55:55","Api Authorization for first party apps and third party apps","<api><security><oauth2>","0","0","","","","CC BY-SA 4.0"
"408469","1","","","2020-04-07 02:30:34","","0","97","<p>I've written an app using <strong>golang</strong> which uses OAuth2(Authorization code flow with PKCE) to interact with the <a href=""https://developers.google.com/gmail/api"" rel=""nofollow noreferrer"">Gmail API</a>.<br>
If I build the app using my own <em>client ID</em> then my <em>client ID</em> can easily be found out through the <em>authorization request URL</em> which my app passes to the system browser during <em>user consent</em>. This won't be a good practice since basically anyone could impersonate my client using my <em>client ID</em>.</p>

<h2>My question</h2>

<p>How am I supposed to distribute my app with my own <em>client ID</em>? If it's not possible with this flow, do any other alternatives exist?</p>
","362386","","","","","2020-04-09 06:29:33","How should I distribute my app with my own OAuth2 client ID, without letting anyone find it out?","<api><security><oauth2><golang>","1","6","","","","CC BY-SA 4.0"
"310366","1","310374","","2016-02-17 22:17:12","","0","2116","<p>There's an application, which accepts a user id and password to login. Validation of the id and password is processed by another system. Now after password validation, the application generates a One Time Passcode (OTP) and sends it as an SMS or email to the user.</p>

<p>This OTP expires in 15-30 minutes. Only when the OTP is validated successfully does the user's login complete.</p>

<p>If the user has two devices, and he enters his password in one device, an OTP is generated. But he doesn't use the OTP on the first device. He uses his second device to log in again, and enters his password there. Since it is within 15-30 minutes, the same OTP is generated again. Now he can log in to two devices with the same OTP.</p>

<p>Does this scenario appear to be good?</p>

<p>Continuing the scenario, his id is locked meanwhile for some reason. He attempts to enter the OTP in either of the devices. Now should we allow the login? Otherwise, should we check the id status every time an OTP is validated?</p>

<p>Similarly, in the 15-30 minute interval, if password is changed via the help desk, should we reset the existing sessions that have successful password validation but are waiting for the OTP? Or can we allow the login with the older password itself?</p>

<p>The technical problem here is that password validation is in one system, but the OTP validation is in another system, and they are mutually exclusive. They don't communicate with each other.</p>

<p>Is this OTP validation procedure appropriate?</p>
","216838","","97259","","2016-02-17 22:47:52","2016-02-18 18:56:25","Handling delay in entry of OTP for log in validation","<security><authentication><validation><passwords><login>","2","12","","","","CC BY-SA 3.0"
"408766","1","","","2020-04-14 04:36:51","","-4","79","<p>I know that browsers use a separate port for each tab. However, in each tab, there might be multiple scripts doing data transfer over the network. How does a browser makes sure that the data is delivered to the right script, to prevent security issues? How does it differentiates between all the scripts?</p>
","362994","","362994","","2020-04-14 13:03:11","2020-04-14 13:03:11","How do browsers isolate traffic within a single tab?","<security><networking><sockets><resources><web-browser>","2","0","0","","","CC BY-SA 4.0"
"194859","1","195129","","2013-04-13 22:26:40","","6","5749","<p>What's the most secure method of performing authentication in a single paged apps? I'm not talking about any specific client-side or server-side frameworks, but just general guidelines or best practices. All the communications are transfered primarily through sockJS.</p>

<p>Also, OAuth is out of the question.</p>
","57448","","","","","2014-03-07 09:57:09","Security in Authentication in single page apps","<javascript><security><authentication>","2","0","","","","CC BY-SA 3.0"
"409124","1","","","2020-04-22 05:16:07","","1","563","<p>The main reason, to my understanding, that Flash is being phased out is that it is fundamentally insecure (i.e. it isn't just tons of individual issues; it's insecure on a 'core' level). I severely doubt that anyone would knowingly build something so insecure (so they wouldn't just accept massive security issues even in favour of program flexibility). This leads me wonder, how can we analyze Flash's shortcomings in order to prevent the same underlying problem from occurring?</p>

<p>Is there a particular form of analysis that can address this issue?</p>
","335470","","","","","2020-04-26 22:24:27","How can we learn from Flash's vulnerabilities?","<security>","3","1","","2020-04-22 17:23:10","","CC BY-SA 4.0"
"310824","1","310975","","2016-02-23 05:39:45","","3","1642","<p>I'm going to implements password recovery in my authentication. I haven't put this together in a while and wondering if there is anything I ought to be aware of.</p>

<p>My idea at the moment is:</p>

<ol>
<li>User clicks ""Forgot my password"" to go the password recover page: a
form with an email field</li>
<li>They enter their email, and an email is sent to that address with a
link and password recover token/key (MD5 string - it just needs to
be somewhat random and long right?). An entry is also made in the
password_recovery database table which ties that token to their
account, and an expire date (1 hour?)</li>
<li>They retrieve the email and click the link to take them to a
password set page: two fields to enter their password, and confirm
their password again.</li>
<li>Done, please login again with new password</li>
</ol>

<p>Does that seem OK? Anything changed over the years where this approach is no longer recommended?</p>

<p>UPDATE</p>

<p>Additions that I opted for:</p>

<ul>
<li>I store the token in the database hashed. If a hacker we to be able to access the database table somehow, they wouldn't be able to use the stored tokens .. hopefully (hashed with sha256)</li>
</ul>
","142254","","142254","","2016-02-24 07:49:43","2016-02-24 11:45:32","Modern recommendations for password recovery","<php><security><authentication><passwords>","3","15","","","","CC BY-SA 3.0"
"195352","1","195356","","2013-04-18 09:03:17","","0","855","<p>In an MVP application, what should be the most appropriate way to implement restriction to some UI actions based on the current user's privileges?</p>

<p>For example, in a role-based security, different roles will have different access to some UI interactions on the same view. If, for instance, we have an online store, on the products list page the customers can only view the details and add items to their cart, but an administrator must be also presented with <code>Add Product</code> buttons and <code>Delete</code> button on each item. </p>

<p><a href=""https://softwareengineering.stackexchange.com/questions/56103/mvp-pattern-philsophical-question-security-checking-in-ui"">Similar question</a> has been asked here already, but the OP is asking for the UI making the permission checks. I am certain the UI (view) should not be responsible for permission validation, but still it has to know whether to visualize or not certain UI components. So, is there any well-defined or widely adopted pattern for telling the view which UI interactions it should disallow? I can think of a few solutions, but if there is a standard and proven one, I'd prefer to stick with that, rather than reinventing the wheel.</p>

<hr>

<p><strong>Update</strong></p>

<p>To clarify a bit further, as suggested in answers below, I am considering the approach of having the view accept the privileges information from the presenter. It is the form of that information that bothers me - if using flags as bit masks or some too-generic representation I will:</p>

<ol>
<li>(+) Gain consistency in passing the permissions to the view</li>
<li>(-) Couple the view with logic for resolving the flags. </li>
</ol>

<p>The other thing I have in mind is having the View expose all the flags it needs as settable properties for the presenter (like <code>view.IsDeleteItemAllowed</code>). So I will:</p>

<ol>
<li>(+) Not have additional logic for the permissions in the view</li>
<li>(-) Add additional complexity to presenter to adapt permission flags to the view's properties.</li>
</ol>

<hr>

<p>So, I am thinking of using the later approach, because that way I can reuse the presenter with different view implementations; and will not rely on the view for understanding the permissions system (which may be a subject of changes). Is there anything I should worry about with that?</p>
","27726","","-1","","2017-04-12 07:31:41","2013-04-18 12:47:40","MVP Pattern - Ways to restrict the user action based on security privilleges","<security><mvp>","1","0","","","","CC BY-SA 3.0"
"195528","1","","","2013-04-20 09:39:44","","0","4802","<p>Is there a difference between HttpRequest and xmlHttpRequest in terms of security? Is one more secure than the other?</p>

<p>Is it more secure to send important data such as passwords via HttpRequest than via xmlHttpRequest ?</p>

<p>Is data packing in both done the same way?</p>
","88693","","18930","","2013-04-20 10:33:18","2013-07-19 13:29:33","Security comparison between xmlHttpRequest and HttpRequest","<security><http-request><xmlhttprequest>","1","1","","","","CC BY-SA 3.0"
"409458","1","409468","","2020-04-29 11:20:14","","1","659","<p>One common issue with secure passwords is that users tend to ""cheat"", one common cheating pattern we meet recently is the ""password swap"" antipattern where the user basically keeps using the same two passwords forever.
e.g.:</p>

<ul>
<li>Password1!</li>
<li>Secret2$</li>
<li>Password3!</li>
<li>Secret4$</li>
</ul>

<p>This antipattern works because:</p>

<ul>
<li>any new passwords is completely different from the previous one</li>
<li>the history of hashes does not contain any exact match</li>
</ul>

<p>is there any algorithm which is ""similar"" to an hash but allows to extract a distance metric from the current plain text password in order to avoid those risks?</p>

<p><strong>Here is my analysis so far</strong></p>

<ul>
<li>Hashing explicitly requires that ""similiar"" passwords turn to very different hashes: otherwise it would be very easy to converge from a generic password toward the one that generated the hash. Any ""hash""-like algorithm which allows to calculate a metric of distance from the current password would be a security threat.</li>
<li>I can't think of any workaround to come up with an hash which allows to measure ""similarity"" without giving away some kind of ""distance"" metric: which as stated above would render it insecure</li>
<li>Another approach would be storing hashes of subsets of the password. E.g. we store the hash of the previous 10 passwords + the hash of the previous passwords minus the last two chars: this one would block the above example. However in order to work we might have to collect too many hashes of too small substrings (eg. every group of 6 chars) and this would give away the plain text password!</li>
</ul>
","364479","","","","","2020-04-29 14:22:12","hash-like algorithm to identify passwords which are ""too similar"" to previous ones from history","<security><hashing><passwords>","3","7","","","","CC BY-SA 4.0"
"409497","1","409501","","2020-04-30 03:31:49","","1","128","<p>I am looking at all the green and red boxes <a href=""https://en.wikipedia.org/wiki/Transport_Layer_Security"" rel=""nofollow noreferrer"">here</a>, and am wondering what it would look like if one were to ""implement TLS"" today? What should you implement if you were to implement TLS today?</p>

<ul>
<li>Do you need to implement all of the previous versions? (SSL 1-3, TLS 1.0-1.3)</li>
<li>Do you need to implement all the cryptography algorithms, or just the TLS 1.3 ones? (RSA is not used in TLS 1.3 it looks like, but is the standard for HTTPS as far as I know, for example).</li>
<li>Do you need to implement all the <em>ciphers</em>, or just the TLS 1.3 ones?</li>
</ul>

<p>Rather than trying to describe what needs to be implemented in order to support TLS <em>today</em>, the simpler question is <strong>do browsers support TLS 1.3</strong>? If not, why not? This leads to the above questions, plus...</p>

<p>In order to fetch ""older"" websites, do you need to support older TLS protocols? Or can you have, let's say, a brand new TLS 1.3 implementation that only implements the following, and be good to go in terms of communicating with ""older"" sites and services? Basically TLS 1.3 seems to only implement:</p>

<ol>
<li>DHE-RSA</li>
<li>ECDHE-RSA</li>
<li>ECDHE-ECDSA</li>
<li>AES GCM</li>
<li>AES CCM</li>
<li>ChaCha20-Poly1305</li>
<li>AEAD</li>
</ol>

<p>That's only 7 things, meanwhile there are about 20 key exchange algorithms in the full range of TLS/SSL versions from SSL 1.0 to TLS 1.3, and about 20 ciphers, and 6 data integrity algorithms.</p>

<p>Basically, in order to support browsing the web <em>if TLS was implemented today</em> in a new open source project for example, would it only need to write the code for those 7 things, or all 20 + 20 + 6 ~ 46 algorithms, basically supporting all SSL and TLS versions of the past?</p>

<p>I am basically confused as to what needs to be implemented to support secure web browsing in the 21st century, given that everything before TLS 1.3 has been found to be insecure (it seems like). The answer to this question would help me come up with a project scope on what it would take to implement TLS properly today.</p>

<p>If you can't just implement TLS 1.3 (and need to support the older TLS/SSL versions), what happens if you only had TLS 1.3? What about only TLS 1.3 and 1.2? etc. Basically, what handicaps do you have by only supporting the latest version. Does it mean simply that you can't fetch certain webpages, or what?</p>

<p>It sounds like browsers have stopped supporting SSL 3.0 and before for a while now, but I'm not sure.</p>
","73722","","73722","","2020-04-30 03:45:28","2020-04-30 05:48:20","Do you need to implement TLS versions < 1.3 if you were to implement a TLS supporting library today?","<architecture><security><cryptography><ssl><https>","1","1","","","","CC BY-SA 4.0"
"195643","1","195677","","2013-04-21 21:22:02","","4","472","<p>I'm just investigating the security and control of the Linux platform in comparison to Android. </p>

<p>In Android there seems to be a huge development around security - Applications are required to ask for system permissions, and if the user grants that permission, then the system allows that application to execute with those granted privileges.</p>

<p>It isn't like that on vanilla Linux. Applications can access anything they want, albeit not granting them to modify files, but nevertheless. Users simply don't know how applications work, and what information - sensitive information - they take and what they do with that information (upload it to a database and sell it to 3rd parties).</p>

<p>So what is this dealt with? </p>

<p>I'd imagine the Linux kernel has to be modified so it accepts access tokens per application basis or something similar.</p>

<p>Windows at least has some type of security system with it's built in firewall and local authority service. (I know little about Windows.)</p>
","49360","","22069","","2013-04-22 05:19:17","2013-04-23 06:34:57","How to implement better security in Linux?","<security><linux>","3","2","","","","CC BY-SA 3.0"
"195660","1","","","2013-04-22 03:49:46","","38","4441","<p>I started logging failed logins attempts on my website with a message like</p>

<p><code>Failed login attempt by qntmfred</code></p>

<p>I've noticed some of these logs look like</p>

<p><code>Failed login attempt by qntmfredmypassword</code></p>

<p>I'm guessing some people had a failed login because they typed their username and their password in the username field. Passwords are hashed in the database, but if somehow the db got compromised, these log messages could be a way for an attacker to figure out passwords for whatever small percentage of people end up having a failed login such as this.</p>

<p>Is there a better way to handle this? Should I even worry about this possibility?</p>
","3888","","","","","2013-04-24 22:08:14","Logging failed login attempts exposes passwords","<web-development><security>","4","3","","","","CC BY-SA 3.0"
"195762","1","","","2013-04-22 20:39:46","","5","492","<p>I've worked at several places with 2-10 developers and each place has struggled in the area of tracking if the company has an account on a given web site or service.  We're always left wondering...</p>

<ul>
<li>What's the username</li>
<li>What's the password (Obviously you don't want to store this, I'm not looking for something that does)</li>
<li>What's the account number</li>
<li>Who created this</li>
<li>When was it created</li>
<li>What email is our account registered under</li>
</ul>

<p><strong>What do you guys use to track this kind of thing between multiple developers?</strong>  I've setup at least a dozen accounts for the company I currently work for and I don't have any documentation to show the next guy what's been done.</p>

<p>Ideally I'm looking for a web solution that will be locked down within our VPN.</p>
","9348","","425568","","2023-01-28 03:25:02","2023-01-28 03:25:02","How do you keep logins organized between multiple developers?","<security><organization><permissions><access>","5","4","","","","CC BY-SA 3.0"
"409614","1","","","2020-05-02 21:08:09","","1","42","<p>I wanted to ask about your ideas on how to solve the problem that I have to solve in my application (App1). This is the classic Fronted + Backend (Angular + Java EE) application to which I am currently adding authentication and authorization. However, the matter does not seem to be simple for several reasons. First, there are different kinds of customers who will use this application:</p>

<ol>
<li>end-user using GUI (Angular calls the Backend API)</li>
<li>end-users using direct backend API</li>
<li>another system calling the API backend</li>
</ol>

<p>In addition, I have an OIDC provider (OIDC_Organization) available in my organization - unfortunately it can only authenticate users. Does not return any information about roles. And my application also needs information about which roles belong to the logged in user. For this reason, I would like to build my own OIDC system (OIDC_Internal), which would delegate authentication to an existing system (OIDC_Organization) in the organization. And from the database I manage (Permission_DB) it would read user permissions / roles. I would return such combined information (id user + role) in new OAuth token(s) to my application. However, I would not like to implement from scratch the entire OIDC system (OIDC_Internal). There must be for sure best options for this. 
The another problem is also that I can't put any technical users in OIDC_Organization. Only real users are there. So for option (1) and (2) I can use OIDC_Organization but for option (3) I need to have a user account in a different place (e.g. in the authorization database that I have -> Permission_DB).</p>

<p>Below is the diagram that seems necessary to ensure security for Application 1. I assume that Authorization Code Flow will be used for the communication of App1-> OIDC_Internal and OIDC_Internal-> OIDC_Organization.
<a href=""https://i.stack.imgur.com/ATZmc.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ATZmc.png"" alt=""End-User Authentication and Authorization""></a></p>

<p>Here diagram of the user's technical connection (ApiCli) to the system (I assume, the Credential Grant Flow will be used here.)
<a href=""https://i.stack.imgur.com/k55Wr.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/k55Wr.png"" alt=""Technical-User Authentication and Authorization""></a></p>

<p>I was thinking about using Keyclock as a kind of proxy-provider but I don't know if this solution is even possible to implement. For example I don't want to show Keyclock's login page - the login page provided by OIDC_Organization would be sufficient. Maybe would you suggest writing your own solution using some Oauth / OIDC / JWT support libraries?</p>

<p>I would be very grateful for any ideas.
Best Regards,
Peter</p>
","364783","","","","","2020-05-02 21:08:09","Defining custom OIDC provider with delegating authentication to another OIDC provider and using own authorization database","<security><authentication><authorization><oauth>","0","0","","","","CC BY-SA 4.0"
"409746","1","409777","","2020-05-05 19:56:05","","1","257","<p>Consider the following</p>

<p><strong>Group A</strong></p>

<pre><code>Job A {
    Depends on Job B of Group A
    Run User -&gt; User1
}

Job B {
    Depends on Job C and Job D of Group A
    Run User -&gt; User2
}

Job C {
    Depends on Job D of Group A and Job A of GroupB
    Run User -&gt; User1
}

Job D {
    Depends on Job E of Group A
    RunUser -&gt; User3
}

Job E { 
    Run User -&gt; User3
}
</code></pre>

<p><strong>Group B</strong></p>

<pre><code>Job A {
    Depends on Job C of Group B
    Run User -&gt; User4 
}

Job F {
    Depends on Job C and Job D of Group B
    RunUser -&gt; User2
}

Job C {
    Depends on Job D of Group A
    Run User -&gt; User1
}

Job D {
    Run User -&gt; User5
}
</code></pre>

<p><strong>Group C</strong></p>

<pre><code>Job C {
    Depends on Job A of Group A
    Run User -&gt; User6 
}

Job G {
    Depends on Job H of Group C
    Run User -&gt; User5
}

Job H {
    Run User -&gt; User7
}
</code></pre>

<p><strong>Group D</strong></p>

<pre><code>Job I {
    Run User -&gt; User8
}
</code></pre>

<p>and so on...</p>

<p>For simplicity let us assume that I have ~50-60 such groups and in each group, I have around 1000 Jobs. Run users are Unix users, a user with which Job runs.</p>

<p>If you look closely you will notice that this is cross-group directed acyclic graph of Jobs. Hence I am thinking to build an event-driven system for triggering these Jobs and for that I am thinking to use Kafka. </p>

<ol>
<li>Producer: Each invocation of a Job is a separate process. These are my producers (short lived).</li>
<li>Consumer: Assume we have one consumer per run user. I am not sure how do I trigger Jobs for cases when Job is dependent on more than one event (i.e. for completion of more than one Job)?</li>
<li>Topics: I am not sure about Kafka Topics. Should I have

<ul>
<li>One topic per group?</li>
<li>One topic per user?</li>
<li>One topic per group per user? Or,</li>
<li>One topic per user per group per job?</li>
</ul></li>
</ol>

<p>Basically I want to solve the following use-cases:</p>

<p><strong>Usecase 1</strong> Secretive Job A run by user x depends on secretive Job B run by user Y. Neither A nor B wants to tell anyone in the world about their existence. A and B need to trust each other which means they can know the existence of each other.</p>

<p><strong>Usecase 2</strong> Public Job A run by user x depends on secretive Job B run by user Y</p>

<p><strong>Usecase 3</strong> Secretive Job A run by user x depends on public Job B run by user Y</p>

<p><strong>Usecase 4</strong> Public Job A run by user x depends on public Job B run by user Y</p>

<p>Any ideas on how should I go about designing</p>

<ol>
<li>Kafka topics from the secure setup perspective to solve use-cases above.</li>
<li>How do I consume events and launch Jobs (for jobs that depend on multiple other Jobs)?</li>
</ol>
","361588","","361588","","2020-05-05 20:22:05","2020-05-06 14:04:06","Designing Kafka topics for secured event driven job scheduling system","<security><event-programming><message-queue><apache-kafka>","1","3","","","","CC BY-SA 4.0"
"311480","1","","","2016-03-01 10:37:43","","2","134","<p>I've found description of vulnerability <a href=""http://www.payatu.com/hijacking-kankun/"" rel=""nofollow"">here</a>.</p>

<blockquote>
  <p>The kankun smart socket device and the mobile app use a hardcoded AES 256 bit key to encrypt the commands and responses between the device and the app. The communication happens over UDP. An attacker on the local network can use the same key to encrypt and send unsolicited commands to the device and hijack it.</p>
</blockquote>

<p>Then how it should be done in a secure way, I mean how to encrypt communication without hard coding key in client?</p>
","115675","","31260","","2016-03-01 10:39:00","2016-03-01 10:46:56","How to encrypt communication without hard coding key in client?","<security><client-server><encryption><keys>","1","0","","","","CC BY-SA 3.0"
"409856","1","","","2020-05-07 20:39:40","","0","424","<p>I am currently developing an application with Qt/C++ which needs to access a Shopify store using the <a href=""https://shopify.dev/docs/admin-api"" rel=""nofollow noreferrer"">Admin API</a>. In order to access the API, my application needs to know the following information:</p>

<ul>
<li>API Token</li>
<li>Shared Secret</li>
<li>API Password</li>
</ul>

<p>These values are stored as strings in a header using a simple <code>#define</code>, for example:</p>

<pre><code>#ifndef STORE_INFO_H
#define STORE_INFO_H

#define ADMIN_API_TOKEN         ""...""
#define ADMIN_API_PASSWORD      ""...""
#define ADMIN_API_SHARED_SECRET ""...""

// Sha la la la

#endif
</code></pre>

<p>Afterwards, these values are used across the application as needed. However, there's one big issue with this approach: if someone is smart enough to open the binary application inside a HEX editor or a decompiler, he or she may be able to see this information (which, if used with malicious purposes, could do a lot of damage). </p>

<p>Irrelevant of the needs of my application or which API I am using, is there are way to ""hide"" or protect sensitive information constants in a C/C++ application?</p>
","87708","","87708","","2020-05-07 20:47:09","2020-05-07 21:04:29","How can I protect sensitive information inside a binary?","<design><api><security><passwords>","2","1","","","","CC BY-SA 4.0"
"409872","1","","","2020-05-08 05:38:24","","0","118","<p>In a large iOS application, I have a database module which is dedicated to handle application databases with read/write public APIs for other module. UI module has a feature to share the database, in which a copy of the database can be sent to another person. Now to attach my database for share feature UI module requires my database path. So, UI team requested to expose a public API to get the database path.</p>

<p>I am concern about security perspective of exposing database path as a public API. What are the general guideline to share the database for other modules? Should I expose my database path via public API? If so, is there any implication on further security vulnerability and does it violate the abstraction?</p>
","208831","","5099","","2020-05-08 13:47:31","2020-05-10 11:35:43","What's the pattern to share database to other module in security perspective?","<architecture><database><security><abstraction><modules>","2","4","","","","CC BY-SA 4.0"
"196014","1","196018","","2013-04-24 20:34:05","","0","1072","<p>I'm not quite sure if this is a question for programmers.se rather than stackoverflow, but here goes.  So Facebook [or any other large company] when given something like an apostrophe or html, can strip it of its malicious intent, but still display it properly.  My current sanitizing function in PHP just strips those characters/makes them harmless via htmlentities() and such.  So if I wrote an HTML tag, I would want it to be sanitized but also displayed on the website.  How do I do this?</p>
","48647","","52512","","2013-04-24 21:59:41","2013-04-25 16:12:26","How does Facebook strip html/apostrophes for XSS but also display it?","<security><html><text-processing><escaping>","2","3","","","","CC BY-SA 3.0"
"410049","1","","","2020-05-12 17:31:34","","4","220","<p>It seems common practice to not positively indicate during a password reset attempt whether the email requested is actually registered or not.  This makes sense because knowing that an email is registered will give an attacker a potential vector for exploit.</p>

<p>However - how does one do this during the new account registration process?  I cannot create an account for an email that already exists, I can merely tell the user that they already have an account and they did they mean to log in instead (etc).</p>

<p>Obviously this exposes the fact that the given email is already registered.  Is there any clever way to prevent this?  Am I overthinking this?</p>
","110451","","","","","2022-12-05 06:16:35","How to protect potential attackers from finding emails that are already registered?","<security>","0","4","","","","CC BY-SA 4.0"
"196322","1","","","2013-04-27 06:03:18","","5","262","<p>It's pretty easy to track when we fix security vulnerabilities in existing code.  But to make sure the whole team is staying on their toes about writing secure code, I'd like to also track how well we are preventing and avoiding writing new security vulnerabilities.  What is the right way to measure that?</p>
","13096","","","","","2013-06-20 14:12:51","How can we track how well we're preventing and avoiding security vulnerabilities?","<code-quality><security><metrics>","4","7","","","","CC BY-SA 3.0"
"196419","1","198121","","2013-04-28 09:58:26","","8","997","<p>Our product registers new players on our service, and we've chosen to host it on Azure (we're using .NET) and we wanted it to be stateless (for scalability) and relatively secure.</p>

<p>Since this is the first REST WS I'm writing, I wanted to get some feedback on whether or not it's a solid solution.</p>

<p>Some presumptions to know about our app:</p>

<ol>
<li>Users are logged into the service anonymously, without requiring a password from a user</li>
<li>The WS must be completely stateless to allow horizontal scaling</li>
<li>We're connecting using HTTPS (SSL) to prevent 3rd party snooping</li>
</ol>

<p><strong>EDIT:</strong></p>

<ol>
<li>We target for native iOS/Android devices</li>
<li>Our main concern is making sure only non-tampered clients are able to send requests</li>
</ol>

<p>And the abstract authentication process:</p>

<ol>
<li>The client creates a simple hash (UDID:Timestamp) and encrypts it using the timestamp with some basic algorithm (for example, secret key is every 2nd character from the hash)</li>
<li>The client sends his UDID, Timestamp &amp; hash to the server</li>
<li>The server rebuilds the hash and decrypts the encrypted hash sent from the user</li>
<li>If the two are equal - we know that it was actually sent from our client (and hopefully not from a malicious sender)</li>
</ol>

<p>Any input/suggestions would be great - obviously since it's the first time I'm handling this issue I might have designed it incorrectly.</p>

<p>Thanks!</p>

<p><strong>2nd update:</strong></p>

<p>Reading the security specs for OAuth, it seems that there is no real answer to my question - since the client and server must know the secret keys and the client is locally stored on our users' mobile devices (as opposed to a web app).</p>

<p>From the OAuth security guide (<a href=""http://hueniverse.com/oauth/guide/security/"">http://hueniverse.com/oauth/guide/security/</a>):</p>

<blockquote>
  <p>When implementing OAuth, it is critical to understand the limitations of shared secrets, symmetric or asymmetric. The client secret (or private key) is used to verify the identity of the client by the server. In case of a web-based client such as web server, it is relatively easy to keep the client secret (or private key) confidential.</p>
  
  <p>However, when the client is a desktop application, a mobile application, or any other client-side software such as browser applets (Flash, Java, Silverlight) and scripts (JavaScript), the client credentials must be included in each copy of the application. This means the client secret (or private key) must be distributed with the application, which inheritably compromises them.</p>
  
  <p>This does not prevent using OAuth within such application, but it does limit the amount of trust the server can have in such public secrets. Since the secrets cannot be trusted, the server must treat such application as unknown entities and use the client identity only for activities that do not require any level of trust, such as collecting statistics about applications. Some servers may opt to ban such application or offer different protocols or extensions. However, at this point there is no known solution to this limitation.</p>
</blockquote>
","89476","","89476","","2013-04-29 08:52:03","2013-05-14 20:52:45","Is this solution RESTful and secure?","<security><web-services><rest><scalability><authentication>","2","8","","","","CC BY-SA 3.0"
"196421","1","196422","","2013-04-28 10:06:49","","15","17927","<p>I need to build a web service API for our mobile app to interact with our server &amp; database (in ASP.Net MVC 4, but that's hardly relevant). Wile most actions do not need users to be registered with our service, we would like to restrict access only to users of our app. </p>

<p>What are the methods to make sure that calls made from somewhere else (e.g. someone wanting all our data, or building an unofficial app) are rejected?</p>

<p>My initial idea is for the device to ask the server for a token, which is randomly generated and sent as is. All other methods will check that the request headers contain a specific one that will be md5 hash of the salted token.  The server knows the token and salt and is able to compute the hash and compares it with the one sent. In addition, the token as a limited lifespan, and the device must get another one every other hour.</p>

<p>That seems quite easy to implement and although probably not 100% proof, that seems to be a good idea. What do you think? </p>
","72180","","","","","2013-04-28 10:49:58","What are the best practices to secure a web API?","<security><web-services>","1","0","","","","CC BY-SA 3.0"
"312384","1","312389","","2016-03-10 21:20:28","","1","379","<p>The <a href=""https://www.owasp.org/index.php/Cross-Site_Request_Forgery_%28CSRF%29_Prevention_Cheat_Sheet"" rel=""nofollow"">synchronizer token pattern</a> is the most effective protection against CSRF attacks. I understand the theory and implementation, but I do not understand why it can't be circumvented.</p>

<p>Generally, the process requires you to visit a malicious site that has a hidden URL that will perform an action against the authenticated site (via <code>img</code> tags, for example). To prevent this, ""real"" URLs on the site require a token parameter to be passed with them, and this token is compared with a token stored on the session for validity. The assumption here is that the malicious site <em>does not know</em> the token.</p>

<p><strong>What is stopping the malicious site from sending a GET request to the form-submission page and simply reading the token and modifying the hidden link?</strong> </p>
","161111","","","","","2016-03-10 21:53:01","Why can't the Synchronizer Token Pattern be circumvented?","<design><security>","2","0","","","","CC BY-SA 3.0"
"410655","1","410713","","2020-05-26 16:39:02","","-3","1362","<p>In a refund tech scam, tech scammers use Chrome Developer Tools to edit the HTML directly on the victim's bank webpage through a Remote Desktop (Teamviewer, AnyDesk, etc) to fool their victim into thinking that they received a 'refund'. </p>

<p>I was wondering if we could detect if the <code>innerHTML</code> of the victim's bank balance has changed (some DOM event?) and compare the value to a private variable storing the bank balance, reload the page if a mismatch was found. A timer could also be used. Is there any way the scammer may be able to stop the listener/timer code from running without being detected by the Javascript code?</p>

<p>Although this may be a stupid idea, making these scams harder to execute for scammers will definitely slow down their progress on scamming more vulnerable victims. </p>
","287790","","","","","2020-05-28 09:52:22","Is it possible to prevent tech scammers from editing bank webpages?","<javascript><html><code-security><chrome><developer-tools>","4","3","","","","CC BY-SA 4.0"
"410914","1","","","2020-06-01 19:50:11","","1","142","<p>I am writing a web service for research and learning purposes and try to find an approach to separate user data from other users to ensure a request can never deliver or reveal data from another user.</p>
<p>I give you an example in a slightly different field. Imagine an HTML form whose inputs will be written into a database. There is the browser logic which can ensure the data is valid. Then the script accepting the connection can revalidate the data as well, and often databases have their own constraints. So there are 3 levels to ensure no spoiled or incorrect data makes it into the database.</p>
<p>Back to my initial problem. Imagine a database with user text messages. In a naive/plain database model, there would be a <code>user</code> and <code>messages</code> table where each message has a <code>user_id</code>. A <em>SQL JOIN</em> would be the naive solution, but that is way to error-prone in my opinion.</p>
<p>Would it be OK to create an entire database for each user to separate the data even more? Would that be enough? How do modern web services separate data?</p>
<p>FYI: The text message example is just an example. Of course I know about end-to-end encryption. But for my web service this is not necessary to go that far.</p>
","345143","","36296","","2022-12-23 20:53:40","2022-12-23 20:53:40","How to separate user data in database models?","<database><database-design><server-security>","0","3","","","","CC BY-SA 4.0"
"411255","1","411258","","2020-06-09 20:20:42","","1","1854","<p>I get that a front-end isn't secure on the web because one could theoretically access the front-end code by opening dev tools and changing the code. </p>

<p>Do I also need to be careful about security for a mobile app? (meaning not a web app)</p>

<p>Based on what I'm reading here <a href=""https://www.quora.com/Can-we-get-the-source-code-of-any-mobile-app"" rel=""nofollow noreferrer"">https://www.quora.com/Can-we-get-the-source-code-of-any-mobile-app</a> and here <a href=""https://www.quora.com/Is-it-possible-to-get-source-code-for-an-iPhone-application-up-to-some-extent-If-yes-how-can-I-do-that"" rel=""nofollow noreferrer"">https://www.quora.com/Is-it-possible-to-get-source-code-for-an-iPhone-application-up-to-some-extent-If-yes-how-can-I-do-that</a>, am I correct that you still need to pay attention to security on a mobile front-end because someone could access the .apk file of an android app and modify it or do the same to the .ipa files of an iPhone app?</p>
","274828","","","","","2020-06-09 22:19:01","Can you modify the front-end source code of a mobile app?","<security><android><ios><mobile><front-end>","2","1","","","","CC BY-SA 4.0"
"313236","1","","","2016-03-19 16:04:03","","1","195","<p>Many companies struggle with even basic sensitive information handling. One screaming example I can give is the attack on TalkTalk's servers resulted as 4 millions customer's personal information being exposed. Definitely a not good situation to be at.</p>

<p>My question is - what are the best practises for startups to handle personal information. Do you think startup should handle their customers information themselves or they should outsource it? Are there any good cloud services offering data storage/encryption. Startups are always looking to cut expenses so I'd be happy to check any service that are offering some free trails/dev packages. Thank you!</p>
","211244","","211244","","2016-03-19 16:27:53","2022-09-10 11:41:55","Best ways for startups to handle sensitive user information","<security><encryption>","2","4","0","2016-03-20 11:29:00","","CC BY-SA 3.0"
"197882","1","226509","","2013-05-13 07:39:20","","3","1535","<p>What exactly does ""<a href=""http://en.wikipedia.org/wiki/Security_through_obscurity"" rel=""nofollow"">Security through obscurity</a>"" means in the context of stroing unencrypted passwords?</p>

<p>I'm using a small program (I won't name it, to not enlarge enough large shame on its author) that uses my Google account for some tasks. I've noticed, that it stores my password in plain-text unencrypted file. Just a string, clearly seen to everyone, that can drag&amp;drop it to Notepad or use <code>F3</code> in Total Commander.</p>

<p>I have risen a ticket asking program author to fix this ASAP. I haven't got any reply yet, but my issue got one comment, that includes only above mentioned link to Wikipedia's ""<em>Security through obscurity</em>"" page.</p>

<p>How should I understand this comment? Is it pro or con my issue? At first I thought, that it supports my statement of fixing this ASAP. But then I found a Eric Raymond's Fetchmail example (in ""<em>The Cathedral and the Bazaar</em>""), who refused to implement config file encryption (passwords are stored in config file for Fetchmail), claiming that it is up to the user to assure security by not letting anyone ""from the outside"" access that configuration file.</p>

<p>This statement (or refusal) is often brought as example of <em>Security through obscurity</em>. And looking from this point of view, I'm completely wrong and that program author is right. He do not have to implement encryption of file with my password, it can remain there, stored unencrypted and it is I, who is responsible for assuring security by not giving anyone access to this file or by deleting it each time I stop using that soft.</p>

<p>(another question is, how can I achieve this on system as unsecure as Windows itself?)</p>

<p>These seems to be in a complete opposition, to what I've been told and learnt for years, so I would like to ask more experienced developers, who is right here and how exactly I should understand ""StO""?</p>
","57759","","","","","2018-03-28 18:20:07","Security through obscurity and storing unencrypted passwords","<security><encryption><passwords>","4","3","","","","CC BY-SA 3.0"
"197977","1","197979","","2013-05-13 20:09:21","","5","5499","<p>Through most of my dev experience, I've never had to deal with much variety of access control architectures.</p>

<p>They've all been pretty straight forward:</p>

<pre><code>Group [Create, Update, Delete]
    - User 1
    - User 2

Group [Update, Delete]
    - User 2
</code></pre>

<p>Which, for all intents and purposes, works well. The problem I have is the actual implementation of it. All the solutions I've worked on either grant/deny the visibility of a menu link, or disable a button etc. This is all controlled via the top-most layer of the app, whether it be a WebApp or WinForms UI.</p>

<p>I'm in the early stages of designing a rather large WinForms system so I'd like to get the security architecture right from the beginning.</p>

<p>Although I don't see myself getting away from visually limiting the user from performing certain actions (by disabling restricted controls etc), I'm sure there are better solutions available then doing most of the work in the UI.</p>

<p>As I understand it (and these might be limited by my ignorance), these are my options:</p>

<ul>
<li>Put the logic to return and verify user rights in the business layer</li>
<li>On the form_load event, get these rules and enable/disabled UI elements</li>
<li>Leave the UI elements in tact and halt the operation from within the business layer if the user doesn't have permission for the action (dirty!)</li>
</ul>

<p>Surely there must be more elegant solutions than this.
Could someone please provide me with alternatives or improvements to the aforementioned ideas?</p>

<p>Am I thinking about it incorrectly? Should I re-evaluate my database design while I'm at it?</p>
","33474","drminnaar","","","","2013-05-13 22:25:02","Is there a better way of handling access control logic instead of it being in the UI?","<c#><winforms><security><database-design><architecture>","3","1","","","","CC BY-SA 3.0"
"313686","1","","","2016-03-24 09:20:07","","0","289","<p>I'm working a PHP project where I need to authenticate users to a portal. Just wanted to get your opinion on the code, statistics of the website show some strange behaviour with the login form. Wondering whether the code is strong enough.</p>

<pre><code>conn.php

&lt;?php
if(!isset($_GET['login']) &amp;&amp; !isset($_GET['pwd']))
{
    header('Location: index.php');
}
else
{
    if(!preg_match('/^[[:alnum:]]+$/', $_GET['login']) or
!preg_match('/^[[:alnum:]]+$/', $_GET['pwd']))
    {
        echo 'Only alphanumeric characters are allowed';
        exit();
    }
    else
    {
        require('config.php');

        $login = $_GET['login'];
        $pwd = $_GET['pwd'];

        $sql = ""SELECT * FROM users WHERE user='"".mysql_escape_string($login).""'"";

        // Check if user exists
        $request_1 = mysql_query($sql) or die ( mysql_error() );

        if(mysql_num_rows($request_1)==0)
        {
            echo 'User does not exist!';
            exit();
        }
        else
        {
            $request_2 = mysql_query($sql."" AND pass='"".$pwd.""'"") or die ( mysql_error() );

            if(mysql_num_rows($request_2)==0)
            {
                $result = mysql_fetch_array($request_1, MYSQL_ASSOC);
                $lastconn = explode(' ', $result[""dates""]);
                $lastday = explode('-', $lastconn[0]);

                $nbr_trial = $result[""nbr_connect""];
                if($lastday[2]==date(""d"") &amp;&amp; $MAX_trial==$nbr_trial)
                {
                    echo 'Too many connection attempts!&lt;br/&gt;';
                    exit();
                }
                else
                {
                    $nbr_trial++;
                    $update = ""UPDATE users SET nbr_connect='"".$nbr_trial.""', dates=NOW()
WHERE id='"".$result[""id""].""'"";
                    mysql_query($update) or die ( mysql_error() );
                    echo 'Incorrect login or password';
                    exit();
                }
            }
            else
            {
                $result = mysql_fetch_array($request_2, MYSQL_ASSOC);
                $nbr_trial = 0;
                $update = ""UPDATE users SET nbr_connect='"".$nbr_trial.""', dates=NOW()
WHERE id='"".$result[""id""].""'"";

                mysql_query($update) or die ( mysql_error() );

                header('Location: portal/index.php');
            }
        }
    }
}
?&gt;

config.php : 

&lt;?php

$DB_serveur = 'localhost';
$DB_utilisateur = 'root';
$DB_motdepasse = '******';
$DB_base = 'siht_portal';

define('_MAX_trial', 3);

?&gt;
</code></pre>
","221739","","","","","2016-05-24 18:41:37","How to secure my authentication code?","<php><security><authentication>","1","10","","","","CC BY-SA 3.0"
"313946","1","","","2016-03-26 19:31:24","","2","178","<p>I do a lot of programming work for other people's businesses. I am currently working on a project for my local Scouts group that I have worked with before.</p>

<p>The problem is I have built them their server and I administer it for them but the problem is they need to make sure it's secure. Which is fine, and then I raised the issue of blocking old users... they then asked what about blocking you?</p>

<p>It's a valid point but I don't know of a way that they can. They have limited server experience so I considered designing an automatic block system which would block me. Ideally, it would require two other users login keys which could then somehow remove my access.</p>

<p>I have no idea how to approach this. I am using Ubuntu Server to run their servers.</p>
","222050","","","user28988","2016-03-27 00:10:54","2016-03-27 00:27:27","Securing my own software... against myself?","<security><server><networks><ubuntu>","2","5","","","","CC BY-SA 3.0"
"198442","1","","","2013-05-16 21:47:29","","0","596","<p>I have a database sanitizing function that I use when the user enters some data into my website.  I escaping the mysqli characters with mysqli_real_escape_string(), but I wish to also output the content with htmlspecialchars().  The problem is, let's just say the user enters something with a single quote; that will be escaped by the sanitize function and will be output as \'.  Is there any way to store it like that, and then output it as '?</p>
","48647","","16929","","2013-05-16 22:25:58","2013-05-16 22:31:05","Storing escaped mysqli characters in database but outputting them correctly with htmlspecialchars()","<php><security>","1","1","","","","CC BY-SA 3.0"
"412144","1","","","2020-06-29 14:40:58","","0","233","<p>I have a front end (WEB GUI) app that I designed (Python for now + JavaScript in the future) that I use to access a controller, it uses REST APIs.</p>
<p>I want to publish this app in the cloud so that others could use it.</p>
<p>The biggest issue I am seeing is the security side as the app needs to authenticate with the remote server (a controller itself) and start sending tasks to the controller that will translate that in internal REST APIs to control for processes on downstream servers</p>
<p>Is there an authentication flow that will guarantee the owners of the controllers that I (the publisher of the front end) do not intercept the authentication flow and I gain unwanted access to their servers ?</p>
<p>My idea is to use a two steps authentication/authorization process like below. Is there a better way?
Please edit <a href=""https://dreampuf.github.io/GraphvizOnline/#digraph%20G%20%7B%0A%20%20node%20%5Bmargin%3D0%20fontcolor%3Dblue%20fontsize%3D8%20width%3D0.5%5D%3B%0A%20%20edge%20%5Bmargin%3D0%20fontcolor%3Dblue%20fontsize%3D8%20%5D%3B%20%20%0A%0A%20%20DesktopClient%20-%3E%20GUICloud%20%5B%20label%20%3D%20%22Step1%3A%20authentication%22%20%5D%3B%0A%20%20DesktopClient%20-%3E%20OnPremController%20%5B%20label%20%3D%20%22Step2%3A%20authorization%5Cn%20the%20user%20manually%5Cn%20allows%20the%20session%22%20%5D%3B%0A%20%20GUICloud%20-%3EOnPremController%20%5B%20label%20%3D%20%22cookie%22%20%5D%3B%0A%20%20OnPremController%20-%3E%20Server1%3B%0A%20%20OnPremController%20-%3E%20Server2%3B%0A%20%20OnPremController%20-%3E%20Server3%3B%0A%20%20GUICloud%20-%3EOAuth%3B%0A%20%20OAuth%20-%3E%20GUICloud%20%5B%20label%20%3D%20%22cookie%22%20%5D%3B%0A%0A%20%20OnPremController%20%5Bshape%3Ddoublecircle%5D%3B%0A%20%20GUICloud%20%5Bshape%3Dsquare%5D%3B%0A%7D"" rel=""nofollow noreferrer"">this diagram</a> if you have suggestions<br />
<a href=""https://i.stack.imgur.com/yBHYa.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/yBHYa.png"" alt=""enter image description here"" /></a></p>
<p>After looking closer at the issue I think this is a better architecture</p>
<p><a href=""https://i.stack.imgur.com/tnCrh.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/tnCrh.png"" alt=""enter image description here"" /></a></p>
","239509","","239509","","2020-06-29 19:17:12","2021-12-22 20:03:20","What is a recommended authentication architecture for a front GUI app that I want to control but that will be used by others to control their servers?","<security><authentication>","3","0","","","","CC BY-SA 4.0"
"412184","1","","","2020-06-30 11:21:38","","1","818","<p>I'm creating a complex web app (written in Nodejs with many containerised instances running in k8s). I may end up decomposing it into microservices down the line but for now it is monolithic.</p>
<p>Regular users will be able to sign up for an account via the web interface, but I need a small number of specific users to have admin privileges. Admin privileges may include inviting new users while in closed beta, or modifying resources belonging to regular users. At the moment, I have a user schema with a 'roles' field, which will allow a regular user to be elevated to an admin role - but how do I 'bootstrap' these users into place when there are no existing admin users?</p>
<p>These admin users need to exist in multiple environments, including testing environments where the db gets regularly wiped, as well as in production where the user should persist until the credentials are revoked (say if the person leaves the company).</p>
<p>The obviously stupid approach would be to just hard-code the creds for one admin user but that is clearly the worst idea of all time. I could manually insert the user into the database outside of the control of the app but allowing access to the db this way seems like it could present data integrity issues.</p>
<p>I'm using Amazon Secrets Manager to inject things like database credentials where they live as environment variables in the pod/container so it occurs to me I could do something similar for admin credentials, but how should the code handle this to create a user?</p>
<p>One option would be to have a function that runs once on startup each time a new instance of the code starts up which grabs the user credentials from AWS, checks if the users exist in the db already, and if they don't create a new user with the Admin role - and when the person leaves I'd need to delete the credentials from AWS and get another admin user to delete them from the app also. Or I could just store a list of known Admin email addresses and when they sign up as a regular user they automatically get the Admin role. Both of these options seem kind of off to me.</p>
<p>Or should the Admin users not be users at all? Should there instead be a separate Admin &quot;login&quot; system, where the credentials are just checked against the AWS creds each time the Admin logs in, instead of creating a regular user in the db? This would mean I would only have to worry about revoking the creds stored in AWS secrets when the user leaves, and the code wouldn't have to redundantly check for existing Admin users each time a new instance spins up. Down side is I'd have to restructure my permissions system a little but this approach seems to be more secure. Are there any negative implications of doing it this way?</p>
","334185","","","","","2020-06-30 11:21:38","How to handle creating first Admin users in a web app","<security>","0","3","","","","CC BY-SA 4.0"
"412720","1","","","2020-07-14 10:12:30","","0","325","<p>I am working on an anonymous survey module in ERP-system and I am thinking if there is a common approach to implement such systems to make them &quot;truly&quot; (I do understand that there still will be an attack to collate results with users with some degree of certainty) anonymous while preventing users from voting multiple times.</p>
<p>My current approach is to record separately survey results and users who voted (not linking them together), and delete vote records after survey completion. But I don't like that system stores users who voted and relies on mechanism that will run after survey to delete vote records.</p>
<p>I was also thinking about generating unique vote links for each user that I will create and send on survey launch but there will a problem with delivery path, because email/sms/messenger service will log messages.</p>
<p>Is it possible to improve that approach?</p>
","51378","","","","","2022-04-12 01:13:23","Model for anonymous surveys preventing duplicate votes","<design><architecture><security>","3","5","","","","CC BY-SA 4.0"
"412846","1","","","2020-07-17 22:15:17","","0","90","<p>I'm making my own client-side router which dynamically requests html pages from Firebase hosting, and the website uses Cloud Firestore with secure rules. Is there any XSS HTML event js injection danger like so:</p>
<p><code>&lt;button onClick = &quot;alert('Some harmful stuff is happening')&quot;&gt;Click me!&lt;/button&gt;</code></p>
<p>If I implement a client-side sanitizer, and is there any danger in general even if I don't sanitize incoming pages since all requests are same origin?</p>
","367551","","","","","2020-07-17 22:15:17","Is XSS by html event injection a problem in this client-side sanitization?","<javascript><security>","0","4","","","","CC BY-SA 4.0"
"199484","1","","","2013-05-26 06:23:59","","7","548","<p>A friend of mine while working on a PHP application asked me to write one part of the application in Java. The part that involved transactions. He said it will be better to write this portion in Java. He talked about how secure it will be!</p>

<p>Though I was too busy to  help him then, I want to know the essence of this idea. Why he was trying to use Java when he wrote the most part in PHP? Will it really boost up the security? And writing transactions in Java is only concerned with security?</p>

<p>The thing seems very interesting but I really have no idea, what it is! Please provide some insight into the topic.</p>

<p>Note: When I say transaction, it involves everything. From accessing account to transferring money.</p>
","34939","","2234","","2013-05-27 06:29:53","2013-05-27 06:29:53","How will writing the transaction part in Java benefit the security of the application, when all other parts are being written in PHP?","<java><php><web-applications><security><java-ee>","3","9","","","","CC BY-SA 3.0"
"315160","1","","","2016-04-08 14:32:47","","2","74","<p>I am developing a program which is to be installed on a ""simple"" machine in a LAN, the only particularity is that the NIC are connected on mirror ports.
The software can scan and monitor the network. What I am looking for is a technique to take down a host on this network.</p>

<p>When I discover a new host on the network I want to ""block"" it until I authorized it but the machine is not a firewall nor a real Network Access Controller (NAC) so I can only use passive methods.</p>

<p>I have tried ARP cache poisoning to associate a fake MAC with the real gateway IP in the target host ARP cache but there is two major issues:</p>

<ul>
<li>The victim can manually set the ARP cache entry of the gateway as static.</li>
<li>The victim can still communicate with the other LAN hosts.</li>
</ul>

<p>So I tried another method: poison the ARP cache of every hosts on the network except the victim's one. I send a broadcast ARP request (works better than reply) with the IP of the victim and a fake MAC. But there is still one issue:</p>

<ul>
<li>When the victim try to communicate with another LAN host, it sends an ARP request which put the valid MAC and IP association in the other hosts ARP cache.</li>
<li>The victim can also manually sends ARP requests or replies to overwrite the fake MAC in the hosts ARP cache.</li>
</ul>

<p>For these reasons I wonder if there is a better method to accomplish such a thing.</p>
","223773","","31260","","2016-04-08 14:33:57","2016-04-08 14:33:57","Technique to passively take down a host on the network","<security><monitoring>","0","2","","2016-04-18 23:40:03","","CC BY-SA 3.0"
"199705","1","","","2013-05-28 21:28:12","","0","683","<p>I am developing an ASP.Net MVC 3 intranet site that will use Integrated Windows Authentication exclusively. What are the vulnerabilities of the challenge/response authentication traffic being sent in plain text? Will someone sniffing the network traffic be able to hijack an authenticated session?</p>
","10126","","","","","2013-05-28 21:30:54","Asp.Net MVC Windows authentication - vulnerabilities of http vs https?","<asp.net><security><asp.net-mvc>","1","0","","","","CC BY-SA 3.0"
"199755","1","199808","","2013-05-29 07:58:18","","0","134","<p>I'm securing a WCF webservice with <code>TransportWithMessageCredential</code> security that uses certificates.
So I'll have to choosee between <strong>signing</strong> headers &amp; body or <strong>signing and encrypting</strong>.</p>
<p>Now my question is, after reading <em><a href=""http://msdn.microsoft.com/en-us/library/aa347692.aspx"" rel=""nofollow noreferrer"">Understanding Protection Level</a></em> what the advantage is of just signing? The fact that WCF will notice that someone has been messing around with the message and going to reject it or am I wrong?</p>
<p>Thanks in advance.</p>
","24798","","-1","","2020-06-16 10:01:49","2013-05-29 15:45:37","How does signing headers and/or body provide security","<security><soa><soap>","1","0","","","","CC BY-SA 3.0"
"199948","1","","","2013-05-30 15:54:55","","7","2732","<p>Most of my work is creating websites in Django (a Python web framework) and deploying them to my own or clients' servers. I work from a <code>virtualenv</code> to separate site from system packages and have perhaps 60-80 packages installed in there and that lot is  shared between two-dozen sites.</p>

<p>This obvious limitation to this approach is needing to test every site if I upgrade a package it uses. I consider that a fair trade-off for not needing to keep on top of umpteen separate virtualenvs.</p>

<p>And that is essentially my whole problem. <strong>How on earth are you supposed to keep on top of <code>virtualenv</code> deployments?</strong> People just seem to treat them like a dumping ground but if the programming universe has learnt anything this past week from the Ruby on Rails explosion, using old versions of software is unacceptable.</p>

<p>I have a simple script that attempts to check for current package versions with the latest <code>pip</code> counterpart but it's quite inacurrate. It also doesn't differentiate between security upgrades and feature upgrades (which require days of testing and fixing).</p>

<p>I am looking for something better. I am looking for something that can let me know if Django has a new security release out, or if something is end-of-life. I want something to help me (and other Python devops) not become the next batch of people crying after a wave of kids with scanners and scripts convert our servers into a botnet.</p>

<p>Does such a thing exist?</p>
","12503","","","","","2018-09-19 09:35:55","How can I keep a production Python environment secure?","<web-development><python><security><maintenance>","5","2","","","","CC BY-SA 3.0"
"413277","1","","","2020-07-30 01:14:37","","0","64","<p>I'm developing an Ionic 4 based (Angular) web application. It has a lot of logic on it and needs to store session specific data (such as a JWT, selected language, among other preferences and temporary settings).</p>
<p>But recently I've been working a lot on its security. The last piece I'm trying to sort out is removing everything from the localStorage (specially user info and the JWT). I have contemplated cyphering the info using crypto-js (with AES256), but anyway the key will be on the client at some point. Also I contemplated obfuscating the data using atob() btoa() methods but that's even easier to sort out.</p>
<p>The things I'm exploring right now are:</p>
<ul>
<li>Having everything on a document based database such as DynamoDB, but
in that way all user's data will be there anyway, in case everything
access it</li>
<li>Using a singleton that holds all that data, with the
disadvantage that it won't be persistent</li>
</ul>
<p>What would you recommend? Thanks in advance.</p>
","151658","","151658","","2020-07-30 01:24:37","2020-07-30 01:24:37","How secure LocalStorage on a SPA","<security><front-end><code-security>","0","2","","","","CC BY-SA 4.0"
"200041","1","200057","","2013-05-31 12:02:54","","40","4478","<p>When forming opinions, it is a good practice to follow scholastic tradition - think as hard as you can <em>against</em> the opinion you hold and try to find counter-arguments.</p>

<p>However, no matter how hard I try, I just cannot find reasonable arguments in favor of antivirus (and related security measures) on development machines.</p>

<p>Arguments against antivirus(AV) in development are plentiful:</p>

<ol>
<li>It is not uncommon for 1 minute build to take 10 times longer with AV on</li>
<li>In a conference talk, IntelliJ developers claim AV software is #1 suspect when their IDE is sluggish</li>
<li>Unzipping comes with roughly 100 kb/s speed with AV on</li>
<li>AV renders Cygwin completely unusable (vim takes 1 minute to open a simple file) </li>
<li>AV blocks me from downloading useful files (JARs, DLLs) from colleagues' e-mails</li>
<li>I can't use multiple computers for development, since AV / security measures prevent me from unblocking ports</li>
<li>AV kills performance of programs with high file turnover, such as Maven or Ant</li>
</ol>

<p>Last, but not least - what does AV actually protect me from? I am not aware of my AV program ever stopping any security thread.</p>

<p>If the reason is fear of disclosing NDA stuff - no AV can possibly prevent me from doing it if I set my mind to it.</p>

<p>If the reason is fear of losing source code and/or documentation - there are distributed revision systems for this (there are at least 20 copies of our repo and we sync on daily basis).</p>

<p>If the reason if fear of disclosing customer data - developers rarely work connected to real production databases, instead they are playing around in toy environments.</p>

<p>Even if there are meaningful arguments in favor of having AV on development machines, they fall apart when faced with the ability to run a Virtual Machine in your paranoidly protected environment.</p>

<p>Since I want to keep an open mind of the issue, could anyone present meaningful, strong argument in favor of Anti-virus software for developers?</p>
","92669","","25936","","2015-05-07 17:27:18","2015-05-07 17:27:18","Looking for meaningful, strong argument in favor of antivirus software on development machines","<security><hardware><development-environment>","9","22","","2013-06-05 05:44:07","","CC BY-SA 3.0"
"315609","1","","","2016-04-13 12:36:15","","0","110","<p>I'm building a API that gets called from web / mobile applications written using Ionic (web languages on mobile), which uses Angular.js.</p>

<p>We want to be able to do server side validation of forms but don't want to have to rewrite functions constantly to match each form. However, we need to make sure the forms are verified completely, containing all intended fields, and having no extra fields, Since form submissions like this are easily modified by the user.</p>

<p>Would having a universal handler for the form be a good idea? Something that looped through all submitted fields and using a switch to match their type to a certain formatting? And to ensure it was the right set of fields, having a form identifier that reads the list of fields it should have from a database?</p>
","223369","","","","","2016-04-28 17:38:47","Universal Form Handler","<architecture><security><validation>","1","0","","","","CC BY-SA 3.0"
"414351","1","","","2020-07-31 21:52:33","","-2","59","<p>I have been reading the AWS documentation for a solid 2 weeks, and configuring a terraform system to deploy a multi-region network. I have it mostly wired up, but I am not sure I have accounted for all the pieces in the system. I would like to ask if the system or &quot;recipe&quot; I am about to outline is wired up correctly from a high-level architecture standpoint, and if I'm missing anything important or doing anything wrong in these pieces.</p>
<p>It starts with the Global Accelerator, goes through VPN to Load Balancer to Subnet to Instance basically. But some stuff feels a bit redundant and I'm not sure if I'm using things entirely correctly yet. Here is the recipe:</p>
<ul>
<li>1 Global Accelerator for the world.</li>
<li>1 Global Accelerator Listener for the different internet ports your application works under. (HTTP 80, HTTPS 443 by convention).</li>
<li>1 Global Accelerator Endpoint Group per Global Accelerator Listener.
<ul>
<li>Connect it to each VPC Load Balancer.</li>
</ul>
</li>
<li>1 VPN per user. Use this to connect to the network.</li>
<li>1 VPC per region.</li>
<li>Public and Private subnets for each Availability Zone (can subdivide however you like).</li>
<li>1 Application Load Balancer per VPN. <em>Or should it be 1 per Subnet?</em>
<ul>
<li>Connect the 1 Load Balancer to the Public Subnet in each Availability Zone. So 1 Load Balancer spans all Availability Zones.</li>
<li>Connect 1 Security Group to the Load Balancer.</li>
</ul>
</li>
<li>1 Security Group per Subnet. This applies to instances in a subnet.</li>
<li>1 Network ACL for each Subnet. This applies to the network as a whole.</li>
<li>1 NAT Gateway per private subnet that connects to the internet (egress). This means 1 NAT Gateway per subnet per availability zone.</li>
<li>1 Internet Gateway per public subnet that connects to the internet (egress). This means 1 Internet Gateway per subnet per availability zone.</li>
<li>1 Route Table for each Subnet.</li>
<li>1 Route for each Route Table for each connection.</li>
<li>1 Network Interface per Instance (can be attached to different instance if one fails).</li>
<li>IAM roles and users play a role on the instance, but I haven't gotten there yet.</li>
<li>Autoscaling groups play a role as well, but haven't gotten there yet.</li>
</ul>
<p>The question I have is:</p>
<ul>
<li>What to do with Elastic IP addresses? They are connected to a Network Interface (and there is 1 Network Interface per Instance). Does that mean each Instance has essentially 1 Elastic IP Address? They are also connected to the NAT Gateway (allocation_id). What does this mean?</li>
<li>What is the order of steps a request goes through? It starts at HTTPS in the browser, then goes to the DNS which somehow goes to the Global Accelerator anycast system. This goes to the Endpoint group configuration (load balancer) that is closest to the request origin. HTTPS is terminated at the load balancer and goes to HTTP internally. The Load Balancer is connected to a Public Subnet, which hahs a security group, NACL, and route table which tells it how to direct traffic to the next layer in the system. <em>Where does the Internet Gateway fit in, specifically with the Load Balancer already handling internet traffic?</em> The HTTP requests then goes to the next subnet, and next subnet, until it reaches the proper subnet based on the target IP. Then it goes to the Network Interface, which does something? Then it goes to the instance.</li>
<li>Is there anything I am missing in this configuration? Anything that can be improved or in which there are clear best practices?</li>
</ul>
<p>This is just for making a request. I haven't done Route53 yet, but I think I can figure that part out.</p>
","73722","","73722","","2020-07-31 21:58:01","2020-08-01 01:00:07","A Recipe for Handling an AWS Network Request from Start to Finish at Global Scale","<architecture><security><http><networking><aws>","1","0","","","","CC BY-SA 4.0"
"414585","1","","","2020-08-07 18:49:16","","0","58","<p>I'd like to create a web API. It would be used on my websites and potentially by others as well. I intend to use a single token to authorise users. You see, this API acts as an OAuth2 client (or medium, I don't quite know how to express it) so it needs to be a front-end of sorts in itself to achieve redirecting the user through the authorisation. However, I'm a bit shaky on how I should go about it despite looking at several resources detailing security practices and general specifications.</p>
<p>Would it be reasonable to set the authorisation token as a HTTP-only cookie? Of course not the result of OAuth, but a generated one.</p>
<p>If I read Mozilla <a href=""https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies"" rel=""nofollow noreferrer"">documentation</a> right, using HTTP-only cookies would allow me to set cookies for individual users, with no way of the websites using the API having access to it. And when they send a request, the cookie would automatically be added to it.</p>
<p>What other security practices should I employ? So far I've gathered a list of header and cookie options:</p>
<ul>
<li>HTTP-only cookies: seem to be the way to go</li>
<li>Secure cookies: packaged with HTTP-only</li>
<li><strike>Same-site cookies</strike>: seems like they would prevent other websites from using the API</li>
<li><code>Strict-Transport-Security: max-age=year; includeSubDomains</code> surely a no-brainer</li>
<li><code>Content-Security-Policy: default-src 'self' *.example.com</code> I feel like this doesn't apply to APIs but rather front-ends</li>
<li><code>X-Content-Type-Options: nosniff</code> honestly, I don't quite know</li>
<li><code>X-XSS-Protection: 1; mode=block</code> used as a backup for a well-defined <code>CSP</code> that is not supported on some browser</li>
</ul>
","301321","","","","","2020-08-07 18:49:16","Security and cookie practices for an API of a website","<web-applications><security><web-api>","0","2","","","","CC BY-SA 4.0"
"200511","1","","","2013-06-05 08:36:34","","18","10857","<p>I've read many, many, <em>many</em> posts on how ""you're probably storing passwords wrong"". They are always referring to storing passwords on a server into which a user is logging; they basically rehash (pun intended) ubiquitous advice like make sure to salt the passwords, etc. etc. However, I've never seen an article on best practises for storing passwords on a <em>client</em> so that the client doesn't have to log in manually every time they want to log in; the ""remember me"" feature.</p>

<p>Many pieces of software have this feature, from browsers to programs like Dropbox.</p>

<p>I did read <a href=""http://news.softpedia.com/news/Design-Security-Flaw-Allegedly-Discovered-in-Dropbox-Client-194427.shtml"">an old article</a> recently about how Dropbox was storing an ID on your computer that you could just copy/paste to another computer and start Dropbox and be logged in as the device you got the ID from; no login, no nothing, and full access to the Dropbox account. This seems like a really stupid design, but I can't think of any better way to do it.</p>

<p>I'm not even sure how to avoid storing something like a cookie in plain-text. If you encrypt it, where do you store the key to decrypt it?</p>

<p>The only way I see to not introduce security vulnerabilities is to remove the autologin feature and make the user type their password every time they want to use  a service, but that's a usability struggle and users are spoiled to expect not to have to do that.</p>

<p>What can I read about locally storing credentials safely to implement the automatic login feature? If the principles are too simple for an entire article, what are they? The software in question should not depend on features not present on all platforms (like the ""keychain"" some linux distributions have).</p>
","93089","","93089","","2013-06-05 09:00:35","2016-01-27 07:16:55","How to securely implement auto-login","<security><login>","4","7","","","","CC BY-SA 3.0"
"414664","1","414697","","2020-08-10 08:52:40","","0","271","<p>Recently I have started rewriting my Rails app to <a href=""https://roda.jeremyevans.net/"" rel=""nofollow noreferrer"">Roda</a>, and encountered a hiccup.</p>
<p>While Rails uses a single CSRF token for the entire application (and stores it in a <code>meta</code> tag), Roda recommends using <a href=""https://roda.jeremyevans.net/rdoc/classes/Roda/RodaPlugins/RouteCsrf.html"" rel=""nofollow noreferrer"">route-specific CSRF tokens</a>.</p>
<p>So, if I have a table of entities on my index page, and I'd want to edit (and update) some of those entities inside said table, I would naturally need to obtain tokens for each entity (since each of them has their own path).</p>
<p>Currently, I ship the tokens in a field in the JSON api, so it looks a bit like this:</p>
<pre><code>{
    &quot;createToken&quot;: &quot;D5pnSokPWiutf2X0Z+lCUshSNfJs3Sv+MvNcg8lxmg3Uh5r57I/EX2ObG1aAChVrxXq1/efv61akUsoN9grt&quot;,
    &quot;data&quot;: [
        {
            &quot;_meta&quot;: {
                &quot;updateToken&quot;: &quot;KKNnxZ9BAdSSjH5oQvHr3AwXcyUHOWH3pHNT1VSTNMqXOVLg4/rK3JQH3h6DeBucGdfvQM+MQU8HGibxonah&quot;
            },
            &quot;id&quot;: 109,
            // Omitting more data
        },
        // Omitting more elements
    ]
}
</code></pre>
<p>But I'm not happy with it. After all, the point of a CSRF token is that it should be hard to obtain for an attacker, but here they can obtain it with just an extra query...</p>
<p>So, is this a good way to serve the entity-specific tokens from backend to frontend? Are there any better ways?</p>
<p>Thank you.</p>
","179431","","","","","2020-08-10 22:31:34","What would be a good way to obtain route-specific CSRF tokens for an API?","<api><security>","1","1","","","","CC BY-SA 4.0"
"200790","1","200799","","2013-06-07 10:36:10","","39","30742","<p>My question has to do with JavaScript security.</p>

<p>Imagine an authentication system where you're using a JavaScript framework like <a href=""http://en.wikipedia.org/wiki/Backbone.js"">Backbone</a> or <a href=""http://en.wikipedia.org/wiki/AngularJS"">AngularJS</a>, and you need secure endpoints. That's not a problem, as the server always has the last word and will check if you're authorized to do what you want.</p>

<p>But what if you need a little security without involving the server? Is that possible?</p>

<p>For example, say you've got a client-side routing system and you want a concrete route to be protected for logged-in users. So you ping the server asking if you're allowed to visit protected routes and you go on. The problem is that when you ping the server, you store the response in a variable, so the next time you go to a private route, it will check that if you're already logged in (no ping to the server), and depending on the response it will go or not.</p>

<p><strong>How easy is for a user to modify that variable and get access?</strong></p>

<p>My security (and JavaScript) knowledge isn't great. But if a variable is not in global scope and is in the private part of a module pattern which only have getters but not setters, even in that case, can you hack the thing out?</p>
","59749","","591","","2013-08-26 18:18:27","2016-12-19 07:13:56","How easy is it to hack JavaScript (in a browser)?","<javascript><security><browser><hacking>","5","12","","","","CC BY-SA 3.0"
"200802","1","","","2013-06-07 11:50:02","","6","2560","<p>I understand PKI well from a conceptual point of view - i.e. private keys/public keys - the math behind them, use of hash &amp; encryption to sign a certificate, Digital Signing of Transactions or Documents etc. I have also worked on projects where openssl C libraries were used with certs for securing communication and authentication. I am also extremely familiar with openssl command line tools.</p>

<p>However, I have very little experience with webbased PKI projects &amp; hence I am trying to design and code a personal project for this.</p>

<h2>The requirements</h2>

<p>(This is a learning project - This is never going to be used in a bank)</p>

<p>This is the website for a bank. All Internet Banking users are allowed use any signing certificate issued by a few known CAs (verisign, Thawte, entrust etc). The Bank is not responsible for procuring certificates for the user. The user logs into the bank site with his userid/password etc. He has access to most parts of his account. However, when the user wants to do a transaction - like transferring money to different account - the bank wants him to sign the transaction with a certificate.</p>

<h2>The design</h2>

<p>When user choses ""Transfer"" option - the website throws up a form where there are 3 entries - ""Transfer To"" account, the Amount of the transaction and a way for chosing a cert for doing the digital signing &amp; do the signing.</p>

<p>I concatenate the ""Transfer To"" Account no &amp; the amount plus a nonce and this is the string which will be signed and sent to the backend.</p>

<p>I have searched a lot but haven't been able to figure out how to achieve 
- letting the user chose a cert
- do the signing.</p>

<p>I know how the user can add certs to his personal truststore on Windows. But how would I ask the browser to show him certs to chose from?</p>

<p>How does the signing get done - I really don't want to write crypto code in Javascript!!! So is the alternative having an ActiveX or a Java Applet? Is there a better way? Is there a way to ask the browser to use the cert and do the signing?</p>

<p>I have not decided on a platform/framework/language for now - so this question is rather generic.</p>

<p>I have searched a lot for this kind of info without luck - all I get is tutorials on digital signing, tutorials on how to enable PKI in Apache etc.</p>

<p>If someone feels my whole approach is wrong &amp; there is a better way to do digital signing in a web-app - feel free to suggest those alternatives also.</p>
","69796","","69796","","2013-06-08 04:21:10","2013-06-12 07:13:58","Implementing Digitally signed data in a Web Application","<web-applications><security><browser><certificate>","1","13","","","","CC BY-SA 3.0"
"414995","1","414998","","2020-08-19 12:58:24","","-4","328","<p>I am developing an SDK which users would use to access my service<br>
The authorization is done using an API key, which is unique to each user.<br>
SDK makes API calls to my server using the provided API Key<br></p>
<p>My question is how do I secure the API Key passed in as a header in the API calls?<br>
Should I encrypt the key while sending it over the network using RSA? But, then there will be two issues:</p>
<ol>
<li>Shipping a public key with the SDK</li>
<li>Overhead of reading keys from file for every API call</li>
</ol>
<p>Is there a better approach to this?</p>
","349317","","","","","2020-08-19 14:25:28","Secure way to send API key","<api><security>","1","4","","","","CC BY-SA 4.0"
"201108","1","","","2013-06-11 03:05:31","","0","42","<p>I understand PKI reasonably well from a conceptual point of view - i.e. private keys/public keys - the math behind them, use of hash &amp; encryption to sign a certificate, Digital Signing of Transactions or Documents etc. I have also worked on projects where openssl C libraries were used with certs for securing communication and authentication. I am also extremely familiar with openssl command line tools.</p>

<p>However, I have very little experience with web based PKI enabled projects &amp; hence I am trying to design and code a personal project for understanding this better.</p>

<h2>The requirements</h2>

<p>This is the website for a bank. All Internet Banking users are allowed use any certificate issued by a few known CAs (verisign, Thawte, entrust etc). The Bank is not responsible for procuring certificates for the user. These certificates will be used for authentication to the banks website either instead of or as an add-on to username/password login. The platforms/OS etc are still not fixed. Assume that enrollment has been done - i.e. bank knows the certificate going to be used by each user.</p>

<h2>Design</h2>

<p>I was wondering what's the best way to do authentication?</p>

<ol>
<li><p>I saw that Apache has a way to enable 2 way ssl - in this case, i think navigating to the website would automatically ask for a cert from the user. But I am not sure if this is enough because it seems that all it verifies is whether a certificate is signed by a trusted CA &amp; also may be whether it falls in a white list of subject lines of the certificates etc. But this is not enough for a bank case because you need to be able to associate a bankuserid with a certificate.</p></li>
<li><p>IIS seems to have a way by which I can have a certificate stored for each user in Active Directory. This is what I understood from reading few MSDN articles. You turn on 2 way SSL in IIS &amp; then when the user tries to navigate to the website, IIS will send a request to the browser with a list of approved CAs and browser will let the user pick an appropriate certificate from his certstore and sends it to backend. I am assuming that IIS will do 2 things</p>

<ul>
<li>Ensure that the user has the private key corresponding to the cert (by under the cover negotiations)</li>
<li>Based on the AD User-Cert Mapping, IIS will report the username to the application.</li>
</ul></li>
<li><p>Do the authentication explicity by calling crypto functions rather depending on depending on the webserver to do it.</p>

<ul>
<li>Show a user screen where he uploads a certificate and the application ensures the user has the private key corresponding to the cert (by asking the front-end to sign some string using the cert).</li>
<li>The application has a database some of data is stored which allows each user to be mapped to his userid. This may be </li>
<li>the whole cert corresponding to each userid</li>
<li>the CA and cert serial number corresponding to each user id.</li>
</ul></li>
</ol>

<p>I was wondering which is the commonly used method? What are the best practices?
If I should go with #3, what are the best ways to do this?</p>
","69796","","","","","2013-06-11 03:05:31","Login to a Web App using PKI Certs","<web-applications><security><authentication><certificate>","0","0","0","2013-06-11 11:06:15","","CC BY-SA 3.0"
"201510","1","201612","","2013-06-14 09:53:56","","4","1806","<p>The tutorials I've read tell you to use [ValidateAntiForgeryToken] attributes and <code>&lt;%= Html.AntiForgeryToken() %&gt;</code> in your code.</p>

<p>I was wondering why this isn't a built-in automatic setting or at least a global toggle in the web.config. Perhaps it is, and I haven't realised, but I am doing it by hand and I can't help but wonder if there is a good reason for not handling it automatically behind the scenes. Any ideas?</p>
","13850","","","","","2013-06-15 01:45:01","Is there a setting to enable anti forgery globally in ASP.NET MVC, and if not, why?","<security><asp.net-mvc>","1","4","","","","CC BY-SA 3.0"
"201596","1","201628","","2013-06-14 22:42:23","","6","845","<p>I was wondering how secure public private key encryption methods are.</p>

<p>If two individuals were sending emails back and forth forever, where each person would encrypt the body of the email they were sending with the other person's public key, would anyone be able to decrypt the body of those emails after a while? </p>

<p>I'm assuming that each person creates their own private-public key pair and then if you wanted to send someone an email you would grab their public key and encrypt your message before sending it to them. They would then decrypt it with their own private key.</p>

<p>Wikipedia (<a href=""http://en.wikipedia.org/wiki/Public-key_cryptography"">http://en.wikipedia.org/wiki/Public-key_cryptography</a>) claims that its effectively impossible to decrypt email if all you know is the public key. But is this really true? What if you had the resources of the NSA, are they not able to brute force the decryption?</p>
","63609","","","","","2013-06-15 06:13:25","Public-key cryptography security given NSA resources","<security><encryption>","4","4","","","","CC BY-SA 3.0"
"317174","1","317177","","2016-04-29 22:50:30","","11","5466","<p><strong>Question 1</strong></p>

<p>I have a login API endpoint</p>

<pre><code>http://127.0.0.1:8080/api/account/login
</code></pre>

<p>It checks if the phone number has been validated. If not it will call</p>

<pre><code>POST http://127.0.0.1:8080/api/account/sendsms  country_code=1, phone_number=1234567
</code></pre>

<p>How can I prevent abuse to requesting sms? (It'll cost money on my part. I also have throttle function)<br> I only want sms to be sent if <code>/login</code> failed (at this point email has been validated)<br>
The way I do is to send a custom header <code>X-TOKEN-SMS</code> which acts like an authorization header with jwt token. X-TOKEN-SMS jwt token is created at <code>/login</code> if phone number is not validated = True. <br>
When <code>/sendsms</code> decodes the jwt without error, proceed with requesting sms.
If jwt decodes with error then the front-end will redirect to <code>/login</code>.</p>

<p>Is this method a good practice?<br>
How do you allow an API endpoint to be accessed only if some endpoint has been accessed?</p>

<p><strong>Question 2</strong></p>

<p>Let's say I have an endpoint that can only be accessed by an authorized user</p>

<pre><code>http://127.0.0.1:8080/api/account/points
</code></pre>

<p>The user can GET points(retrieve all of his/her points)
POST points (create a new point) or PATCH (update a point)</p>

<p>How can I prevent an authorized user from abusing the POST /points? They might add points as they please, which is not what my app want it to be. Adding points should be handled by the app logic. </p>

<p>If adding point should not be consumed by REST API, then create a new row directly to the db is more secure?</p>

<p>I found a similar question asked before <a href=""https://softwareengineering.stackexchange.com/questions/273409/secure-rest-api-from-authenticated-user"">Secure Rest api from authenticated user</a>
But couldn't seem to understand it.</p>
","70237","","-1","","2017-04-12 07:31:37","2016-05-05 08:52:06","Prevent abuse to REST API endpoint","<rest><security><api><authorization>","2","1","","","","CC BY-SA 3.0"
"202111","1","","","2013-06-20 08:16:21","","5","627","<p>I am building an web site which will allow users to aggregate the information stored in their online profiles (""data feeds"") in one place. </p>

<p>I am wondering - what is the accepted (from a secureness point of view) way to store user name / password information in a my database? </p>

<p>Normally I would derive a salted-hash value from a password and would store this, but that obviously would not work in this case, as ""data feeds"" websites would need an actual password.</p>

<p>Storing the credentials it in a clear text is not an option, as it would be a huge security risk.</p>

<p>Not storing passwords in a database, asking users to type them in at the beginning of each session and then keeping them in a in-session memory does not seem like a viable option either, as it would be too much trouble for users to enter the same passwords many times again and again.</p>

<p>So far it seems that the only option is to encrypt passwords somehow, but I don't know what are the best design patters for such option.</p>

<p>Or perhaps there is way to deal with that problem, I haven't even considered ...</p>

<p>What would you recommend? </p>
","75470","","7422","","2013-06-20 08:31:26","2013-06-20 11:11:00","How to store / not to store passwords","<security><passwords>","3","7","","","","CC BY-SA 3.0"
"415962","1","","","2020-09-17 00:41:10","","1","441","<p>I'm developing a web service that have following structure:</p>
<ol>
<li>Web Server: this is implemented with NextJS which do Server-Side Rendering and serve server-side rendered webpage data to Client.</li>
<li>API Server: and this one is implemented with NestJS. Clients will send  graphql queries/mutations to this server.</li>
<li>Client: any clients can visit my web service and sign in (or sign up)</li>
</ol>
<p>and I want to implement authentication feature for my web server, but problem is came up here. how can I <strong>share</strong> the auth data between <code>Web Server, API Server, Client</code>? if you signed in on your own browser, eventually a signing request will be sent to the API server.</p>
<p>but there's literally no way to know whether the client is signed in or not from <code>Web Server</code>. I mean, auth data (<code>whether if user has signed in or not</code>) will be stored only at <code>API Server</code>.</p>
<p>I had searched and spent a lot of time about this and I've got an answer that I have to use JWT Token but there were several ways to store it:</p>
<ol>
<li><p>Storing it on clients' web storage: I don't think this can be an answer since the <code>Web Server</code> shouldn't able to get clients' web storage data. this means SSR (server-side rendering) wouldn't work well.</p>
</li>
<li><p>Storing it on <code>Cookie</code>: this is bad too. because we send a signing in request to the <code>API Server</code> that will be on different container (or server) and domain. we cannot set cookies <strong>from</strong> different domain with proper way. and if we get token and store it cookies directly from client side (setting cookie from javascript), It will be really huge security issue since attackers can take users' token with XSS.</p>
</li>
<li><p>Using <code>Cookie</code> but set from other subdomains with specifying <code>Domain</code>: we can specify domain for setting cookie. as far as I know, a response from <code>api.example.com</code> can set cookies for <code>example.com</code> with specifying <code>Domain</code> property of <code>Set-Cookies</code> value. <a href=""https://stackoverflow.com/questions/18492576/share-cookie-between-subdomain-and-domain#:%7E:text=The%202%20domains%20mydomain.com,%22host%2Donly%20cookie%22."">read this</a></p>
</li>
</ol>
<p>yeah, method 3 seems pretty neat to have but I absolutely don't know that setting cookies from another sub-domains will cause big security hole. my web service will process about users' money so security issues will come very critical.</p>
<p>someone I know advised me that I can use reverse proxy with <strong>paths</strong> not domain. I mean, if <code>API Server</code> was serving on <code>api.example.com</code>, we can serve it on <code>example.com/api/*</code> so now we can share the cookies between all the server and client. but we should store cookies on web storage too since cookies will be flagged as <code>HttpOnly</code>. this will cause increasing complexity of development.</p>
<p>In this case, which method will be the <strong>best</strong> answer for my case? are these methods I've mentioned above are really safe to do?</p>
","374993","","","","","2021-01-06 23:17:30","How can I share authentication information between all the server?","<web-development><security><node.js><authentication>","1","0","","","","CC BY-SA 4.0"
"317762","1","317763","","2016-05-06 22:02:44","","-1","435","<p>I've been studying the cyber security field with great interest. I understand how networking can help cyber security but I am not sure how advanced programming knowledge can help fight cyber crime or why certain cyber security experts need programming knowledge. 
In my experience so far with penetration testing tools and networks i came across some need for it, such as bash shell scripts and a bit of python but not enough to become an expert.
In what ways can programming help fight cyber crime? Hope the question is not too general.</p>
","227459","","","","","2016-05-06 22:11:51","In what way does programming help towards cyber security","<python><security>","1","4","0","2016-05-09 11:59:34","","CC BY-SA 3.0"
"317867","1","","","2016-05-08 10:57:11","","1","162","<p>I have built a simple authentication system for my web application that makes use of the open-source time-based OTP algorithm (<a href=""https://www.rfc-editor.org/rfc/rfc6238"" rel=""nofollow noreferrer"">RFC 6238</a>). The key for each user is generated when the user is registered in the system. When the user first signs into their account, they are asked to set up their authenticator apps with the provided QR code.</p>
<p>Now, I've done a bit of research, and couldn't find much on the topic, so I'd like to know from you when the secret keys generated by the application need to be reset.</p>
<p>Is it a good idea to have the key reset if the user changes their passphrase? If so, what is the best way to present their new QR code to them? I would assume that there are two choices: the first is to present it to them the next time they sign in, and the second is to send the actual QR to them in the email that lets them know their passphrase changed. For me, the latter is more secure, but I guess it wouldn't make much of a difference if email is used to reset the passphrase anyway.</p>
<p>Your thoughts and insights on this topic would be most appreciated.</p>
","82704","","-1","","2021-10-07 07:34:52","2021-07-28 14:37:47","When do I reset Two Factor Authentication secret keys?","<web-applications><security><authentication><qr-code>","1","1","","","","CC BY-SA 3.0"
"202842","1","202854","","2013-06-26 16:29:23","","5","2747","<p>Using signed manifests in ClickOnce deployments, it is not possible to modify files after the deployment package has been published - installation will fail as hash information in the manifest won't match up with the modified files. I recently stumbled upon a situation where this was problematic - customers need to be able to set things like connection strings in app.config before deploying the software to their users.</p>

<p>I got round the problem by un-checking the option to ""Sign the ClickOnce manifests"" in VS2010 and explicitly excluding the app.config file from the list of files to have hashes generated during the publish process.</p>

<p>From <a href=""http://msdn.microsoft.com/en-us/library/che5h906.aspx"" rel=""nofollow"">a related page on MSDN</a></p>

<blockquote>
  <p>""Unsigned manifests can simplify development and testing of your
  application. However, unsigned manifests introduce substantial
  security risks in a production environment. Only consider using
  unsigned manifests if your ClickOnce application runs on computers
  within an intranet that is completely isolated from the internet or
  other sources of malicious code.""</p>
</blockquote>

<p>In my situation, this isn't an immediate problem - the deployment won't be internet-facing. However, I'm curious to learn what the ""substantial security risks"" of what I've done would be if it was internet-facing (or if things changed and it needed to be in the future).</p>

<p>Thanks in advance!</p>

<hr>

<p><strong>Edit / follow-up:</strong></p>

<p>Does <em>not signing</em> the ClickOnce manifest constitute an unsigned manifest (as per MSDN's definition)? The application manifest contains a hash of the files in the deployment package. Any changes to the files within it results in a validation failure during installation. Does this negate the above security risks, at all?</p>
","79698","","79698","","2013-07-02 12:29:14","2015-10-30 15:42:34","Security Risks of Unsigned ClickOnce Manifests","<.net><security><deployment><installer>","1","2","","","","CC BY-SA 3.0"
"202938","1","202946","","2013-06-27 13:55:14","","4","2351","<p>I have been working on some software application and I update them every 6 months. Currently, the way I track the date is by extracting the date from the system when the user installs the application, encrypt it and store it in a file locally. Whenever the application is started, it checks if 6 months have passed, then it works or it doesn't, in which case it shows an error message telling the user to update.</p>

<p>If the user finds the encrypted date in the file they can simply replace it with one from a more recent install. I am wondering if there's a more secure way to do this? </p>
","94998","","31260","","2016-12-20 15:24:47","2016-12-20 15:24:47","Secure an Application/Software by expiration with Date?","<security><software-updates>","2","6","","","","CC BY-SA 3.0"
"318471","1","","","2016-05-14 03:52:12","","2","976","<p>This is how I do my JWT refresh token:</p>

<p>A token is check for validity every time a request is made.
If it's not expired, allow access.</p>

<p>If it's expired calls another function named RefreshToken to give a new token to the user.</p>

<p>Ok this mechanism is good enough except that every expired token (of that user, provided that it is valid) can fire up the creation of a new fresh token. </p>

<p>For example<br>
Expiration is at 15 minutes.<br>
Token A is created.<br>
Token A asks for a new refresh token after 1 hour.<br>
New token is issued, named Token B.<br>
After 15 minutes, Token B is expired.<br>
Now, Token A and Token B can ask for a new token.<br>
Wouldn't that create the ability to issue token exponentially?<br>
Just from 1 token. <br>
And the token can issue another token and so on.
An expired token 15 years ago can issue a new refresh token today even though it was used some time in 15 years ago and had issued another token too.</p>

<p><a href=""https://i.stack.imgur.com/GjRQb.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GjRQb.png"" alt=""enter image description here""></a>  </p>

<p>Now every token issued can create another token.
Can I just allow Token A --> Token B --> Token E
without storing expired token into database?</p>

<p><strong>Order of token alphabet takes precedence</strong></p>
","70237","","70237","","2016-05-14 05:11:07","2016-07-13 16:55:07","JWT refresh token exponentially?","<security><authentication>","2","1","","","","CC BY-SA 3.0"
"418304","1","","","2020-10-24 12:41:17","","-4","3991","<p>In Computer Systems: a Programmer's Perspective,</p>
<blockquote>
<p>Unfortunately,
a number of commonly used library functions, including <code>strcpy</code>, <code>strcat</code>, and
<code>sprintf</code>, have the property that they can generate a byte sequence without being
given any indication of the size of the destination buffer [97]. Such conditions can
lead to vulnerabilities to buffer overï¬‚ow.</p>
</blockquote>
<p>Since <code>strcpy</code>, <code>strcat</code>, and <code>sprintf</code> are dangerous, what shall we use instead of them, or how shall we use them correctly/securely?</p>
<hr />
<p>In the book, there is an example of implementing a simple shell, which calls <code>strcpy()</code>. I was wondering what purpose is <code>strcpy(buf, cmdline)</code> in <code>eval()</code>?  Does it introduce security vulnerability, or does it improve  security, by limiting the size of the char array to an known size? Is it a regular way for security coding?</p>
<p>What if we don't know the max limit of a command line length?</p>
<p>Thanks.</p>
<pre><code>#include &quot;csapp.h&quot;
#define MAXARGS 128

/* Function prototypes */
void eval(char *cmdline);
int parseline(char *buf, char **argv);
int builtin_command(char **argv);

int main()
{
  char cmdline[MAXLINE]; /* Command line */

  while (1) {
    /* Read */
    printf(&quot;&gt; &quot;);
    Fgets(cmdline, MAXLINE, stdin);
    if (feof(stdin))
      exit(0);

    /* Evaluate */
    eval(cmdline);
  }
}


/* eval - Evaluate a command line */
void eval(char *cmdline)
{
  char *argv[MAXARGS]; /* Argument list execve() */
  char buf[MAXLINE]; /* Holds modified command line */
  int bg; /* Should the job run in bg or fg? */
  pid_t pid; /* Process id */

  strcpy(buf, cmdline);
  bg = parseline(buf, argv);
  if (argv[0] == NULL)
    return; /* Ignore empty lines */

  if (!builtin_command(argv)) {
    if ((pid = Fork()) == 0) { /* Child runs user job */
      if (execve(argv[0], argv, environ) &lt; 0) {
    printf(&quot;%s: Command not found.\n&quot;, argv[0]);
    exit(0);
      }
    }

    /* Parent waits for foreground job to terminate */
    if (!bg) {
      int status;
      if (waitpid(pid, &amp;status, 0) &lt; 0)
    unix_error(&quot;waitfg: waitpid error&quot;);
    }
    else
      printf(&quot;%d %s&quot;, pid, cmdline);
  }
  return;
}

/* If first arg is a builtin command, run it and return true */
int builtin_command(char **argv)
{
  if (!strcmp(argv[0], &quot;quit&quot;)) /* quit command */
    exit(0);
  if (!strcmp(argv[0], &quot;&amp;&quot;)) /* Ignore singleton &amp; */
    return 1;
  return 0; /* Not a builtin command */
}


/* parseline - Parse the command line and build the argv array */
int parseline(char *buf, char **argv)
{
  char *delim; /* Points to first space delimiter */
  int argc; /* Number of args */
  int bg; /* Background job? */

  buf[strlen(buf)-1] = â€™ â€™; /* Replace trailing â€™\nâ€™ with space */
  while (*buf &amp;&amp; (*buf == â€™ â€™)) /* Ignore leading spaces */
    buf++;

  /* Build the argv list */
  argc = 0;
  while ((delim = strchr(buf, â€™ â€™))) {
    argv[argc++] = buf;
    *delim = â€™\0â€™;
    buf = delim + 1;
    while (*buf &amp;&amp; (*buf == â€™ â€™)) /* Ignore spaces */
      buf++;
  }
  argv[argc] = NULL;

  if (argc == 0) /* Ignore blank line */
    return 1;

  /* Should the job run in the background? */
  if ((bg = (*argv[argc-1] == â€™&amp;â€™)) != 0)
    argv[--argc] = NULL;

  return bg;
}
</code></pre>
","699","","699","","2020-10-24 23:13:30","2021-01-11 04:49:05","Since `strcpy`, `strcat`, and `sprintf` are dangerous, what shall we use in stead of them?","<c><strings><code-security>","4","5","","","","CC BY-SA 4.0"
"319058","1","319084","","2016-05-20 12:01:37","","0","124","<p>Say my website contains 2 functions:</p>

<ol>
<li>Allow a user to change their own password</li>
<li>Allow an administrator to change a user's password (the user must change again before they login)</li>
</ol>

<p>Now let's say that there is a business requirement which stipulates that a user is not allowed to reuse a previous password. </p>

<p>In 1, it is ok to return a ""You cannot reuse a previous password"" message, providing the user has successfully authenticated themselves with their current password.</p>

<p>In 2, I need to prevent information leakage. The administrator should not be given information on a user's previous password. I have implemented this by returning a generic ""Invalid password"" message. However I think a smart user can still figure out that if an ""Invalid password"" message is being returned for a perfectly valid string, then something else is going on.</p>

<p>Is there any way around this or am I just being too fastidious? My first thought is that the solution is to remove 2, and add a Reset Password feature.</p>

<p>EDIT - I think there is a bit of misunderstanding of the problem. The problem is that the user may have used one of their previous passwords on another site (eg: Bank). Thinking a bit more about this, I'm not sure how much more problematic the ""changing another users password"" leakage source is than someone simply trying to brute-forcing the main login form...</p>
","79635","","79635","","2016-05-20 16:05:21","2016-05-20 16:53:21","Preventing information leakage while returning an error message","<security><error-handling><passwords><error-messages>","3","1","","","","CC BY-SA 3.0"
"418409","1","418411","","2020-10-28 13:29:07","","-1","122","<p>I was reading a blog of how a problem was solved on the Lyft blog here: <a href=""https://eng.lyft.com/applying-gevent-learnings-to-deliver-value-to-users-part-4-of-4-36ad932deea8"" rel=""nofollow noreferrer"">https://eng.lyft.com/applying-gevent-learnings-to-deliver-value-to-users-part-4-of-4-36ad932deea8</a></p>
<p>This made me go to their main page: <a href=""https://eng.lyft.com/"" rel=""nofollow noreferrer"">https://eng.lyft.com/</a> which is a Medium site and I saw a lot of such blogs. I was wondering why would a tech for-profit company share such info besides having to spend time writing it on a site like Medium that too for free? Doesn't this turn into a risk both security wise and competition wise besides the time spent by paid employees putting work on content which will doesn't generate revenue for it.</p>
<p>What am I missing?</p>
","378406","","","","","2020-10-28 14:01:42","Why do some tech companies share their workings on a blog for free","<security>","1","2","","2020-10-28 14:35:40","","CC BY-SA 4.0"
"418755","1","","","2020-11-07 18:03:18","","0","62","<h2>Disclaimer:</h2>
<p>I'm not sure if this is the right site as this question sits under both software engineering and security domains.</p>
<h2>Background:</h2>
<p>Assume you have a financial web application that receives sensitive requests from its users (e.g. money transfers) and you want your application to be able to process sensitive operations only if they were originated by the client. Your application also has a &quot;back-office&quot; interface, which allows specific employees to perform bulk operations such as a promotional giveaway.</p>
<p>Your architecture is based on micro-services with loosely coupled design principles in mind, hosted on a public cloud (e.g. AWS, GCP, Azure).
Some of the services are frontends, some are backends.
The communication method is varied, some utilize REST, some utilize message queues.</p>
<p>You decide you want to embrace the defense-in-depth approach by applying multiple trust boundaries instead of a single perimeter to avoid a security single point of failure (having one of the services breached to bypass all security boundaries inside the network). With that approach, each service authenticates its consumers, checks their authorization scope, validates their supplied input, and so forth.</p>
<h2>The actual question:</h2>
<p>How can a complete backend service be sure that a request, along with its data was initiated by a client, while not having an increased coupling/being as agnostic as possible between the service and the client?</p>
<p>Alternatively, how trust can be achieved between the service and its consumer?</p>
<h2>Things I have considered so far:</h2>
<ol>
<li>Client-side Digital Signature: the client digitally signs the payload, where the private key is only known to the client. The service can verify the integrity of the message before execution (signed message is passed the whole way)
<ul>
<li>Pros:
<ul>
<li>Provides the highest degree of data integrity and non-repudiation</li>
<li>Backend service can be designed in a way of message validation, which is <em>relatively</em> not that coupled (request can be either signed by a customer, or by the back-office interface operator)</li>
</ul>
</li>
<li>Cons:
<ul>
<li>Key management on the client-side has many problems</li>
<li>The backend service would still need to map the verification key to the request initiator</li>
<li>Cannot support bulk operations unless requests are stacked along with their signatures (increases used storage)</li>
</ul>
</li>
</ul>
</li>
<li>Side-channel Verification: before final execution, a separated channel reaches to the client to confirm the details of the transaction
<ul>
<li>Pros:
<ul>
<li>Adds a service that handles just that without a significant modification of code on the rest of the services</li>
<li>Avoids having key materials stored on the client-side</li>
</ul>
</li>
<li>Cons:
<ul>
<li>Requires an additional &quot;moving part&quot; that might break the system if malfunctioned</li>
<li>Does not provide non-repudiation</li>
<li>Friction with the client as she needs to be available to confirm the operation twice</li>
<li>If the client is not available it would not be possible to process the request</li>
</ul>
</li>
</ul>
</li>
</ol>
","379018","","","","","2020-11-07 18:36:07","Application Security VS Tight coupling - High assurance of user intent","<design><security><coupling>","0","3","","","","CC BY-SA 4.0"
"319725","1","","","2016-05-29 03:07:16","","-1","734","<p>I'm looking for a notation that is familiar to modern developers and can supersede <a href=""https://en.wikipedia.org/wiki/S-expression"" rel=""nofollow noreferrer"">s-Notation</a>. (additional insight into <a href=""https://loopback.io/doc/en/lb2/Controlling-data-access.html"" rel=""nofollow noreferrer"">Rivest's proposal of s-Expression is here</a>)</p>

<p>Is there any Swagger, JSON or other notation that is very intuitive for ACL control?</p>
","175","","175","","2019-12-12 21:17:50","2019-12-12 21:17:50","Are there any JSON based notations for Access Control Lists? (Alternative to S-Expression)","<security><json><lisp><protocol><privacy>","1","9","","","","CC BY-SA 4.0"
"418978","1","418991","","2020-11-14 20:17:44","","0","142","<p>I have experience building RBAC-based authorization mechanisms, and understand the <em>theory</em> behind ACLs (DAC?) though I've never had the need to implement them.</p>
<p>A situation was just presented to me that I realize I have never thought about dealing with before, but absolutely <em>should</em> have. I believe OWASP refers to this problem as <strong>Broken Access Control</strong>, but the scenario is this:</p>
<blockquote>
<p><code>User X should not be allowed to read/write certain data belonging to User Y.</code></p>
</blockquote>
<p>So for instance, User X is a valid, authenticated user/principal in my system; and so is User Y.</p>
<p>Each user in the system has a &quot;public profile&quot; which consists of, say, 20+ tidbits of information about them that is safe to be shared with all other authenticated users. Things like: username, last login time, length of time they've been a user, their favorite food, etc.</p>
<p>However, certain information, such as their email, payment info, password, and perhaps other sensitive information should only be visible to the user for whom the information belongs to, and only on the appropriate screens, when they are logged in. Furthermore, no one other than them should <em>ever</em> be able to write new values for those pieces of data. So User X should never be able to update User Y's email or password, etc.</p>
<p>Let's say I have RESTful endpoints that allow users to fetch + update their data. So you might have:</p>
<ul>
<li><code>GET /users/{userId}/profile</code> : returns a JSON object with all their shareable &quot;public&quot; data</li>
<li><code>PUT /users/{userId}/email</code> : updates a user's email address with a new value</li>
</ul>
<p>In the latter case, we need to restrict access to the endpoint in such a way that the requester can only be permitted to take the action if its for their own <code>userId</code>.</p>
<p><strong>I'm wondering what the typical solution is for such a scenario?</strong></p>
<p>Assume a JWT-based authentication mechanism where the user logs in, the backend generates a JWT for them, and they can then make calls to authenticated URLs using those JWTs. The JWTs can contain whatever claims they need in order to make the solution work!</p>
","309754","","","","","2020-11-15 13:16:52","OWASP Broken Access Control by example: preventing user's from reading/writing data that isn't theirs","<security><authorization><access-control><jwt><rbac>","1","1","","","","CC BY-SA 4.0"
"321322","1","321326","","2016-06-05 07:29:48","","4","7116","<p>A small company without any IT skills wants to run a web application where customers can enter various bits of data and upload pdfs.
The documents regard product specifications and have to be kept secure.</p>

<p>They have one external IT guy who wants to sell them a PHP application for the task. He wants to store the documents directly on the webserver, and sync them with Google Drive, which they use for their internal documents.</p>

<ul>
<li><p>Is it ok to store the documents on the server, or does this create a potential security problem?
I have the feeling that they should not keep the files on the server after uploading, and that they should get them away from the webserver and into a more protected domain right after the upload has taken place?</p></li>
<li><p>Is it okay to sync these sensitive files with a Google apps for business account? The Google credentials must be known to the webapplication. Does this pose another security risk?</p></li>
<li><p>Would you advise against the use of PHP in this scenario?</p></li>
<li><p>Is there a better solution to this?</p></li>
</ul>

<p>Thanks a lot! :-)</p>
","232119","","","","","2016-06-06 16:44:27","How to store uploaded client documents securely in webapplication","<architecture><web-applications><security><upload>","3","0","","","","CC BY-SA 3.0"
"419330","1","419358","","2020-11-25 01:54:18","","2","401","<p>I am debating whether to give my files a public url or a limited private one.</p>
<p>I am hosting various files for a mobile/web application. These will include product images and videos. Currently only authorized users can access this application, and so the files are private. However, I suppose users may want to directly share the file URLs with other users who are not authorized users so they can view them directly (eg through a web browser).</p>
<p>Currently the files are on an AWS S3 bucket (which has no public access) files are given a public url that expires after a short period of time (eg hours). By following this system we also avoid DOS attacks on our S3 bucket.</p>
<p>Am I missing any major reasons to make them public vs private (and the other way around)?</p>
<p>I noticed that facebook used to have persistent file urls for user photos across their CDN, but now they are only valid for an authenticated user (I haven't tested their persistence over time).</p>
","175594","","175594","","2020-11-26 18:20:07","2020-11-26 18:20:07","Should a Web Application File URL Have Public or Private Access","<web-applications><security><aws><access-control><files>","1","2","","","","CC BY-SA 4.0"
"419511","1","419519","","2020-11-30 13:12:33","","0","238","<p>For a project that's going to live/used/maintained by the developer for a very long time (ex: 20-50 year); Is custom (self made) framework better than (open source) popular frameworks? Basically my highest priority requirement is security and very long term lifetime.</p>
<p>My current situation is having to maintain 15 year-ish old web application written in PHP5 (at the time, it was a cutting edge application since <a href=""https://en.wikipedia.org/wiki/PHP#cite_ref-about_PHP_9-5"" rel=""nofollow noreferrer"">PHP5 released at July 2004</a>. The application used custom, closed-source framework (since I imagine at that time there's yet any popular or mature frameworks yet)</p>
<p>The application have served the organization for long time, and it's rather business critical. I'm trying to make a new mobile friendly version of it (to run alongside the old one). Should I use the same framework, or should I use newer frameworks like symfony or laravel?</p>
<p>[A] When I read the source code of the old framework, I realized that there's a lot of demerit:</p>
<ul>
<li>a lot of it didn't follow some of OWASP best practices (I can't say which ones);</li>
<li>no automated test, no documentation (every time we need to change something, we're reverse engineering it and hope things didn't break);</li>
<li>a lot of bad PHP programming practice in general (variable name upper\lower-casing, drowning in warnings, gigantic monolith, no null safety, very loosely typed, no error logging, not using abstraction layer, basically going against every PSR that exist out there)</li>
<li>basically a very huge technical debt</li>
</ul>
<p>[B] Even so, the consideration of keep using our old, custom, closed-source framework is that:</p>
<ul>
<li>it's more secure
<ul>
<li>security through obscurity (only us know the source code, unlike open source frameworks which their code are basically 'leaked' through the internet),</li>
<li>AND security through very strict network firewall rules,</li>
<li>AND security through enforced legal and organizational law);</li>
</ul>
</li>
<li>more understandable by the team (us);</li>
<li>PHP5 will still run on servers;</li>
<li>it's lifetime is forever (since the team: us; still maintain it and patch security vulnerabilities), - it will never get deprecated, never get breaking changes; I know that symfony provide LTS release that receive maintenance for 4 years. But it's still very-very short in term of the application's lifetime (our team expect 20-50 year);</li>
<li>it's receiving very huge amount of request every day, no framework (less footprint/resource usage);
even if I try to change to new framework and follow every best practice out there, it'll be bad practices again after 20-50 year</li>
<li>our requirements doesn't mind if the app appears old (in html/css presentation); that's not where our customer find us</li>
</ul>
<p>My question is:</p>
<ul>
<li>should I propose for a change of framework and design?</li>
<li>is there any of my point in [A] or [B] that is wrong or misguided?</li>
</ul>
<p>Related question (but quite different): <a href=""https://stackoverflow.com/questions/1836351/thoughts-on-abandoning-proprietary-framework-for-a-larger-open-source-project"">https://stackoverflow.com/questions/1836351/thoughts-on-abandoning-proprietary-framework-for-a-larger-open-source-project</a> (my question is more on security and long lifecycle)</p>
","146356","","118878","","2020-11-30 15:16:42","2020-12-01 04:24:31","For a very long lived PHP web application project, is custom (self made) framework better than (open source) popular frameworks?","<php><security><frameworks><web-framework>","2","5","","","","CC BY-SA 4.0"
"321744","1","321746","","2016-06-09 13:39:15","","0","144","<p>I have a simple web application built with Angular which fetches some state from a web server and shows it to the user. Additionally I want to implement a feature where users are able to customize the view of this application by dynamically appending new code on the rendered page in a way that the changes would reflect on the other clients. In principle this could be implemented with a templating engine on the server side, but of course this opens a huge security problem where any user is able to add arbitrary functionality to the app. What could be the appropriate solution for this problem? My first though would be to implement a server where angular sends the models and lets those parts of the view be rendered remotely, but of course this defeats the purpose of using Angular in the first place.</p>
","232496","","","","","2016-06-09 13:57:40","Extensible web application where users can upload client-side code","<web-development><web-applications><security><browser><client>","1","0","","","","CC BY-SA 3.0"
"419814","1","","","2020-12-08 23:04:06","","1","611","<p>I hope this is the right site for this question...</p>
<p>I tutor in my spare time, and recently I downloaded a past GCSE exam paper and was attempting to edit the pdf- to select just a few pages to send to my student. Unfortunately, I could not do so because the pdf is password protected for editing.</p>
<p>Perhaps this is a silly question, but I am wondering how this works? Where is the security status of the pdf kept when I download it? What exactly is it that I am downloading when I click download for the pdf? I presume there is some code that describes the pdf, security etc as well as its contents. Is there a way for me to view where this is? Where is the 'password' stored? Presumably it is somewhere among the code describing the pdf, so that my computer can check against it when I try to gain access? But then how can the password be stored in code without me being able to decode what it is?</p>
<p>Sorry if some of these questions are basic. I don't have much of a formal background in computer science.</p>
<p>EDIT: Could the down-voters please tell me what is wrong with the question? Is it not suitable for the site? Is there a way I can improve it?</p>
","339357","","339357","","2020-12-08 23:37:11","2020-12-09 09:25:07","How do password-protected pdf documents work?","<security><passwords><pdf>","2","1","","","","CC BY-SA 4.0"
"321882","1","321886","","2016-06-10 16:42:18","","0","97","<p>I have a hashed value X and need to ensure that any of the data sets D1...Dn can be concatenated with a correctional value C1...Cn and passed into a hashing algorithm to result in the value of X.  What I need is a way to figure out what Ci should be in order to ensure that hash( Di ++ Ci ) == X.  If I use a simple hash like addition or XOR then it'll be pretty easy, but is there any way to figure out Ci for better hashing algorithms?</p>

<p>Thanks for any help.</p>
","123075","","123075","","2016-06-10 19:59:50","2016-06-10 19:59:50","Hash system to generate same (specified) hash from multiple datasets?","<algorithms><security><hashing>","1","8","","","","CC BY-SA 3.0"
"419907","1","","","2020-12-11 10:15:00","","-2","756","<p>I have a React App (created via create-react-app) secured with OAUTH2. Currently all dynamic content is via REST APIs, secured with the same OAUTH2 token issued at login. It is hosted on AWS.</p>
<p>I want to implement a picture library and here are two React components that i'm considering:</p>
<ul>
<li><a href=""https://www.npmjs.com/package/react-photo-gallery"" rel=""nofollow noreferrer"">https://www.npmjs.com/package/react-photo-gallery</a></li>
<li><a href=""https://www.npmjs.com/package/react-image-gallery"" rel=""nofollow noreferrer"">https://www.npmjs.com/package/react-image-gallery</a></li>
</ul>
<p>Both components get the images from a URL, meaning each image must be hosted on a web server and be publicly accessible. My understanding is that the client browser will download the React page (including gallery component) then attempt to fetch the image from the URL.</p>
<p>My question is how would i secure access to the images using the same OAUTH2 token? The obvious (?) answer is to serve the images via the REST APIs, thus keeping the security architecture consistent. I'd appreciate some feedback on whether this is indeed the optimum approach or there are other options.</p>
<p>Thankyou</p>
","380931","","","","","2020-12-13 08:26:35","Advice: How to secure access to photos in a React App","<security><reactjs>","2","5","","","","CC BY-SA 4.0"
"321988","1","","","2016-06-12 02:09:05","","3","3066","<p>I'm designing a RESTful API for my organization. We do use password-based authentication, which generates tokens. One part of our API requires that the users be physically in the office, i.e. there is no use case where someone would need to be using those particular endpoints while working remotely. (It has to do with a physical check-in card-scanning scenario.) </p>

<p>We're writing the REST API in ASP Web API, so my first inclination was simply to check the Request object to see what the remote IP address is, and only allow access to the given resource if that IP address falls within a whitelist. (For those calls which should be restricted)</p>

<p>My co-worker, however, believes this to be insecure. He believes there are ways to abuse HTTP in such a way that a malicious client could cause ASP.NET to report the incorrect remote IP address; therefore, he feels as long as someone knows the valid range of addresses (e.g. a worker could simply ""ipconfig"" on their machine while in the office to determine a valid IP), that person could abuse the API and access it from anywhere.</p>

<p>He suggests, instead, depending solely on a client secret. We're already using password authentication, so that's not the issue. What I'm not sure of is how we'd implement a client secret in such a way that 1. it could not be copied from one machine to another, and 2. that it couldn't be accidentally removed. Obviously anything client-side would be in JavaScript so the ""dev tools"" console is the equivalent of a disassembler.</p>

<p>I have to feel that a combination of the two methods is at least a start - perhaps make the client secret involve the IP address in question, and then have the remote API check the client secret against the IP that the request appears to be coming from. (However, if a user can somehow copy the client secret, that won't help anyway since they could just combine both hacking methods...) This also still does not answer how we would ""pre-install"" a client secret into the client. If we had the REST API provide a secret for later use, you're back where you started - a malicious hacker could (apparently) spoof their IP and retrieve a secret they're not supposed to have.</p>

<p>My understanding of TCP/IP tells me that it's not possible to spoof your source IP address to anything you want and obtain a successful TCP connection. Since we're using a whitelist, someone would have to somehow be able to spoof their IP from the outside to appear to be on our network and engage in a full TCP connection to the HTTP server. I don't even think this is possible, but my co-worker still believes there's a way to abuse the IP whitelist. </p>

<p>Which one of us is right? Or are neither of us right at all and there's a completely different and better approach?</p>
","233076","","","","","2016-06-13 05:54:02","Preventing abuse of a RESTful Web API (can the server trust the remote IP address?)","<rest><security>","3","4","","","","CC BY-SA 3.0"
"322221","1","322225","","2016-06-14 15:32:17","","4","427","<p>A recently-published article demonstrates <a href=""http://incolumitas.com/2016/06/08/typosquatting-package-managers/"">a way to make ""typo-squatting"" attacks on popular programming package managers.</a>  It singles out Python's <code>pip</code>, Ruby's <code>gem</code> and Node's <code>npm</code> systems, and shows that they have two things in common:</p>

<ol>
<li>Packages can be submitted and accepted automatically, with no manual review or human oversight</li>
<li>Packages can cause the package manager to execute arbitrary ""setup"" code on the client system at install-time.</li>
</ol>

<p>This means that it's possible to <a href=""https://en.wikipedia.org/wiki/Typosquatting"">register a package with a name that's very similar to that of a popular package</a>, and get your package (complete with a malicious setup script) installed anytime someone mistypes the package name.</p>

<p>This makes me wonder, does NuGet have these same two characteristics?  Does it have any mechanism in place to mitigate attacks of this type?</p>
","935","","","","","2016-06-14 17:12:47","Is NuGet vulnerable to this typosquatting attack?","<security><nuget>","1","7","","","","CC BY-SA 3.0"
"420227","1","","","2020-12-21 06:06:01","","2","352","<p>My question may sound very naÃ¯ve to someone, but it is what it is.</p>
<p>I have below scenario:</p>
<ul>
<li>Relational MySQL Database with <code>BIGINT</code> primary keys and foreign keys</li>
<li>Spring boot as a backend (technology doesn't matter here)</li>
<li>Angular as a frontend (again technology doesn't matter)</li>
</ul>
<p>This system is a large system and there are many intermingled modules with foreign key references, lookup tables, etc. and all the users must be authenticated (we have Spring Security OAuth) to access this system. So from authentication view-point, we are safe. Also we are managing roles and permissions for user's actions (they are mostly used on UI to hide/show menus, buttons, and actions). Everything good so far. The real challenge arises here - lets say there is some ABC module, and authenticated user X is accessing its information using REST call <code>/api/abc/1</code>, here <code>1</code> is the primary key of ABC, and ABC data with key <code>1</code> belongs to X only. But as you can see here, changing the <code>id</code> in above URL, user can access ABC module data of other users too. So how can these actions be authorized?</p>
<p>Below are the points of my research, but none of them seem viable:</p>
<ul>
<li><em><strong>Use UUID instead of Int primary keys.</strong></em> But there are drawbacks of UUIds that they increases the database size and they are also guessable at some point by bots.</li>
<li><em><strong>Do not expose the primary keys.</strong></em> But this case will not work in my scenario, as I told that there are many intermingled modules with many references. And in many of the modules, primary keys are the one which are unique.</li>
<li><em><strong>Intercept every REST call, and check whether the passed <code>id/ids</code> belong to that particular authenticated user.</strong></em> But this solution will also become clumsy after some extends because there are many modules, and it will also increase the number of queries to database.</li>
</ul>
<p>So what is the best way for authorization in this kind of application?</p>
<p><strong>NOTE:</strong> This question is not related to any of the technology or implementation, but just related to Security design of REST APIs.</p>
","237932","","237932","","2020-12-21 06:28:24","2020-12-21 22:28:44","What are the best practices to authorize every REST request?","<rest><api-design><security><authorization>","2","3","","","","CC BY-SA 4.0"
"420379","1","420412","","2020-12-26 19:47:52","","1","104","<p>I ran into an issue when developing where a user that did not exist, but had a correctly signed JWT, was logged in.</p>
<p>This happened when I absentmindedly logged in using a browser while running the test server. Because I used the same makeshift credentials for the user in both databases, the login succeeded. I then switched back to the development server which caused various problems.</p>
<p>In the end, I added a check that the user existed and a unit test that non-existing, but correctly signed, users are rejected. But in production, the leak of my secret would be a catastrophic failure in itself that should never happen. I was already rejecting incorrectly signed tokens. Does having a check like this make sense, or does it just add needless complexity?</p>
","328116","","","","","2020-12-28 10:12:07","Should I check for non-existing users with correctly signed tokens?","<security><passwords><configuration-management><jwt>","2","3","","","","CC BY-SA 4.0"
"420723","1","420724","","2021-01-06 07:19:51","","3","131","<p>I'd like to build a simple privnote-type clone for fun. The idea is this:</p>
<ol>
<li>User A writes a note in their browser, browser encrypts it client-side</li>
<li>Server saves the pre-encrypted note without knowing the decryption key</li>
<li>User A then sends a link like <code>abc.hidden/mynoteid#mydecryptionkey</code> to user B</li>
<li>User B decrypts the message on a local browser</li>
</ol>
<p><strong>The question I'm struggling with is this</strong> - should the server allow anyone to fetch <code>abc.hidden/mynoteid</code>? Server being able to decrypt messages (I'd like this to be entirely immune to logging of any sort and all encryption/decryption happening clientside) defeats the entire purpose.</p>
<p><strong>Because the notes are one-time-use-only, a fetching of the note must destroy it.</strong> But how can I know that a correct decryption key was supplied without decrypting the message server-side exposing it to logging?</p>
<p>Lastly, would a React app and a generic REST server with Redis to store messages suffice for this task? (Supposing that messages have a TTL, Redis seems an ideal choice) What happens if a malicious actor gains access somehow (without knowing the decryption keys which should be generated on the spot and only just once)</p>
<p>What encryption algorithm is best suited for this task? I don't think we need 10 seconds of <code>bcrypt</code> &quot;work&quot;.</p>
<p>I understand that sending sensitive info over the internet is yucky but it happens a lot and if it does happen in a proverbial &quot;marketing department&quot;, having a tool like that could ease some worries about PII.</p>
<p>Plus, I think it's a fun project either way.</p>
","238360","","238360","","2021-01-06 07:26:23","2021-01-06 11:06:09","Designing a privnote clone - security considerations","<design><security><encryption>","1","1","","","","CC BY-SA 4.0"
"420940","1","","","2021-01-12 02:08:18","","3","177","<p>TL;DR: How distributed open-source apps like Scuttlebutt are secured from DoS and hackers who can make custom version of application?</p>
<p>I'm struggle with designing an open-source distributed application architecture. I want to create an application consisting of open source server, client, and provider. Client sends requests to one random provider instance that have list of all instances both client and server, and sends it to one of the random server, which, after processing the information, sends a result request back to the client. Every part of this distributed app is open-source, so everyone can create their own instance of client, provider, server, and everything seems to be fine, but what if some programmers will have bad intentions, and they will change client code in the way, that it will send millions of requests (DoS attack) to the specific, not random provider, or change providers with, so it will send all requests to one specific server? Also they can change server code, so if client expects to get a specific picture from server database, hacker will send some inappropriate pictures to all avaible clients.</p>
<p>If I hardcode some kind of verification, like hashing of important functions of API, then hacker will just remove this in his own fork. Therefore, I cannot solve this problem in any way, except by making the code of one of the parts private. For example I can make provider application with private code, so it will check hash of both client and server, and if this check fails - provider will delete this instance from list of instances. This solution sounds good, but in this case, the whole project will no longer be open source.</p>
<p>Summarize: I want to create an open source distributed application, so everyone can make their own instance, improve it, add new functionality, but how can I secure it, so this ability to create custom versions should not be misused for DoS, sniffing, or information corruption in conjunction with all many different versions working together.</p>
<p>I don't quite familiar with this topic, so I'll be glad if you can give me advice, a link to an article on a similar topic, or a book.</p>
","382921","","9113","","2021-01-12 06:51:06","2021-02-19 09:19:24","How to protect an open-source distributed application consisting of clients and servers from forks made by hackers?","<design><open-source><security><distributed-system><forking>","1","5","","","","CC BY-SA 4.0"
"323181","1","","","2016-06-24 15:22:14","","1","72","<p>Password reset option should be given only if the link has come from that specific user's inbox and not from somewhere else. How to implement url in such a way that the required information i.e. Mailbox  can be obtained from the url? Facebook and Twitter like companies seem to have already implemented it. Any suggestions or ideas would be appreciated. </p>
","207545","","","","","2016-06-24 15:39:09","How to implement a secure way to allow users to reset password via url?","<web-applications><security><authentication>","1","0","","","","CC BY-SA 3.0"
"323315","1","323323","","2016-06-26 20:01:40","","2","473","<p>Are there any viable approaches to dealing with data coming from devices with unreliable clocks?</p>

<p>We have a database system running on a central server. The latest addition to the system is a bunch of mobile barcode scanners running Android. We are creating a specific app and the devices will be completely locked down so the user may only interact with this app (so no access to any settings).</p>

<p>Overall it's very simple, the devices will connect using an ethernet dock and download a list of items to move along with their destinations. The user scans the items at the destination and collects a signature for delivery. Once connected to the dock, the location of any delivered items will be updated, along with the signature and timestamp of the move.</p>

<p>The plan was that the app would set the device clock from the server time whenever it was connected to the dock. Unfortunately, Android does not allow apps to set the time (the <code>SET_TIME</code> permission is only allowed for system apps). Additionally, the network is incredibly locked down, so we can't rely on the built-in synchronisation, and the devices only have a network connection when docked in the ethernet cradle anyway.</p>

<p>So, given that the devices may have arbitrarily incorrect clocks, is there any way we can correct for this when the data is uploaded? It would be possible to keep a log on the server of the clock for each device whenever it is connected.</p>

<p>In many ways this problem could apply to any offline-capable application. What do you do with time-related data from a device with an unreliable or untrusted clock?</p>

<p>It's not too difficult to correct a consistently-incorrect time, but it seems completely impossible if you consider that the device may lose time completely if the battery goes flat. A similar problem arises for an untrusted device - if the user may change the clock arbitrarily.</p>

<p>Has any research been done on this problem?</p>
","40209","","","","","2016-06-27 08:43:40","Data from devices with unreliable clocks","<security><mobile><synchronization><time><offline>","3","2","","","","CC BY-SA 3.0"
"421182","1","","","2021-01-18 04:00:18","","1","59","<p>I need to run arbitrary code snippets in Python and Javascript on a server. It cannot be run in the browser.</p>
<p>I'm thinking of sandboxing the code in an AWS Lambda serveless function. However, I'm unsure of the best ways to disable networking (outside of the AWS returning a response over the network) and other potential threats.</p>
<p>How do sites like HackerRank sanitize user submitted code? Is there anything else I should think about?</p>
<p>I've seen answers such as <a href=""https://stackoverflow.com/questions/3068139/how-can-i-sandbox-python-in-pure-python"">this</a>, but the top rated answers tend to be out of date.</p>
","383289","","","","","2021-01-18 04:00:18","Securing Arbitrary Code","<javascript><python><security>","0","1","","","","CC BY-SA 4.0"
"421534","1","","","2021-01-27 09:18:46","","0","106","<p>I'm working on a security policy system design and I'm facing an existential question.</p>
<p>Some of the policies have a model-level scope that could be defined like so :</p>
<pre><code>UserGroup x EntityType x AccessMode -&gt; Boolean
</code></pre>
<p>Meantime, I want to have finer policies that opperate at data-level, to restrain users to access only specific instances.</p>
<pre><code>UserGroup x Set&lt;EntityType&gt; x AccessMode -&gt; Boolean
</code></pre>
<p>In one case, the policy is defined over a Data Model, in one other over Data.
I'm not especially familiar with security policies, is it a bad design to make cohabit two different kind of policies ? Or is it just a misunderstanding that I have, and they work seamlessly ?</p>
<p><strong>Let's me illustrate this :</strong></p>
<p>For AccessMode we can use a CRUD-based approach.</p>
<p>Read, Update and Delete mode may operate both over entities and specific instances of entities.
We can write a rule that allows all users belonging to a group Group1 to access any Post in Read mode :</p>
<pre><code>Group1 = {User1, User2, ...}
Group1 x Post x Read -&gt; True
</code></pre>
<p>But, we can also restrain this policy to allow access to specific instances of Post like this :</p>
<pre><code>Group2 = {User6, User7, ...}
Group2 x {Post1, Post3, Post4} x Read -&gt; True
</code></pre>
<p>Here, Users of Group2 can read specific posts Post1, Post3 and Post4, but don't have global permissions over the Post entity.</p>
<p>We can also imagine more complex logic like so :</p>
<pre><code>{user in Group1} x {post in Post if post.author = user} x Write -&gt; True
</code></pre>
<p>Here, users that are allowed to write posts are users that belong to Group1 and that are specifically the author of the post.</p>
<p>Being able to have access control at data-level is important.
But there's at least one case which requires to deal with entity-level policy, which is the Create mode since it defines whether the users may instanciate an entity type and has nothing to do with existing data.</p>
<p>In this case (but could also apply to other access modes) :</p>
<pre><code>Group1 = {User1, User2, ...}
Group1 x Post x Create -&gt; True
</code></pre>
<p><code>Post</code> refers to the entity type.</p>
","87947","","87947","","2021-01-28 15:25:39","2021-02-09 05:54:50","Security Policies scope (should they rule seamlessly over data and models)?","<design><security-policy>","2","7","","","","CC BY-SA 4.0"
"421631","1","421634","","2021-01-29 18:14:56","","3","158","<p>I'll explain my case as an example, but I think the problem applies to other web projects as well:</p>
<p>I have developed a Telegram bot in Python and made its source public. Then, I have deployed the bot on Heroku, where it is running now. The question is, how can I assure users that the bot runs on the shared code and not on a modified version?</p>
<p>I'm asking for web applications in general, but if there are specific tools or methods for Python or Heroku, I'll be happy to learn about them to use in this project.</p>
<p>EDIT: Judging by the comments and answers, I think the task is not possible as long as the server's contents cannot be reached by the users. I do not know if Heroku allows access to the app's files, but some tools for other kinds of projects exist. For example, a webpage repository on Github can be configured to be hosted in github.io, and the source on Github is guaranteed to be the same as the hosted site's source.</p>
<p>Please let me know if you know of a tool or method that applies to my case.</p>
","384088","","384088","","2021-02-01 18:58:39","2021-02-01 18:58:39","How to assure users that an open source web application actually runs the publicized source?","<web-applications><open-source><security>","2","8","","","","CC BY-SA 4.0"
"421649","1","421651","","2021-01-30 10:25:49","","1","791","<p>One of our customers had a pen test performed on our application this week and let's just say it didn't go well.</p>
<p>The main issue they have is that user authentication takes place on the client, rather than the server. The reason being that an attacker could decompile our (C#) application and build a modified version which could allow any password to be accepted.</p>
<p>The problem is, a requirement from our customer is that the application needs to work offline, so some sort of authentication will need to be done by the application without communicating with the server.</p>
<p>The pen testers suggested using a token system where the user authenticates with the server and it stores a token in the local database which would be used while offline, but I don't see how this solves the decompiling issue. Surely this could be bypassed in the same way?</p>
<p>Is my only option to tell the customer that if they want the application to be secure, then it can't work offline?</p>
<p>-- additional details</p>
<p>There isn't an &quot;offline-mode&quot; as such, just when an Internet connection is not available (several of the users might take a laptop to farms, for example), so authenticating with a server isn't possible. Admittedly, this isn't as much of an issue as it used to be, with 4G/5G availability.</p>
<p>On first login, after the initial authentication with the server, settings/config data is downloaded and stored in a local database (MSSQL or SQLite). Logging in while offline would allow access this data (so the program can function) and data the user has entered/saved.</p>
<p>The program has to &quot;phone home&quot; occasionally already (the settings expire after a week of no contact with the server), but I can't see how to stop a user from logging into the program if it is decompiled. If it downloads a token from the server, checking this could be bypassed in the same way entering a password could be.</p>
<p>I guess this question boils down to &quot;is it possible to prevent an attacker decompiling my program to circumvent authentication without requiring a server?&quot;. So far the only option seems to be to use the user's password as a key to encrypt the data, but then if (when!) the user forgets their password, the data is lost.</p>
","62302","","62302","","2021-02-04 17:42:24","2021-07-27 23:04:15","Offline user authentication","<c#><security><authentication>","3","7","","","","CC BY-SA 4.0"
"422185","1","422186","","2021-02-12 17:46:09","","7","286","<p>My company has its own proprietary software that I have both built and maintained over the last 5 years</p>
<p>I am about to release a big change for all of my software to use OAuth2 instead of handling emails and passwords ourselves. Prior to this release because I managed 100% of the dataflow, I had a feature for the admins that they could generate user token to impersonate the user - this was especially useful for troubleshooting while in production.</p>
<p>My question is, what is the business standard for a developer who does not provide software for the open market, but supports private users for one company? Without the feature we had I am reduced to troubleshooting via screen-share with the end user themselves.</p>
<p>Would it be bad practice for me to implement a similar feature to what I had before? What do other companies do?</p>
","351116","","118878","","2021-02-12 18:01:14","2021-02-13 11:34:18","What are best practices for enterprise software, should a developer be able to login as one of its users? (when its your own company)","<security><users><computer-architecture>","2","1","","","","CC BY-SA 4.0"
"422430","1","","","2021-02-18 20:59:42","","-1","61","<p>Now that Tesla has bought a large amount of BitCoin, other companies may follow suit. If my company wanted to do that, I was thinking about how it could be done.</p>
<p>I'm familiar with the way private individuals store keys.</p>
<p>I could see two possibilities:</p>
<ol>
<li>The Chief Financial Officer or someone like that would be the only with the keys, with some type of backup.  The data is done in a way very similar to how an individual would do it.</li>
<li>The Information Technology (I.T.) may be called upon.  For example, they might write a bot to buy the cryptos at certain prices or criteria.</li>
</ol>
<p>If I.T. is involved, then one or more programmers or I.T. staff would have access to the keys. If they weren't honest, or left the company, they could use the keys to transfer out all the cryptos.  Even if I.T. created an application for the company, the &quot;bad people&quot; could simply do a transfer using the private key totally outside the company's network.</p>
<p>I was thinking that one approach might be to have some automated software to keep moving the cryptos around to new accounts every x hours. To do this, the private/public key would have to be generated by software, but still stored in a data store of some type.  Maybe that would have to be a separate database instance that only very key people had the access codes to.</p>
<p>The issue is similar to API Keys, but they often have more flexibility (<a href=""https://softwareengineering.stackexchange.com/questions/232788/protecting-api-keys"">Protecting API Keys</a>).</p>
","385410","","","","","2021-02-18 21:25:06","Protecting cryptocurrency private keys in a corporate environment","<security><passwords><cryptography>","1","3","","","","CC BY-SA 4.0"
"422640","1","422651","","2021-02-23 22:30:05","","2","104","<p>I have a set of UUIDs that I want to assign to a set of people. I want to deliver these UUIDs to people in a secure manner, such that everyone knows that I do not know which UUID corresponds to which person. I.e., I want it to be publicly verifiable that the assignment process was random and that the delivery process was private, and that no record is kept of the assignments and deliveries. I am having a lot of trouble figuring out how to implement this digitally.</p>
<p>The purpose here is to allow people to prove that they received a legitimate ID for authentication purposes, without revealing who they are in particular when they submit said ID. A real life analogy would be to have people one at a time pick a random slip of paper with their ID written on it from a jar, where everyone can see that the jar owner does not know which ID was picked by each person, and also everyone knows that every person only received one ID.</p>
<p>I toyed with the idea of sending a link to a private webpage via email, where people could then click one of a set of links on said webpage to claim a particular ID, but then I have no way of ensuring that each person claims only one ID without recording some kind of credential to keep track of who has already claimed an ID.</p>
","385791","","","","","2021-02-24 06:39:52","How to randomly allocate a set of IDs digitally, one ID per person, such that everyone knows that the particular allocations are kept private?","<security><authentication><email><cryptography><identity>","1","7","","","","CC BY-SA 4.0"
"422687","1","","","2021-02-24 18:40:45","","-2","39","<p>There are many ways to secure the REST APIs, from authentication and authorization view point. Below are the two which I know so far:</p>
<ol>
<li><p>Using existing token based IAM solutions like Okta, KeyCloak, Auth0, etc.</p>
<ul>
<li><strong>Pros:</strong> Already proven solution, feature rich, easy to start and run</li>
<li><strong>Cons:</strong> Difficult to customize as per needs as the application grows, application becomes dependent on these third party solutions</li>
</ul>
</li>
<li><p>Building custom solution using filters, interceptors, and JWT (or opaque tokens)</p>
<ul>
<li><strong>Pros:</strong> Easy to customize as per needs as we have full control</li>
<li><strong>Cons:</strong> Chances of error/leaks increases, amount of code to write and manage increases</li>
</ul>
</li>
</ol>
<p>Above are the points as per my understanding of securing the REST APIs, using token based authentication and authorization. I want to know -</p>
<ol>
<li>Which of these (or any other) are widely accepted and used in production environments?</li>
<li>Which from these are best suited for small to mid scale projects?</li>
<li>Is there any other way/solution (token based or anything else) to secure the REST APIs?</li>
</ol>
","237932","","","","","2021-02-24 21:11:21","Securing the REST APIs - Security Framework (Technology) V/S Custom","<rest><api><api-design><security>","1","0","","","","CC BY-SA 4.0"
"422871","1","","","2021-03-01 21:18:49","","-2","76","<p>At work there is a given task where a python application is currently running on a server, this application is using a enviorment file, which has username and password information. The current ask is to encrypt the  username and password string such that only application is able to decrypt the username/password and use it to run the application. Is this possible or is there some type of industry wide best practice  we can adopt at this juncture.</p>
","116927","","","","","2021-03-01 22:15:03","mask username and password in service file, or better approach","<security><passwords>","1","2","","","","CC BY-SA 4.0"
"422984","1","","","2021-03-04 10:48:45","","5","1039","<p>What is considered good practice for application security wise when returning errors from a backend API?</p>
<p>I have inherited a project with a lot of technical debt, which I intend to improve.</p>
<p>One noticeable problem is that error codes are not informative at all. Sometimes it gives a 500 &quot;error&quot;, with no further. Sometimes it gives a 200 with an error in the JSON. Sometimes it returns a 403 not authorized which is nicer.</p>
<p>I want to make debugging easier, so giving more information in the error would be useful, but I wonder if there are security considerations to take into account when returning more information in error responses.</p>
<p>Are codes considered better than informative messages? (Seems like security through obscurity).</p>
<p>Are there any recommended best practices?</p>
","68808","","68808","","2021-03-11 10:10:35","2021-03-11 11:38:49","Error messages and security concerns","<security><error-messages>","6","4","","","","CC BY-SA 4.0"
"423445","1","","","2021-03-15 21:45:52","","1","281","<p>We develop web-applications using a javascript frontend framework (ReactJS), to retrieve the data to show, the user's browser calls an authenticated REST API which is our backend (Kotlin+Spring), the backend then connects to the relational database to retrieve the data (see the sequence diagram).</p>
<p><a href=""https://i.stack.imgur.com/ymf7s.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ymf7s.png"" alt=""current interaction"" /></a></p>
<p>Our customer doesn't seem to like this simple architecture anymore and he is asking us to add a layer for security purposes, his idea being that no service reachable by users should talk directly to the database because if the service gets hacked then the whole database is exposed.
He suggests we add another gateway layer which cannot connect to the database, this gateway layer then should connect to the backend service instead; the backend service wouldn't be directly exposed to the clients anymore (see the second sequence diagram)</p>
<p><a href=""https://i.stack.imgur.com/Ukkfg.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Ukkfg.png"" alt=""sequence diagram with middle layer"" /></a></p>
<p>I've never seen this pattern explicitly described in literature as a security feature and it seems kind-of pointless but I might be wrong, maybe it makes sense in some contexts. So is it a good practice? Does this pattern have a name?</p>
","187102","","187102","","2021-03-15 22:15:35","2021-03-16 15:12:02","Is it a good practice to isolate the database from public APIs?","<architecture><security><microservices><data><architectural-patterns>","3","3","","","","CC BY-SA 4.0"
"423552","1","","","2021-03-18 11:07:00","","0","143","<p>let's say I would like to create a service like eToro that allows people to trade stocks but with their own brokers.
If I do it just for me, it's pretty straightforward:</p>
<ol>
<li>create logic that replicates someone's trades (or from my own instructions)</li>
<li>use my API keys to get the best price with my brokers and trade</li>
</ol>
<p>Now if I want to share this with people I don't know, and who are not technical, the minimum I would need from them is their API key to trade &quot;for them&quot; (let's imagine we put all the legal stuff aside with waivers etc...). How could I, technically do that? Below are my concerns:</p>
<ul>
<li>if I store the keys myself, I could be hacked which brings liability</li>
<li>if I store the keys myself, I could use it for my own benefit (not
the intention but you know what I mean)</li>
</ul>
<p>so I am looking for, and haven't found yet, a service or a design pattern that would allow me to mitigate that, do you know what that could be?</p>
<p>What I had in mind:</p>
<ul>
<li>a third party like 1Password, but better, as I need to remove the need to
validate the unlock AND sees the passwords (the service is automated)</li>
<li>or a technical approach like OAuth but where I can guarantee that I
can't decipher the message (whereas in my case if I get the public
key only, than the user would need to use manually the private key
all the time, so no automation or if I have public + private, then I could decipher the message and get the API key...)</li>
</ul>
<p>Does this makes sense?
Thanks for your help!</p>
","387326","","","","","2021-03-18 11:55:27","How to use an API key without knowing it?","<design-patterns><api><security>","1","0","","","","CC BY-SA 4.0"
"423580","1","","","2021-03-18 17:41:42","","1","940","<p>Most of applications, when you sign up, you must agree with some terms and conditions.</p>
<p>Should the information that the user agreed to those terms be saved in the database?</p>
<p>I asking this because I'm thinking, If the user breaks one of those terms, I will need some prove that the user agreed to it? Like have a flag on the database which will be set when the user creates it's account?</p>
<p>I'm also thinking about when the terms changes and the user needs to re-agree with the terms. Should I also save some information that the user agreed with the new terms?</p>
","352191","","","","","2021-03-19 14:29:12","Should I keep in the database a record of the user accepting the terms and coditions?","<security><language-agnostic><privacy><terms-of-service>","3","6","","","","CC BY-SA 4.0"
"423609","1","","","2021-03-19 14:38:29","","0","186","<p>I'm creating a mobile app that will have a verification process of the phone number like most of apps do when they use your phone.</p>
<p>I'm also developing the back-end but I don't know exactly what is the safer way to generate a 4-6 digits code and send by SMS to verify that account.</p>
<p>How should I implement the generation of the code? And also, how to validate if it's a valid code for that phone?</p>
<p>Should I generate a random code and store it in the database? How to ensure the code is unique for each phone? Is it necessary to handle the case when I have more than 999999 (6 digits number max) users requesting the code even when it's certain that it won't happen?</p>
","352191","","","","","2021-03-19 16:21:20","How to create a code that will be send by SMS to verify that it's a valid phone number?","<security><language-agnostic><privacy><sms>","3","1","","2021-03-19 16:39:17","","CC BY-SA 4.0"
"423654","1","423656","","2021-03-21 15:45:58","","2","1331","<p>Recently In an interview I was asked this question -
Question- If are storing passwords in encrypted format in DB and in future  when user login into our website how will we perform authentication?</p>
<p>Me:-we will first first encrypt the password using same hash function then compare it with already stored password.</p>
<p>Interviewer:- But if someone breaks into our system and find out our hash function which is same for all then he can easily access customer's password.</p>
<p>Me-: We can create a hash function based on User-id. So everytime we are not using same hash function.</p>
<p>Interviewer- But this means app knows the user original password which is against User Privacy , even the app should not be know user's password.</p>
<p>Me- I don't know :(</p>
<p>Interviewer- Rejected!!!</p>
<p>Anyone here knows the solution of this question?</p>
","387531","","","","","2021-03-22 12:01:22","How to compare passwords which is stored in DB in encrypted form in secure way?","<security><authentication><spring><passwords><spring-boot>","4","4","","","","CC BY-SA 4.0"
"423667","1","423673","","2021-03-22 07:59:26","","1","59","<p>Let's consider such an example:</p>
<p>I'm an author of application like <code>Google Chrome</code>. I would like to my application sends anonymous telemetry logs to my server. How do I prevent somebody to use my server API to pretend he is my application to insert some malicious / spammy logs?</p>
<p>User of that application might be anonymous. Would it be valuable to set some quota to my API that would prevent too many logs from the same source in some span of a time?</p>
<p>How would you approach that? How big-tech companies do that? How google do that with their <code>Chrome</code> application? Microsoft with <code>Windows</code>?</p>
<p>Also, would it be possible to access some API only by signed application?</p>
","216982","","216982","","2021-03-22 09:13:00","2021-03-22 09:59:35","Limiting access to telemetry API only for certain application","<design><architecture><security>","1","1","","","","CC BY-SA 4.0"
"425009","1","425014","","2021-04-01 07:12:07","","0","50","<p>We are currently making the codebase for our company.
In this project we upload user data like users ID card, drive license, bills for identity confirmation and a lot of other sensitive data.</p>
<p>My question is why we should use a server that only helps with authentication when we already have to deal with the user data?</p>
<p>From my point of view we are just adding a layer of confusion...</p>
","383923","","383923","","2021-04-01 07:19:53","2021-04-01 09:37:19","Should we use an Identity server for our core?","<security>","1","0","","2021-04-21 09:43:08","","CC BY-SA 4.0"
"425051","1","","","2021-04-02 12:00:49","","1","42","<p>I would like to create GUI + API that calls third party API as follows:</p>
<ul>
<li>third party API is consumed once a day by my API,</li>
<li>GUI user doesnâ€™t have to log in every day (eg. can log in only once every 30 days to request data from my API)</li>
<li>design my API scalable</li>
</ul>
<p>The flow of system:</p>
<ol>
<li>desktop/browser GUI sends request with 3rd party API credentials to my API</li>
<li>my API prepares request to 3rd party API to get JWT token</li>
<li>after retrieving token the JWT is used to request data from 3rd party API and store it in database</li>
</ol>
<p>Since each request for collecting data requires valid JWT token, I have come across a few problems on how to make API collect data each day <strong>without any user interaction</strong>.</p>
<p>Things I have thought of (and optionally reasons why I've rejected them - which may be wrong)</p>
<ol>
<li>Since JWT is valid for 30 days by default, maybe I could store it in (for example) Azure KeyVault?</li>
<li>...but on the other hand I feel uncomfortable storing JWT when it's not needed. Therefore, I thought of storing credentials for each client in database and reducing token's lifetime to (let's say) 5 minutes, so I have it just for the time it's needed. But if I was to store those credentials, afaik I should store them hashed (if I am not wrong - I won't be able to use them in request for JWT)</li>
</ol>
<p>My questions are:</p>
<ul>
<li><p>if I am correct and ideas presented above are wrong - I would like to hear more remarks (just for self development)</p>
</li>
<li><p>what is the proper way of designing application (my API in that case) so it can <strong>securely</strong> deal with credentials/JWT and <strong>securely</strong> prepare requests <strong>for many days without user interacting with it</strong>.</p>
</li>
</ul>
<p>any remarks related to any aspect of such system are welcome</p>
","389294","","","","","2021-04-02 12:00:49","Automatic interaction between API and secured 3rd party API","<api><security><authorization><3rd-party>","0","0","","","","CC BY-SA 4.0"
"425063","1","425273","","2021-04-02 18:37:48","","1","343","<p>In open source projects handling user data in a secure manner can be managed, for example through encryption and password protected functionality. What I'd like to create is a way for the user to publish content, which can be read by other users, but not manipulated.</p>
<p>In case a program has some safeguards against tempering with user data, but is open source, there is the possibility for anyone with access to the source code to create a custom version of it without the safeguards. As a result a modified version of the code can be used maliciously.</p>
<p>I thought of a way to compare a checksum (generated by the published source code) with an internal checksum shipped with the program binary. Unfortunately this still can be bypassed the same way I was describing above; It seems I am thinking inside the box here.</p>
<p>An example scenario of what I'd like to avoid is:</p>
<blockquote>
<p>User A receives content from user B; modify it, and then send it to user C, pretending that user B made the modified content.</p>
</blockquote>
<p>This can be done easily if user A has an unsecure modified version of the program.</p>
<p>Is there any way data of an open-source software can be protected from the usage of malicious versions like this?</p>
","358372","","358372","","2021-04-03 12:36:18","2021-04-09 08:59:33","How can Data security be ensured in an open source software?","<open-source><code-security>","4","8","","","","CC BY-SA 4.0"
"425297","1","","","2021-04-10 00:05:59","","1","880","<p>I read a lot about using ongoing numbers vs UUIDs as the primary key and had an idea how it might be possible to combine both and profit from their advantages, without their disadvantages.</p>
<p>The table would have an <code>id</code> column that is auto-incremented and another column that contains a random string [A-Za-z0-9].</p>
<p>A blog article URL would look like this:</p>
<p><code>https://myexampleblog.com/article/236424.As5df8</code></p>
<p>This way the number is used for lookup and the string is used to check if it is someone trying to randomly guess URLs by incrementing the id.</p>
<p>Is this worth implementing, are there any flaws that I am missing?</p>
","389855","","389855","","2021-04-10 13:08:09","2021-04-10 13:08:09","Better than ongoing integer and uuid as primary key","<database-design><security><uuid>","3","3","","","","CC BY-SA 4.0"
"425373","1","","","2021-04-12 20:05:51","","0","112","<p>Typically in any application, the way a user (human) is authenticated is using a username/id and a password, whereas programmatic or api based access is authenticated using API keys (based on system designs that I have seen online).</p>
<p>Other than one reason that usernames and passwords work for humans because they're easy to remember vs machines which can work with arbitrary strings, is there any benefit of choosing one over the other ?</p>
<p>I say typically because AWS for eg., Uses an Id and a secret key (AWS Credentials) for programmatic access as well. Is there any additional benefit of having one public and one secret credential over having just one secret ?</p>
<p>Also, in case of humans, auth tokens are used to avoid credential verification / login for every call to an application. What are the  techniques used for the same purpose when two machines/programs are communicating ?</p>
","380739","","","","","2021-04-13 17:19:44","Why do users and programs have different client authentication mechanisms?","<api-design><security><authentication>","1","1","","","","CC BY-SA 4.0"
"425594","1","","","2021-04-20 09:13:31","","-3","788","<p>I'm developing a new application that allows the user to do many writes. Therefore, it is very inefficient that we use our server-side to handle every write request by users. Should we allow users to write to the database directly, without going through a server process? we're using Firebase so we can write security rules easily.</p>
<p>If yes, how can we protect against malicious attacks? For example, some attackers may send a lot of bytes to overload the database</p>
","390531","","","","","2021-04-20 18:49:33","Should we allow users to write to database directly? How to do it correctly","<design><database><security>","3","5","","","","CC BY-SA 4.0"
"426199","1","","","2021-05-09 09:33:17","","0","146","<p><img src=""https://github.com/blauertee/images/blob/master/offline%20secure%20two%20party%20computation.png?raw=true"" alt=""Offline secure two-party computation"" /></p>
<p>Is there a solution for the following problem?</p>
<ul>
<li>We have a function f(x,y) where the inputs are secret an cannot be
known by anyone besides the party that submitted them.</li>
<li>The output of f is public and can be known by anyone.</li>
<li>An adversary has access to any machine in the middle (not the devices of the two submitting parties).</li>
<li>The computation has has to happen on a third party device without interacting with any of the owners of x and y more than once to get an input eg. Enc(x).</li>
</ul>
<p>To me this sounds pretty much impossible, but since I cannot come up with a proof and the first time I heard of MPC all of it sounded impossible, let's give it a try.</p>
","391856","","379622","","2021-05-09 12:34:48","2021-10-07 17:44:54","Is offline secure two party computation possible?","<security><encryption>","3","8","","","","CC BY-SA 4.0"
"426203","1","","","2021-05-09 14:44:32","","74","9729","<p>Companies like Google and Microsoft use identifier-first screens: where you provide your identifier (like an email) before providing the password.</p>
<p>Why is this done, is this somehow more secure?</p>
<p>I'm setting up a login with Auth0 and identifier-first is one of the options; should I use it?</p>
","391828","","","","","2021-05-10 19:03:31","What is the purpose of identifier-first login screens?","<security><oauth2><login>","4","10","","","","CC BY-SA 4.0"
"426729","1","426842","","2021-05-26 10:28:56","","3","1427","<p>The motto of the upcoming question is &quot;I don't know what I don't know&quot;.
I would like to know if there are downsides or security risks with an authentication implementation.</p>
<p>Right now, I'm storing a JWT in an HTTP only cookie to send it from the client (React application) to the server (Spring Boot/Kotlin application). This removes the XSS vulnerability.</p>
<p>The JWT follows the basic principles (encoded secret, expiration date, issuer check, etc.). The server has servlet filters that check an existing cookie for validity on every request. When signing in via the client, the server responds with a valid JWT:</p>
<p><a href=""https://i.stack.imgur.com/0GAlG.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/0GAlG.png"" alt=""sign in"" /></a></p>
<p>The client will send its cookie with every request, which is furthermore checked for validity by the server's servlet filters on every request. When these checks are positive, the user is authenticated with Spring Security.</p>
<p>As described above, the JWT expires after 1 hour, 1 day, or whatever is configured. That's why I need to refresh it some way or another. Now, instead of using a refresh token and placing it in the client's local storage, I decided to just make a small request to the server and create a new JWT, which is send back via the response again:</p>
<p><a href=""https://i.stack.imgur.com/SJv0n.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/SJv0n.png"" alt=""refresh"" /></a></p>
<p>Again, when the <code>refresh</code> endpoint is called, the servlet filters will check for validity. So only an already authenticated user will receive a new JWT token that way. Some invalid JWT will not receive a new JWT.
I'm calling this endpoint from the client in an interval and therefore regularly extend the expiration date of the JWT inside the cookie.</p>
<hr />
<p>What I'm aware of:</p>
<ul>
<li>With the current refresh mechanism, an access token can be valid indefinitely (when the user is signed in regularly).</li>
<li>I also don't persist valid tokens or sessions in the database, so I can't really invalidate specific user sessions &quot;globally&quot; that way, as the cookie is the only source of truth. But this has nothing to do with the refresh token, I could create such whitelist/blacklist via the user ID instead.</li>
</ul>
<p>If something really bad happens, I could still</p>
<ul>
<li>...change the expiration date of all JWT to 0, so every authenticated user will be unauthenticated the next time he sends a request.</li>
<li>...or I could change the JWT secret, from which one no request will be authenticated anymore.</li>
</ul>
<p>My question is: Has what I'm doing (replacing the JWT inside the cookie) any more downsides?</p>
","309192","","","","","2021-05-29 18:22:09","Authentication with JWT in HTTP only cookie without refresh token","<security><authentication><spring><reactjs><jwt>","1","0","","","","CC BY-SA 4.0"
"429672","1","","","2021-06-24 11:29:37","","1","416","<p>We are currently in the early phases of developing several applications that differ significantly in their functionality. As part of building these applications, we have also developed a few generic BCs. Ideally these BCs should be reusable in order to minimize duplication and remove cross cutting conerns, and further improve development of future applications. Among these are a generic BC used to handle notifications such as emails, a BC dedicated to activity feeds, and more--and even more in the future.</p>
<p>This all works well and nicely in terms of the functionality they implement. However, I am unsure as to how to handle authorization and filtering of data in the case of either querying or executing commands.</p>
<p>Essentially, the source of truth with respect to the authorization rules are the non-generic applications/BCs. These applications can be totally different, but they all require authorization and the use of zero or more of the aforementioned generic BCs. Now, comes the question: What is the best way to handle this cross cutting concern without having to duplicate authorization logic for each new application we develop?</p>
<p>Our plan was originally to have a generic BC for Security that stores information about the resources and subjects that are in the system. In order to enforce the authorization, we envisioned developing an API-gateway for each non-generic application we develop and have the API-gateway enforce security policies. This approach should work well for handling authorization of command.</p>
<p>However, for queries, things seem to be complicated. For instance, our activity feeds may contain records that only a subset of the users of some application should be able to see, based on their roles in that specific application. In addition, some users may be able to only access a subset of the information of the returned records. For instance when fetching information from the generic BC that handles a Filesystem, some documents should be visible to some, while hidden from others.</p>
<p>Would filtering the information provided by the generic BC in the API-gateway before returning the data be a viable solutions? For instance when a given user fetches an activity feed from the Activity BC, the API-gateway queries the Security BC for information required to filter the results. This would incur overhead by having unnecessary data returned from the generic BC (i.e. the records/fields that are removed after filtering), but on the other hand this greatly reduces the complexity that filtering within that BC itself would incur. To me it seems that there should be a better approach without polluting each and every generic BC with authorization logic.</p>
<p>I have also read about the <strong>sidecar pattern</strong>. Would it make sense that each service implementing a generic BC has a sidecar containing the generic Security/Authorization BC? In order to avoid polluting each QueryHandler with authorisation filtering, the query result could e.g. be passed through a filter that interacts with the sidecar.</p>
<p>I am sorry for the long post; I hope I articulated myself in an understandable way. The approach to solving cross cutting concerns in DDD (and microservices) seem to be a highly debated topic, and it can be overwhelming to interpret the massive amounts of opinions regarding this.</p>
","382375","","382375","","2021-06-24 12:19:51","2021-06-24 12:19:51","Authorization and Cross-Cutting Concerns in DDD (CQRS) - Filtering Data","<domain-driven-design><security><cqrs><authorization><filtering>","0","3","","","","CC BY-SA 4.0"
"430008","1","","","2021-07-06 20:48:51","","0","75","<p>I'm creating an authorisation service, which does signing using a key.</p>
<p>For local development I was randomly generating a key on application start-up.</p>
<p>Now I'm deploying to the cloud (currently going with AWS), I'm refactoring this approach to be more robust / persistent.</p>
<p>The current idea I have is to generate some keys and dump these into environment variables - where the PRODUCTION private key would need to be handled with care / protected.</p>
<p>Because they'd be in environment variables, I'd use the PEM format.</p>
<p>At startup, I'd now load the keys from environment variables such as <code>APPLICATION_SIGNING_KEY_PUBLIC/PRIVATE</code>, parse the base-64 encoded bits and process the X509 thingy into <code>Private/PublicKey</code>s in memory.</p>
<p>Is this standard - or even acceptable? Are there any holes in this design?</p>
","391828","","","","","2021-07-06 20:48:51","How should I handle keys in production","<java><security><spring><aws><encryption>","0","2","","","","CC BY-SA 4.0"
"430282","1","430321","","2021-07-15 12:26:22","","0","172","<p>I'm on a dev team where the product manager wants to allow internal users to &quot;impersonate end-user and show the site exactly as the user sees it&quot;. I argue that this raises security flags and, even if it is allowed, data should be obfuscated and the UI should be read-only. When I call my bank or phone company for tech support, can they impersonate me?</p>
<p>Googling <a href=""https://www.google.com/search?q=where%20can%20i%20discuss%20web%20application%20data%20security"" rel=""nofollow noreferrer"">&quot;where can I discuss web application data security&quot;</a> leads to white papers and product web sites rather than forums or discussions.</p>
<p>Is impersonating an end user something that should be allowed, and if so how should it be done? How can it be done without loosing data integrity?</p>
","3268","","26494","","2021-07-16 00:00:57","2021-07-16 13:00:50","How do web apps provide support without revealing customer data?","<web-development><web-applications><security>","3","9","","","","CC BY-SA 4.0"
"430654","1","","","2021-07-28 15:32:26","","0","201","<p>Question on securing JWT token integrity, given the following scenario:</p>
<ol>
<li>Client sends a JWT to server signed with Client's private key</li>
<li>Server caches public key, but uses http (and not https) to retrieve the public key to validate that JWT is signed by the client.</li>
<li>Attacker intercepts the http connection, changes the public key to the attacker's public key, and sends a JWT to the server with the attacker's signature on it - misrepresenting the message as if it were sent from the Client.</li>
</ol>
<p>Is there a way out of this?
Thanks</p>
","277468","","","","","2021-07-30 18:34:32","JWT token security - public key forgery prevention","<security><jwt>","2","3","","","","CC BY-SA 4.0"
"430809","1","","","2021-08-04 12:29:59","","2","805","<p>What would be a secure way of storing client secrets used for authentication (webservices) in Xamarin/Android apps ?</p>
<p><a href=""https://docs.microsoft.com/en-us/xamarin/essentials/secure-storage?tabs=android"" rel=""nofollow noreferrer"">Secure Storage</a>, which interacts with <a href=""https://developer.android.com/training/articles/keystore"" rel=""nofollow noreferrer"">Android Keystore</a>, seems very useful for storing sensitive data acquired at runtime, such as access tokens, but not for sensitive data that needs to be immediately accessible.</p>
<p>EDIT: A practical example of client secrets would be, for instance, a static, universal client id and client secret used in OAuth2.0 authentication.</p>
","399808","","399808","","2021-08-06 10:15:44","2021-08-09 20:09:06","Secure way of storing client secrets in Xamarin / Android mobile apps","<security><android><mobile><oauth2><xamarin>","1","5","","","","CC BY-SA 4.0"
"430873","1","","","2021-08-07 20:05:42","","0","544","<p>So I'm currently running an analysis task for my company. I won't go into too much detail but we are dealing with medical records and other confidential data. Previously this application was only used internally but now there's come a business requirement that would allow for external access by an unauthenticated user outside of the business to view a document once they've completed a sort of handshaking process involving emails and an access code.</p>
<p>So, my question is, should I separate the new requirements into another publicly accessible application separate from the original application that requires user authentication? The app currently sits on an angular/.Net/MSSQL stack so this could require duplicating all or some portions of the stack. What are the things to consider in regards to one app with both public and private access vs two apps, one for the public and one used internally?</p>
","170457","","","","","2021-08-10 07:35:36","Should I separate the public and private portions of an application into two separate apps?","<architecture><web-development><web-applications><api-design><security>","3","2","","","","CC BY-SA 4.0"
"431478","1","431487","","2021-08-29 01:48:08","","1","291","<p>We are building a system that runs on our cloud and that needs information from our clients network that must not be exposed openly. We have concluded that the only way this could work, is if our clients can install an agent in their network, that would gather the required information and push it to our system through the internet.</p>
<p>This agent application, cannot communicate to our server using a regular RestAPI or webservice, because we have use cases that require us requesting specific information to the specific agent instances (a request to resync data from client 1 should only go to client 1's agent). We looked into gRPC streams and keep a stream open with every agent and just routes those requests to the stream, but since our backend has multiple instances, it would be hard to identify and reuse a single stream from different instances.</p>
<p>Then something that works for us, is using Redis streams and create a stream per agent, then our backend would only have to write to the specific agent redis stream (it would know the name of the stream as it would the agent/client identifier) from whichever of our instances.</p>
<p>The concern though, is the &quot;over the internet&quot; part.</p>
<p>Redis has TLS support since version 6, allows us to block certain commands (flushall for example) and supports defining users with access to only specific commands and keys/streams...</p>
<p>I understand exposing Redis over the internet or to any other network that not the one serving redis itself, has always been discouraged (AWS ElastiCache only allows access from within the same VPC/subnet for example). However, everything I find about redis security, say something in the lines of:</p>
<blockquote>
<p>Do not publicly expose the Redis server
Since Redis has no default authentication, it does not support encryption. All data is stored in cleartext. An attacker can use FLUSHALL command to delete all key-value data sets...
<a href=""https://www.gspann.com/resources/blogs/best-practices-to-secure-redis-implementation-in-cloud-infrastructure/"" rel=""nofollow noreferrer"">Source</a></p>
</blockquote>
<p>That type of statement holds very true to older versions of Redis that didn't provide TLS nor access control. But since those are now supported since version 6, am I crazy to go forward with this?</p>
<p>There's a concern about rate limiting, which is probably something that is not addressed by Redis itself, but that we can possibly find a solution with Kubernetes or network configuration in the cloud.</p>
<p>So, I know this is an unusual architecture and I am not the only one to <a href=""https://medium.com/@treeder/exposing-messaging-internals-to-the-outside-world-9eb8a9b886aa"" rel=""nofollow noreferrer"">think about it</a>, but  I am just looking for your opinions on whether exposing Redis streams over the internet for my use case, considering the features that Redis now has, is that much of a security risk/ bad idea overall.</p>
","401127","","","","","2021-08-29 14:34:09","Exposing redis to external clients","<architecture><security><message-queue><redis><cloud>","1","4","","","","CC BY-SA 4.0"
"431481","1","431519","","2021-08-29 06:39:52","","2","278","<p>How does phone number based authentication work, and what are its best practices?</p>
<p>I've noticed there are apps with streamlined sign-up/log-in processes where only a phone number is required, simply the phone number and then a verification code sent to the user via SMS. A good example is the dating app Hinge.</p>
<p>I don't really understand how this works, as it seems sort of insecure without a secret/password involved, and some obvious edge cases come to mind like:</p>
<ol>
<li>What happens if the user switches phone numbers? Can they access their account or need to go through some kind of customer service? How would you prove the new owner was tied to the old number? Could someone else access the original account if they later obtained the original number?</li>
<li>Do you need to keep track of device information in order to identify when a new device is authenticating with a phone number?</li>
</ol>
<p>I can't seem to find much for educational content on SMS based authentication, greatly appreciated if you can share some wisdom or point to good resources!</p>
","401131","","","","","2021-08-31 13:00:38","Understanding passwordless sign up for mobile apps","<security><authentication><patterns-and-practices><mobile>","2","2","","","","CC BY-SA 4.0"
"431591","1","431593","","2021-09-02 08:01:38","","1","217","<ul>
<li>I wrote a Java web service using <a href=""https://spring.io/"" rel=""nofollow noreferrer"">Spring</a> that handles REST calls from
the Internet.</li>
<li>The web service uses a Postgres database underneath to    store, modify and read data.</li>
<li>The Postgres database is used    exclusively by
this web service, no other program accesses the    database.</li>
</ul>
<p>The web service uses a database user that has all rights in the database schema (dropping tables, modifying tables, etc.).</p>
<p>Would there be any <em>tangible</em> benefit in using a database user for this web service, that only has rights to modify table entries (<code>select</code>, <code>insert</code>, <code>update</code>, etc.), but no rights to execute <a href=""https://en.wikipedia.org/wiki/Data_definition_language"" rel=""nofollow noreferrer"">DDL</a> statements?</p>
<p>Or would this be over engineered?</p>
","344152","","344152","","2021-09-02 08:08:52","2021-09-03 15:31:04","Is it OK for a public web service to use a database user with rights to execute DDL statements to access its underlying, exclusive database?","<database><security><web-services>","3","4","","","","CC BY-SA 4.0"
"431973","1","431975","","2021-09-16 17:46:48","","1","162","<p>Suppose user A creates a private resource at, for example, <code>/books/somebooktitle</code></p>
<p>If user B attempts to access the resource at <code>/books/somebooktitle</code> what code should be returned?</p>
<p>HTTP403: Permission denied seems obvious BUT, does this not leak information to user B that someone has created a book and named that book with the title &quot;somebooktitle&quot;? That's two pieces of information that user B shouldn't technically be entitled to.</p>
<p>HTTP404: hides the fact that the book exists.</p>
<p>Is there best practice?</p>
","339042","","","","","2021-09-17 01:59:20","REST HTTP Response code for a resource that the user is not authorised to access","<rest><security><http>","2","1","","","","CC BY-SA 4.0"
"432110","1","","","2021-09-22 00:52:10","","0","30","<p>Iâ€™m currently writing a software for my company (3rd world country), and I wanted it as simple as possible to install and maintain, so I started with <code>Qt</code> and no server app beside the database, (<code>MariaDB</code> or <code>MySQL</code>). The app is made to be used by different users on the same machine.</p>
<p>The app the communicating directly with the database, authentication and permissions are handled by the app against the database, only the database settings and a hashed master password to change them are kept locally (using <code>QSettings</code>) and set by the IT of the company (currently me) not the user himself. Now Iâ€™m wondering how to â€œuser proofâ€ that.</p>
<p>Ultimately, a user can open the settings and directly communicate with the database to change values. Encrypting the values would help but it wouldnâ€™t be â€œsecuredâ€ as I would either have to store the encryption key in the settings, or hard code it in the app. Some malicious users will try to break the app, to change the stocks values or to make an invoice disappear (thatâ€™s why they are doing with our old system, hidden by frequent malfunctions, so no ultimate proof, thatâ€™s why Iâ€™m recording something from scratch) but itâ€™s also very unlikely our users have the skills to disassemble and find the KDF algorithm or the hard coded passphrase. I canâ€™t tie the passphrase to a userâ€™s desktop session or login, as multiple users can use the same machine.</p>
<p>The choice was made not to have a web server and APIs to have less component to maintain for the IT, so Iâ€™m looking for ideas to secure the app a little bit better without APIs. Any idea ?</p>
","54783","","","","","2021-09-22 00:52:10","User proof network app with distant database","<design><c++><database><security><qt>","0","9","","2021-09-22 05:42:03","","CC BY-SA 4.0"
"432796","1","432797","","2021-10-19 10:26:35","","0","147","<p>This <em>would be</em> a broad question - but I'm asking specific to the situation around an app that I've developed.</p>
<p>In short, I've written an app that allows users to persist their photos and videos to the 'cloud'.</p>
<p>In an effort to keep this brief I won't go into too much detail but, essentially, any media captured through the app will be sync'd to Azure blob storage. Should they wish to access this again in the future I have a bit of .Net that will generate a sas token.</p>
<p>That's fine, from what I understand it's a typical implementation for secure storage of media.</p>
<h2>Question</h2>
<p>As the developer - I can jump onto the Azure portal at any time and view <em>any</em> media that I want.</p>
<p>Even if I were to take on other developers in the future, naturally there'd be serious restrictions over the team accessing data in the prod environment, but still - somebody has access.</p>
<p>This doesn't feel quite right, am I missing a security/privacy measure here?</p>
<p>I'm thinking about pushing this app soon, potentially marketing it but, at first, simply handing the APK to family and friends for wider use and testing of the beta - I'll have access to their most personal memories. Is it a matter of trust or is there some way I can implement a certificate or something somehow for this?</p>
<p><em>Note: Obviously only the original authors can download via sas token, I don't just generate the sas token for anybody authenticated/anonymous.</em></p>
","403757","","","","","2021-10-19 11:46:16","Do I have too much access to my users' personal media?","<security><mobile><privacy><blob>","2","0","","","","CC BY-SA 4.0"
"433145","1","","","2021-10-29 10:03:36","","1","394","<p>Usually, the web server that is serving a page includes the CSRF token inside the HTML. However when I'm using a cross-origin REST API, there is no &quot;initial&quot; page that could include the CSRF token.</p>
<p>My idea is to respond with a CSRF token after the user logs in, but I'm not entirely sure if this protects against a CSRF-attack?</p>
","404354","","","","","2022-08-12 09:59:36","How to get the CSRF token when using a cross-origin REST API?","<rest><api><security>","2","3","","","","CC BY-SA 4.0"
"433272","1","","","2021-11-03 22:18:10","","4","1398","<p>Recently, at the organization I work for, we've been using a static code inspection tool.</p>
<p>One of the more interesting findings is that private information, such as passwords, may be stored in the heap where it could potentially be intercepted by an application scanning the heap or perhaps a disk swap.</p>
<p>The app being scanned is a web app that runs on a private web server behind a firewall, so I'm wondering if this finding is relevant.</p>
<p>The app is written in C# and the &quot;remediation&quot; suggestion is to store sensitive information in character arrays rather than string objects so that they aren't stored in the heap.  I realize it would take up some time to properly remediate this issue, so I wanted to ask if this finding is relevant when the code runs on a private server because presumably, a hypothetical attacker would have to bypass the firewall and run malicious code on the web server to steal data.</p>
","25262","","","","","2021-11-05 08:41:25","If a code inspection tool finds a ""heap inspection"" vulnerability, is that relevant if the code is for a web app running on a private server?","<security><heap><code-security>","1","9","","","","CC BY-SA 4.0"
"433503","1","433504","","2021-11-13 12:04:03","","27","7962","<p>I have always wondered whether <code>public</code>, <code>protected</code>, and <code>private</code> has security implications post compilation.</p>
<h2>Hypothetically:</h2>
<pre class=""lang-cpp prettyprint-override""><code>class Foo 
{
public:
    int m_Foo; // Completely vulnerable and dangerous
    
protected:
    int m_Bar; // Possible attack vector from subclasses
    
private:
    int m_FooBar; // Totally secure
};
</code></pre>
<p><code>public</code> members [by terminology alone] suggest that they are more vulnerable than <code>private</code> members, but I can not imagine how this could be taken advantage of post compilation in something like a proprietary program.</p>
<h2>Questions:</h2>
<ol>
<li><p>Pre-Compilation, are members unneccessarily left in <code>public</code>, a security concern?</p>
</li>
<li><p>Why or why not?</p>
</li>
<li><p>Post-Compilation, are members unneccessarily left in <code>public</code>, a security concern?</p>
</li>
<li><p>Why or why not?</p>
</li>
<li><p>Are there any historical or hypothetical examples of attacks which used <code>public</code> designated members as an attack vector?</p>
</li>
</ol>
","136084","","9113","","2021-11-13 14:42:21","2021-11-17 19:18:51","Is it a security vulnerability to declare class members as public?","<c++><security><class><vulnerabilities><struct>","9","16","","","","CC BY-SA 4.0"
"434133","1","","","2021-12-07 10:53:26","","0","151","<p>I'm using a third party CRM application which allows you to build web forms using drag and drop widgets and the ability to add javascript code to manipulate those widgets.</p>
<p>I need to build a form to take payments using another third party payment gateway.</p>
<p>The basic process is as follows:</p>
<ul>
<li>customer selects products on the form.</li>
<li>I use inline javascript to work out the total cost.</li>
<li>customer submits form which generates a case ref number</li>
<li>upon the submit event i use javascript to create a payment basket using the payment gate way api and upon successful creation I redirect user to the payment gateway to make payment.</li>
</ul>
<p>My question is when i create the payment basket using the payment gateway api, i send the json payload including the total to pay using javascript. e.g.</p>
<pre><code>var total = 100;
var ref = 123456;

$.ajax({
  url: 'paymentgatewaycreatebasketurl',
  dataType: 'json',
  type: 'post',
  contentType: 'application/json',
  data: JSON.stringify( { &quot;Ref&quot;: ref, &quot;PaymentAmount&quot;: total, &quot;Quantity&quot;: 1, ... } ),
  processData: false,
  success: function( data, textStatus, jQxhr ){
    // redirect user to paymentgateway payment page using returned token and basket ref.
  },
  error: function( jqXhr, textStatus, errorThrown ){
    console.log( errorThrown );
  }
 });
</code></pre>
<p>Is it possible for a malicious user to edit the javascript and change the total amount e.g. using chrome dev tools etc?</p>
<p>What are the implications of doing it this way and is there a more secure method to prevent users from editing the total to pay?</p>
<p>I'm unable to define the total on the server side due to limitations of the CRM product hence having to do it using javascript.</p>
","221145","","","","","2021-12-07 10:59:13","Javascript and payment security","<javascript><api><security><browser><payment>","1","0","","","","CC BY-SA 4.0"
"435467","1","","","2021-12-21 09:44:08","","0","1293","<p>I want to adhere to the best practices and obviously encrypt the data sent to me by user. And I also want to provide the full-text search feature to the user (user can only search their own data, if that is not quite obvious).</p>
<p>Example usecase:<br>
There's a messaging app which is privacy oriented (for the simplicity of the example, we omit the e2e-encryption). This app stores messages in an encrypted form in a PostgreSQL database. I would like to provide a fulltext search feature, thus I need to build an fts-index.</p>
<p>I, however, cannot think of any possible solution. How to achieve it?</p>
<h2>EDIT:</h2>
<p>I am not asking about messaging app architecture, just a way to use fulltextsearch on encrypted data. And think of some other usecases, where the data to be searched is in orders of terrabytes, so offsetting the fts indexing to the client itself does not seem like a viable solution.</p>
","393096","","393096","","2021-12-22 07:35:03","2021-12-22 08:55:36","HOWTO: Full-text search over an encrypted database?","<database><security><sql><search><postgres>","4","11","","","","CC BY-SA 4.0"
"436050","1","","","2022-01-17 14:37:45","","0","1403","<p>I used docker to containerize the node.js express app and used GitHub action to add the .env file in the container. I googled this method when I was doing the DEV project. But I think that if someone gets the docker image then they can easily find out the .env file.
So I wanted to know whatâ€™s the industry standard used to deploy this .env file.</p>
<p>docker-build.yml:</p>
<pre class=""lang-yaml prettyprint-override""><code>        name: Make envfile
        uses: SpicyPizza/create-envfile@v1
        with:
          envkey_DB_USER: ${{ secrets.DB_USER }}
          envkey_DB_PASS: ${{ secrets.DB_PASS }}
          envkey_DB_NAME: ${{ secrets.DB_NAME }}
          directory: /home/runner/work/IMDb-MongoDb/IMDb-MongoDb
          file_name: .env
</code></pre>
<blockquote>
<p>â€œThe .env file should never be pushed to your github repo !â€</p>
</blockquote>
<p>What is the standard way to use or recreate this env file after we pull the code from GitHub or when the app is deployed in a container?</p>
","409038","","209774","","2022-02-19 12:55:50","2023-07-14 16:08:26","Whatâ€™s the standard used to deploy .env files?","<security><variables><environment>","1","1","0","","","CC BY-SA 4.0"
"436062","1","436063","","2022-01-17 21:10:03","","8","540","<p>There is a practice of showing bullets, not characters when a user inputs a password. Is this security through obscurity?</p>
<p>My first thought was that it's not, it's not really a system, we know how it works, one bullet = one character. It's just not showing the password so I don't think the definition of security by obscurity applies here. However, I'm not sure about it.</p>
","378463","","209665","","2022-01-17 21:21:31","2022-01-18 13:35:34","Is masking an entered password security through obscurity?","<security>","1","9","","","","CC BY-SA 4.0"
"436449","1","","","2022-02-03 06:43:24","","0","33","<p>I have an endpoint API for a POST request in a multi-tenant application, let's say it is for a Payment, where we have to store these fields:</p>
<ul>
<li>tenant_id (this is the account owner)</li>
<li>amount</li>
<li>date</li>
<li>payer_id -- the user that makes the payment</li>
<li>user_id  -- another user that has to be attached to this payment</li>
<li>category_id -- a category payment that the user can select from a dropdown menu</li>
</ul>
<p>The JWT can tell me the tenant that is making the request and I can trust it, so the tenant_id is filled by the server-side. But every other field is going to be stored from the POST request.</p>
<p>Should I check the ownership of every *_id field?
In this case, I should make 3 queries to the database, a process like this:</p>
<ul>
<li>Get the row payer_id from the users table.</li>
<li>Check if row-&gt;tenant_id == tenant_id</li>
<li>If yes, payer_id is a resource owned by this tenant, if no return an error.</li>
</ul>
<p>Repeat for user_id and category_id ... end every other *_id field.</p>
<p>My question is about good practice.</p>
","410099","","","","","2022-02-03 07:18:23","Should I check the ownership of every ""somethig_id"" fields from a POST request?","<web-development><rest><security><development-process>","1","0","","","","CC BY-SA 4.0"
"436467","1","","","2022-02-03 15:14:10","","0","127","<p>I am familiar with and see the benefits of <a href=""https://developer.mozilla.org/en-US/docs/Web/Security/Subresource_Integrity"" rel=""nofollow noreferrer""><strong>Subresource Integrity</strong></a> (<strong>SRI</strong>).</p>
<p>I understand that with <strong>SRI</strong>, once you've added a script reference with the correct <code>integrity</code> attribute, if the remote script is subsequently compromised, then the <strong>SRI Hash</strong> will not match the remote asset and the remote script will not download.</p>
<p>That's an effective safeguard as long as the remote script was uncompromised at the point when you first referenced it.</p>
<p>But what if, at that point, the remote script was <em>already</em> compromised (and a new SRIHash generated to match the compromised asset)?</p>
<p>The asset must be able to self-verify. My principle concern here is <strong>self-verification</strong>.</p>
<p>That is, an asset needs to be able to authenticate itself in the absence of third-party verification.</p>
<p>(An SRIHash will verify that the asset is a data-match, but that doesn't help if a bad actor is able to alter both the asset <em>and</em> the SRI Hash.)</p>
<p>At the very least, we need <em>more</em> than just an SRIHash.</p>
<p>To verify the integrity of a new unknown remote asset from a new unknown source, when we cannot say for certain if either the remote asset or the remote source has not been compromised, we need something that <em>cannot be plausibly altered</em> without giving the game away.</p>
<p>Can this be achieved (?) by adding to the asset and the SRIHash the combination of:</p>
<ul>
<li>a <strong>timestamp</strong></li>
<li>a <strong>geostamp</strong></li>
</ul>
<blockquote>
<p><strong>N.B.</strong> I'm specifically talking about a <em>legitimate asset</em> which has been compromised, <em>not</em> a <em>bad asset</em> which was bad from the outset. I
recognise there's nothing that can be done about the latter.</p>
</blockquote>
<p>This is what I've come up with so far in terms of an unknown remote asset self-verifying its integrity:</p>
<p>The remote asset has a conventional <strong>SRI Hash</strong>.</p>
<ol>
<li>the asset has a name and a version</li>
<li>the named, versioned asset contains a <strong>Unix Timestamp</strong> giving the time it was first published</li>
<li>the named, versioned asset contains <strong>Lat and Long Geo-coordinates</strong> giving the location it was first published</li>
</ol>
<p>The three pieces of data above are used to derive from the <strong>SRI Hash</strong>:</p>
<ol start=""4"">
<li>a 256-character key.</li>
</ol>
<p>That 256-character key is then used to derive from the asset itself:</p>
<ol start=""5"">
<li>a 16-character slug</li>
</ol>
<p>That 16-character slug is then inserted into the named, versioned filename and becomes a <strong>canonical part</strong> of that filename:</p>
<pre><code>https://example.com/remote-folder/remote-script--2-4--39dsoe26shw82czm.js
</code></pre>
<p>Wherever <strong>Remote Script 2.4</strong> is hosted on the web, it will always have the filename:</p>
<pre><code>remote-script--2-4--39dsoe26shw82czm.js
</code></pre>
<p>Nearly all pieces of information (the SRIHash, the timestamp, the geo-coordinates, the 16-character slug) are referenced in the data itself so that everything can either:</p>
<p>i) be checked as identical by the computer (eg. Is the SRIHash in the attribute the same as the one listed in the asset? Does the filename duplicate the same 16-character sequence from the asset? Is the Asset Name the same as listed? Is the Asset Version the same as listed?); or else</p>
<p>ii) the technician referencing the remote script can be asked if they trust the asset's signature (eg, This data reports that it was published [in the middle of the Pacific] in 1981? Do you wish to continue?)</p>
<p>It occurs to me that a determined exploiter who wants to generate a 256-character key for their own compromised version, where the key is consistent with a <em>plausible publishing time and location</em> will need to manipulate the asset itself by inserting comments. Consequently a semi-automated check would <em>also</em> be required to verify that the asset doesn't contain any unusual comments.</p>
<p>Is this level of self-verification of integrity (using a <strong>timestamp</strong> and a <strong>geostamp</strong>) enough? Or is this too easily circumvented?</p>
<p>This is mostly as far as I've got on my own, but I'm happy to answer any further questions to clarify any detail I may have inadvertently left out.</p>
","359345","","359345","","2022-02-03 16:37:08","2022-02-03 16:37:08","How to verify that a legitimate (but unknown) remote asset from an unknown source has not been compromised and that its integrity remains intact?","<security><web><cryptography><verification><data-integrity>","2","32","","","","CC BY-SA 4.0"
"438156","1","438157","","2022-04-21 09:14:04","","3","327","<p>How does antivirus protect itself from malware?</p>
<p>Some types of malware will kill the running processes and since antivirus is just another software like any other why they can't just kill the antivirus process?</p>
<p>I understand that antivirus will scan the malware before it can kill the antivirus process but still it does not guarantee that the malware signature is in the database or that the malicious behavior of malware will be detected right away.</p>
<p>I assume that antivirus software somehow makes itself &quot;closer&quot; to operating system and because of that disables random software from killing its process but would like to know if this is true and how it is achieved.</p>
<p>Same question could be asked for other security systems/software like host-based intrusion detection systems and its agents that run on workstations and send data to server.</p>
<p>Thank you</p>
","413835","","","","","2022-04-21 09:32:17","How does antivirus software protect itself from malware?","<security><malicious-code>","1","1","","","","CC BY-SA 4.0"
"438359","1","438397","","2022-05-01 22:01:14","","0","303","<p>I use Postgres database to store user information. Some of that information is sensitive so it was decided to store that information in <a href=""https://www.vaultproject.io"" rel=""nofollow noreferrer"">Vault</a>. The user table in Postgres has id's generated by a Postgres sequence and also it has unique identifiers for each user which come from an external system. My teammate wants to store user data in Vault by using Postgres user row id as the key in Vault while I think it's better to store by unique user identifier as the key.</p>
<p>The disadvantages of using Postgres id's is that:</p>
<ul>
<li>Vault is tightly coupled with Postgres</li>
<li>When I use local DB for development the ids might be different so I will also have to use a local instance of Vault for development instead of using a staging Vault instance</li>
<li>I can't think of an exact example but I think using Postgres id's can somehow become inconsistent with Vault id's (maybe when a transaction fails but Vault is updated with a new user id which will become a &quot;zombie&quot; key).</li>
</ul>
<p>The advantages of using Postgres id's is that:</p>
<ul>
<li>Vault keys don't contain unique user identifier which makes them more secure</li>
</ul>
<p>Which approach is better?</p>
","282823","","","","","2022-05-02 19:20:08","Is it a good idea to use database sequential id as a key in external key-value storage?","<design><database><security>","2","1","","","","CC BY-SA 4.0"
"438360","1","","","2022-05-01 22:57:05","","2","552","<p>This is a question for software engineers who are tasked with managing the development cycle for a Web application using NPM packages for deployment on a customer's Intranet or the Internet.</p>
<p>This is not about what could theoretically be done managing security risks but what you are actually doing when bringing a commercial Web app to market.</p>
<p>If you think that you have good procedures in place to manage security risks, then please share your knowledge!</p>
<p>The answer should ideally outline the steps taken at various points in the development cycle. Example only, not exhaustive:</p>
<ol>
<li>Before we opt to install a package we assess trustworthyness. We [also review][do not review] secondary dependencies.</li>
<li>We have selected developments tools [React][Angular][etc.] because [any security considerations][just developer preference]</li>
<li>We [disable][do not disable] scripts when installing packages and we do this [...]</li>
<li>Before production or development packages are accepted for wider use we do [...]</li>
<li>For installed packages we monitor for vulnerabilities [by running <code>npm audit</code> every x days][by subscribing to monitoring service x][by using tool y]</li>
<li>For any vulnerability found we do this [...]</li>
<li>We [accept][do not accept] these vulnerabilities in dev packages [...]</li>
<li>We [accept][do not accept] these vulnerabilities in production packages [...]</li>
<li>When testing we [do][do not] monitor for network activity, CPU usage, and we also test [...]</li>
<li>For release, vulnerabilites [are][are not] acceptable if [...]</li>
<li>Also [...]</li>
</ol>
<p>The sections below elaborate a bit more on the subject and specific concerns.</p>
<hr />
<p>When setting up a Javascript/Typescript tool chain to develop a Web application using, for example, <code>webpack</code>, React and Jest, then you may be able to select a few &quot;must have&quot; and a few &quot;wanted&quot; NPM top level packages. But even when these are carefully chosen, there will usually be hundreds if not thousands of secondary, tertiary, etc., dependencies dragged in that fall outside of the &quot;carefully chosen&quot; realm and it is impossible to keep track of security and quality for all of them.</p>
<p>An <code>npm audit</code> will show vulnerabilities and it may be possible to get these to zero at least for the production code. But often interdependencies prevent an outright update of all packages, even when prepared to adapt for breaking changes. That means that, at least for the dev dependencies, vulnerabilities may remain and each vulnerability should be carefully considered before allowing development to continue. This could become a time consuming task as changes can be frequent.</p>
<p>I'm aware that there are commercial offerings that may assist in managing vulnerabilities but I have no experience with those.</p>
<p>Within the current software landscape of 2022, and with cybersecurity on everybody's mind:</p>
<p>If you are developing web applications commercially using NPM packages, what do you do to reduce risks?</p>
<p>In other words:</p>
<p>How do you setup your tool chain and manage the development cycle securely in a commercial setting where there are constraints on time and money?</p>
<hr />
<p>Following the comment by @Flater, I'd like to elaborate on what I consider 'risks'.</p>
<p>My concern would not be breaking the build or breaking functionality due to altered behavior (i.e. unintended bugs in the package). The former is obvious and the latter should be caught during product testing.</p>
<p>Firstly, there is a risk of infecting the developer machine with malware; this could be ransomware or some other destructive software, i.e. software that deletes files randomly and spreads across the network. Would you install each NPM update onto an isolated machine and observe for x hours or x days before the update can be considered secure for deployment on developer machines? That's probably not workable. Use some third party tool that must flag the NPM package as secure? Which tool and how would that work? Update first onto a virtual machine then run the tool for a scan? Or trust that someone else would have discovered any misbehavior of NPM packages and simply run the update? Any other approach?</p>
<p>Secondly, there is the risk of delivering malware to the customer, i.e. hidden bitcoin miners, adware, spyware, possibly even Web apps that attempt to exploit browser vulnerabilities. Do you monitor the Web app for a while as part of the testing regime, for example running in the browser while monitoring network activity or looking out for &quot;unusual behavior&quot;? Do you monitor browser CPU usage as part of your testing?</p>
<p>Thirdly, less severe, there may be unwanted 'pings' (i.e. downloading an icon via CDN rather than locally) or other 'phoning home' incidents (i.e. usage monitoring) originating from packages that you may otherwise consider trustworthy. These could be something simply forgotten by the author or it is documented &quot;somewhere&quot; that this is expected behavior unless this or that configuration parameter is set. Web apps that are deployed onto Intranets of security conscious customers would question these incidents flagged by their firewalls. Although this may not turn out to be a security risk per se, random attempts to contact the Internet may be a risk to your reputation. Again, do you monitor network activity in a browser to ensure that no unwanted Internet contact is established? If there is contact from what you consider a trustworthy package, would you halt the release? Or add it to the release notes to explain it away and prepare to answer awkward questions asked by customers? Any other steps taken?</p>
<p>I realize that businesses and budgets for software testing and quality assurance vary greatly. So assuming you are not NASA and must remain competitive, what steps does your business take to minimize the above risks? Is there a &quot;best practice&quot; when it comes to NPM with it's unique authoring and delivery mechanisms, fit for 2022?</p>
<hr />
<p>If you are downvoting then please comment why so that I can learn from it.</p>
","414290","","414290","","2022-05-05 19:51:05","2022-11-02 18:34:12","How do you reduce security risks when using NPM packages in commercial Web development?","<web-development><web-applications><security><npm>","3","5","","","","CC BY-SA 4.0"
"438389","1","","","2022-05-02 13:58:13","","2","188","<p>I am looking for an approach to verify that some information has not been modified after a certain point in time.</p>
<p>Let's assume a data provider records a data set at time X and provides it to a data consumer at time X+10. How could an approach look like in which the data consumer could now verify that the data set has not been manipulated by the data provider since time X?</p>
<p>Of course, a PKI can be used for authentication and authorization. In this case, however, it is not only important to know from <strong>whom</strong> the data comes, but also that it <strong>has not been changed</strong> from the data provider after a specfic timestamp.</p>
<p>I thought maybe the data provider could hash the recorded data and sign it with his private key. The signatures would now have to be stored in a trusted location. For this, a blockchain came to my mind at first. After receiving the record the data consumer, could retrieve the corresponding signature from blockchain and verify it against the received record.</p>
<p>But since I am not an IT security expert, I wanted to ask what solutions already exist for such a problem?</p>
","414319","","","","","2022-05-02 19:30:18","Which approach can be used to verify that information has not been manipulated after it has been recorded?","<security><blockchain><trust>","4","3","","","","CC BY-SA 4.0"
"438621","1","438622","","2022-05-15 08:28:16","","0","134","<p>In a web app I'm writing, a singed-in user is recognized by their cookie containing a session identifier. That session id has sixty-four bits of entropy, so I believe brute-force attacks are impossible in practice. However, not signing it to prevent tampering still feels less secure than it ought to be.</p>
<p>I'd also like to keep the session id not signed not to increase the attack surface through the cryptography code I'm using, since I'm not a cryptography expert, and crypto is hard, so I always could get those details wrong.</p>
<p>But maybe I'm missing something? Is there an industry practice on that?</p>
","414857","","","","","2022-05-15 10:19:59","Should an access token really be cryptographically signed?","<web-applications><security><authentication>","1","0","","","","CC BY-SA 4.0"
"439238","1","439239","","2022-06-14 14:50:34","","0","44","<p>Assume an application developed in a PaaS public cloud environment. The application stores and processes some kind of sensitive data.</p>
<p><strong>Encryption-at-rest</strong> seems clearly described already, and the option to manage keys outside the cloud which can help ensure nobody outside your organisation has access to your unencrypted data when stored in cloud.</p>
<p><strong>Encryption-in-transit</strong> seems clearly described already. E.g. TLS encryption at Presentation-level would mean that the unencrypted data is not readable at the lower levels of the OSI-model during transit.</p>
<p><strong>This leaves us with data-in-use</strong>. Cloud providers are increasingly vague on this, and there seems to be much misunderstanding on this aspect. The time data is logically stored in RAM and being processed by e.g. an application, to my understanding it is not encrypted. This is the part of Cloud encryption I do not fully understand how to explain, and I need your help.</p>
<ul>
<li><p>Who can theoretically access the clear data at this point?</p>
<ul>
<li>Would container escape techniques allow an attacker to access other cloud-customers' data?</li>
<li>Would a memory dump of the virtualisation-layers or the physical machine in a datacenter allow an attacker to access clear data?</li>
<li>Are there other ways an attacker could move &quot;below&quot; the virtual application and access the information as it is being prcocessed?</li>
</ul>
</li>
<li><p>To my old-school-hardware-brain (while this may be complicated by the many levels of abstraction involved), at some point the data must exist on some server somewhere in RAM. How is the data protected at that point? From attackers? From the cloud provider? From other customers?</p>
</li>
<li><p>Is this even a viable attack vector to be concerned about? Why? Why not?</p>
</li>
</ul>
<p><strong>Notes:</strong></p>
<ul>
<li><em>&quot;Confidential computing&quot; initiatives is outside scope for this question, since it is not yet in use on a wider scale to my understanding.</em></li>
<li><em>What I want to understand is: At what points in time is what information/data accessible to whom in a cloud infrastructure.</em></li>
<li><em>I want to understand what is &quot;possible&quot; rather than what is &quot;intended&quot;.
Please correct, if my understanding is wrong.</em></li>
</ul>
","416135","","","","","2022-06-14 15:15:59","At which points in the process/stack is Cloud data not encrypted - Cloud Security","<security><cloud-computing><encryption><cloud>","2","0","","","","CC BY-SA 4.0"
"439547","1","439560","","2022-06-29 14:28:06","","1","1516","<p>People say &quot;<em>don't expose primary keys from the database in your API</em>&quot; because its a major security leak, so I'm trying to come up with a way for:</p>
<ul>
<li>RESTful HTTP requests to reference server-side resources without requiring their DB PK
<ul>
<li>example: I want to update a <code>Widget</code> resource with a PK ID of 293, so I want the equivalent of a <code>POST /myapi/widgets/293</code> but without having to mention <code>293</code></li>
</ul>
</li>
<li>RESTful HTTP responses should be able to reference server-side resources without sending back their DB PKs
<ul>
<li>example: I want to fetch all blue Widgets, so I want to request <code>GET /myapi/widgets?color=blue</code> and any Widgets that come back in the JSON array should not have their DB PKs</li>
</ul>
</li>
</ul>
<p>I can solve the 2nd issue (the read) via DTOs, and just make sure that I have a <code>WidgetDto</code> that doesn't include the <code>Widget#id</code> field at all.</p>
<p>But as far as referencing resources without their database keys, what are typical solutions here?</p>
<p>The only thing I can think of is to generate UUIDs for each resource (each <code>Widget</code>) and store it in the DB alongside its primary key, so:</p>
<pre><code>[widgets] table
===
[id] --&gt; bigint primary key auto increment not null
[ref_id] --&gt; varchar(36) not null (UUID)
</code></pre>
<p>...and then rotate UUIDs every so often. But that creates its own headaches if something client-side is caching or currently using a resource reference and we change its UUID on the server-side. Any ideas? Thanks!</p>
","309754","","309754","","2022-08-05 14:43:40","2022-08-05 14:43:40","Designing APIs that don't expose database primary keys","<database><rest><api><api-design><security>","3","9","","","","CC BY-SA 4.0"
"440287","1","440291","","2022-08-08 06:06:53","","0","64","<p>I went through different ideas about storing AES key for encrypting database columns, I learnt that there are the possible solutions:</p>
<ol>
<li>put the key in the database</li>
<li>find a Key Management Service to help you keep the key</li>
</ol>
<p>Below is my suggestion:</p>
<ol start=""3"">
<li>prompt the user to input the key everytime he/she uses the database, it is a sentence he/she sets. After removing non-numeric characters, it has 256 bits for AES-256 to use.</li>
</ol>
<p>So why (3) does not work, coz if not a lot of people is using now?</p>
<p>And why (1) works if someone accesses the database, and simply gets the key and decrypts the columns?</p>
<p>Why (2) works if someone gets your Key Management Service credentials in your source code?</p>
<p>What is the most secure way that is available to keep the AES key?</p>
","418873","","418873","","2022-08-08 07:10:02","2022-08-08 09:15:37","Personal AES keys storage idea not working reason","<security>","2","4","","","","CC BY-SA 4.0"
"441125","1","441128","","2022-09-19 15:40:40","","-3","68","<p>I'm creating a service for creating web tools. The tool is a generated web page with some JS engine. The user can interact with the JS engine through the user interface. The user interface can be either ready-made or custom.</p>
<p>The idea of â€‹â€‹using a custom user interface is dangerous. This approach creates possible security issues (eg XSS).</p>
<p>Please advise a more efficient solution for the implementation of the HTML playground.</p>
","420667","","","","","2022-09-19 16:41:46","HTML Playground","<javascript><security><html><customization>","1","1","","2022-09-19 19:08:23","","CC BY-SA 4.0"
"441257","1","","","2022-09-26 06:12:27","","1","490","<p>In microservice architecture, let's say I have 4 services that will need file upload/download feature, I have two options for this:</p>
<ol>
<li>I can create another new service(5th) to expose an file
upload/download API.</li>
</ol>
<p>But when it comes file download authorization, the download privilege actually depends on the other 4 services data (if the user can acces this customer, then he can download the customer's contract), this will introduce an high coupling with the other 4 services, and when the data types (customer order contract...) increase, it will become more complicated.</p>
<ol start=""2"">
<li>I can duplicate an file upload/download API on each of the 4
services, since all the data is avalibel locally for each service,
the cohesion will be very high.</li>
</ol>
<p>Which one will you choose, or do you have any other solution?</p>
","23287","","404182","","2022-09-27 01:30:14","2022-09-30 11:03:15","microservice file upload/download central vs distributed api","<microservices><security>","1","1","","","","CC BY-SA 4.0"
"441566","1","","","2022-10-11 21:49:52","","-2","170","<p>I understand that credential leakage occurs reasonably often due to people forgetting to .gitignore a .env file</p>
<p>I'm building an application in VueJS and right now I'm storing some S3 credentials as environment variables in order to retrieve and access some data in the site.</p>
<p>Is there any way that this can expose credentials to an end user of the application? I've searched for any info I can but all I'm finding is articles about accidentally publishing .env files which is a risk I'm less concerned about here.</p>
","421601","","","","","2022-10-11 22:07:29","Security implications of storing credentials in a .env file","<security><vue.js>","1","0","","","","CC BY-SA 4.0"
"442055","1","","","2022-11-02 19:15:12","","0","59","<p>Have an enterprise web application with a Web API 2 backend and other external backend processes. Both of these send mail with or without user interaction. I identified the client credential flow as the appropriate authorization flow for our application, but I discovered it is not supported for SMTP AUTH on Office 365.</p>
<p>Q: If we use the authorization code flow and have an admin user login to the Microsoft prompt, do consent, obtain an access token and refresh token, and store these (securely on the server or in our database), can we continually get new access tokens using the refresh tokens without user interaction again? Or will these expire at some point and require the user to interactively sign in again?</p>
<p>Our goal is a one-time system configuration, which is achieved with the client credentials flow via tenant, app id, and client secret, but going this route requires us to use Microsoft Graph for mail which has some limitations that SMTP AUTH does not. However, my concern is whether the authorization code flow might require an IT administrator of the system to continually log in on a periodic basis, which would not be acceptable.</p>
<p>Would the authorization code flow also fit our use case?</p>
<p>Migrating away from Basic Authentication for context; where Basic Authentication is a one-time system configuration in most software.</p>
","25240","","422559","","2022-11-09 03:55:00","2022-11-09 03:55:00","Authorization Code Flow or Client Credential Flow for One-Time Mail Configuration","<design><security><oauth><office365>","0","0","","","","CC BY-SA 4.0"
"442390","1","","","2022-11-22 11:54:47","","0","98","<p>I am building a simple web app where one set of users have varying admin privileges who can write to database and the other set can only view data.</p>
<p>I am used to securing APIs with JWT or session tokens, but my boss is 50-year-old DBA who thinks it's not secure. He is saying I should implement security within database itself and create all users with appropriate roles in database. The application would then connect to the database using the credentials of each user and perform operations they are allowed. He is also asking me to do all data validations in database using triggers rather than dealing with it on application layer.</p>
<p>His reasoning is that if the application gets compromised in some way the data would still be consistent and secure. I can't really argue with it because it is true.</p>
<p>I understand his reasoning, but I am used to building apps with ORMs which uses one role to get all data. Is it even possible to do it with common Orms like Prisma, hibernate or EF core? I think it could even conflict with a lot of caching mechanisms ORM tools employ.</p>
<p>I don't really understand how to proceed. I can do it, but it will significantly increase the development and maintenance time.</p>
<p>How should I proceed?</p>
","423418","","","","","2022-11-22 14:54:51","Should security and data validation be implemented within database or application?","<database><api><security><orm>","3","0","","","","CC BY-SA 4.0"
"442759","1","442760","","2022-12-10 09:10:43","","1","112","<p>We develop a SaaS solution that processes customer ERP data and provides analyses from it in a front-end. The software is a standard solution and should require as little customization as possible for the respective customer. Unfortunately, the <strong>ERP data is business-critical data (not legal protected data e.g. personal data, rather than corporate secret data), so processing the data on our cloud is not an option for the customer</strong>.</p>
<p>For this reason, we have considered three alternatives and asking whether there are any other options, or what is best practice in such a case.</p>
<ol>
<li><strong>On-premise</strong>, i.e. each customer hosts its own instance on its own server</li>
<li><strong>Analysis at the customer's site</strong>: We provide each customer with an analyzer service that prepares the data. The rest of the application is hosted by us. If our application is requested by the customer, the frontend collects the data via REST calls from our servers as well as from the customer's server.</li>
<li><strong>Anonymize-deanonymize data</strong>: We provide an anonymizer service which anonymizes the data on the customer side before it is sent to us. In the next step we perform the analysis and send the results back to the customer.
In the last step, the data is de-anonymized again by the customer and stored in a local database at his site. If our application is requested by the customer, the frontend collects the data via REST calls from our servers as well as from the customer's server.</li>
</ol>
<p>Do you know any other methods/best practices and are there names for these strategies?</p>
","424183","","424183","","2022-12-10 12:07:51","2022-12-10 18:12:28","How can I enable user data sovereignty in a B2B SaaS application?","<security><application-design><software-as-a-service><strategy><privacy>","2","5","","","","CC BY-SA 4.0"
"442984","1","","","2022-12-22 10:27:39","","0","497","<p>I want to build a web application with a Single Page Application as the front end and an API as the back end. The front-end SPA will read and write data to the API.</p>
<p><strong>The SPA and the API will be hosted on two different domains:</strong></p>
<ul>
<li>SPA: <code>https://my-spa.com</code></li>
<li>API: <code>https://my-api.com</code></li>
</ul>
<p>The API needs to be private so only authenticated users can use it.</p>
<p>I wonder if I should use a simple cookie session mechanism or OAuth for the authentication.
Oauth seems to be the standard for this kind of app, but it also seems more prone to security breaches because it is more complex to implement.</p>
<p><strong>My questions:</strong></p>
<ol>
<li><p>Can I use a simple session cookie, or is there any technical blocker for it? By session cookie, I mean having a sign-in endpoint that will generate and save a random string in the database and set it as a cookie. Then in each API request, I would get the user information from the database using the session cookie random string to manage permissions. I understand the session cookie should be set with the <code>secure</code> and <code>sameSite=None</code> attributes because the SPA and the API are not on the same domain. Is that a problem?</p>
</li>
<li><p>Why OAuth seems more used in this situation if it is more complex to implement and could lead to more security issues?</p>
</li>
</ol>
","424723","","","","","2022-12-22 14:39:47","Can I use a session cookie for API authentication?","<api><security><authentication><cookies><single-page-apps>","1","0","","","","CC BY-SA 4.0"
"443529","1","","","2023-01-22 16:24:00","","1","126","<p>At deployment time, I register my microservices in the following way:</p>
<ul>
<li>They register themselves in Keycloak to have an identity as a confidential client;</li>
<li>Then they call an endpoint on a dedicated internal microservice &quot;AUTH-SRV&quot; that grants them the appropriate permissions/roles;</li>
<li>They also register themselves with the permissions that they are granted in this &quot;AUTH-SRV&quot; as a client for the other internal microservice that they need to talk to.</li>
</ul>
<p>All my microservices are deployed on premises (without Docker support).</p>
<p>It's working but I find it's not very secure to let a service register itself and its permissions to call others services.</p>
<p>On the other hand, I do not know how to find a better way to do it. For example, if an admin user needs to register a service by hand in a back-office UI, it's not manageable, because we have more than 30 microservices. It will require a lot of work and my application could easily break at runtime because of a missing permission granted between two internal services.</p>
<p>If I  opt for another solution, like authorizing all internal calls between services, I may not have a secure in-depth solution.</p>
<p>The question is, is there a more secure way to register and manage internal service to service permissions?</p>
","285517","","379622","","2023-01-29 15:03:12","2023-01-29 15:03:12","How to manage autorization for internal service to service communication in a microservice architecture?","<microservices><security>","1","8","","","","CC BY-SA 4.0"
"443542","1","","","2023-01-23 09:19:58","","1","245","<p>Suppose you are given a python API:</p>
<pre class=""lang-py prettyprint-override""><code>def onArgumentReceived(x):
    doWhatever(x) # expects a unicode string
</code></pre>
<p><strong>I am not a security expert by any stretch of the imagination,</strong> however on the face of this, without explicit checking, this just instinctively <em>feels</em> like an obvious place to find a vulnerability laid bare.</p>
<p>Whereas:</p>
<pre class=""lang-cpp prettyprint-override""><code>void onArgumentReceived( const QString &amp;x )
{
    doWhatever(x); 
}
</code></pre>
<p>seems inherently safe because the static typing will prevent strange types being fed into the function.</p>
<ul>
<li>Am I right to assume the latter probably is more secure?</li>
<li>Is the former a good place to discover vectors of attack?</li>
</ul>
<p>Thanks.</p>
","136084","","","","","2023-01-24 12:08:21","Are interchangeable types a security vulnerability? Are they good vectors for attack?","<c++><python><security><dynamic-typing><static-typing>","3","6","","","","CC BY-SA 4.0"
"443584","1","","","2023-01-25 20:06:08","","0","49","<p>I have an application that employs &quot;zero knowledge&quot; data security, where even with full backend access to our application, customer data cannot be read without knowing their individual passwords. I use what I believe to be a fairly standard method for this: password, after hashing, protects a data key; password change = re-encrypting data key with new password hash. So far so good.</p>
<p>Now we have customers asking for SSO, specifically through AAD and/or Okta. I'm more familiar with AAD at this point, so I'm going to focus on that platform (but answers which address other platforms would be welcome too!).</p>
<p>The obvious problem is that we won't have access to the user password, and thus can't use it to protect the data key. (And even if we did get the password on login, we wouldn't know when it was changed). So how do we make this work without compromising &quot;zero knowledge&quot; security?</p>
<p>My first thought is that for each user added to the application a secret will need to be created in the SSO user profile, and then sent back each time as one of the identity claims or just be retrieved some other way after login. For AAD I believe this can only be done with an <a href=""https://learningbydoing.cloud/blog/getting-started-with-azuread-extension-attributes/"" rel=""nofollow noreferrer"">extension attribute</a>. There are a few drawbacks to this though, at least with AAD:</p>
<ol>
<li><p>An AAD admin would be required to add each user to the application (even if they were already in AAD), since only the User Administrator role can apparently set extension property values; unless I'm doing something wrong, standard users cannot set extension attribute values on their own profiles. So this precludes the possibility of the customer's users accessing the application without admin intervention for each user.</p>
</li>
<li><p>Customers might not want to give my application the Graph API permission &quot;User.ReadWrite.All&quot; (which, even if under the admin's identity, is needed to write extension properties to the AAD user profiles when they're added to the application). If not, then admins will have to do something like run a Powershell script every time they want to add a user in their Directory to our application; they could not be added purely in-app (even by the admin).</p>
</li>
<li><p>Customers might not want to be adding extension properties to their directories at all. This one seems like a deal breaker.</p>
</li>
</ol>
<p>Another option I've considered that at least avoids (1) and (2) is having one secret for the customer, so that they only have to set up the application once and all users could then access it without admin intervention. Even assuming it were possible to get this information returned with each login, the problem is obvious - if that &quot;secret&quot; were compromised it would compromise the whole organization, not just one user.</p>
<p>Finally I've considered just requiring users, as part of the signup process, to pick a PIN that they have to enter every time they log in, even when using SSO. This rather defeats the purpose of SSO, is not going to be popular, and unless the required PIN is long, really doesn't add that much security.</p>
<p>Can anyone suggest any other, better approaches to this, or let me know if I've missed something or am mistaken about anything above?</p>
<p>Update - I'm thinking of exploring using an Azure KeyVault with RBAC. Each user gets their own secret that only they and admins can access. After sign-in the user's AAD access token (the one I can use to call the Graph API, etc.) would be provided to the backend temporarily to access the Key Vault, which would be firewalled with an IP whitelist. Any feedback on this idea would be appreciated!</p>
","424678","","424678","","2023-01-31 14:53:39","2023-01-31 14:53:39","SSO Application Storing a Custom Secret in the User Profile","<security><encryption><sso>","0","9","","","","CC BY-SA 4.0"
"443873","1","443874","","2023-02-09 09:48:51","","0","177","<p>Assume you have to figure out a dynamic way where the user can provide an API call to hit in the backend
for example, user to provide a webhook to call on his end server</p>
<p>So, An idea for users to provide a CURL command in UI would be an ideal way to cover all cases such as request method types, authorization, params... etc</p>
<p>Then this CURL command gets sent to the backend and gets saved in the database for future use</p>
<p>Then when the time to use it, it gets executed with the native OS command from the Java code</p>
<p>This solution offers a very dynamic way of building a request giving the user all flexibility possible</p>
<p>But since the curl command is going to be executed from the backend against the server OS, User can simply provide some malicious script into that CURL command which can cause serious damage to the server</p>
<p>is there a way to either validate the CURL command or execute the command at a higher level than the OS</p>
","92003","","92003","","2023-02-09 10:33:12","2023-02-09 11:09:32","Is it secured to accept and execute user provided CURL commands","<design><java><architecture><security><linux>","1","1","","","","CC BY-SA 4.0"
"444353","1","444354","","2023-03-07 09:47:36","","45","6166","<p>In my company's codebase, we hardcode sql queries without using an ORM.</p>
<p>Here's an example of a query we would run:</p>
<pre><code>UPDATE client SET status=&quot;active&quot; WHERE client_id=123
</code></pre>
<p>Since the query is hardcoded and the parameters are passed in, the code would look like this (Python):</p>
<pre><code>'UPDATE client SET status=&quot;{}&quot; WHERE client_id={}'.format('active', 123)
</code></pre>
<p>The only place that the parameters are coming from is the code where they are set. There is no case where external users can pass in arguments.</p>
<p>The codebase is not large but is quite sprawling and interrelated, so sanitizing the SQL would require a legitimate reason for the time spent.</p>
<p>Therefore, is there a reason to worry about sanitizing the SQL?</p>
","427764","","","","","2023-03-08 15:12:03","SQL sanitizing in code with no user input","<security><sql><backend>","5","16","","","","CC BY-SA 4.0"
"444394","1","444401","","2023-03-08 23:57:30","","0","153","<p>To best explain my context, imagine that Iâ€™m creating an alternative piece of software to google analytics (since my personal projectâ€™s principle is similar). Each unique user creates an account and needs to place a tracking script on their website so that their website visitor actions can be tracked. Something like this in the head:</p>
<pre><code>&lt;script defer data-domain=&quot;testing.com&quot; src=â€œurl/path/to/my/website/scriptâ€œ&gt;&lt;/script&gt;
</code></pre>
<p>The script needs to make an API request to send the data to the server for processing. As the script would be on every page of every customersâ€™ sites, there would be a lot of API requests. I worry that if a customer stops paying but leaves the script on their website, it will still make API requests, hence I need a way of rejecting the API requests.</p>
<p>Iâ€™ve been reading around and am trying to figure out the best way of preventing unauthorised use of an API. Ideas that have been raised are using an auth token, API key/secret, and throttling/rate limiting, and tracking IDs for convenience. Would using an auth token be:</p>
<ol>
<li>Possible, since assume the user can place their tracking script on their site only once, and JWTs will eventually expire. Would it mean that the script would no longer work? Or could they renew their JWT?</li>
<li>Necessary, and;</li>
<li>Required in order to check whether the customer is still paying and decline the API requests if not?</li>
</ol>
<p>If it is not possible to use an auth token (since it would expire), could the request just use the website URL origin (since each user has a unique website URL), find the user associated with that account, check whether they are a paying customer and decline their API requests accordingly?</p>
<p>Are there any better approaches to this, or any suggestions that anyone has? I wonder what companies like Google etc do.</p>
<p>Presumably even rejecting API requests costs money since my server would have to respond with a 401/403 error, but presumably nothing can be done about this as the script installed on customersâ€™ sites has to have a src attribute that points to the script path on my server. This still concerns me since there could be a large amount of even declined API requests.</p>
<p>FYI, the client-side script uses javascript, my server uses node and GraphQL Apollo server for the API. I would not be able to prevent non-paying customers from removing the tracking script from their websites.</p>
<p>Thanks - any suggestions would be much appreciated.</p>
","427852","","","","","2023-03-09 11:15:19","The best way of preventing unauthorised API use and reducing costs of declining API requests","<api><security><authorization>","2","0","","","","CC BY-SA 4.0"
"444508","1","","","2023-03-15 19:28:34","","-1","52","<p>I am trying to build an IVR system that requires some form of username &amp; password/pin entry to access sensitive data. My naÃ¯ve solution seemed obvious enough, until I realized that username/pass over a keypad essentially reduces to a long string of digits (0-9) -&gt; <a href=""https://i.redd.it/5fhljsxwpzk81.png"" rel=""nofollow noreferrer"">easy to attack</a>.</p>
<p>The application is designed to be a sort of fail-safe or safety net in times of emergency, so authentication-over-the-phone is necessary. Plan B is to have the user enter their username using voice and to use the keypad to enter their pin; but I lack the security expertise to judge whether or not this workaround is safe enough for the field, <a href=""https://infocondb.org/con/def-con/def-con-19/brute-forcing-interactive-voice-response-ivr-systems"" rel=""nofollow noreferrer"">especially given all of the novel ways to brute-force interfaces these days</a>.</p>
<p>How is this typically done in production?</p>
","92090","","92090","","2023-03-15 19:52:29","2023-03-15 19:56:09","What is the best way to authenticate a user over IVR?","<security><authentication><asterisk>","1","1","","","","CC BY-SA 4.0"
"444514","1","","","2023-03-16 02:26:22","","1","99","<p>We are trying to implement an authorization and authentication service for our product.</p>
<p>Now, we would have to cater to different kinds of IAM systems like SSO, LDAP and Basic Username+Password in Database for accessing our product since we have different kinds of client applications that use either one of these security mechanisms. Each of such IAM systems would also hold the necessary authorisation roles as well in their respective formats as expected.</p>
<p>We are thinking of building an API Gateway between our clients and backend microservices, that has a pluggable security module that can cater to requests from either SSO, LDAP, Username+Password in Database based  clients to authenticate and authorise the incoming requests accordingly and issue a JWT for system-wide use within the downstream internal microservices in our backend.
Does this design approach seem reasonable for my usecase?</p>
","428012","","183832","","2023-03-16 04:25:52","2023-03-16 22:29:49","Is my security pattern correct for authenticating principal users to my microservices?","<microservices><security><authentication><authorization>","1","2","","","","CC BY-SA 4.0"
"444783","1","444784","","2023-03-30 21:48:12","","0","186","<p>Iâ€™ll try my best to explain, but for the closest context I could think of, imagine that I am building an analytics platform that allows paying users to sign up, place a tracking script on their website and track their website visitorsâ€™ data. This would mean anyone who visits their site would need to be able to make an API request (without them even necessarily knowing - done via the tracking script) to send the analytics data to the database. E.g. users may install a script in the head like this:</p>
<pre><code>&lt;script data-domain=&quot;somedomain.com&quot; src=&quot;path/to/tracking/script.js?id=SOMETHING&quot; defer&gt;&lt;/script&gt;
</code></pre>
<p>I also wouldnâ€™t want users to have to ever update this script.</p>
<p>My scenario is somewhat similar, but to summarise, I worry that anyone (e.g. a hacker) would be able to insert a load of junk data into the database (since they could make API requests that require no auth).</p>
<p>What could be done to prevent this, but not prevent the script from tracking all users? I was thinking along these lines:</p>
<ol>
<li>IP rate throttling to cap the no. of requests someone can make</li>
<li>Auth tokens send in request headers (but they expire, unless they could be updated automatically some way? From another script? But couldnâ€™t a hacker also access this anyway?)</li>
<li>Ensure that the API endpoint used by the tracking script is designed to only accept requests from the tracking script, and not directly from other sources (e.g. how? via CORS headers?)</li>
</ol>
<p>But presumably authenticating requests is not an option since it would prevent tracking everyone else.</p>
<p>I could be wrong in my assumptions here, but any ideas would be greatly appreciated. It just feels weird, since anyone would be able to insert a load of junk data into the database. It may not be the signed-up user who misuses the API, but instead a random hacker visiting their site</p>
","427852","","427852","","2023-03-30 22:07:46","2023-03-31 07:42:55","How to best protect a public API from unwanted requests","<api><security><authorization>","2","3","","","","CC BY-SA 4.0"
"444963","1","","","2023-04-11 06:18:20","","18","5291","<p>Currently, I'm involved in a research project in which we are evaluating an existing web environment providing a safe online playground for children/adolescents with intellectual disabilities. Certain areas of this web application require identification of the user to allow the content to be aligned with the user's capabilities and to prevent user impersonation. The current version is very outdated and uses a very weak username/password-like authentication mechanism, which boils more or less down to unsecured access (abuse has been detected in the past).</p>
<p>I think some kind of <a href=""https://en.wikipedia.org/wiki/Multi-factor_authentication"" rel=""noreferrer"">MFA</a>, or MFA-based approach is recommended as a replacement for the username/password solution in place. It could be interesting to have an adult, for example, a parent (when used in a home setting) or a teacher (when used at school), confirm access to the online resources on behalf of the user when the user it not able to authenticate for whatever possible reason.</p>
<p>Because some of the users have (very) limited intellectual capabilities, (more) complex mechanisms (like <a href=""https://en.wikipedia.org/wiki/One-time_pad"" rel=""noreferrer"">OTP</a>, mobile authenticator, digipass, etc.) are not always suited. Also because of the age range of the target audience (ranging between 8 and 21), we cannot assume every user has access or is allowed to use a smartphone that could be used in the authentication flow. Under such circumstances, parental approval might be a valid alternative solution.</p>
<p>Many possible approaches probably exist to implement such authentication and authorisation solution. Please feel free to share any thoughts/ideas/suggestions to setup such solution.</p>
<p>Currently, a parent or teacher (guardian) registers a child/adolescent (user) via an online registration procedure. This procedure is email based and assigns a username for the user (based on the first name, last name and date of birth), a 3-letter password (limited to the first 10 characters of the alphabet) for the user and a free text guardian password. Using the website, the guardian uses the username/guardian password to add the user account to the local browser (cookie based). When a user want to authenticate, he/she selects his/her picture/avatar and enters the 3-letter password.</p>
<p>My concerns about this approach are:</p>
<ol>
<li>Adding avatars using a browser cookie to ease future authentication with such a weak password makes authentication pointless.</li>
<li>The very limited number of user password combinations possible with 3 characters out of of a set of 10 possibilities makes it very prone to attacks.</li>
<li>I find the overall procedure somewhat confusing and not very guardian friendly.</li>
</ol>
<p>I deliberately did not explicitly mention before that the current solution is a browser based platform to keep as many possibilities open as possible. Interviewing guardians and users, we noticed a more or less even distribution among the desire for web based solutions and native mobile solutions (the latter does not exist today).</p>
","331862","","591","","2023-04-13 16:28:01","2023-05-17 08:20:17","Authentication and authorisation for people with intellectual disabilities","<security><authentication>","9","23","","","","CC BY-SA 4.0"
"445188","1","445202","","2023-04-23 17:35:46","","0","197","<p>Suppose today I'm designing a new application that will employ asymmetric cryptography to allow users to securely exchange data with one another. As far as I can tell there are no quantum-safe algorithms yet generally accepted, let alone that are ready to be used in production. (Please correct me if I'm wrong!) Thus I'm assuming I'm still looking at RSA as the gold standard. Estimates for when RSA can be cracked vary from 5 to 15 years or more. 15 years doesn't bother me too much, but 5 years does, especially for a new application.</p>
<p>So, if I'm starting from scratch, what would be considered the best practices to be as prepared as possible for a post-quantum world? And to explain what I mean by prepared, I don't simply mean ready to change algorithms, but rather to best ensure that data transmitted today won't be vulnerable in the future.</p>
<p>Two things I've considered -</p>
<ul>
<li>Using 4096-bit keys. However I don't see a consensus on whether this actually makes much of a difference even for classical attacks, let alone quantum ones.</li>
<li>Keeping public keys effectively private. My idea here is to keep even public keys within the confines of the secure application servers and unavailable to users. We would not allow clients to encrypt or verify sender signatures directly, but rather servers would hold public keys as closely as they hold their other secrets. Encrypting and verifying signatures would thus require client API calls.</li>
</ul>
<p>I'm wondering if these ideas add any genuine security value, or if not why not, and if there are other measures that experts would recommend at this time to architect a new application to be as resilient as possible to the so-called quantum apocalypse.</p>
","424678","","","","","2023-04-24 06:01:08","Best practices for a new application to be ready for post-quantum cryptography","<security><encryption>","2","2","","","","CC BY-SA 4.0"
"445580","1","","","2023-05-18 09:14:58","","2","206","<p>I have a SaaS application in which users can connect their RDBMS (postgres, mysql etc) and query data from it. I'm wondering what's the best practice to keep their connection details  safe. Currently, I'm saving them to my application db (postgres) in plain text.</p>
<p>Maybe I can encrypt them?</p>
<p>Eventually, I'd like to achieve SOC2 compliance too.</p>
","337853","","209774","","2023-05-18 11:19:04","2023-06-18 09:01:15","Keeping user provided passwords to 3rd party services safe","<database><security><passwords>","2","4","","","","CC BY-SA 4.0"
"445733","1","","","2023-05-26 13:32:07","","0","31","<p>We have an object Root, which references many other objects. Which eventually is translated into FKs on the DB level. We came up with an ACL scheme where there's a separate <code>permissions</code> table with the <code>user,resource,access_level</code>. And so we change our logic to look at this table before returning the data to the user.</p>
<p>Problem is, objects that are nested should also have the same permissions. And so there are 2 solutions that I could think of:</p>
<ol>
<li>Each nested object is written into <code>permissions</code>. Every time we update Root object, we cascade the changes to all nested ones.</li>
<li>We add <code>root_id</code> to all relevant tables (even if they are referenced through some other intermediate object). And keep checking permissions using this <code>root_id</code>.</li>
</ol>
<p>Both approaches aren't easy to implement. So I wonder maybe there are other approaches that I'm missing.</p>
","386656","","","","","2023-05-27 18:30:54","Cascading ACL to embedded objects","<database-design><security><permissions>","0","4","","","","CC BY-SA 4.0"
"445796","1","","","2023-05-30 16:24:26","","1","101","<p>An application has a multifactor login.
The user logs in with its e-mail and password, and then the following screen asks for a <em>one time password</em> received via e-mail or generated by a mobile app.</p>
<p>In that second screen there's also a link called &quot;cancel login&quot; that points to, for example <code>/login/cancel</code>. The user can click this to cancel the login process and the sessions/cookies for the process are cleaned up and you would have to start over.</p>
<p>My question is about this kind of 'action' links. Clicking it actually sends a <code>GET</code> request, but not for just displaying a page or retrieving data, but for performing an action in the application. In practice, another website could contain a link or even an image that points to the &quot;login cancel url&quot; of our application and logout unknowing users.
Simply said, a CSRF attack.</p>
<p>I use the Laravel PHP framework, and use the built-in CSRF protection for html forms. But I wonder how to implement this protection for <code>GET</code> requests properly. Would it be sufficient to add a query parameter to the url of the action link, and then manually verify the included CSRF token?
Also, I wonder if it is acceptable anyway to use links for executing an action in a web application. It works well, but a <code>GET</code> request is semantically not intended for 'saying/executing'.
One alternative is that I don't use links but a small form containg a hidden CSRF token field and a submit button that acts as (and is styled as) a link. The form is sent using a <code>POST</code> request then.
What are best practises and are there any security guidelines?</p>
","352709","","","","","2023-06-01 02:56:28","Best way to protect action links from CSRF","<php><web-development><web-applications><security><http>","2","0","","","","CC BY-SA 4.0"
"445864","1","445870","","2023-06-02 15:27:19","","-1","221","<p>I have a Delphi software application that uses non standard port nnnnn to nnnnn+50 with the FTPS protocol TLS 1.3
Until now I was suggesting my customers that the Server Side application needs to have</p>
<ol>
<li>Public Static IP</li>
<li>Physical Firewall</li>
<li>Port Forwarding</li>
<li>No sharing of any Drives/Folders</li>
<li>Machine to be used exclusively for my application</li>
</ol>
<p>I am considering relaxing the first two points by giving option of</p>
<ol>
<li>DDNS</li>
<li>Trust the Router and Windows OS Firewall</li>
</ol>
<p>Will this be safe enough as compared to my existing prerequisites ?
Will the router have to be used exclusively for my Server only or can there be other regular machines behind router ?</p>
","261521","","283352","","2023-06-07 19:48:13","2023-06-07 19:48:13","Are Physical Firewalls mandatory","<architecture><security><server-side><ssl>","2","3","","","","CC BY-SA 4.0"
"445994","1","","","2023-06-09 14:04:12","","1","159","<p>I (unfortunately) work in a large German corporation, in a department where the codebase is up to 20 years old, written in C++ (actually more like C with the occasional classes, since most developers used to be electrical engineers).
We have a requirement to adhere to certain security standards (which ones exactly I am not told).
This includes creating a new process to which the current process will connect to via TLS and make requests, so essentially a local server. Except the server can also send requests to the client, and there are also asynchronous notifications being sent.
We cannot use any existing libraries due to security concerns (with a few exceptions), so we use plain old Unix sockets and OpenSSL.
Also we use an in-house database system to store users, groups and associated rights.
I found out the DB stores everything in a single json file.
Also we have a software architect who is obsessed with encrypting everything, like there is a SecureString class which given a string encrypts it and stores that in a member variable.
The class is basically a subset of std::string, which stores the string in an encrypted manner.</p>
<p>Now the thing is I am still relatively early in my career and lack some experience, but a lot of this sounds wrong. I am just second guessing myself and wondering if I am the crazy one here, and the described stuff is actually sane.</p>
","415581","","","","","2023-06-09 15:10:12","Is it more secure to develop libraries in-house than using existing libraries?","<architecture><c++><security><sockets>","1","4","","2023-06-09 18:33:54","","CC BY-SA 4.0"
"446332","1","446333","","2023-07-03 13:07:00","","2","107","<p>As a fellow SW developer in EU, I hope that you know that there is a proposal for a new law, called <strong>Cyber Resilience Act</strong>, that will, if approved, will affect all digital products on the EU market.</p>
<p>In the proposal there is two annexes, I and II, that contains requirements on the product and the development of the product.</p>
<p>Under ANNEX I. 1.2 there is one requirement:</p>
<blockquote>
<p>Products with digital elements shall be delivered without any known
exploitable vulnerabilities;</p>
</blockquote>
<p>And under ANNEX I 2.1 there is another:</p>
<blockquote>
<p>Manufacturers of the products with digital elements shall: (1)
identify and document vulnerabilities and components contained in the
product, including by drawing up a software bill of materials in a
commonly used and machine-readable format covering at the very least
the top-level dependencies of the product;</p>
</blockquote>
<p>My question is:
Are not those two requirements contradictory?</p>
<p>Or are the second requirement meant to be for when the product is on the market?</p>
<p><em>And yes, I know that it's a proposal and are under subject for change, but for what I know any updates to the proposal has not yet been done.</em></p>
<p>More info can be found here:</p>
<p><a href=""https://ec.europa.eu/commission/presscorner/detail/en/ip_22_5374"" rel=""nofollow noreferrer"">Press release from EU</a></p>
<p><a href=""https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=celex:52022PC0454"" rel=""nofollow noreferrer"">Proposal and annexes</a></p>
","431973","","","","","2023-07-03 13:35:36","EU Cyber Resilience Act - Conflicting Requirements?","<security><development-process><requirements>","1","1","","2023-07-03 16:16:48","","CC BY-SA 4.0"
"446403","1","","","2023-07-07 02:19:40","","9","6672","<p>In software design and security, why would it <em>not</em> be a good idea for users to send you their passwords and it would be a <em>better</em> idea to delegate: use public-key auth or logging in with one of these: OpenID connect, &quot;sign in with Google&quot; or &quot;Facebook&quot;, etc.</p>
<p>I am curious to understand more about these topics.  I recently moved from a very large tech company to a much smaller one, and in my current company, they have a practice of storing user passwords in a database.  They salt and hash the passwords, but I think that trying to manage security and cryptography themselves is biting off more than they can chew.  In my research, I found this (source: Stanford University) and wondered if this community had any thoughts about the claims made here (this is a little dated...&quot;Facebook&quot; for example is mentioned, although I wondered if these recommendations are still relevant today).</p>
<p>For clarity, this is from a lecture entitled, &quot;Bad (Attitude) Guide to Computer Security&quot;.  So it is likely that the author is making these big claims with a kind of playfulness.  I'm asking the question here to better understand the actual concepts and the seriousness of the claim (along the lines of, &quot;is this a total joke that shouldn't be taken seriously at all, or is there actually a good lesson in this advice?&quot;)</p>
<blockquote>
<h3>Password hashing is bad.</h3>
<ul>
<li>Password hashing is bad because it makes you think it's okay for users to send you their passwords.</li>
<li>Users should not send you their passwords.</li>
<li>Your site security should not depend on your enforcement of a password complexity requirement.</li>
<li>You do not want a server compromise to expose anything that allows a bad guy to intercept or crack user passwords.</li>
<li><strong>Better:</strong> Delegate. Use public-key auth, or &quot;Log in with Google&quot; / &quot;Log in with Facebook&quot; / OpenID Connect.</li>
</ul>
</blockquote>
<p><sup><a href=""https://i.stack.imgur.com/WPbWH.png"" rel=""noreferrer"">Screenshot of the lecture slide</a></sup></p>
<p>Source: <a href=""https://cs144.github.io/handouts/Winstein-Bad-Attitude-Guide-8April2016.pdf"" rel=""noreferrer"">https://cs144.github.io/handouts/Winstein-Bad-Attitude-Guide-8April2016.pdf</a></p>
","188996","","113871","","2023-07-08 16:24:32","2023-07-10 19:32:22","Is Password Hashing Bad?","<security><oauth2><passwords>","8","20","","","","CC BY-SA 4.0"
"446582","1","","","2023-07-16 22:20:17","","0","55","<p>I want to build an app with a SPA (Angular) frontend and a REST API (Spring Boot) backend.<br />
I want a modern account system for this app: users log in through OpenID Connect, using either a social login like Facebook or Google or a custom account with us (achieved through the use of an OAuth authorization server like Keycloak deployed alongside the application).</p>
<p>I see two possible ways of achieving this: the SPA/client-side authorization code flow with PKCE or the REST API/server-side traditional authorization code flow. The latter seems like the most secure approach and is supported by Spring Boot's OpenID client library.</p>
<p>However, when using Spring Boot's client library, when the authentication is complete I notice that Spring starts a traditional session. I have the feeling that in modern web applications using stateless bearer token authorization headers is recommended. While traditional sessions can also be very secure and scalable, using bearer tokens does seem much more easy to maintain.</p>
<p>My question is then simply: are Spring Boot's OpenID client's defaults actually sensible? Should I override them and use bearer tokens with my client web app instead of sessions (using HTTP-only cookies or some other mechanism for my SPA to remember the authentication token and emulate sessions securely), should I stick to Spring Boot's strategy of using sessions or should I do something else entirely?</p>
<p>To me Spring Boot's defaults mainly make sense considering traditional Java EE or Spring landscapes, or to easen the migration to OpenID Connect. But I could be wrong. I'd really appreciate your thoughts on the matter.</p>
","263468","","","","","2023-07-16 22:20:17","Should we use sessions instead of bearer tokens with OpenID Connect server-side authorization code flows?","<security><oauth2><spring-boot><angular><openid>","0","1","","","","CC BY-SA 4.0"
"446637","1","","","2023-07-19 21:53:28","","1","77","<p>There are tools like dependabot or greenkeeper for npm and others for other languages. Now at first glance they improve security by keeping open source dependencies up-to-date. But I am wondering, do the benefits outweigh the risk of a hostile party taking over or sneaking in a seemingly harmless commit, which will then automatically be rolled out via the updater? How quickly such exploits are found depends on the number of users and the activity of the maintainers, so I assume the best trade-off would be to instruct the update-script to wait somewhere between 1-3 months before a version update is applied, no? I am not sure if that actually is possible with most tools, but surely a feature for versions to &quot;mature&quot; before being applied would make sense?</p>
","274703","","","","","2023-07-20 05:37:05","Are mature dependencies less risky than state of the art ones?","<security><node.js><scripting><software-updates><automatic-update>","2","0","","","","CC BY-SA 4.0"
"447145","1","","","2023-08-21 18:09:15","","1","167","<p>I recently finished an interview with a company as a web developer. I'm the first and only developer that is about to be hired in this company.</p>
<p>They have a web application that was created by a software company, and they have received the source code of the app.</p>
<p>Years went by, and now they want to refactor their web app, but this time by hiring a full time web developer that takes responsibility of anything regarding the web app.</p>
<p>I just finished the interview and everything went perfect! but here comes the problem ..</p>
<p>They wanted to test my refactoring ability, so they gave me a couple of tasks to refactor. I said that's great, send me a copy of the source code and I'll refactor the web app locally and show you all the updates I can make. but they refused for security reasons, they seem to be afraid that I might steal, hijack, or attack the web app in any shape or form by having a copy of the source code.</p>
<p>They instead wanted me to do a live refactor during an online call by accessing the IT admin's screen using a software and accessing the C panel from his computer and modify the code live inside the C panel.</p>
<p>It was pretty difficult, I explained to the IT admin that this is difficult for a variety of reasons:</p>
<p>1- I'm completely new to the code base, I need sometime to understand what's going on with the code and study it good.</p>
<p>2- Refactoring inside the C panel is difficult, I need a code editor like Visual Studio Code to easily navigate through the project and better understand what is going on.</p>
<p>But unfortunately, he refused, saying that he can't share the source code to a stranger, as I haven't signed a job agreement yet.</p>
<p>I explained to him that it's perfectly normal to share a &quot;COPY&quot; of the source code for a potential hire, as any modifications will only reflect in my local machine, and not the hosted app, they are two separate instances.</p>
<p>I'm feeling a bit overwhelmed and I'm not sure how to proceed, so I posted this question here to learn from you experts and those who had a similar experience.</p>
","433882","","131624","","2023-08-21 21:53:19","2023-08-25 11:42:38","Handling a Refactoring Project with Limited Access to Source Code","<web-development><security><refactoring><interview><source-code>","3","3","","","","CC BY-SA 4.0"
"447259","1","447260","","2023-08-27 09:53:05","","1","110","<p>I was just reading a <a href=""https://stackoverflow.com/questions/9153571/is-there-a-way-to-get-version-from-package-json-in-nodejs-code/10855054#10855054"">StackOverflow question here</a>, about extracting the version number from a node package.json file. And the simple</p>
<blockquote>
<p>'read in the json and access the property in your build tool'</p>
</blockquote>
<p>got huge number of</p>
<blockquote>
<p>'no no no you risk exposing all your dependency versions to the client'</p>
</blockquote>
<p>-type responses.</p>
<p>But I'm a bit confused when this relates to open source projects. Isn't the whole code base exposed in the repository? Package.json and all?</p>
<p><em><strong>Also</strong></em>, hasn't there been a huge push lately for - especially enterprise and security-critical software - to make available Software Bills of Materials, so the exact composition of the software is made clear, both to the end user/purchaser and for allowing for automatic checking against any emerging vulnerabilities in its dependencies?</p>
<p>So which is it?</p>
<p>And let's not forget open-source licensing requirements, that sometimes specify that you should include a copy of the dependency's license?</p>
<p>I had built an app that I was going to open source, and I had used some tools to extract out every package dependency:</p>
<ol>
<li>including all transitive dependencies</li>
<li>including all licenses where obtainable, and</li>
<li>the exact dependency version used to compile the app.</li>
</ol>
<p>I was going to make that available to the end user. A kind of SBOM in itself.</p>
<p>I thought this was the right thing to do, but now I'm not so sure. Am I inviting security exploits by being so open about the dependencies? Or is it the <em>right</em> thing to do, as long as I'm using appropriate security auditing tools and not doing anything very obviously dangerous (allowing unfiltered, un-sanitized user input for example).</p>
","330137","","","","","2023-08-28 07:58:35","Open source projects, SBOMs and security","<licensing><open-source><security><node.js><dependencies>","1","1","","","","CC BY-SA 4.0"